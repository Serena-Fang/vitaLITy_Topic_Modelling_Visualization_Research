{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Topic_Modeling.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "12755762908545f88b5d6af0364aca3a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87e6c0e88e634c4998990e9ec6216f42",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e55f144e0d314a45a18c667d3a03e2db",
              "IPY_MODEL_a8a7cf99a1494ca484ef7c2c9bec47eb",
              "IPY_MODEL_ab49618f37a04d2f89fc2f88670a26d7"
            ]
          }
        },
        "87e6c0e88e634c4998990e9ec6216f42": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e55f144e0d314a45a18c667d3a03e2db": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8c9a7683f1294991b718b742fed05019",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0356fd4ab5154b608d71261ff6a9dcd5"
          }
        },
        "a8a7cf99a1494ca484ef7c2c9bec47eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b8324dd3b3d04cd0b8575a27bd543471",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 321,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 321,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4c9ad935bd344ce9a7393e3473709f33"
          }
        },
        "ab49618f37a04d2f89fc2f88670a26d7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2aceb949d5af48d696063964abd1729f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 321/321 [00:00&lt;00:00, 9.72kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9ea4f74b4b244e85aec0d000bf378c62"
          }
        },
        "8c9a7683f1294991b718b742fed05019": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0356fd4ab5154b608d71261ff6a9dcd5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b8324dd3b3d04cd0b8575a27bd543471": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4c9ad935bd344ce9a7393e3473709f33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2aceb949d5af48d696063964abd1729f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9ea4f74b4b244e85aec0d000bf378c62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "461ff0187d76472a88cf553d0626c148": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_b4ed47e0ba1f406aa0c0bbe5df835d53",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_01d0b7ceeab848da996ae57f76979b06",
              "IPY_MODEL_ab7eab324262453ab3c4a1a72ec1c365",
              "IPY_MODEL_35fd38a008844d3483c16c3f3bab1a1d"
            ]
          }
        },
        "b4ed47e0ba1f406aa0c0bbe5df835d53": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "01d0b7ceeab848da996ae57f76979b06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4a04f8ce4ba943078225d53b63f0cbb5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_27355a4301e448728ec6f2b8a546cc2d"
          }
        },
        "ab7eab324262453ab3c4a1a72ec1c365": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c945b60ac98745e2a6d79ceb087fabb3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 612,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 612,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_964f400cd6ba4b9a9fa1f5752c96e576"
          }
        },
        "35fd38a008844d3483c16c3f3bab1a1d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_da9c43ab21b24e9ba141894c07e9be51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 612/612 [00:00&lt;00:00, 17.7kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2092783bb17940f9b7692838db75b5bf"
          }
        },
        "4a04f8ce4ba943078225d53b63f0cbb5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "27355a4301e448728ec6f2b8a546cc2d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c945b60ac98745e2a6d79ceb087fabb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "964f400cd6ba4b9a9fa1f5752c96e576": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "da9c43ab21b24e9ba141894c07e9be51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2092783bb17940f9b7692838db75b5bf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f7d8bcdd7bd444ae88c099918cb7845a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_34ff96c878d543b99957fae4fb360883",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bd95c801bf346ab8353a1d781db93e4",
              "IPY_MODEL_665e3335ae2446ecb7ceea097ac6b7c2",
              "IPY_MODEL_226afbba5ec1446ea5bc81f283cce3de"
            ]
          }
        },
        "34ff96c878d543b99957fae4fb360883": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bd95c801bf346ab8353a1d781db93e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3dfa790bcaac4d87982365f15c6c71f2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_16a4cf9020e44ef795140a6b7538efce"
          }
        },
        "665e3335ae2446ecb7ceea097ac6b7c2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_0ab35e00655441babc64e79d697788e0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 222296,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 222296,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1672547ff7834ee4b4c3956980728543"
          }
        },
        "226afbba5ec1446ea5bc81f283cce3de": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_60004d8ccbc64b2da8756e52d6740436",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 217k/217k [00:00&lt;00:00, 235kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_18da541ebde94fc8be7d7c2545c9e158"
          }
        },
        "3dfa790bcaac4d87982365f15c6c71f2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "16a4cf9020e44ef795140a6b7538efce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "0ab35e00655441babc64e79d697788e0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1672547ff7834ee4b4c3956980728543": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "60004d8ccbc64b2da8756e52d6740436": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "18da541ebde94fc8be7d7c2545c9e158": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "219e3f1810d94093b791e6ea731152cc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e93248b272f94e48868a1e35b272acf8",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_1f22bfc0853a45528c533860e7712de6",
              "IPY_MODEL_72f6af730623497086e53f6755a6f842",
              "IPY_MODEL_5a3ff6df93094d1096aca303f2710583"
            ]
          }
        },
        "e93248b272f94e48868a1e35b272acf8": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1f22bfc0853a45528c533860e7712de6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_152c1dc309b54b51ace998ce7ce3f914",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_495f7e7a92794455acad9e871acc3e76"
          }
        },
        "72f6af730623497086e53f6755a6f842": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_791850fb30e241c488ed92bf8f450353",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2b2c0a54f0fe49dcb5fc23d98d272858"
          }
        },
        "5a3ff6df93094d1096aca303f2710583": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4fa24c1d6ff0482eb250c930139d1ff5",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 4.08kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fd8a7f6bf65f40fc9504808d1376c023"
          }
        },
        "152c1dc309b54b51ace998ce7ce3f914": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "495f7e7a92794455acad9e871acc3e76": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "791850fb30e241c488ed92bf8f450353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2b2c0a54f0fe49dcb5fc23d98d272858": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4fa24c1d6ff0482eb250c930139d1ff5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fd8a7f6bf65f40fc9504808d1376c023": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d1cee1996e945ae8705e6551c824516": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_06aa1330313e4225b24533414575515f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3bf26de2ad10447c9875f5e187f53ebd",
              "IPY_MODEL_31cdabb28fae4f209666664e71b64cf0",
              "IPY_MODEL_5e28cedeee9f408498b9ab11da72999a"
            ]
          }
        },
        "06aa1330313e4225b24533414575515f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3bf26de2ad10447c9875f5e187f53ebd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_266f3c134f2e459d984c8f8c4b701397",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a719e125e514637a2b39e36afd2cf36"
          }
        },
        "31cdabb28fae4f209666664e71b64cf0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_cfa2aef9531d40818086436bb73dbe98",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 690,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 690,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_63b86c0e1687451486063ceb2a113831"
          }
        },
        "5e28cedeee9f408498b9ab11da72999a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e582ab9ccf55406981dc9af5c7669c80",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 690/690 [00:00&lt;00:00, 21.8kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a45b6b67f6aa44ac8e32d4cd58706455"
          }
        },
        "266f3c134f2e459d984c8f8c4b701397": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a719e125e514637a2b39e36afd2cf36": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "cfa2aef9531d40818086436bb73dbe98": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "63b86c0e1687451486063ceb2a113831": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e582ab9ccf55406981dc9af5c7669c80": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a45b6b67f6aa44ac8e32d4cd58706455": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ee9c127985f4eb4896e83db5b94703c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_bc23607028254a948ac2d6d01e2889f4",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_20668cbf680346ff8639270da76e27c5",
              "IPY_MODEL_e898e4a266b2499e9184f32cdfbb0b3e",
              "IPY_MODEL_9c0ef6af239941968c550d12d8cfe8e4"
            ]
          }
        },
        "bc23607028254a948ac2d6d01e2889f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "20668cbf680346ff8639270da76e27c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8b4d75d8edf841a5bb456944e6238bba",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9284b446d579477c9887ce1fe5aa5a1f"
          }
        },
        "e898e4a266b2499e9184f32cdfbb0b3e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ef2b275b32264b8382e27cdecae3b9da",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2709,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2709,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e82f51e4f46481d8d40d179c7781d35"
          }
        },
        "9c0ef6af239941968c550d12d8cfe8e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_eb264d4ee1d9442a87803960febb139b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2.71k/2.71k [00:00&lt;00:00, 71.6kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0d9bab6412014858897eb65b2dbdc064"
          }
        },
        "8b4d75d8edf841a5bb456944e6238bba": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9284b446d579477c9887ce1fe5aa5a1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ef2b275b32264b8382e27cdecae3b9da": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e82f51e4f46481d8d40d179c7781d35": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "eb264d4ee1d9442a87803960febb139b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0d9bab6412014858897eb65b2dbdc064": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92f5c6a9d0914fe69cd1f484e9269c06": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad273bacf1d049058f7876c5110f805e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5bf12977756f4c5b83db3b5a9503f2af",
              "IPY_MODEL_d6d6962f9bf84deb8bc16d4b07603227",
              "IPY_MODEL_730e3bfff7fc48648774c4e869847971"
            ]
          }
        },
        "ad273bacf1d049058f7876c5110f805e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5bf12977756f4c5b83db3b5a9503f2af": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_f89cc8f24a40437cadea0e7fc9f6902c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_fdc51cf6be574622856c18bbb484352f"
          }
        },
        "d6d6962f9bf84deb8bc16d4b07603227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f9f897eee55e453bbb2331a60a77726b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 622,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 622,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b3ac0c79e12a49f5a0474581725b4555"
          }
        },
        "730e3bfff7fc48648774c4e869847971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8f21f2b0a5e44e94af2911d5cc84a84f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 622/622 [00:00&lt;00:00, 16.5kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8879d03970334d67aba54111f490a691"
          }
        },
        "f89cc8f24a40437cadea0e7fc9f6902c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "fdc51cf6be574622856c18bbb484352f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f9f897eee55e453bbb2331a60a77726b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b3ac0c79e12a49f5a0474581725b4555": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8f21f2b0a5e44e94af2911d5cc84a84f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8879d03970334d67aba54111f490a691": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "50ade055577446279ca20db2a51bd1fa": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4a409307ee1644fda0ed6b5d29abf3d2",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_ac1d40eadddd45a68f227f04f5e1f0a4",
              "IPY_MODEL_20e5211525c34f9db1e4efe669f9ce8c",
              "IPY_MODEL_d0529e64de054fb5a388ef71826ee66d"
            ]
          }
        },
        "4a409307ee1644fda0ed6b5d29abf3d2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "ac1d40eadddd45a68f227f04f5e1f0a4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_454840f2b096416db01b6c711e72a187",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_53e9dce4afdb45989a1da6640c6986fc"
          }
        },
        "20e5211525c34f9db1e4efe669f9ce8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_32201a0cf2964dc8b7a82f02f3a7b432",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 122,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 122,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d9444ce6a17a45bfa7962a7ec0d5a5d0"
          }
        },
        "d0529e64de054fb5a388ef71826ee66d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e5cb562cf43a45d3ab1005221b863323",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 122/122 [00:00&lt;00:00, 3.72kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2f718ef7937549159b147593b7c0364b"
          }
        },
        "454840f2b096416db01b6c711e72a187": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "53e9dce4afdb45989a1da6640c6986fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "32201a0cf2964dc8b7a82f02f3a7b432": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d9444ce6a17a45bfa7962a7ec0d5a5d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5cb562cf43a45d3ab1005221b863323": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2f718ef7937549159b147593b7c0364b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "48a3a1a9d1794e738b72d652d996fd18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5b8f032990f74dd9959f21417786e89d",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_d202a58490744b7da3ee4a55540bcb3f",
              "IPY_MODEL_d500d3eb08dd441e9aad012d4871add0",
              "IPY_MODEL_1aff2450641a4d0e8d52df0d74f77b56"
            ]
          }
        },
        "5b8f032990f74dd9959f21417786e89d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d202a58490744b7da3ee4a55540bcb3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_37ae081c7bfb4e8f8e42743fb82eb50b",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_afad8516e41b4440bbe1bd3ad7f23a02"
          }
        },
        "d500d3eb08dd441e9aad012d4871add0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_470c7912e69441508e805ae152053b60",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 229,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 229,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_840a9207bf8e411f80549cefca4b1380"
          }
        },
        "1aff2450641a4d0e8d52df0d74f77b56": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_4c01fb0f7c724157befe01dec1aa7ccd",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 229/229 [00:00&lt;00:00, 7.93kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a284211d80f944c7b0df801d72e4de95"
          }
        },
        "37ae081c7bfb4e8f8e42743fb82eb50b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "afad8516e41b4440bbe1bd3ad7f23a02": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "470c7912e69441508e805ae152053b60": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "840a9207bf8e411f80549cefca4b1380": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4c01fb0f7c724157befe01dec1aa7ccd": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a284211d80f944c7b0df801d72e4de95": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "89ec04c7d86d4006b2fef84563115eff": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_87ab90329f1a4dbbb59124adcdde8047",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_7492335557c249febf6662a659adb6e3",
              "IPY_MODEL_ab352460673d47ada149ff64d1952d82",
              "IPY_MODEL_b7645b5ce15e44bebcbbbe3c42e04474"
            ]
          }
        },
        "87ab90329f1a4dbbb59124adcdde8047": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7492335557c249febf6662a659adb6e3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_21901cb1cc8d4c9c961f39860eb792bb",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d5977c52c02c4a65857bceacb6b850e4"
          }
        },
        "ab352460673d47ada149ff64d1952d82": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_799c53cc04a640cf9115b3e2951cabbe",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 439832305,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 439832305,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_f442cd76a1574b449fe0d9dbe6298f34"
          }
        },
        "b7645b5ce15e44bebcbbbe3c42e04474": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_98afbc992b0841ef8350ff988e8a0840",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 440M/440M [00:29&lt;00:00, 24.5MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_c8e0bb9c30654427a052eaa2128ec0b9"
          }
        },
        "21901cb1cc8d4c9c961f39860eb792bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d5977c52c02c4a65857bceacb6b850e4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "799c53cc04a640cf9115b3e2951cabbe": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "f442cd76a1574b449fe0d9dbe6298f34": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "98afbc992b0841ef8350ff988e8a0840": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "c8e0bb9c30654427a052eaa2128ec0b9": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5f20efbaf9c24e148cfb60d9fa5f90f5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_cb7b9a06dfe84207ac7bc576082ff0fe",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_dc5a43b5d5374d3a9636bea5ee3e6d2c",
              "IPY_MODEL_6e42b9ba7741491dabdfd54021acd1e9",
              "IPY_MODEL_12211a5cb248445cbb314d42ea17074d"
            ]
          }
        },
        "cb7b9a06dfe84207ac7bc576082ff0fe": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "dc5a43b5d5374d3a9636bea5ee3e6d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_89974ca412b2455f8621eaba293c1237",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_37bed17e94cc4eb98ae98004e1f7f095"
          }
        },
        "6e42b9ba7741491dabdfd54021acd1e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5286f69522c5418899f426adcb6e14a6",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 53,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 53,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0bfcea5c67ad4396a0793ab55735dd03"
          }
        },
        "12211a5cb248445cbb314d42ea17074d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9690538029ed4bdf8ee40300ba9e39ed",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 53.0/53.0 [00:00&lt;00:00, 1.18kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6450320a0d3e48609057d9c909ee2ef0"
          }
        },
        "89974ca412b2455f8621eaba293c1237": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "37bed17e94cc4eb98ae98004e1f7f095": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5286f69522c5418899f426adcb6e14a6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0bfcea5c67ad4396a0793ab55735dd03": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9690538029ed4bdf8ee40300ba9e39ed": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6450320a0d3e48609057d9c909ee2ef0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "321a492d2d8246cfbaa9de2949017980": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_d78e6d5bb7cf412a8ee23cbfe076e2fc",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_050a162b4f3d4d348c9dd54a1883f514",
              "IPY_MODEL_81e96ada8d434473b3ddc3a196c48f26",
              "IPY_MODEL_65f58312088440e19b6108e1b60725f1"
            ]
          }
        },
        "d78e6d5bb7cf412a8ee23cbfe076e2fc": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "050a162b4f3d4d348c9dd54a1883f514": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_77182d745bd54c2fa58fa745bfca1d2c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1a7669e13005427ab944741c9ff529ae"
          }
        },
        "81e96ada8d434473b3ddc3a196c48f26": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b5f4bd2a66ca425ca57d84c7177ea58a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d0f4272f741648fb97dca6a451bc104b"
          }
        },
        "65f58312088440e19b6108e1b60725f1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7e93bd6c7d6b4629a4b624c3dc413ea8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 3.97kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b55a400fd48a4545bd54e9e986baa13a"
          }
        },
        "77182d745bd54c2fa58fa745bfca1d2c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1a7669e13005427ab944741c9ff529ae": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b5f4bd2a66ca425ca57d84c7177ea58a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d0f4272f741648fb97dca6a451bc104b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7e93bd6c7d6b4629a4b624c3dc413ea8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b55a400fd48a4545bd54e9e986baa13a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c247d7c7a10d46da945d32e885494afb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_dea2217c8f0849b7b71f3ba49c8c13f6",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb3c95f4b9224ce894ba7bcb5b8a0f72",
              "IPY_MODEL_14c3c1d680044a809d0a4d654ae90f70",
              "IPY_MODEL_a68694e8031d46298596e7917bc7228c"
            ]
          }
        },
        "dea2217c8f0849b7b71f3ba49c8c13f6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb3c95f4b9224ce894ba7bcb5b8a0f72": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_5e748102e2b54714abc756652f870b1e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4a4362409a524fd3b5a181f715cf12a2"
          }
        },
        "14c3c1d680044a809d0a4d654ae90f70": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9d4944bca8064c0e8343d63680bd460a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 461628,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 461628,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_5cdef1e33ad94ba69ee3b5f52f78da84"
          }
        },
        "a68694e8031d46298596e7917bc7228c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_2483e30713b144f5a80a66d9bc0908f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 462k/462k [00:00&lt;00:00, 540kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3807ca6ebf534cbcaeecf2dd1ff7eb73"
          }
        },
        "5e748102e2b54714abc756652f870b1e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4a4362409a524fd3b5a181f715cf12a2": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9d4944bca8064c0e8343d63680bd460a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "5cdef1e33ad94ba69ee3b5f52f78da84": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "2483e30713b144f5a80a66d9bc0908f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3807ca6ebf534cbcaeecf2dd1ff7eb73": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "16aaa0713ca04f1db4286b006a392e55": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_75ad65a6a3ff4661aa0d006da245f31f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_6855f02cba4c40ae8bca392ffd7baa18",
              "IPY_MODEL_d5069a609cc94a6fbece55dc656e3f0a",
              "IPY_MODEL_57174fe9e3534800a4a56717c98797e5"
            ]
          }
        },
        "75ad65a6a3ff4661aa0d006da245f31f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6855f02cba4c40ae8bca392ffd7baa18": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9aac759aa7e24a2089e73cb8f2a570ce",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_bada3b0546024dcab7c20b088c8792ef"
          }
        },
        "d5069a609cc94a6fbece55dc656e3f0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_037a8247f685472891d82583811be8f3",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 331,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 331,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_20ab6f52b5bf4fcdab15e1b343ff3686"
          }
        },
        "57174fe9e3534800a4a56717c98797e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_1c358154a5d54cabb551a984d61e58ad",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 331/331 [00:00&lt;00:00, 6.37kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4cd7ee6ae0024502bad73d1547b44baf"
          }
        },
        "9aac759aa7e24a2089e73cb8f2a570ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "bada3b0546024dcab7c20b088c8792ef": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "037a8247f685472891d82583811be8f3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "20ab6f52b5bf4fcdab15e1b343ff3686": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1c358154a5d54cabb551a984d61e58ad": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4cd7ee6ae0024502bad73d1547b44baf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4cb4834451b84e5e97d3016c1acdf4fb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_57f2bd4aa5834b598a630f378585e5f1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4d59059a626b4ecdb9b92c36d0e02487",
              "IPY_MODEL_346b319926db469caa6544286def748c",
              "IPY_MODEL_bd514f5d2d2946eb9f5c4dfab7432abb"
            ]
          }
        },
        "57f2bd4aa5834b598a630f378585e5f1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4d59059a626b4ecdb9b92c36d0e02487": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7a137e04718f491f8705489fb7494325",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e0a844b3ecb64088b1ed6ceaaa4c8773"
          }
        },
        "346b319926db469caa6544286def748c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_f300b94fd04243e1ba129347089ade71",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 222296,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 222296,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1b1699bcb53d41c5b4decbad2bea8495"
          }
        },
        "bd514f5d2d2946eb9f5c4dfab7432abb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a6daf77eae464e8db4a69a509629f1e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 222k/222k [00:00&lt;00:00, 250kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ce026121a36e47a8880b4f99c51b2793"
          }
        },
        "7a137e04718f491f8705489fb7494325": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e0a844b3ecb64088b1ed6ceaaa4c8773": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f300b94fd04243e1ba129347089ade71": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1b1699bcb53d41c5b4decbad2bea8495": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a6daf77eae464e8db4a69a509629f1e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ce026121a36e47a8880b4f99c51b2793": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b64b21591962464baf1653b1c047bdde": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0a7269499ca64c2ba36d2664cc2bad9e",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_70589dc57d444fadbb09464b66c74227",
              "IPY_MODEL_9ba81f9d38f547f0a667dd57325a42c5",
              "IPY_MODEL_19b688cde7144328a5fdfd8b80e5020b"
            ]
          }
        },
        "0a7269499ca64c2ba36d2664cc2bad9e": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70589dc57d444fadbb09464b66c74227": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_dfd4f253cb41438fb44a87f2dc996209",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_d7858bc9b5d14e43af6af78c140e3c5d"
          }
        },
        "9ba81f9d38f547f0a667dd57325a42c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_73cac99f31fb403795f2828de21907e1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 190,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 190,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3a85b8acaaf44a18840c85d6343bb4f7"
          }
        },
        "19b688cde7144328a5fdfd8b80e5020b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e1eb4eff97844b34af52774bac1b530f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 190/190 [00:00&lt;00:00, 4.67kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_71e0fbe0f24e4566ac19ecbb204ba854"
          }
        },
        "dfd4f253cb41438fb44a87f2dc996209": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "d7858bc9b5d14e43af6af78c140e3c5d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "73cac99f31fb403795f2828de21907e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3a85b8acaaf44a18840c85d6343bb4f7": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e1eb4eff97844b34af52774bac1b530f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "71e0fbe0f24e4566ac19ecbb204ba854": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1b0555a2dfc94c50a9e6905325127206": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_06b4d4f829864b9487aef28f7c8283ff",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_12a85994578f48cf87744ccdd1665d0a",
              "IPY_MODEL_121cc9157aed4260955f052da3484e7e",
              "IPY_MODEL_6cea8c0d37fc4229964d3feb62ee6cc5"
            ]
          }
        },
        "06b4d4f829864b9487aef28f7c8283ff": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "12a85994578f48cf87744ccdd1665d0a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_cfed4ad164dc455880034da279c8a353",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Batches: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_af8bc99fa43c41e0975ada8bbe844b74"
          }
        },
        "121cc9157aed4260955f052da3484e7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_553db02d1e23415596a28a95a3031c96",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1851,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1851,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_027aa0444a7347cfbf2b988f1c2ed8f0"
          }
        },
        "6cea8c0d37fc4229964d3feb62ee6cc5": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_010459db35594250bef6b3be4b1baf31",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1851/1851 [07:47&lt;00:00, 14.45it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_28415e6ed5ad49c2aedb0bc9f8643a87"
          }
        },
        "cfed4ad164dc455880034da279c8a353": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "af8bc99fa43c41e0975ada8bbe844b74": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "553db02d1e23415596a28a95a3031c96": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "027aa0444a7347cfbf2b988f1c2ed8f0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "010459db35594250bef6b3be4b1baf31": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "28415e6ed5ad49c2aedb0bc9f8643a87": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kdDqzHAFY33Y"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4Yco0CLj_8xY"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T3tn9opa9bZn",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "39fc81e6-86aa-44e9-f1e1-eac0097632c2"
      },
      "source": [
        "!pip install bertopic"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting bertopic\n",
            "  Downloading bertopic-0.9.3-py2.py3-none-any.whl (57 kB)\n",
            "\u001b[K     |████████████████████████████████| 57 kB 2.3 MB/s \n",
            "\u001b[?25hCollecting hdbscan>=0.8.27\n",
            "  Downloading hdbscan-0.8.27.tar.gz (6.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 6.4 MB 7.7 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm>=4.41.1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (4.62.3)\n",
            "Collecting plotly<4.14.3,>=4.7.0\n",
            "  Downloading plotly-4.14.2-py2.py3-none-any.whl (13.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 13.2 MB 113 kB/s \n",
            "\u001b[?25hCollecting numpy>=1.20.0\n",
            "  Using cached numpy-1.21.4-cp37-cp37m-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (15.7 MB)\n",
            "Requirement already satisfied: scikit-learn>=0.22.2.post1 in /usr/local/lib/python3.7/dist-packages (from bertopic) (0.22.2.post1)\n",
            "Collecting sentence-transformers>=0.4.1\n",
            "  Downloading sentence-transformers-2.1.0.tar.gz (78 kB)\n",
            "\u001b[K     |████████████████████████████████| 78 kB 7.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyyaml<6.0 in /usr/local/lib/python3.7/dist-packages (from bertopic) (3.13)\n",
            "Requirement already satisfied: pandas>=1.1.5 in /usr/local/lib/python3.7/dist-packages (from bertopic) (1.1.5)\n",
            "Collecting umap-learn>=0.5.0\n",
            "  Downloading umap-learn-0.5.2.tar.gz (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.4 MB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (1.4.1)\n",
            "Requirement already satisfied: joblib>=1.0 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (1.1.0)\n",
            "Requirement already satisfied: cython>=0.27 in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (0.29.24)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from hdbscan>=0.8.27->bertopic) (1.15.0)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.1.5->bertopic) (2.8.2)\n",
            "Requirement already satisfied: retrying>=1.3.3 in /usr/local/lib/python3.7/dist-packages (from plotly<4.14.3,>=4.7.0->bertopic) (1.3.3)\n",
            "Collecting transformers<5.0.0,>=4.6.0\n",
            "  Downloading transformers-4.12.3-py3-none-any.whl (3.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.1 MB 57.8 MB/s \n",
            "\u001b[?25hCollecting tokenizers>=0.10.3\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 55.7 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (1.10.0+cu111)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (0.11.1+cu111)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.7/dist-packages (from sentence-transformers>=0.4.1->bertopic) (3.2.5)\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.96-cp37-cp37m-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.2 MB 72.8 MB/s \n",
            "\u001b[?25hCollecting huggingface-hub\n",
            "  Downloading huggingface_hub-0.1.2-py3-none-any.whl (59 kB)\n",
            "\u001b[K     |████████████████████████████████| 59 kB 8.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.6.0->sentence-transformers>=0.4.1->bertopic) (3.10.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.3.2)\n",
            "Collecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 71.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.23.0)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (21.2)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (4.8.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2019.12.20)\n",
            "Collecting pyyaml<6.0\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 79.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: pyparsing<3,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.4.7)\n",
            "Requirement already satisfied: numba>=0.49 in /usr/local/lib/python3.7/dist-packages (from umap-learn>=0.5.0->bertopic) (0.51.2)\n",
            "Collecting pynndescent>=0.5\n",
            "  Downloading pynndescent-0.5.5.tar.gz (1.1 MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1 MB 63.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (0.34.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from numba>=0.49->umap-learn>=0.5.0->bertopic) (57.4.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.6.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (2021.10.8)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers<5.0.0,>=4.6.0->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Requirement already satisfied: pillow!=8.3.0,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->sentence-transformers>=0.4.1->bertopic) (7.1.2)\n",
            "Building wheels for collected packages: hdbscan, sentence-transformers, umap-learn, pynndescent\n",
            "  Building wheel for hdbscan (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hdbscan: filename=hdbscan-0.8.27-cp37-cp37m-linux_x86_64.whl size=2311827 sha256=e510728486d7eeba575cf7e502937119ebc19c74548ffccd28c7ad456ae02b5d\n",
            "  Stored in directory: /root/.cache/pip/wheels/73/5f/2f/9a259b84003b84847c259779206acecabb25ab56f1506ee72b\n",
            "  Building wheel for sentence-transformers (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sentence-transformers: filename=sentence_transformers-2.1.0-py3-none-any.whl size=121000 sha256=a1aac1af837b0b2ca75ffb2ea429201a16485bd35f7d11c3b175311498fc6892\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/f0/bb/ed1add84da70092ea526466eadc2bfb197c4bcb8d4fa5f7bad\n",
            "  Building wheel for umap-learn (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for umap-learn: filename=umap_learn-0.5.2-py3-none-any.whl size=82709 sha256=a80a0d7f17448571fc2da4aab303ae984a2eb6978585fcc8e450a9432a259a42\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/1b/c6/aaf68a748122632967cef4dffef68224eb16798b6793257d82\n",
            "  Building wheel for pynndescent (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pynndescent: filename=pynndescent-0.5.5-py3-none-any.whl size=52603 sha256=348a29109a42f7a98697b505ff06e58e326738621772f40659ee76ea5e941e64\n",
            "  Stored in directory: /root/.cache/pip/wheels/af/e9/33/04db1436df0757c42fda8ea6796d7a8586e23c85fac355f476\n",
            "Successfully built hdbscan sentence-transformers umap-learn pynndescent\n",
            "Installing collected packages: numpy, pyyaml, tokenizers, sacremoses, huggingface-hub, transformers, sentencepiece, pynndescent, umap-learn, sentence-transformers, plotly, hdbscan, bertopic\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.19.5\n",
            "    Uninstalling numpy-1.19.5:\n",
            "      Successfully uninstalled numpy-1.19.5\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "  Attempting uninstall: plotly\n",
            "    Found existing installation: plotly 4.4.1\n",
            "    Uninstalling plotly-4.4.1:\n",
            "      Successfully uninstalled plotly-4.4.1\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "datascience 0.10.6 requires folium==0.2.1, but you have folium 0.8.3 which is incompatible.\n",
            "albumentations 0.1.12 requires imgaug<0.2.7,>=0.2.5, but you have imgaug 0.2.9 which is incompatible.\u001b[0m\n",
            "Successfully installed bertopic-0.9.3 hdbscan-0.8.27 huggingface-hub-0.1.2 numpy-1.21.4 plotly-4.14.2 pynndescent-0.5.5 pyyaml-5.4.1 sacremoses-0.0.46 sentence-transformers-2.1.0 sentencepiece-0.1.96 tokenizers-0.10.3 transformers-4.12.3 umap-learn-0.5.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "numpy"
                ]
              }
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fRd54Gg_gQz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "575cbd4c-b5d3-4540-c458-7f23cd079939"
      },
      "source": [
        "# Need to replace dataset with 59,000+ VitaLITy dataset\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "import json\n",
        "import pandas as pd   \n",
        "\n",
        "file = '/content/drive/My Drive/vitaLITy/VitaLITy-1.0.0-Title-Abstract.json'\n",
        "with open(file) as train_file:\n",
        "    dict_papers = json.load(train_file)\n",
        "#\n",
        "# converting json dataset from dictionary to dataframe\n",
        "df = pd.DataFrame.from_dict(dict_papers, orient='index')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oRLc3qpWCgVv",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 395
        },
        "outputId": "3e63f335-5c26-40b6-e0a3-d3ae9a0fddd0"
      },
      "source": [
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>59192</th>\n",
              "      <th>59193</th>\n",
              "      <th>59194</th>\n",
              "      <th>59195</th>\n",
              "      <th>59196</th>\n",
              "      <th>59197</th>\n",
              "      <th>59198</th>\n",
              "      <th>59199</th>\n",
              "      <th>59200</th>\n",
              "      <th>59201</th>\n",
              "      <th>59202</th>\n",
              "      <th>59203</th>\n",
              "      <th>59204</th>\n",
              "      <th>59205</th>\n",
              "      <th>59206</th>\n",
              "      <th>59207</th>\n",
              "      <th>59208</th>\n",
              "      <th>59209</th>\n",
              "      <th>59210</th>\n",
              "      <th>59211</th>\n",
              "      <th>59212</th>\n",
              "      <th>59213</th>\n",
              "      <th>59214</th>\n",
              "      <th>59215</th>\n",
              "      <th>59216</th>\n",
              "      <th>59217</th>\n",
              "      <th>59218</th>\n",
              "      <th>59219</th>\n",
              "      <th>59220</th>\n",
              "      <th>59221</th>\n",
              "      <th>59222</th>\n",
              "      <th>59223</th>\n",
              "      <th>59224</th>\n",
              "      <th>59225</th>\n",
              "      <th>59226</th>\n",
              "      <th>59227</th>\n",
              "      <th>59228</th>\n",
              "      <th>59229</th>\n",
              "      <th>59230</th>\n",
              "      <th>59231</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Title</th>\n",
              "      <td>Evaluating Information Visualizations.</td>\n",
              "      <td>Theoretical Foundations of Information Visuali...</td>\n",
              "      <td>Phoneme exchange in, serial-position effect on...</td>\n",
              "      <td>Tracking the Response Dynamics of Implicit Par...</td>\n",
              "      <td>The Value of Information Visualization.</td>\n",
              "      <td>Creation and Collaboration: Engaging New Audie...</td>\n",
              "      <td>Eye movement-based probabilistic models for ph...</td>\n",
              "      <td>Language dominance modulates cross-language le...</td>\n",
              "      <td>Process and Pitfalls in Writing Information Vi...</td>\n",
              "      <td>Black Dialect Activates Violent Stereotypes.</td>\n",
              "      <td>Categorical perception of spatial relations ac...</td>\n",
              "      <td>Teaching Information Visualization.</td>\n",
              "      <td>An Empirical Evaluation of Models for How Peop...</td>\n",
              "      <td>Movements and Visuospatial Working Memory: Exa...</td>\n",
              "      <td>Visual Analytics: Definition, Process, and Cha...</td>\n",
              "      <td>Hierarchical Models of Individuals Engaged in ...</td>\n",
              "      <td>Does the anticipation of a partner's reaction ...</td>\n",
              "      <td>The Attentional Blink is Modulated by First Ta...</td>\n",
              "      <td>The Distinction Between Unaccusative and Unerg...</td>\n",
              "      <td>Transductionally Bounded Hierarchical Systems.</td>\n",
              "      <td>Differences between Observation and Interventi...</td>\n",
              "      <td>How Sharp is Occam's Razor? Language Statistic...</td>\n",
              "      <td>Gricean epistemic reasoning in 4-year-olds.</td>\n",
              "      <td>Is it Possible to Train the Approximate Number...</td>\n",
              "      <td>The Importance of Explanations in Guided Scien...</td>\n",
              "      <td>Developmental See-Saws: Ordered visual input i...</td>\n",
              "      <td>Knowledge tracing and cue contrast: Second lan...</td>\n",
              "      <td>One-shot learning of generative speech concepts.</td>\n",
              "      <td>Quantifying linguistic coordination.</td>\n",
              "      <td>Memory is Deceiving: a Typical Size Induces th...</td>\n",
              "      <td>A Cognitive Model of Fraction Arithmetic.</td>\n",
              "      <td>The Bouba Effect: Sound-Shape Iconicity in Ite...</td>\n",
              "      <td>The Concept of Transcendent God and the Emerge...</td>\n",
              "      <td>Incorporating Social Psychological Theories in...</td>\n",
              "      <td>Limits on the Use of Simulation in Physical Re...</td>\n",
              "      <td>A Hierarchical Bayesian Model of Individual Di...</td>\n",
              "      <td>Emergence: A Proposal for a Foundational Revol...</td>\n",
              "      <td>Adaptive uses of random criterion: The largest...</td>\n",
              "      <td>Learning Deterministic Causal Networks from Ob...</td>\n",
              "      <td>P3 as a neural index of response inhibition.</td>\n",
              "      <td>...</td>\n",
              "      <td>Box Sort, a multidimensional binary sorting me...</td>\n",
              "      <td>Estimation of Kinect depth confidence through ...</td>\n",
              "      <td>Interactive continuous collision detection for...</td>\n",
              "      <td>Spatial consistency of dense features within i...</td>\n",
              "      <td>Atoms to astronomy: Computer graphics at the J...</td>\n",
              "      <td>Components of the visual computer: a review of...</td>\n",
              "      <td>Seamless patches for GPU-based terrain rendering.</td>\n",
              "      <td>Robust tracking via monocular active vision fo...</td>\n",
              "      <td>Markov-type velocity field for efficiently ani...</td>\n",
              "      <td>EEG correlates of video game experience and us...</td>\n",
              "      <td>Real-time geometric deformation displacement m...</td>\n",
              "      <td>Learning semantic dependencies with channel co...</td>\n",
              "      <td>GPU-based point radiation for interactive volu...</td>\n",
              "      <td>Point-wise saliency detection on 3D point clou...</td>\n",
              "      <td>Extension of the Nicholls-Lee-Nichols algorith...</td>\n",
              "      <td>View synthesis with 3D object segmentation-bas...</td>\n",
              "      <td>Conic-like subdivision curves on surfaces.</td>\n",
              "      <td>SUSAN structure preserving filtering for mesh ...</td>\n",
              "      <td>Recent advances in facial soft biometrics.</td>\n",
              "      <td>A variational model for normal computation of ...</td>\n",
              "      <td>Surface skinning revisited.</td>\n",
              "      <td>Facial expression recognition algorithm based ...</td>\n",
              "      <td>Real-time EEG-based emotion monitoring using s...</td>\n",
              "      <td>Precise rendering method for exact anti-aliasi...</td>\n",
              "      <td>Sense and sidedness in the graphics pipeline v...</td>\n",
              "      <td>Feature correspondences using Morse Smale comp...</td>\n",
              "      <td>Interactive design of 3D models with geometric...</td>\n",
              "      <td>Real-time accumulation of occlusion-based snow.</td>\n",
              "      <td>Modeling fruits and their internal structure u...</td>\n",
              "      <td>Point-and-edge model for edge-preserving splat...</td>\n",
              "      <td>Non-rigid 3D object retrieval using topologica...</td>\n",
              "      <td>Video-graphic query facility for database retr...</td>\n",
              "      <td>Controlling shapes of air bubbles in a multi-p...</td>\n",
              "      <td>Audio-visual object removal in 360-degree videos.</td>\n",
              "      <td>Parametric editing of clothed 3D avatars.</td>\n",
              "      <td>Inverse lighting and photorealistic rendering ...</td>\n",
              "      <td>Automatic alignment for virtual fitting using ...</td>\n",
              "      <td>The Attraction Effect in Information Visualiza...</td>\n",
              "      <td>A Task-Based Taxonomy of Cognitive Biases for ...</td>\n",
              "      <td>Mitigating the Attraction Effect with Visualiz...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>Abstract</th>\n",
              "      <td>Information visualization research is becoming...</td>\n",
              "      <td>The field of Information Visualization, being ...</td>\n",
              "      <td>Serial-order control is a fundamental aspect o...</td>\n",
              "      <td>Despite widespread political conspiracy theori...</td>\n",
              "      <td>Researchers and users of Information Visualiza...</td>\n",
              "      <td>In recent years we have seen information visua...</td>\n",
              "      <td>Humans make prediction about physical environm...</td>\n",
              "      <td>Languages differ in the way they package eleme...</td>\n",
              "      <td>The goal of this chapter is to help authors re...</td>\n",
              "      <td>After viewing Black males faces, US participan...</td>\n",
              "      <td>Cross-language differences in spatial language...</td>\n",
              "      <td>Teaching InfoVis is a challenge because it is ...</td>\n",
              "      <td>We propose simple parameter-free models that p...</td>\n",
              "      <td>Previous studies have shown that, under specif...</td>\n",
              "      <td>We are living in a world which faces a rapidly...</td>\n",
              "      <td>Our ability to learn statistically regular pat...</td>\n",
              "      <td>Actions in joint tasks are affected by the way...</td>\n",
              "      <td>When two targets (T1 &amp; T2) are presented in ra...</td>\n",
              "      <td>The Unaccusativity Hypothesis (UH) holds that ...</td>\n",
              "      <td>Using a hierarchical-systems analysis, this pa...</td>\n",
              "      <td>Previous studies have suggested that learning ...</td>\n",
              "      <td>According to the dominant view in cognitive sc...</td>\n",
              "      <td>Recent experimental evidence suggests that adu...</td>\n",
              "      <td>Humans are believed to be equipped with an App...</td>\n",
              "      <td>This study examined whether embedding explanat...</td>\n",
              "      <td>The first two years of life are characterized ...</td>\n",
              "      <td>This paper introduces a cognitive tutor design...</td>\n",
              "      <td>One-shot learning -- the human ability to lear...</td>\n",
              "      <td>Language has been defined as a social coordina...</td>\n",
              "      <td>Grounded cognition theories state that concept...</td>\n",
              "      <td>Learning about fractions is a critical step on...</td>\n",
              "      <td>Although wordforms are often arbitrarily linke...</td>\n",
              "      <td>The author addresses the emergence of cognitiv...</td>\n",
              "      <td>Social psychology aims to reveal how social be...</td>\n",
              "      <td>In this paper, we describe three experiments i...</td>\n",
              "      <td>When participants view and then reproduce simp...</td>\n",
              "      <td>Emergence has been a fundamental part of physi...</td>\n",
              "      <td>Many cognitive processes appear to incorporate...</td>\n",
              "      <td>Previous work suggests that humans find it dif...</td>\n",
              "      <td>This study aimed to identify which ERP are spe...</td>\n",
              "      <td>...</td>\n",
              "      <td>In many geometrical applications data needs to...</td>\n",
              "      <td>All depth data captured by Kinect devices are ...</td>\n",
              "      <td>We present a highly interactive, continuous co...</td>\n",
              "      <td>Recently, feature grouping has been proposed a...</td>\n",
              "      <td>Within the Jet Propulsion Laboratory in Pasade...</td>\n",
              "      <td>Visual computing emhpasizes visibility of info...</td>\n",
              "      <td>In this paper we present a novel approach for ...</td>\n",
              "      <td>The research of this paper investigates a prac...</td>\n",
              "      <td>In computer graphics, one of the most challeng...</td>\n",
              "      <td>Through the use of brain–computer interfaces (...</td>\n",
              "      <td>Striving for photorealism, texture mapping, an...</td>\n",
              "      <td>Multi-label image classification is a fundamen...</td>\n",
              "      <td>Internal structures, features, and properties ...</td>\n",
              "      <td>In the human visual system, visual saliency pe...</td>\n",
              "      <td>A new algorithm for clipping a line segment ag...</td>\n",
              "      <td>Numerous depth image-based rendering algorithm...</td>\n",
              "      <td>In this paper, we introduce a novel nonlinear ...</td>\n",
              "      <td>Motivated by the impressive effect of the SUSA...</td>\n",
              "      <td>Face as a biometric attribute has been extensi...</td>\n",
              "      <td>In this paper we present a novel model for com...</td>\n",
              "      <td>Surface skinning is a powerful tool that allow...</td>\n",
              "      <td>In view of the high dimensionality, nonrigidit...</td>\n",
              "      <td>In human–computer interaction (HCI), electroen...</td>\n",
              "      <td>This paper introduces the Precise Rendering Me...</td>\n",
              "      <td>Computer graphics is ostensibly based on proje...</td>\n",
              "      <td>Establishing corresponding features on two non...</td>\n",
              "      <td>In this paper, an interactive graphical approa...</td>\n",
              "      <td>This paper describes a technique to allow the ...</td>\n",
              "      <td>Modeling a fruit using classic 3D modeling sof...</td>\n",
              "      <td>We introduce the point-and-edge model for edge...</td>\n",
              "      <td>Combining the properties of conformal geometry...</td>\n",
              "      <td>The goal of this project was to develop a prot...</td>\n",
              "      <td>Controlling shapes is a challenging problem in...</td>\n",
              "      <td>We present a novel concept audio–visual object...</td>\n",
              "      <td>Easy editing of a clothed 3D human avatar is c...</td>\n",
              "      <td>We present a practical and robust photorealist...</td>\n",
              "      <td>In recent years, researches on virtual fitting...</td>\n",
              "      <td>The attraction effect is a well-studied cognit...</td>\n",
              "      <td>Information visualization designers strive to ...</td>\n",
              "      <td>Human decisions are prone to biases, and this ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ID</th>\n",
              "      <td>5</td>\n",
              "      <td>2</td>\n",
              "      <td>17</td>\n",
              "      <td>11</td>\n",
              "      <td>3</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>15</td>\n",
              "      <td>4</td>\n",
              "      <td>12</td>\n",
              "      <td>14</td>\n",
              "      <td>6</td>\n",
              "      <td>10</td>\n",
              "      <td>13</td>\n",
              "      <td>0</td>\n",
              "      <td>9</td>\n",
              "      <td>16</td>\n",
              "      <td>8</td>\n",
              "      <td>27</td>\n",
              "      <td>40</td>\n",
              "      <td>48</td>\n",
              "      <td>39</td>\n",
              "      <td>22</td>\n",
              "      <td>45</td>\n",
              "      <td>33</td>\n",
              "      <td>24</td>\n",
              "      <td>28</td>\n",
              "      <td>29</td>\n",
              "      <td>46</td>\n",
              "      <td>23</td>\n",
              "      <td>18</td>\n",
              "      <td>30</td>\n",
              "      <td>31</td>\n",
              "      <td>32</td>\n",
              "      <td>35</td>\n",
              "      <td>41</td>\n",
              "      <td>87</td>\n",
              "      <td>75</td>\n",
              "      <td>63</td>\n",
              "      <td>88</td>\n",
              "      <td>...</td>\n",
              "      <td>59435</td>\n",
              "      <td>59467</td>\n",
              "      <td>59487</td>\n",
              "      <td>59471</td>\n",
              "      <td>59476</td>\n",
              "      <td>59351</td>\n",
              "      <td>59332</td>\n",
              "      <td>59337</td>\n",
              "      <td>59298</td>\n",
              "      <td>59325</td>\n",
              "      <td>59395</td>\n",
              "      <td>59475</td>\n",
              "      <td>59477</td>\n",
              "      <td>59338</td>\n",
              "      <td>59319</td>\n",
              "      <td>59382</td>\n",
              "      <td>59356</td>\n",
              "      <td>59346</td>\n",
              "      <td>59456</td>\n",
              "      <td>59428</td>\n",
              "      <td>59410</td>\n",
              "      <td>59388</td>\n",
              "      <td>59457</td>\n",
              "      <td>59434</td>\n",
              "      <td>59397</td>\n",
              "      <td>59459</td>\n",
              "      <td>59490</td>\n",
              "      <td>59486</td>\n",
              "      <td>59496</td>\n",
              "      <td>59305</td>\n",
              "      <td>59365</td>\n",
              "      <td>59344</td>\n",
              "      <td>59313</td>\n",
              "      <td>59429</td>\n",
              "      <td>59415</td>\n",
              "      <td>59400</td>\n",
              "      <td>59417</td>\n",
              "      <td>59502</td>\n",
              "      <td>59503</td>\n",
              "      <td>59504</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3 rows × 59232 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                          0  ...                                              59231\n",
              "Title                Evaluating Information Visualizations.  ...  Mitigating the Attraction Effect with Visualiz...\n",
              "Abstract  Information visualization research is becoming...  ...  Human decisions are prone to biases, and this ...\n",
              "ID                                                        5  ...                                              59504\n",
              "\n",
              "[3 rows x 59232 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JStBFGrTDRs6",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "7458365e-ddaa-4da3-f491-b256292c24f6"
      },
      "source": [
        "df = df.transpose()\n",
        "df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Abstract</th>\n",
              "      <th>ID</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Evaluating Information Visualizations.</td>\n",
              "      <td>Information visualization research is becoming...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Theoretical Foundations of Information Visuali...</td>\n",
              "      <td>The field of Information Visualization, being ...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Phoneme exchange in, serial-position effect on...</td>\n",
              "      <td>Serial-order control is a fundamental aspect o...</td>\n",
              "      <td>17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Tracking the Response Dynamics of Implicit Par...</td>\n",
              "      <td>Despite widespread political conspiracy theori...</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>The Value of Information Visualization.</td>\n",
              "      <td>Researchers and users of Information Visualiza...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...  ID\n",
              "0             Evaluating Information Visualizations.  ...   5\n",
              "1  Theoretical Foundations of Information Visuali...  ...   2\n",
              "2  Phoneme exchange in, serial-position effect on...  ...  17\n",
              "3  Tracking the Response Dynamics of Implicit Par...  ...  11\n",
              "4            The Value of Information Visualization.  ...   3\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YDItrezPE144",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d066eb72-7c74-4f25-e9e0-09e86f4de3c9"
      },
      "source": [
        "df.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(59232, 3)"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "26euPQhAGYqf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "34fa43ae-b5a9-4bae-aaf5-42257b2c16a1"
      },
      "source": [
        "abstracts = [_ for _ in df['Abstract'] if not _ == \"\"]\n",
        "abstracts[0:5]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Information visualization research is becoming more established, and as a result, it is becoming increasingly important that research in this field is validated. With the general increase in information visualization research there has also been an increase, albeit disproportionately small, in the amount of empirical work directly focused on information visualization. The purpose of this chapter is to increase awareness of empirical research in general, of its relationship to information visualization in particular; to emphasize its importance; and to encourage thoughtful application of a greater variety of evaluative research methodologies in information visualization.',\n",
              " 'The field of Information Visualization, being related to many other diverse disciplines (for example, engineering, graphics, statistical modeling) suffers from not being based on a clear underlying theory. The absence of a framework for Information Visualization makes the significance of achievements in this area difficult to describe, validate and defend. Drawing on theories within associated disciplines, three different approaches to theoretical foundations of Information Visualization are presented here: data-centric predictive theory, information theory, and scientific modeling. Definitions from linguistic theory are used to provide an over-arching framework for these three approaches.',\n",
              " 'Serial-order control is a fundamental aspect of speech processing, and analyses of speech errors provide clues to the mechanisms that control this phenomenon. The present study employed a speech-error induction technique to identify speech errors that strongly resembled recall errors observed in verbal immediate serial recall. In three experiments, participants repeatedly produced a target word/nonword and, immediately before the utterance, were unexpectedly exposed to an auditory distractor word/nonword, which was either phonologically similar or dissimilar to the target. This technique successfully induced within-word phoneme exchange/transposition errors and elicited a within-word serial-position effect. On the other hand, lexical/semantic variables (e.g., lexicality of the target) led to only a very weak effect. We discussed mechanisms for the retention and production of a phoneme sequence in the context of these results.',\n",
              " 'Despite widespread political conspiracy theories about Presidents Barack Obama and George W. Bush, a majority of partisans continue to distance themselves from such beliefs. Even so, the ideological biases that drive conspiratorial thinking may be hard to overcome. In this study, we examine the unintentional endorsement of conspiratorial beliefs as revealed in movement dynamics. We track the cursor movements of Republicans and Democrats as they click target regions on their computer screens, ostensibly providing bias-free opinions (e.g., clicking “FALSE” upon reading “Barack Obama was born in Kenya”). However, during these response movements, we find inhibition and movement attraction to regions of the screen where a competitor response is located (e.g., “TRUE” for the “birther” conspiracy). These dynamics are not present for general conspiracies or political knowledge items. Though both Republicans and Democrats show evidence of implicit biases, changes in the strength of competition also reveal key asymmetrical differences.',\n",
              " 'Researchers and users of Information Visualization are convinced that it has value. This value can easily be communicated to others in a face-to-face setting, such that this value is experienced in practice. To convince broader audiences, and also, to understand the intrinsic qualities of visualization is more difficult, however. In this paper we consider information visualization from different points of view, and gather arguments to explain the value of our field.']"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9fF6jPCvDZ73",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74cc5783-2bce-4bf1-c2de-520ad7fc2279"
      },
      "source": [
        "papers_dict = (df[['Title','Abstract']]\n",
        "  .rename(columns={\"Title\": \"title\", \"Abstract\": \"abstract\"})\n",
        "  .to_dict(orient='records'))\n",
        "\n",
        "papers_dict[1]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'abstract': 'The field of Information Visualization, being related to many other diverse disciplines (for example, engineering, graphics, statistical modeling) suffers from not being based on a clear underlying theory. The absence of a framework for Information Visualization makes the significance of achievements in this area difficult to describe, validate and defend. Drawing on theories within associated disciplines, three different approaches to theoretical foundations of Information Visualization are presented here: data-centric predictive theory, information theory, and scientific modeling. Definitions from linguistic theory are used to provide an over-arching framework for these three approaches.',\n",
              " 'title': 'Theoretical Foundations of Information Visualization.'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWylRNxkI7S7"
      },
      "source": [
        "!pip install sentence_transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iq-0PZyrJjzh"
      },
      "source": [
        "!pip install bertopic "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rze1yNIHJf8x"
      },
      "source": [
        "from bertopic import BERTopic"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rFp7lsDWDaFG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 583,
          "referenced_widgets": [
            "12755762908545f88b5d6af0364aca3a",
            "87e6c0e88e634c4998990e9ec6216f42",
            "e55f144e0d314a45a18c667d3a03e2db",
            "a8a7cf99a1494ca484ef7c2c9bec47eb",
            "ab49618f37a04d2f89fc2f88670a26d7",
            "8c9a7683f1294991b718b742fed05019",
            "0356fd4ab5154b608d71261ff6a9dcd5",
            "b8324dd3b3d04cd0b8575a27bd543471",
            "4c9ad935bd344ce9a7393e3473709f33",
            "2aceb949d5af48d696063964abd1729f",
            "9ea4f74b4b244e85aec0d000bf378c62",
            "461ff0187d76472a88cf553d0626c148",
            "b4ed47e0ba1f406aa0c0bbe5df835d53",
            "01d0b7ceeab848da996ae57f76979b06",
            "ab7eab324262453ab3c4a1a72ec1c365",
            "35fd38a008844d3483c16c3f3bab1a1d",
            "4a04f8ce4ba943078225d53b63f0cbb5",
            "27355a4301e448728ec6f2b8a546cc2d",
            "c945b60ac98745e2a6d79ceb087fabb3",
            "964f400cd6ba4b9a9fa1f5752c96e576",
            "da9c43ab21b24e9ba141894c07e9be51",
            "2092783bb17940f9b7692838db75b5bf",
            "f7d8bcdd7bd444ae88c099918cb7845a",
            "34ff96c878d543b99957fae4fb360883",
            "3bd95c801bf346ab8353a1d781db93e4",
            "665e3335ae2446ecb7ceea097ac6b7c2",
            "226afbba5ec1446ea5bc81f283cce3de",
            "3dfa790bcaac4d87982365f15c6c71f2",
            "16a4cf9020e44ef795140a6b7538efce",
            "0ab35e00655441babc64e79d697788e0",
            "1672547ff7834ee4b4c3956980728543",
            "60004d8ccbc64b2da8756e52d6740436",
            "18da541ebde94fc8be7d7c2545c9e158",
            "219e3f1810d94093b791e6ea731152cc",
            "e93248b272f94e48868a1e35b272acf8",
            "1f22bfc0853a45528c533860e7712de6",
            "72f6af730623497086e53f6755a6f842",
            "5a3ff6df93094d1096aca303f2710583",
            "152c1dc309b54b51ace998ce7ce3f914",
            "495f7e7a92794455acad9e871acc3e76",
            "791850fb30e241c488ed92bf8f450353",
            "2b2c0a54f0fe49dcb5fc23d98d272858",
            "4fa24c1d6ff0482eb250c930139d1ff5",
            "fd8a7f6bf65f40fc9504808d1376c023",
            "9d1cee1996e945ae8705e6551c824516",
            "06aa1330313e4225b24533414575515f",
            "3bf26de2ad10447c9875f5e187f53ebd",
            "31cdabb28fae4f209666664e71b64cf0",
            "5e28cedeee9f408498b9ab11da72999a",
            "266f3c134f2e459d984c8f8c4b701397",
            "0a719e125e514637a2b39e36afd2cf36",
            "cfa2aef9531d40818086436bb73dbe98",
            "63b86c0e1687451486063ceb2a113831",
            "e582ab9ccf55406981dc9af5c7669c80",
            "a45b6b67f6aa44ac8e32d4cd58706455",
            "3ee9c127985f4eb4896e83db5b94703c",
            "bc23607028254a948ac2d6d01e2889f4",
            "20668cbf680346ff8639270da76e27c5",
            "e898e4a266b2499e9184f32cdfbb0b3e",
            "9c0ef6af239941968c550d12d8cfe8e4",
            "8b4d75d8edf841a5bb456944e6238bba",
            "9284b446d579477c9887ce1fe5aa5a1f",
            "ef2b275b32264b8382e27cdecae3b9da",
            "0e82f51e4f46481d8d40d179c7781d35",
            "eb264d4ee1d9442a87803960febb139b",
            "0d9bab6412014858897eb65b2dbdc064",
            "92f5c6a9d0914fe69cd1f484e9269c06",
            "ad273bacf1d049058f7876c5110f805e",
            "5bf12977756f4c5b83db3b5a9503f2af",
            "d6d6962f9bf84deb8bc16d4b07603227",
            "730e3bfff7fc48648774c4e869847971",
            "f89cc8f24a40437cadea0e7fc9f6902c",
            "fdc51cf6be574622856c18bbb484352f",
            "f9f897eee55e453bbb2331a60a77726b",
            "b3ac0c79e12a49f5a0474581725b4555",
            "8f21f2b0a5e44e94af2911d5cc84a84f",
            "8879d03970334d67aba54111f490a691",
            "50ade055577446279ca20db2a51bd1fa",
            "4a409307ee1644fda0ed6b5d29abf3d2",
            "ac1d40eadddd45a68f227f04f5e1f0a4",
            "20e5211525c34f9db1e4efe669f9ce8c",
            "d0529e64de054fb5a388ef71826ee66d",
            "454840f2b096416db01b6c711e72a187",
            "53e9dce4afdb45989a1da6640c6986fc",
            "32201a0cf2964dc8b7a82f02f3a7b432",
            "d9444ce6a17a45bfa7962a7ec0d5a5d0",
            "e5cb562cf43a45d3ab1005221b863323",
            "2f718ef7937549159b147593b7c0364b",
            "48a3a1a9d1794e738b72d652d996fd18",
            "5b8f032990f74dd9959f21417786e89d",
            "d202a58490744b7da3ee4a55540bcb3f",
            "d500d3eb08dd441e9aad012d4871add0",
            "1aff2450641a4d0e8d52df0d74f77b56",
            "37ae081c7bfb4e8f8e42743fb82eb50b",
            "afad8516e41b4440bbe1bd3ad7f23a02",
            "470c7912e69441508e805ae152053b60",
            "840a9207bf8e411f80549cefca4b1380",
            "4c01fb0f7c724157befe01dec1aa7ccd",
            "a284211d80f944c7b0df801d72e4de95",
            "89ec04c7d86d4006b2fef84563115eff",
            "87ab90329f1a4dbbb59124adcdde8047",
            "7492335557c249febf6662a659adb6e3",
            "ab352460673d47ada149ff64d1952d82",
            "b7645b5ce15e44bebcbbbe3c42e04474",
            "21901cb1cc8d4c9c961f39860eb792bb",
            "d5977c52c02c4a65857bceacb6b850e4",
            "799c53cc04a640cf9115b3e2951cabbe",
            "f442cd76a1574b449fe0d9dbe6298f34",
            "98afbc992b0841ef8350ff988e8a0840",
            "c8e0bb9c30654427a052eaa2128ec0b9",
            "5f20efbaf9c24e148cfb60d9fa5f90f5",
            "cb7b9a06dfe84207ac7bc576082ff0fe",
            "dc5a43b5d5374d3a9636bea5ee3e6d2c",
            "6e42b9ba7741491dabdfd54021acd1e9",
            "12211a5cb248445cbb314d42ea17074d",
            "89974ca412b2455f8621eaba293c1237",
            "37bed17e94cc4eb98ae98004e1f7f095",
            "5286f69522c5418899f426adcb6e14a6",
            "0bfcea5c67ad4396a0793ab55735dd03",
            "9690538029ed4bdf8ee40300ba9e39ed",
            "6450320a0d3e48609057d9c909ee2ef0",
            "321a492d2d8246cfbaa9de2949017980",
            "d78e6d5bb7cf412a8ee23cbfe076e2fc",
            "050a162b4f3d4d348c9dd54a1883f514",
            "81e96ada8d434473b3ddc3a196c48f26",
            "65f58312088440e19b6108e1b60725f1",
            "77182d745bd54c2fa58fa745bfca1d2c",
            "1a7669e13005427ab944741c9ff529ae",
            "b5f4bd2a66ca425ca57d84c7177ea58a",
            "d0f4272f741648fb97dca6a451bc104b",
            "7e93bd6c7d6b4629a4b624c3dc413ea8",
            "b55a400fd48a4545bd54e9e986baa13a",
            "c247d7c7a10d46da945d32e885494afb",
            "dea2217c8f0849b7b71f3ba49c8c13f6",
            "bb3c95f4b9224ce894ba7bcb5b8a0f72",
            "14c3c1d680044a809d0a4d654ae90f70",
            "a68694e8031d46298596e7917bc7228c",
            "5e748102e2b54714abc756652f870b1e",
            "4a4362409a524fd3b5a181f715cf12a2",
            "9d4944bca8064c0e8343d63680bd460a",
            "5cdef1e33ad94ba69ee3b5f52f78da84",
            "2483e30713b144f5a80a66d9bc0908f3",
            "3807ca6ebf534cbcaeecf2dd1ff7eb73",
            "16aaa0713ca04f1db4286b006a392e55",
            "75ad65a6a3ff4661aa0d006da245f31f",
            "6855f02cba4c40ae8bca392ffd7baa18",
            "d5069a609cc94a6fbece55dc656e3f0a",
            "57174fe9e3534800a4a56717c98797e5",
            "9aac759aa7e24a2089e73cb8f2a570ce",
            "bada3b0546024dcab7c20b088c8792ef",
            "037a8247f685472891d82583811be8f3",
            "20ab6f52b5bf4fcdab15e1b343ff3686",
            "1c358154a5d54cabb551a984d61e58ad",
            "4cd7ee6ae0024502bad73d1547b44baf",
            "4cb4834451b84e5e97d3016c1acdf4fb",
            "57f2bd4aa5834b598a630f378585e5f1",
            "4d59059a626b4ecdb9b92c36d0e02487",
            "346b319926db469caa6544286def748c",
            "bd514f5d2d2946eb9f5c4dfab7432abb",
            "7a137e04718f491f8705489fb7494325",
            "e0a844b3ecb64088b1ed6ceaaa4c8773",
            "f300b94fd04243e1ba129347089ade71",
            "1b1699bcb53d41c5b4decbad2bea8495",
            "a6daf77eae464e8db4a69a509629f1e1",
            "ce026121a36e47a8880b4f99c51b2793",
            "b64b21591962464baf1653b1c047bdde",
            "0a7269499ca64c2ba36d2664cc2bad9e",
            "70589dc57d444fadbb09464b66c74227",
            "9ba81f9d38f547f0a667dd57325a42c5",
            "19b688cde7144328a5fdfd8b80e5020b",
            "dfd4f253cb41438fb44a87f2dc996209",
            "d7858bc9b5d14e43af6af78c140e3c5d",
            "73cac99f31fb403795f2828de21907e1",
            "3a85b8acaaf44a18840c85d6343bb4f7",
            "e1eb4eff97844b34af52774bac1b530f",
            "71e0fbe0f24e4566ac19ecbb204ba854"
          ]
        },
        "outputId": "ffd37a34-8b39-4feb-fa00-bdf65041e9d2"
      },
      "source": [
        "from sentence_transformers import SentenceTransformer\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('allenai/specter')\n",
        "\n",
        "# concatenate title and abstract\n",
        "title_abs = [d['title'] + '[SEP]' + (d.get('abstract') or '') for d in papers_dict]\n",
        "\n",
        "sentence_model = SentenceTransformer('sentence-transformers/allenai-specter', device=\"cuda\")\n",
        "topic_model = BERTopic(embedding_model=sentence_model).fit(title_abs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "12755762908545f88b5d6af0364aca3a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/321 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "461ff0187d76472a88cf553d0626c148",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/612 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f7d8bcdd7bd444ae88c099918cb7845a",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/217k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "219e3f1810d94093b791e6ea731152cc",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "9d1cee1996e945ae8705e6551c824516",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/690 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3ee9c127985f4eb4896e83db5b94703c",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/2.71k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "92f5c6a9d0914fe69cd1f484e9269c06",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/622 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "50ade055577446279ca20db2a51bd1fa",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/122 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "48a3a1a9d1794e738b72d652d996fd18",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/229 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "89ec04c7d86d4006b2fef84563115eff",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "5f20efbaf9c24e148cfb60d9fa5f90f5",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/53.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "321a492d2d8246cfbaa9de2949017980",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c247d7c7a10d46da945d32e885494afb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/462k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "16aaa0713ca04f1db4286b006a392e55",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/331 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4cb4834451b84e5e97d3016c1acdf4fb",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/222k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b64b21591962464baf1653b1c047bdde",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/190 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/numba/np/ufunc/parallel.py:363: NumbaWarning: The TBB threading layer requires TBB version 2019.5 or later i.e., TBB_INTERFACE_VERSION >= 11005. Found TBB_INTERFACE_VERSION = 9107. The TBB threading layer is disabled.\n",
            "  warnings.warn(problem)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bPyux-vKDaHk",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "eec7a55a-c855-4c9c-d12e-fc7938a93418"
      },
      "source": [
        "topic_model.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>29758</td>\n",
              "      <td>-1_mobile_digital_web_view</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>880</td>\n",
              "      <td>0_language_linguistic_lexical_verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>571</td>\n",
              "      <td>1_flow_vortex_vortices_velocimetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>484</td>\n",
              "      <td>2_database_query_join_queries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>463</td>\n",
              "      <td>3_gaze_eye_tracking_eyes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>567</td>\n",
              "      <td>10</td>\n",
              "      <td>567_menu_menus_designs_items</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>566</td>\n",
              "      <td>10</td>\n",
              "      <td>566_drug_adverse_drugs_drugpathseeker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>565</td>\n",
              "      <td>10</td>\n",
              "      <td>565_shading_buffer_aliasing_accumulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>569</td>\n",
              "      <td>10</td>\n",
              "      <td>569_isosurface_ptot_octree_spt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>575</td>\n",
              "      <td>10</td>\n",
              "      <td>575_programmers_instructional_conversational_c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>577 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count                                               Name\n",
              "0       -1  29758                         -1_mobile_digital_web_view\n",
              "1        0    880                 0_language_linguistic_lexical_verb\n",
              "2        1    571                 1_flow_vortex_vortices_velocimetry\n",
              "3        2    484                      2_database_query_join_queries\n",
              "4        3    463                           3_gaze_eye_tracking_eyes\n",
              "..     ...    ...                                                ...\n",
              "555    567     10                       567_menu_menus_designs_items\n",
              "554    566     10              566_drug_adverse_drugs_drugpathseeker\n",
              "553    565     10           565_shading_buffer_aliasing_accumulation\n",
              "552    569     10                     569_isosurface_ptot_octree_spt\n",
              "576    575     10  575_programmers_instructional_conversational_c...\n",
              "\n",
              "[577 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "id": "W70UkDG6kged",
        "outputId": "b9b1e853-e72e-4e3e-bf60-e39af7b1c5cd"
      },
      "source": [
        "topic_model.get_topic_freq()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>29758</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>880</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>463</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>567</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>566</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>565</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>569</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>576</th>\n",
              "      <td>575</td>\n",
              "      <td>10</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>577 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count\n",
              "0       -1  29758\n",
              "1        0    880\n",
              "2        1    571\n",
              "3        2    484\n",
              "4        3    463\n",
              "..     ...    ...\n",
              "555    567     10\n",
              "554    566     10\n",
              "553    565     10\n",
              "552    569     10\n",
              "576    575     10\n",
              "\n",
              "[577 rows x 2 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfyZGCBKhbGQ"
      },
      "source": [
        "BERTopic().save(\"topic_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myRs3CyRDaKD",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "1b0555a2dfc94c50a9e6905325127206",
            "06b4d4f829864b9487aef28f7c8283ff",
            "12a85994578f48cf87744ccdd1665d0a",
            "121cc9157aed4260955f052da3484e7e",
            "6cea8c0d37fc4229964d3feb62ee6cc5",
            "cfed4ad164dc455880034da279c8a353",
            "af8bc99fa43c41e0975ada8bbe844b74",
            "553db02d1e23415596a28a95a3031c96",
            "027aa0444a7347cfbf2b988f1c2ed8f0",
            "010459db35594250bef6b3be4b1baf31",
            "28415e6ed5ad49c2aedb0bc9f8643a87"
          ]
        },
        "outputId": "6f873219-95bc-48e9-83ef-7c874b50c711"
      },
      "source": [
        "## Get SPECTER embeddings -- ideally use CUDA/GPU\n",
        "embeddings = sentence_model.encode(title_abs, show_progress_bar=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b0555a2dfc94c50a9e6905325127206",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Batches:   0%|          | 0/1851 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kdW6JqHqDaMV"
      },
      "source": [
        "topics, probs = topic_model.fit_transform(title_abs, embeddings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kea4mkcwxfVL"
      },
      "source": [
        "pd.set_option('display.max_columns', None)\n",
        "pd.set_option('display.max_rows', None)\n",
        "pd.set_option('display.max_colwidth', None)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "UZ6dFhN2xhq7",
        "outputId": "49a33241-bf02-446f-99c0-b135e789600e"
      },
      "source": [
        "topic_model.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>29650</td>\n",
              "      <td>-1_digital_mobile_rendering_touch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>693</td>\n",
              "      <td>0_query_database_queries_schema</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>658</td>\n",
              "      <td>1_graphics_graphic_raster_standards</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>598</td>\n",
              "      <td>2_flow_vortex_vortices_velocimetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>440</td>\n",
              "      <td>3_multidimensional_dimensional_scatterplots_plots</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>433</td>\n",
              "      <td>4_gaze_eye_movements_pointing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>396</td>\n",
              "      <td>5_animation_motion_motions_locomotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>368</td>\n",
              "      <td>6_frequent_itemsets_mining_association</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>359</td>\n",
              "      <td>7_haptic_tactile_vibrotactile_haptics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>342</td>\n",
              "      <td>8_graphs_layout_graph_link</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>340</td>\n",
              "      <td>9_ray_rays_traversal_casting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>336</td>\n",
              "      <td>10_fabrication_printing_manufacturing_printers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>310</td>\n",
              "      <td>11_illumination_light_photon_radiance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>275</td>\n",
              "      <td>12_recommendation_recommender_factorization_ratings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>238</td>\n",
              "      <td>13_series_subsequence_shapelets_sequences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>221</td>\n",
              "      <td>14_category_categorization_categories_exemplars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>217</td>\n",
              "      <td>15_robot_robots_robotic_robotics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>215</td>\n",
              "      <td>16_collaboration_groupware_collaborative_developers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>214</td>\n",
              "      <td>17_crowdsourcing_workers_crowd_worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18</td>\n",
              "      <td>211</td>\n",
              "      <td>18_game_games_players_player</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19</td>\n",
              "      <td>204</td>\n",
              "      <td>19_rehabilitation_exercise_exergames_exertion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>201</td>\n",
              "      <td>20_transaction_transactions_concurrency_commit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21</td>\n",
              "      <td>199</td>\n",
              "      <td>21_gpu_splatting_rendering_meshes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>195</td>\n",
              "      <td>22_driving_driver_vehicle_drivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23</td>\n",
              "      <td>195</td>\n",
              "      <td>23_usability_testing_evaluation_evaluators</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24</td>\n",
              "      <td>188</td>\n",
              "      <td>24_pragmatic_verb_verbs_syntactic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>25</td>\n",
              "      <td>184</td>\n",
              "      <td>25_keyboard_keyboards_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>181</td>\n",
              "      <td>26_diagrams_diagrammatic_logic_reasoning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>178</td>\n",
              "      <td>27_trajectories_trajectory_spatio_city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>28</td>\n",
              "      <td>176</td>\n",
              "      <td>28_infovis_visualizations_heuristics_studies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29</td>\n",
              "      <td>167</td>\n",
              "      <td>29_texture_textures_synthesis_texturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>165</td>\n",
              "      <td>30_reconstruction_surface_mesh_meshes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>31</td>\n",
              "      <td>165</td>\n",
              "      <td>31_symbolic_magnitude_numbers_arithmetic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>32</td>\n",
              "      <td>154</td>\n",
              "      <td>32_label_unlabeled_instance_supervised</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>33</td>\n",
              "      <td>141</td>\n",
              "      <td>33_mobility_trajectory_urban_location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>34</td>\n",
              "      <td>139</td>\n",
              "      <td>34_displays_navigation_display_magnification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>35</td>\n",
              "      <td>138</td>\n",
              "      <td>35_fluid_fluids_particle_particles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>36</td>\n",
              "      <td>138</td>\n",
              "      <td>36_causal_causation_counterfactual_explanations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>37</td>\n",
              "      <td>134</td>\n",
              "      <td>37_spline_splines_interpolation_surfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38</td>\n",
              "      <td>134</td>\n",
              "      <td>38_smart_things_homes_households</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>39</td>\n",
              "      <td>134</td>\n",
              "      <td>39_vessel_ultrasound_vessels_vascular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>40</td>\n",
              "      <td>133</td>\n",
              "      <td>40_ethical_practitioners_researchers_research</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>41</td>\n",
              "      <td>132</td>\n",
              "      <td>41_privacy_private_anonymity_anonymization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>42</td>\n",
              "      <td>132</td>\n",
              "      <td>42_crowd_crowds_pedestrians_pedestrian</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>130</td>\n",
              "      <td>43_lidar_road_driving_vehicles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>44</td>\n",
              "      <td>130</td>\n",
              "      <td>44_color_colors_palettes_palette</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>45</td>\n",
              "      <td>128</td>\n",
              "      <td>45_shadow_shadows_light_shadowing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>46</td>\n",
              "      <td>125</td>\n",
              "      <td>46_deformable_contact_elastic_fracture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>47</td>\n",
              "      <td>125</td>\n",
              "      <td>47_gesture_gestures_gestural_touch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>48</td>\n",
              "      <td>125</td>\n",
              "      <td>48_gesture_gestures_sign_iconicity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>49</td>\n",
              "      <td>123</td>\n",
              "      <td>49_twitter_tweets_media_rumors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50</td>\n",
              "      <td>123</td>\n",
              "      <td>50_interfaces_accessibility_interface_adaptation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>51</td>\n",
              "      <td>122</td>\n",
              "      <td>51_molecular_molecules_atoms_proteins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>52</td>\n",
              "      <td>121</td>\n",
              "      <td>52_series_chronoview_trend_analysts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>53</td>\n",
              "      <td>120</td>\n",
              "      <td>53_wikipedia_communities_newcomers_contributors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>54</td>\n",
              "      <td>120</td>\n",
              "      <td>54_voice_speech_voicemail_voices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>55</td>\n",
              "      <td>118</td>\n",
              "      <td>55_clustering_clusterings_clusters_cluster</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>56</td>\n",
              "      <td>117</td>\n",
              "      <td>56_touch_finger_fingers_hand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>57</td>\n",
              "      <td>117</td>\n",
              "      <td>57_gene_genome_genomic_pathways</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>58</td>\n",
              "      <td>116</td>\n",
              "      <td>58_topic_documents_topics_texts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>59</td>\n",
              "      <td>114</td>\n",
              "      <td>59_solid_solids_boundary_geometric</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>60</td>\n",
              "      <td>112</td>\n",
              "      <td>60_fabrication_textile_printing_stretchable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61</td>\n",
              "      <td>107</td>\n",
              "      <td>61_search_web_searching_seeking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>62</td>\n",
              "      <td>106</td>\n",
              "      <td>62_consumption_electricity_heating_households</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63</td>\n",
              "      <td>106</td>\n",
              "      <td>63_programmers_developers_mashups_reuse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>64</td>\n",
              "      <td>102</td>\n",
              "      <td>64_urban_buildings_building_city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>65</td>\n",
              "      <td>100</td>\n",
              "      <td>65_speech_phonetic_spoken_phonological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>66</td>\n",
              "      <td>99</td>\n",
              "      <td>66_illumination_camera_cameras_defocus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>67</td>\n",
              "      <td>98</td>\n",
              "      <td>67_xml_xquery_xpath_twig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>68</td>\n",
              "      <td>98</td>\n",
              "      <td>68_activity_activities_sensors_sensor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>69</td>\n",
              "      <td>97</td>\n",
              "      <td>69_students_achievement_metacognitive_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>70</td>\n",
              "      <td>96</td>\n",
              "      <td>70_classification_categorization_spam_classifier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>71</td>\n",
              "      <td>94</td>\n",
              "      <td>71_extraction_web_template_wrapper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>72</td>\n",
              "      <td>94</td>\n",
              "      <td>72_facebook_privacy_friends_social</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>73</td>\n",
              "      <td>93</td>\n",
              "      <td>73_tutoring_tutors_student_courses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>74</td>\n",
              "      <td>91</td>\n",
              "      <td>74_scientific_parallel_distributed_grid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>75</td>\n",
              "      <td>89</td>\n",
              "      <td>75_art_artist_digital_artists</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>76</td>\n",
              "      <td>86</td>\n",
              "      <td>76_fractal_fractals_chaos_terrain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>77</td>\n",
              "      <td>86</td>\n",
              "      <td>77_reality_vr_mixed_mr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>78</td>\n",
              "      <td>86</td>\n",
              "      <td>78_attention_search_target_attentional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>79</td>\n",
              "      <td>86</td>\n",
              "      <td>79_ensemble_weather_climate_ensembles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>80</td>\n",
              "      <td>85</td>\n",
              "      <td>80_machine_deep_automl_explanations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>81</td>\n",
              "      <td>84</td>\n",
              "      <td>81_story_narrative_video_stories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>82</td>\n",
              "      <td>84</td>\n",
              "      <td>82_choice_risky_decision_choices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>83</td>\n",
              "      <td>83</td>\n",
              "      <td>83_brain_physiological_emotion_emotional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>84</td>\n",
              "      <td>83</td>\n",
              "      <td>84_classroom_teachers_education_classrooms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>85</td>\n",
              "      <td>82</td>\n",
              "      <td>85_impaired_visually_sighted_accessibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>87</td>\n",
              "      <td>81</td>\n",
              "      <td>87_moral_dilemmas_morality_morally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>86</td>\n",
              "      <td>81</td>\n",
              "      <td>86_subdivision_interpolatory_meshes_interpolating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>89</td>\n",
              "      <td>81</td>\n",
              "      <td>89_correspondence_isometric_correspondences_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>88</td>\n",
              "      <td>81</td>\n",
              "      <td>88_segmentation_watershed_superpixel_foresting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>90</td>\n",
              "      <td>80</td>\n",
              "      <td>90_walking_locomotion_virtual_flying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>91</td>\n",
              "      <td>79</td>\n",
              "      <td>91_classifiers_class_ensemble_imbalance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>92</td>\n",
              "      <td>79</td>\n",
              "      <td>92_mesh_polygonal_meshes_collapse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>93</td>\n",
              "      <td>79</td>\n",
              "      <td>93_passwords_password_authentication_surfing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>94</td>\n",
              "      <td>78</td>\n",
              "      <td>94_interruptions_interruption_interruptibility_interrupted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>95</td>\n",
              "      <td>78</td>\n",
              "      <td>95_volume_volumetric_opacity_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>96</td>\n",
              "      <td>77</td>\n",
              "      <td>96_heritage_archaeological_museum_exhibitions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>97</td>\n",
              "      <td>77</td>\n",
              "      <td>97_video_videos_frames_browsing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>98</td>\n",
              "      <td>75</td>\n",
              "      <td>98_compression_meshes_mesh_coding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>99</td>\n",
              "      <td>75</td>\n",
              "      <td>99_influence_marketing_spread_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>100</td>\n",
              "      <td>75</td>\n",
              "      <td>100_facial_face_animation_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>101</td>\n",
              "      <td>74</td>\n",
              "      <td>101_deblurring_denoising_inpainting_resolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>103</td>\n",
              "      <td>72</td>\n",
              "      <td>103_email_emails_folders_webmail</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>102</td>\n",
              "      <td>72</td>\n",
              "      <td>102_retrieval_images_image_similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>105</td>\n",
              "      <td>72</td>\n",
              "      <td>105_community_communities_networks_modularity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>104</td>\n",
              "      <td>72</td>\n",
              "      <td>104_outlier_outliers_anomaly_distance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>106</td>\n",
              "      <td>71</td>\n",
              "      <td>106_diffusion_tensor_tracts_tractography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>107</td>\n",
              "      <td>71</td>\n",
              "      <td>107_metaphors_metaphor_metaphorical_adjective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>108</td>\n",
              "      <td>70</td>\n",
              "      <td>108_twitter_sentiment_tweets_microblog</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>109</td>\n",
              "      <td>69</td>\n",
              "      <td>109_advertising_bid_bidding_advertisers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>110</td>\n",
              "      <td>68</td>\n",
              "      <td>110_brdf_reflectance_brdfs_materials</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>111</td>\n",
              "      <td>68</td>\n",
              "      <td>111_sports_soccer_tennis_player</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>112</td>\n",
              "      <td>67</td>\n",
              "      <td>112_conversational_dialogue_agents_agent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>115</td>\n",
              "      <td>67</td>\n",
              "      <td>115_spiking_neural_neurons_synaptic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>116</td>\n",
              "      <td>67</td>\n",
              "      <td>116_analogical_analogy_analogies_relational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>113</td>\n",
              "      <td>67</td>\n",
              "      <td>113_security_cyber_intrusion_traffic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>114</td>\n",
              "      <td>67</td>\n",
              "      <td>114_clothing_clothes_aesthetic_garments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>117</td>\n",
              "      <td>66</td>\n",
              "      <td>117_precipitation_climate_agriculture_agricultural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>118</td>\n",
              "      <td>65</td>\n",
              "      <td>118_augmented_reality_prototyping_protoar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>119</td>\n",
              "      <td>65</td>\n",
              "      <td>119_customer_marketing_customers_sales</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>120</td>\n",
              "      <td>65</td>\n",
              "      <td>120_drift_ensemble_drifting_classifiers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>122</td>\n",
              "      <td>64</td>\n",
              "      <td>122_video_recognition_videos_descriptor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>123</td>\n",
              "      <td>64</td>\n",
              "      <td>123_narrative_story_stories_storytelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>121</td>\n",
              "      <td>64</td>\n",
              "      <td>121_dynamic_graphs_graph_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>124</td>\n",
              "      <td>63</td>\n",
              "      <td>124_sentence_comprehension_verb_gaze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>125</td>\n",
              "      <td>63</td>\n",
              "      <td>125_surgery_surgical_endoscopy_laparoscopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>126</td>\n",
              "      <td>63</td>\n",
              "      <td>126_compiler_cache_multiprocessors_processors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>127</td>\n",
              "      <td>62</td>\n",
              "      <td>127_web_personalization_usage_pskip</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>62</td>\n",
              "      <td>128_landmarks_wayfinding_navigation_landmark</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>129</td>\n",
              "      <td>61</td>\n",
              "      <td>129_event_events_records_sentinel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>130</td>\n",
              "      <td>61</td>\n",
              "      <td>130_word_situational_words_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>131</td>\n",
              "      <td>60</td>\n",
              "      <td>131_museum_museums_visitors_heritage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>132</td>\n",
              "      <td>60</td>\n",
              "      <td>132_aneurysm_aneurysms_vessel_rupture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>133</td>\n",
              "      <td>60</td>\n",
              "      <td>133_flow_unsteady_particles_particle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>134</td>\n",
              "      <td>59</td>\n",
              "      <td>134_trauma_hospital_care_nurses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>135</td>\n",
              "      <td>58</td>\n",
              "      <td>135_wavelet_wavelets_multiresolution_subdivision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>136</td>\n",
              "      <td>58</td>\n",
              "      <td>136_video_couples_chat_sharing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>139</td>\n",
              "      <td>57</td>\n",
              "      <td>139_pointing_endpoint_movement_moving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>137</td>\n",
              "      <td>57</td>\n",
              "      <td>137_creativity_creative_ideas_idea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>138</td>\n",
              "      <td>57</td>\n",
              "      <td>138_dialogue_interlocutors_miscommunication_syntactic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>140</td>\n",
              "      <td>56</td>\n",
              "      <td>140_descriptors_descriptor_shape_signature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>141</td>\n",
              "      <td>55</td>\n",
              "      <td>141_entity_entities_named_disambiguation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>142</td>\n",
              "      <td>55</td>\n",
              "      <td>142_join_spatial_queries_joins</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>143</td>\n",
              "      <td>54</td>\n",
              "      <td>143_coordination_interpersonal_synchrony_partner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>144</td>\n",
              "      <td>53</td>\n",
              "      <td>144_music_musical_songs_song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>145</td>\n",
              "      <td>53</td>\n",
              "      <td>145_nearest_neighbor_hashing_similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>146</td>\n",
              "      <td>52</td>\n",
              "      <td>146_collision_collisions_deformable_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>147</td>\n",
              "      <td>51</td>\n",
              "      <td>147_flow_texture_unsteady_streamlines</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>148</td>\n",
              "      <td>51</td>\n",
              "      <td>148_topic_topics_dirichlet_documents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>149</td>\n",
              "      <td>51</td>\n",
              "      <td>149_software_code_developers_source</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>150</td>\n",
              "      <td>51</td>\n",
              "      <td>150_courses_teaching_education_curriculum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>154</td>\n",
              "      <td>50</td>\n",
              "      <td>154_analytics_business_vast_big</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>151</td>\n",
              "      <td>50</td>\n",
              "      <td>151_civic_civics_citizens_infrastructure</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>152</td>\n",
              "      <td>50</td>\n",
              "      <td>152_tracking_tracker_trackers_occlusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>155</td>\n",
              "      <td>50</td>\n",
              "      <td>155_tabletop_collaboration_groupware_touch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>153</td>\n",
              "      <td>50</td>\n",
              "      <td>153_plant_trees_plants_leaves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>156</td>\n",
              "      <td>49</td>\n",
              "      <td>156_verb_noun_syntactic_inflection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>157</td>\n",
              "      <td>48</td>\n",
              "      <td>157_musical_music_melodic_musicians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>158</td>\n",
              "      <td>48</td>\n",
              "      <td>158_visflow_datasplash_visdb_visualizations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>159</td>\n",
              "      <td>48</td>\n",
              "      <td>159_papers_symposium_pacific_pacificvis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>160</td>\n",
              "      <td>48</td>\n",
              "      <td>160_memory_associative_episodic_items</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>161</td>\n",
              "      <td>48</td>\n",
              "      <td>161_linguistic_language_languages_variation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>162</td>\n",
              "      <td>48</td>\n",
              "      <td>162_route_map_layout_wayfinding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>163</td>\n",
              "      <td>47</td>\n",
              "      <td>163_children_child_participatory_ethical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>164</td>\n",
              "      <td>47</td>\n",
              "      <td>164_diabetes_health_patients_care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>165</td>\n",
              "      <td>47</td>\n",
              "      <td>165_vehicle_vehicles_planning_road</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>166</td>\n",
              "      <td>47</td>\n",
              "      <td>166_painting_paintings_painterly_artistic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>167</td>\n",
              "      <td>47</td>\n",
              "      <td>167_subspace_clusters_subspaces_clustering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>172</td>\n",
              "      <td>46</td>\n",
              "      <td>172_sound_acoustic_propagation_listener</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>169</td>\n",
              "      <td>46</td>\n",
              "      <td>169_parents_parenting_life_caregivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>168</td>\n",
              "      <td>46</td>\n",
              "      <td>168_sketch_sketching_sketches_sketched</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>171</td>\n",
              "      <td>46</td>\n",
              "      <td>171_mesh_smoothing_filtering_anisotropic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>170</td>\n",
              "      <td>46</td>\n",
              "      <td>170_sketching_sketches_sketch_sketchify</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>173</td>\n",
              "      <td>45</td>\n",
              "      <td>173_diagrams_diagrammatic_uml_diagram</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>174</td>\n",
              "      <td>45</td>\n",
              "      <td>174_terrain_terrains_rendering_quadtree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>175</td>\n",
              "      <td>45</td>\n",
              "      <td>175_matrix_factorization_norm_convex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>176</td>\n",
              "      <td>45</td>\n",
              "      <td>176_papers_conference_issue_journal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>177</td>\n",
              "      <td>45</td>\n",
              "      <td>177_optical_displays_mounted_display</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>180</td>\n",
              "      <td>44</td>\n",
              "      <td>180_demand_avoidance_cognitive_adaptivity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>178</td>\n",
              "      <td>44</td>\n",
              "      <td>178_recommendation_location_friends_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>179</td>\n",
              "      <td>44</td>\n",
              "      <td>179_morphing_deformation_shape_deformations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>181</td>\n",
              "      <td>43</td>\n",
              "      <td>181_sensecam_memories_reminiscence_lifelogging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>182</td>\n",
              "      <td>43</td>\n",
              "      <td>182_musical_music_musicians_creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>183</td>\n",
              "      <td>43</td>\n",
              "      <td>183_chatbot_chatbots_chat_conversational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>184</td>\n",
              "      <td>43</td>\n",
              "      <td>184_distributed_convergence_parallel_stochastic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>185</td>\n",
              "      <td>43</td>\n",
              "      <td>185_reachability_subgraph_graphs_graph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>186</td>\n",
              "      <td>43</td>\n",
              "      <td>186_autism_autistic_therapy_intervention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>189</td>\n",
              "      <td>42</td>\n",
              "      <td>189_cognition_cognitive_mind_enactivism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>187</td>\n",
              "      <td>42</td>\n",
              "      <td>187_video_videos_news_browsing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>191</td>\n",
              "      <td>42</td>\n",
              "      <td>191_discovery_databases_knowledge_mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>188</td>\n",
              "      <td>42</td>\n",
              "      <td>188_crowdsensing_privacy_obfuscation_crowdsourcing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>190</td>\n",
              "      <td>42</td>\n",
              "      <td>190_graph_gnns_convolutional_graphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>192</td>\n",
              "      <td>41</td>\n",
              "      <td>192_game_games_players_pokémon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>193</td>\n",
              "      <td>41</td>\n",
              "      <td>193_biometric_face_fingerprint_facial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>194</td>\n",
              "      <td>41</td>\n",
              "      <td>194_column_columns_stores_columnar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>195</td>\n",
              "      <td>41</td>\n",
              "      <td>195_collaborative_collaboration_analysts_team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>196</td>\n",
              "      <td>41</td>\n",
              "      <td>196_museum_visitors_heritage_museums</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>197</td>\n",
              "      <td>40</td>\n",
              "      <td>197_transportation_travel_location_places</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>198</td>\n",
              "      <td>40</td>\n",
              "      <td>198_wrist_finger_forearm_sensors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>199</td>\n",
              "      <td>40</td>\n",
              "      <td>199_traffic_prediction_travel_temporal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>200</td>\n",
              "      <td>40</td>\n",
              "      <td>200_privacy_apps_app_smartphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>201</td>\n",
              "      <td>40</td>\n",
              "      <td>201_diagrams_diagram_diagrammatic_teachers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>208</td>\n",
              "      <td>39</td>\n",
              "      <td>208_ontology_ontologies_rdf_semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>203</td>\n",
              "      <td>39</td>\n",
              "      <td>203_cultural_psychological_attributions_normative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>204</td>\n",
              "      <td>39</td>\n",
              "      <td>204_fire_flame_flakes_vorticity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>202</td>\n",
              "      <td>39</td>\n",
              "      <td>202_graph_graphs_partitioning_subgraph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>206</td>\n",
              "      <td>39</td>\n",
              "      <td>206_vortex_vortices_flow_unsteady</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>207</td>\n",
              "      <td>39</td>\n",
              "      <td>207_motion_pose_tracking_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>205</td>\n",
              "      <td>39</td>\n",
              "      <td>205_kernel_discriminant_subspace_discriminative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>212</td>\n",
              "      <td>38</td>\n",
              "      <td>212_feature_selection_subset_features</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>211</td>\n",
              "      <td>38</td>\n",
              "      <td>211_indoor_localization_positioning_location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>210</td>\n",
              "      <td>38</td>\n",
              "      <td>210_occlusion_culling_visibility_occluders</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>213</td>\n",
              "      <td>38</td>\n",
              "      <td>213_skinning_skeleton_deformation_animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>209</td>\n",
              "      <td>38</td>\n",
              "      <td>209_archaeological_heritage_immersive_archaeology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>215</td>\n",
              "      <td>38</td>\n",
              "      <td>215_gesture_recognition_gestures_sign</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>214</td>\n",
              "      <td>38</td>\n",
              "      <td>214_embedding_network_networks_heterogeneous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>216</td>\n",
              "      <td>37</td>\n",
              "      <td>216_cleaning_repairing_constraints_conformance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>217</td>\n",
              "      <td>37</td>\n",
              "      <td>217_aware_context_campus_hospital</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>218</td>\n",
              "      <td>37</td>\n",
              "      <td>218_dementia_care_wellbeing_participatory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>219</td>\n",
              "      <td>37</td>\n",
              "      <td>219_tracking_camera_pose_registration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>220</td>\n",
              "      <td>37</td>\n",
              "      <td>220_ubicomp_ubiquitous_activitydesigner_awarecon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>221</td>\n",
              "      <td>37</td>\n",
              "      <td>221_dance_dancers_dancer_choreographers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>226</td>\n",
              "      <td>36</td>\n",
              "      <td>226_students_course_educational_courses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>222</td>\n",
              "      <td>36</td>\n",
              "      <td>222_touch_visualizations_touchpivot_wimp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>223</td>\n",
              "      <td>36</td>\n",
              "      <td>223_clipping_polygon_segments_drawing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>224</td>\n",
              "      <td>36</td>\n",
              "      <td>224_parallel_rendering_mpk_parallelism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>225</td>\n",
              "      <td>36</td>\n",
              "      <td>225_matting_video_camera_depth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>228</td>\n",
              "      <td>36</td>\n",
              "      <td>228_health_communities_patients_online</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>229</td>\n",
              "      <td>36</td>\n",
              "      <td>229_insight_solving_hint_metacognitive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>230</td>\n",
              "      <td>36</td>\n",
              "      <td>230_immersive_reality_visualizations_virtual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>231</td>\n",
              "      <td>36</td>\n",
              "      <td>231_skeleton_skeletons_skeletonization_shapes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>227</td>\n",
              "      <td>36</td>\n",
              "      <td>227_browser_web_browsing_pages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>232</td>\n",
              "      <td>35</td>\n",
              "      <td>232_neurons_neuronal_confocal_brain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>233</td>\n",
              "      <td>35</td>\n",
              "      <td>233_spreadsheet_spreadsheets_formulas_uncertainty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>234</td>\n",
              "      <td>35</td>\n",
              "      <td>234_projector_camera_calibration_projection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>235</td>\n",
              "      <td>35</td>\n",
              "      <td>235_graph_graphs_kernel_classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>241</td>\n",
              "      <td>34</td>\n",
              "      <td>241_desktop_paste_windowscape_copy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>236</td>\n",
              "      <td>34</td>\n",
              "      <td>236_uims_interface_wimp_interfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>238</td>\n",
              "      <td>34</td>\n",
              "      <td>238_privacy_consent_policies_protection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>237</td>\n",
              "      <td>34</td>\n",
              "      <td>237_topological_topology_points_piecewise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>240</td>\n",
              "      <td>34</td>\n",
              "      <td>240_streamline_streamlines_seeding_flow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>242</td>\n",
              "      <td>34</td>\n",
              "      <td>242_spatial_linguistic_languages_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>239</td>\n",
              "      <td>34</td>\n",
              "      <td>239_translation_multilingual_translations_translators</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>247</td>\n",
              "      <td>33</td>\n",
              "      <td>247_multimodal_modality_modalities_multimodality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>246</td>\n",
              "      <td>33</td>\n",
              "      <td>246_polygons_polygon_surface_visibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>243</td>\n",
              "      <td>33</td>\n",
              "      <td>243_citation_papers_bibliographic_publications</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>244</td>\n",
              "      <td>33</td>\n",
              "      <td>244_conversations_blog_conversation_emailtime</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>250</td>\n",
              "      <td>33</td>\n",
              "      <td>250_lstm_driving_vehicle_traffic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>245</td>\n",
              "      <td>33</td>\n",
              "      <td>245_particle_particles_rendering_gpu</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>251</td>\n",
              "      <td>33</td>\n",
              "      <td>251_olfactory_odor_smell_arousal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>248</td>\n",
              "      <td>33</td>\n",
              "      <td>248_scrolling_scroll_scrollbar_flick</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>249</td>\n",
              "      <td>33</td>\n",
              "      <td>249_cloth_deformation_draping_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>252</td>\n",
              "      <td>32</td>\n",
              "      <td>252_color_grayscale_colors_gray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>253</td>\n",
              "      <td>32</td>\n",
              "      <td>253_diving_scuba_immersive_sickness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>256</td>\n",
              "      <td>31</td>\n",
              "      <td>256_probabilistic_uncertain_queries_databases</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>254</td>\n",
              "      <td>31</td>\n",
              "      <td>254_videos_lecture_video_lectures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>255</td>\n",
              "      <td>31</td>\n",
              "      <td>255_sketch_sketches_recognition_sketching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>257</td>\n",
              "      <td>31</td>\n",
              "      <td>257_intelligence_artificial_checklists_hype</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>258</td>\n",
              "      <td>31</td>\n",
              "      <td>258_breast_cancer_mammogram_nodules</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>260</td>\n",
              "      <td>31</td>\n",
              "      <td>260_misconception_teacher_teachers_pedagogical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>261</td>\n",
              "      <td>31</td>\n",
              "      <td>261_patient_medical_records_clinical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>259</td>\n",
              "      <td>31</td>\n",
              "      <td>259_dogs_birdhouse_birds_owners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>262</td>\n",
              "      <td>31</td>\n",
              "      <td>262_cartographic_cartograms_cartogram_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>269</td>\n",
              "      <td>30</td>\n",
              "      <td>269_emotions_affective_emotional_emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>263</td>\n",
              "      <td>30</td>\n",
              "      <td>263_finger_fingertip_touch_worn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>264</td>\n",
              "      <td>30</td>\n",
              "      <td>264_credit_fraud_card_financial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>265</td>\n",
              "      <td>30</td>\n",
              "      <td>265_topic_topics_news_latent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>266</td>\n",
              "      <td>30</td>\n",
              "      <td>266_phobias_games_therapy_game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>268</td>\n",
              "      <td>30</td>\n",
              "      <td>268_tensor_boolean_decomposition_factorization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>272</td>\n",
              "      <td>30</td>\n",
              "      <td>272_subgraph_subgraphs_densest_cliques</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>267</td>\n",
              "      <td>30</td>\n",
              "      <td>267_political_media_citizens_social</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>271</td>\n",
              "      <td>30</td>\n",
              "      <td>271_tweets_twitter_tweet_event</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>273</td>\n",
              "      <td>30</td>\n",
              "      <td>273_disease_alzheimer_brain_connectivity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>274</td>\n",
              "      <td>30</td>\n",
              "      <td>274_tone_luminance_binocular_contrast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>275</td>\n",
              "      <td>30</td>\n",
              "      <td>275_animation_animations_learners_comprehension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>270</td>\n",
              "      <td>30</td>\n",
              "      <td>270_experimentation_experiments_testing_online</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>276</td>\n",
              "      <td>29</td>\n",
              "      <td>276_treemaps_treemap_treecube_hierarchies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>279</td>\n",
              "      <td>29</td>\n",
              "      <td>279_convolutional_neural_deep_recognition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>277</td>\n",
              "      <td>29</td>\n",
              "      <td>277_ranking_question_answering_deepprobe</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>278</td>\n",
              "      <td>29</td>\n",
              "      <td>278_programming_demonstration_programmers_program</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>283</td>\n",
              "      <td>29</td>\n",
              "      <td>283_projector_handheld_projected_projection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>280</td>\n",
              "      <td>29</td>\n",
              "      <td>280_saliency_salient_detection_region</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>282</td>\n",
              "      <td>29</td>\n",
              "      <td>282_game_educational_games_gamification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>281</td>\n",
              "      <td>29</td>\n",
              "      <td>281_encrypted_encryption_secure_security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>290</td>\n",
              "      <td>28</td>\n",
              "      <td>290_twitter_news_tweets_rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>284</td>\n",
              "      <td>28</td>\n",
              "      <td>284_appliance_water_homes_thermal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>285</td>\n",
              "      <td>28</td>\n",
              "      <td>285_descriptor_descriptors_texture_butterfly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>286</td>\n",
              "      <td>28</td>\n",
              "      <td>286_communication_intercultural_negotiation_chat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>287</td>\n",
              "      <td>28</td>\n",
              "      <td>287_ocean_water_sea_mesoscale</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>288</td>\n",
              "      <td>28</td>\n",
              "      <td>288_mtl_tasks_task_sparsity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>289</td>\n",
              "      <td>28</td>\n",
              "      <td>289_facial_recognition_face_deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>292</td>\n",
              "      <td>28</td>\n",
              "      <td>292_hypermedia_hypertext_documents_document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>293</td>\n",
              "      <td>28</td>\n",
              "      <td>293_metric_dissimilarity_sparse_distances</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>294</td>\n",
              "      <td>28</td>\n",
              "      <td>294_crowdfunding_donations_campaigns_funding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>295</td>\n",
              "      <td>28</td>\n",
              "      <td>295_logs_bug_traces_workflow</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>296</td>\n",
              "      <td>28</td>\n",
              "      <td>296_credibility_political_guilt_voters</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>297</td>\n",
              "      <td>28</td>\n",
              "      <td>297_clusters_mining_location_geominer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>291</td>\n",
              "      <td>28</td>\n",
              "      <td>291_motion_motions_capture_warping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>298</td>\n",
              "      <td>27</td>\n",
              "      <td>298_dyslexia_characters_writing_reading</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>299</td>\n",
              "      <td>27</td>\n",
              "      <td>299_classifier_classifiers_classification_analytics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>300</td>\n",
              "      <td>27</td>\n",
              "      <td>300_underwater_seabed_marine_plume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>301</td>\n",
              "      <td>27</td>\n",
              "      <td>301_segmentation_mesh_cutting_snake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>302</td>\n",
              "      <td>27</td>\n",
              "      <td>302_spatio_air_geo_pollution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>303</td>\n",
              "      <td>27</td>\n",
              "      <td>303_motion_biomechanics_motions_motionexplorer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>304</td>\n",
              "      <td>27</td>\n",
              "      <td>304_home_networking_infrastructure_internet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>305</td>\n",
              "      <td>27</td>\n",
              "      <td>305_gene_genes_microarray_biclustering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>306</td>\n",
              "      <td>27</td>\n",
              "      <td>306_sleep_sleeping_circadian_sleepbandits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>307</td>\n",
              "      <td>27</td>\n",
              "      <td>307_personality_agents_agent_embodied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>308</td>\n",
              "      <td>27</td>\n",
              "      <td>308_cultural_culturally_usability_dimensions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>309</td>\n",
              "      <td>27</td>\n",
              "      <td>309_meetings_telemeeting_openmessenger_informal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>314</td>\n",
              "      <td>26</td>\n",
              "      <td>314_archaeological_roman_restoration_fossils</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>316</td>\n",
              "      <td>26</td>\n",
              "      <td>316_virtual_vr_environments_reality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>310</td>\n",
              "      <td>26</td>\n",
              "      <td>310_polygons_polygon_hull_logn</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>311</td>\n",
              "      <td>26</td>\n",
              "      <td>311_gaze_saccade_movements_saccades</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>312</td>\n",
              "      <td>26</td>\n",
              "      <td>312_geometric_algebra_quaternions_algebraic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>313</td>\n",
              "      <td>26</td>\n",
              "      <td>313_blockchain_blockchains_bitcoin_ledger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>315</td>\n",
              "      <td>26</td>\n",
              "      <td>315_fairness_fair_unfairness_bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>319</td>\n",
              "      <td>26</td>\n",
              "      <td>319_app_apps_usage_personalized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>320</td>\n",
              "      <td>26</td>\n",
              "      <td>320_location_sharing_privacy_concerns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>321</td>\n",
              "      <td>26</td>\n",
              "      <td>321_façades_urban_façade_geollery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>322</td>\n",
              "      <td>26</td>\n",
              "      <td>322_ux_experience_managing_uxcb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>323</td>\n",
              "      <td>26</td>\n",
              "      <td>323_cosmological_halos_universe_cosmic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>318</td>\n",
              "      <td>26</td>\n",
              "      <td>318_semantic_word_words_lexical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>317</td>\n",
              "      <td>26</td>\n",
              "      <td>317_naming_languages_categories_words</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>324</td>\n",
              "      <td>25</td>\n",
              "      <td>324_metaphors_temporal_past_duration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>325</td>\n",
              "      <td>25</td>\n",
              "      <td>325_bilingual_bilinguals_monolinguals_bilingualism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>326</td>\n",
              "      <td>25</td>\n",
              "      <td>326_isosurface_isosurfaces_triangles_surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>327</td>\n",
              "      <td>25</td>\n",
              "      <td>327_drivers_transit_ridesharing_ride</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>336</th>\n",
              "      <td>328</td>\n",
              "      <td>24</td>\n",
              "      <td>328_transitions_animated_animation_transition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>333</th>\n",
              "      <td>331</td>\n",
              "      <td>24</td>\n",
              "      <td>331_drug_patients_readmission_drugs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>335</th>\n",
              "      <td>329</td>\n",
              "      <td>24</td>\n",
              "      <td>329_brush_brushes_painting_paintings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>334</th>\n",
              "      <td>330</td>\n",
              "      <td>24</td>\n",
              "      <td>330_brain_fmri_connectivity_functional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>332</th>\n",
              "      <td>333</td>\n",
              "      <td>24</td>\n",
              "      <td>333_construction_building_visualisation_schedule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>331</th>\n",
              "      <td>334</td>\n",
              "      <td>24</td>\n",
              "      <td>334_segmentation_spine_vertebral_vertebrae</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>330</th>\n",
              "      <td>332</td>\n",
              "      <td>24</td>\n",
              "      <td>332_registration_scans_alignment_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>329</th>\n",
              "      <td>335</td>\n",
              "      <td>24</td>\n",
              "      <td>335_graphs_evolving_networks_subgraphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>343</th>\n",
              "      <td>340</td>\n",
              "      <td>23</td>\n",
              "      <td>340_courses_learners_instructors_students</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>347</th>\n",
              "      <td>336</td>\n",
              "      <td>23</td>\n",
              "      <td>336_remote_reality_augmented_telepresence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>346</th>\n",
              "      <td>337</td>\n",
              "      <td>23</td>\n",
              "      <td>337_public_displays_display_ambient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>345</th>\n",
              "      <td>338</td>\n",
              "      <td>23</td>\n",
              "      <td>338_sampling_disk_hypersphere_packing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>344</th>\n",
              "      <td>339</td>\n",
              "      <td>23</td>\n",
              "      <td>339_clustering_networks_clusters_partite</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>342</th>\n",
              "      <td>341</td>\n",
              "      <td>23</td>\n",
              "      <td>341_editorial_editor_chief_introductory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>341</th>\n",
              "      <td>343</td>\n",
              "      <td>23</td>\n",
              "      <td>343_string_strings_similarity_signatures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>340</th>\n",
              "      <td>344</td>\n",
              "      <td>23</td>\n",
              "      <td>344_statistical_null_statsplorer_statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>339</th>\n",
              "      <td>345</td>\n",
              "      <td>23</td>\n",
              "      <td>345_mining_frequent_parallel_itemset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>338</th>\n",
              "      <td>346</td>\n",
              "      <td>23</td>\n",
              "      <td>346_aesthetics_websites_website_aesthetic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>337</th>\n",
              "      <td>342</td>\n",
              "      <td>23</td>\n",
              "      <td>342_reading_books_comprehension_storybook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>360</th>\n",
              "      <td>349</td>\n",
              "      <td>22</td>\n",
              "      <td>349_flash_storage_ssd_page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>358</th>\n",
              "      <td>351</td>\n",
              "      <td>22</td>\n",
              "      <td>351_ink_reading_inkanchor_document</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>359</th>\n",
              "      <td>350</td>\n",
              "      <td>22</td>\n",
              "      <td>350_garment_wrinkles_cloth_wrinkle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>355</th>\n",
              "      <td>356</td>\n",
              "      <td>22</td>\n",
              "      <td>356_lens_lenses_optical_aberration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>361</th>\n",
              "      <td>348</td>\n",
              "      <td>22</td>\n",
              "      <td>348_tilings_tiling_ornamental_patterns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>362</th>\n",
              "      <td>347</td>\n",
              "      <td>22</td>\n",
              "      <td>347_spectator_liveness_improvisation_idiographic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>356</th>\n",
              "      <td>353</td>\n",
              "      <td>22</td>\n",
              "      <td>353_remote_video_collaboration_conferencing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>357</th>\n",
              "      <td>352</td>\n",
              "      <td>22</td>\n",
              "      <td>352_sensing_smartwatch_soundcraft_sensor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>354</th>\n",
              "      <td>355</td>\n",
              "      <td>22</td>\n",
              "      <td>355_trees_tree_pruning_treepod</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>353</th>\n",
              "      <td>361</td>\n",
              "      <td>22</td>\n",
              "      <td>361_financial_banking_payments_monies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>352</th>\n",
              "      <td>360</td>\n",
              "      <td>22</td>\n",
              "      <td>360_television_film_viewing_watching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>351</th>\n",
              "      <td>354</td>\n",
              "      <td>22</td>\n",
              "      <td>354_archaeological_excavation_photogrammetry_heritage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>350</th>\n",
              "      <td>358</td>\n",
              "      <td>22</td>\n",
              "      <td>358_frequent_subgraph_subgraphs_mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>349</th>\n",
              "      <td>357</td>\n",
              "      <td>22</td>\n",
              "      <td>357_simd_pixel_processor_shaded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>348</th>\n",
              "      <td>359</td>\n",
              "      <td>22</td>\n",
              "      <td>359_word_phonological_phonotactic_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>368</th>\n",
              "      <td>366</td>\n",
              "      <td>21</td>\n",
              "      <td>366_driving_vehicles_scenarios_maneuvers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>371</th>\n",
              "      <td>362</td>\n",
              "      <td>21</td>\n",
              "      <td>362_security_ssl_phishing_browser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>370</th>\n",
              "      <td>363</td>\n",
              "      <td>21</td>\n",
              "      <td>363_circuit_circuits_breadboard_electronics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>369</th>\n",
              "      <td>364</td>\n",
              "      <td>21</td>\n",
              "      <td>364_tensor_tensors_glyph_glyphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>366</th>\n",
              "      <td>368</td>\n",
              "      <td>21</td>\n",
              "      <td>368_watermarking_watermark_watermarks_steganographic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>367</th>\n",
              "      <td>365</td>\n",
              "      <td>21</td>\n",
              "      <td>365_seismic_reservoirs_geological_storm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>365</th>\n",
              "      <td>369</td>\n",
              "      <td>21</td>\n",
              "      <td>369_bars_glyph_comparison_heatmaps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>364</th>\n",
              "      <td>370</td>\n",
              "      <td>21</td>\n",
              "      <td>370_reading_dyslexia_comprehension_font</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>363</th>\n",
              "      <td>367</td>\n",
              "      <td>21</td>\n",
              "      <td>367_emotions_emotion_empathy_emotional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>377</th>\n",
              "      <td>377</td>\n",
              "      <td>20</td>\n",
              "      <td>377_illustrations_contours_silhouettes_renderings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>382</th>\n",
              "      <td>375</td>\n",
              "      <td>20</td>\n",
              "      <td>375_surgical_surgery_cutting_tissue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>381</th>\n",
              "      <td>371</td>\n",
              "      <td>20</td>\n",
              "      <td>371_privacy_anonymization_anonymized_publishing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>380</th>\n",
              "      <td>372</td>\n",
              "      <td>20</td>\n",
              "      <td>372_relational_autocorrelation_dependencies_dependency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>379</th>\n",
              "      <td>373</td>\n",
              "      <td>20</td>\n",
              "      <td>373_reward_rewards_bandit_choice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>378</th>\n",
              "      <td>374</td>\n",
              "      <td>20</td>\n",
              "      <td>374_fields_symmetry_topological_topology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>375</th>\n",
              "      <td>379</td>\n",
              "      <td>20</td>\n",
              "      <td>379_evolution_copying_fitness_creativity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>374</th>\n",
              "      <td>380</td>\n",
              "      <td>20</td>\n",
              "      <td>380_topology_bifurcations_bifurcation_topological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>373</th>\n",
              "      <td>381</td>\n",
              "      <td>20</td>\n",
              "      <td>381_quad_quadrilateral_remeshing_meshes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>372</th>\n",
              "      <td>376</td>\n",
              "      <td>20</td>\n",
              "      <td>376_lighting_office_lights_lightshare</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>376</th>\n",
              "      <td>378</td>\n",
              "      <td>20</td>\n",
              "      <td>378_cubic_algebraic_polynomials_rational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>389</th>\n",
              "      <td>385</td>\n",
              "      <td>19</td>\n",
              "      <td>385_game_gameplay_games_players</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>388</th>\n",
              "      <td>386</td>\n",
              "      <td>19</td>\n",
              "      <td>386_sentiment_opinion_opinions_lexicons</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>392</th>\n",
              "      <td>382</td>\n",
              "      <td>19</td>\n",
              "      <td>382_event_endpoints_duration_events</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>391</th>\n",
              "      <td>383</td>\n",
              "      <td>19</td>\n",
              "      <td>383_compression_texture_textures_bpp</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>390</th>\n",
              "      <td>384</td>\n",
              "      <td>19</td>\n",
              "      <td>384_forecasting_forecast_forecasts_series</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>387</th>\n",
              "      <td>389</td>\n",
              "      <td>19</td>\n",
              "      <td>389_financial_market_stock_portfolio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>386</th>\n",
              "      <td>390</td>\n",
              "      <td>19</td>\n",
              "      <td>390_uncertainty_visualizations_uncertain_emptiness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>385</th>\n",
              "      <td>391</td>\n",
              "      <td>19</td>\n",
              "      <td>391_battery_power_powerlet_smartphone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>384</th>\n",
              "      <td>387</td>\n",
              "      <td>19</td>\n",
              "      <td>387_retinal_glaucoma_fovea_glaucomatous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>383</th>\n",
              "      <td>388</td>\n",
              "      <td>19</td>\n",
              "      <td>388_facial_avatar_avatars_emotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>404</th>\n",
              "      <td>392</td>\n",
              "      <td>18</td>\n",
              "      <td>392_teams_team_intergroup_personalities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>402</th>\n",
              "      <td>396</td>\n",
              "      <td>18</td>\n",
              "      <td>396_food_eating_snacking_soylent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>403</th>\n",
              "      <td>395</td>\n",
              "      <td>18</td>\n",
              "      <td>395_agent_deep_dynamicsexplorer_reward</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400</th>\n",
              "      <td>394</td>\n",
              "      <td>18</td>\n",
              "      <td>394_analytic_analytics_analysts_sensemaking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>405</th>\n",
              "      <td>393</td>\n",
              "      <td>18</td>\n",
              "      <td>393_explainable_agent_explanations_agents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>406</th>\n",
              "      <td>397</td>\n",
              "      <td>18</td>\n",
              "      <td>397_navigation_landmark_obstacle_indoor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>401</th>\n",
              "      <td>398</td>\n",
              "      <td>18</td>\n",
              "      <td>398_provenance_datamaran_databases_workflows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>395</th>\n",
              "      <td>402</td>\n",
              "      <td>18</td>\n",
              "      <td>402_egocentric_judgments_height_person</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>399</th>\n",
              "      <td>400</td>\n",
              "      <td>18</td>\n",
              "      <td>400_porosity_polymers_porous_pore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>397</th>\n",
              "      <td>404</td>\n",
              "      <td>18</td>\n",
              "      <td>404_caricature_face_facial_caricatures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>396</th>\n",
              "      <td>399</td>\n",
              "      <td>18</td>\n",
              "      <td>399_organizations_business_deconstructivist_managers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>393</th>\n",
              "      <td>403</td>\n",
              "      <td>18</td>\n",
              "      <td>403_infants_infant_toddlers_gaze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>394</th>\n",
              "      <td>401</td>\n",
              "      <td>18</td>\n",
              "      <td>401_reviews_app_ratings_review</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>398</th>\n",
              "      <td>405</td>\n",
              "      <td>18</td>\n",
              "      <td>405_link_fraudulent_networks_network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>416</th>\n",
              "      <td>414</td>\n",
              "      <td>17</td>\n",
              "      <td>414_provenance_sensemaking_annotation_analysts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>424</th>\n",
              "      <td>413</td>\n",
              "      <td>17</td>\n",
              "      <td>413_messaging_messages_communication_message</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>423</th>\n",
              "      <td>406</td>\n",
              "      <td>17</td>\n",
              "      <td>406_notifications_notification_smartphone_scheduling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>422</th>\n",
              "      <td>407</td>\n",
              "      <td>17</td>\n",
              "      <td>407_job_talent_career_salary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>421</th>\n",
              "      <td>408</td>\n",
              "      <td>17</td>\n",
              "      <td>408_comprehension_trickett_trafton_unconventional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>420</th>\n",
              "      <td>409</td>\n",
              "      <td>17</td>\n",
              "      <td>409_remeshing_mesh_meshes_vertex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>419</th>\n",
              "      <td>410</td>\n",
              "      <td>17</td>\n",
              "      <td>410_haze_hazy_sky_removal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>418</th>\n",
              "      <td>411</td>\n",
              "      <td>17</td>\n",
              "      <td>411_segmentation_deconvolutional_mri_glioma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>417</th>\n",
              "      <td>412</td>\n",
              "      <td>17</td>\n",
              "      <td>412_texture_geometry_textured_camera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>415</th>\n",
              "      <td>416</td>\n",
              "      <td>17</td>\n",
              "      <td>416_meditation_bodily_body_wearables</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>413</th>\n",
              "      <td>418</td>\n",
              "      <td>17</td>\n",
              "      <td>418_rfid_tags_tagged_shopeye</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>412</th>\n",
              "      <td>419</td>\n",
              "      <td>17</td>\n",
              "      <td>419_gpu_gpus_culling_triangles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>411</th>\n",
              "      <td>420</td>\n",
              "      <td>17</td>\n",
              "      <td>420_patent_patents_companies_stock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>410</th>\n",
              "      <td>421</td>\n",
              "      <td>17</td>\n",
              "      <td>421_question_answer_answers_qa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>409</th>\n",
              "      <td>422</td>\n",
              "      <td>17</td>\n",
              "      <td>422_maintenance_views_updates_refresh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>408</th>\n",
              "      <td>423</td>\n",
              "      <td>17</td>\n",
              "      <td>423_hair_hairstyles_hairs_hairstyle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>407</th>\n",
              "      <td>415</td>\n",
              "      <td>17</td>\n",
              "      <td>415_debugging_programming_program_vpl</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>414</th>\n",
              "      <td>417</td>\n",
              "      <td>17</td>\n",
              "      <td>417_clipboards_displays_touch_devices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>440</th>\n",
              "      <td>432</td>\n",
              "      <td>16</td>\n",
              "      <td>432_presentation_presentations_slide_slides</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>437</th>\n",
              "      <td>425</td>\n",
              "      <td>16</td>\n",
              "      <td>425_blending_blends_surfaces_blend</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>438</th>\n",
              "      <td>426</td>\n",
              "      <td>16</td>\n",
              "      <td>426_play_outdoor_playground_playful</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>439</th>\n",
              "      <td>427</td>\n",
              "      <td>16</td>\n",
              "      <td>427_food_practices_sustainable_waste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>435</th>\n",
              "      <td>433</td>\n",
              "      <td>16</td>\n",
              "      <td>433_cloth_fiber_fabrics_textile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>441</th>\n",
              "      <td>429</td>\n",
              "      <td>16</td>\n",
              "      <td>429_manufacturing_golden_industrial_welding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>442</th>\n",
              "      <td>430</td>\n",
              "      <td>16</td>\n",
              "      <td>430_comics_narratives_narrative_comprehension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>443</th>\n",
              "      <td>431</td>\n",
              "      <td>16</td>\n",
              "      <td>431_rural_literacy_literate_educational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>436</th>\n",
              "      <td>428</td>\n",
              "      <td>16</td>\n",
              "      <td>428_spam_reviews_spammers_fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>425</th>\n",
              "      <td>439</td>\n",
              "      <td>16</td>\n",
              "      <td>439_knot_knots_knotted_knotpad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>434</th>\n",
              "      <td>424</td>\n",
              "      <td>16</td>\n",
              "      <td>424_disparity_stereo_projection_stereoscopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>429</th>\n",
              "      <td>434</td>\n",
              "      <td>16</td>\n",
              "      <td>434_sensor_cps_wireless_monitoring</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>426</th>\n",
              "      <td>436</td>\n",
              "      <td>16</td>\n",
              "      <td>436_skin_insertable_tactile_thin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>427</th>\n",
              "      <td>437</td>\n",
              "      <td>16</td>\n",
              "      <td>437_diagnostic_judgments_probabilities_disjunction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>428</th>\n",
              "      <td>438</td>\n",
              "      <td>16</td>\n",
              "      <td>438_premises_reasoning_belief_logicist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>433</th>\n",
              "      <td>435</td>\n",
              "      <td>16</td>\n",
              "      <td>435_watermarking_watermark_watermarks_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>430</th>\n",
              "      <td>440</td>\n",
              "      <td>16</td>\n",
              "      <td>440_event_pattern_streams_queries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>431</th>\n",
              "      <td>441</td>\n",
              "      <td>16</td>\n",
              "      <td>441_epidemic_influenza_epidemics_infectious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>432</th>\n",
              "      <td>442</td>\n",
              "      <td>16</td>\n",
              "      <td>442_skyline_sdc_skylines_skycube</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>453</th>\n",
              "      <td>453</td>\n",
              "      <td>15</td>\n",
              "      <td>453_camera_videographers_cameras_lecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>462</th>\n",
              "      <td>451</td>\n",
              "      <td>15</td>\n",
              "      <td>451_csg_solid_scanline_scan</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>461</th>\n",
              "      <td>443</td>\n",
              "      <td>15</td>\n",
              "      <td>443_assistive_nable_prostheses_disabilities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>460</th>\n",
              "      <td>444</td>\n",
              "      <td>15</td>\n",
              "      <td>444_developers_proxemics_pairing_experiences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>459</th>\n",
              "      <td>445</td>\n",
              "      <td>15</td>\n",
              "      <td>445_cursor_bubble_cursors_target</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>458</th>\n",
              "      <td>446</td>\n",
              "      <td>15</td>\n",
              "      <td>446_truth_truths_answers_conflicting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>457</th>\n",
              "      <td>447</td>\n",
              "      <td>15</td>\n",
              "      <td>447_publications_scholarly_articles_topic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>456</th>\n",
              "      <td>448</td>\n",
              "      <td>15</td>\n",
              "      <td>448_faces_face_n170_configural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>455</th>\n",
              "      <td>449</td>\n",
              "      <td>15</td>\n",
              "      <td>449_hair_hairs_strands_hairstyles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>454</th>\n",
              "      <td>450</td>\n",
              "      <td>15</td>\n",
              "      <td>450_font_fonts_typefaces_typeface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>451</th>\n",
              "      <td>455</td>\n",
              "      <td>15</td>\n",
              "      <td>455_causal_counterfactual_reasoning_additivity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>450</th>\n",
              "      <td>456</td>\n",
              "      <td>15</td>\n",
              "      <td>456_collective_agents_cooperate_cooperation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>449</th>\n",
              "      <td>457</td>\n",
              "      <td>15</td>\n",
              "      <td>457_delaunay_triangulation_voronoi_packing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>448</th>\n",
              "      <td>458</td>\n",
              "      <td>15</td>\n",
              "      <td>458_hadoop_teradata_analytics_workloads</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>447</th>\n",
              "      <td>459</td>\n",
              "      <td>15</td>\n",
              "      <td>459_flight_laser_cameras_calibration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>446</th>\n",
              "      <td>460</td>\n",
              "      <td>15</td>\n",
              "      <td>460_whiteboard_whiteboards_groupware_sdg</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>445</th>\n",
              "      <td>461</td>\n",
              "      <td>15</td>\n",
              "      <td>461_eye_hmms_hmm_mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>444</th>\n",
              "      <td>452</td>\n",
              "      <td>15</td>\n",
              "      <td>452_smale_complexes_decompositions_complex</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>452</th>\n",
              "      <td>454</td>\n",
              "      <td>15</td>\n",
              "      <td>454_classification_rules_association_rule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>475</th>\n",
              "      <td>473</td>\n",
              "      <td>14</td>\n",
              "      <td>473_dbpal_sql_nlidb_translation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>480</th>\n",
              "      <td>467</td>\n",
              "      <td>14</td>\n",
              "      <td>467_reading_books_book_notepals</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>477</th>\n",
              "      <td>470</td>\n",
              "      <td>14</td>\n",
              "      <td>470_hdri_flash_underexposed_brightness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>478</th>\n",
              "      <td>469</td>\n",
              "      <td>14</td>\n",
              "      <td>469_cartograms_cartogram_map_maps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>479</th>\n",
              "      <td>468</td>\n",
              "      <td>14</td>\n",
              "      <td>468_hackathons_hacking_hackerspace_hackability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>485</th>\n",
              "      <td>462</td>\n",
              "      <td>14</td>\n",
              "      <td>462_location_keywords_queries_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>481</th>\n",
              "      <td>466</td>\n",
              "      <td>14</td>\n",
              "      <td>466_qsanglyzer_question_qa_questions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>482</th>\n",
              "      <td>464</td>\n",
              "      <td>14</td>\n",
              "      <td>464_commerce_product_facebook_cueflik</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>483</th>\n",
              "      <td>463</td>\n",
              "      <td>14</td>\n",
              "      <td>463_hashing_hash_hamming_retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>484</th>\n",
              "      <td>472</td>\n",
              "      <td>14</td>\n",
              "      <td>472_category_categorization_inattention_fixation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>476</th>\n",
              "      <td>471</td>\n",
              "      <td>14</td>\n",
              "      <td>471_edit_edits_pixels_editing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>466</th>\n",
              "      <td>477</td>\n",
              "      <td>14</td>\n",
              "      <td>477_quantum_axiom_classical_logic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>474</th>\n",
              "      <td>465</td>\n",
              "      <td>14</td>\n",
              "      <td>465_cascades_diffusion_networks_citation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>472</th>\n",
              "      <td>483</td>\n",
              "      <td>14</td>\n",
              "      <td>483_relief_reliefs_depth_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>471</th>\n",
              "      <td>482</td>\n",
              "      <td>14</td>\n",
              "      <td>482_gpus_gpu_cpu_radix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>470</th>\n",
              "      <td>481</td>\n",
              "      <td>14</td>\n",
              "      <td>481_parallelism_scheduling_parallel_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>469</th>\n",
              "      <td>480</td>\n",
              "      <td>14</td>\n",
              "      <td>480_sound_hearing_sounds_deaf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>468</th>\n",
              "      <td>484</td>\n",
              "      <td>14</td>\n",
              "      <td>484_tensor_degenerate_topological_topology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>467</th>\n",
              "      <td>478</td>\n",
              "      <td>14</td>\n",
              "      <td>478_terrain_terrains_elevation_landscapes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>465</th>\n",
              "      <td>476</td>\n",
              "      <td>14</td>\n",
              "      <td>476_cooperation_prisoner_dilemma_payoff</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>464</th>\n",
              "      <td>479</td>\n",
              "      <td>14</td>\n",
              "      <td>479_kernel_margin_cuts3vm_mixture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>473</th>\n",
              "      <td>475</td>\n",
              "      <td>14</td>\n",
              "      <td>475_sustainability_sustainable_environmental_permaculture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>463</th>\n",
              "      <td>474</td>\n",
              "      <td>14</td>\n",
              "      <td>474_calibration_camera_tracking_scanner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>504</th>\n",
              "      <td>487</td>\n",
              "      <td>13</td>\n",
              "      <td>487_aircraft_openspace_earth_planetary</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>500</th>\n",
              "      <td>495</td>\n",
              "      <td>13</td>\n",
              "      <td>495_text_segmentation_ligatures_page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>501</th>\n",
              "      <td>485</td>\n",
              "      <td>13</td>\n",
              "      <td>485_recommender_explanations_recommendations_explanation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>503</th>\n",
              "      <td>488</td>\n",
              "      <td>13</td>\n",
              "      <td>488_halftoning_dither_diffusion_dispersed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>509</th>\n",
              "      <td>494</td>\n",
              "      <td>13</td>\n",
              "      <td>494_fallacies_conditionals_logical_logic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>505</th>\n",
              "      <td>490</td>\n",
              "      <td>13</td>\n",
              "      <td>490_sound_taste_vowels_meaning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>506</th>\n",
              "      <td>491</td>\n",
              "      <td>13</td>\n",
              "      <td>491_operators_filters_structuring_graylevel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>507</th>\n",
              "      <td>492</td>\n",
              "      <td>13</td>\n",
              "      <td>492_embodied_embodiment_students_tutor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>508</th>\n",
              "      <td>493</td>\n",
              "      <td>13</td>\n",
              "      <td>493_stabilization_video_stabilized_videos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>498</th>\n",
              "      <td>496</td>\n",
              "      <td>13</td>\n",
              "      <td>496_stixels_segmentation_deep_deepvid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>499</th>\n",
              "      <td>489</td>\n",
              "      <td>13</td>\n",
              "      <td>489_radial_interpolation_reconstruction_fitting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>502</th>\n",
              "      <td>486</td>\n",
              "      <td>13</td>\n",
              "      <td>486_grading_students_student_essay</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>497</th>\n",
              "      <td>501</td>\n",
              "      <td>13</td>\n",
              "      <td>501_ideas_inspirations_idea_ideation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>490</th>\n",
              "      <td>508</td>\n",
              "      <td>13</td>\n",
              "      <td>508_stock_trading_investment_stocks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>496</th>\n",
              "      <td>498</td>\n",
              "      <td>13</td>\n",
              "      <td>498_lighting_light_lights_bendylights</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>486</th>\n",
              "      <td>503</td>\n",
              "      <td>13</td>\n",
              "      <td>503_polygonization_surfaces_triangles_surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>487</th>\n",
              "      <td>499</td>\n",
              "      <td>13</td>\n",
              "      <td>499_distributed_coactive_privacy_selfish</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>489</th>\n",
              "      <td>502</td>\n",
              "      <td>13</td>\n",
              "      <td>502_ocean_underwater_water_waves</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>488</th>\n",
              "      <td>500</td>\n",
              "      <td>13</td>\n",
              "      <td>500_drone_drones_somaesthetic_emergency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>491</th>\n",
              "      <td>504</td>\n",
              "      <td>13</td>\n",
              "      <td>504_flight_cockpit_command_military</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>492</th>\n",
              "      <td>505</td>\n",
              "      <td>13</td>\n",
              "      <td>505_survivors_violence_justice_perpetrators</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>493</th>\n",
              "      <td>506</td>\n",
              "      <td>13</td>\n",
              "      <td>506_rdma_database_servers_storage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>494</th>\n",
              "      <td>507</td>\n",
              "      <td>13</td>\n",
              "      <td>507_drug_drugs_diseases_disease</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>495</th>\n",
              "      <td>497</td>\n",
              "      <td>13</td>\n",
              "      <td>497_counting_streaming_listing_graph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>519</th>\n",
              "      <td>514</td>\n",
              "      <td>12</td>\n",
              "      <td>514_blendshape_facial_animation_expressions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>525</th>\n",
              "      <td>509</td>\n",
              "      <td>12</td>\n",
              "      <td>509_lighting_phosphorescent_photorealistic_reflectance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>524</th>\n",
              "      <td>516</td>\n",
              "      <td>12</td>\n",
              "      <td>516_brain_cortical_morphometry_surface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>523</th>\n",
              "      <td>510</td>\n",
              "      <td>12</td>\n",
              "      <td>510_shape_shapevae_shapes_functionality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>522</th>\n",
              "      <td>511</td>\n",
              "      <td>12</td>\n",
              "      <td>511_personality_priming_trait_psychology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>521</th>\n",
              "      <td>512</td>\n",
              "      <td>12</td>\n",
              "      <td>512_menstrual_ovum_fertility_menstruating</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>520</th>\n",
              "      <td>513</td>\n",
              "      <td>12</td>\n",
              "      <td>513_journal_submissions_papers_submitted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>518</th>\n",
              "      <td>515</td>\n",
              "      <td>12</td>\n",
              "      <td>515_impaired_impairments_photos_visually</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>516</th>\n",
              "      <td>519</td>\n",
              "      <td>12</td>\n",
              "      <td>519_augmented_educational_app_greenhat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>515</th>\n",
              "      <td>520</td>\n",
              "      <td>12</td>\n",
              "      <td>520_music_musical_melody_soundtrack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>514</th>\n",
              "      <td>521</td>\n",
              "      <td>12</td>\n",
              "      <td>521_photo_photos_sharing_photolurking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>513</th>\n",
              "      <td>522</td>\n",
              "      <td>12</td>\n",
              "      <td>522_infants_names_parents_referents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>512</th>\n",
              "      <td>523</td>\n",
              "      <td>12</td>\n",
              "      <td>523_bike_station_rebalancing_bikes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>511</th>\n",
              "      <td>524</td>\n",
              "      <td>12</td>\n",
              "      <td>524_care_older_elderly_caregivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>517</th>\n",
              "      <td>517</td>\n",
              "      <td>12</td>\n",
              "      <td>517_diagrams_diagram_inductively_zones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>510</th>\n",
              "      <td>518</td>\n",
              "      <td>12</td>\n",
              "      <td>518_dataflow_ape_manyvis_architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>538</th>\n",
              "      <td>532</td>\n",
              "      <td>11</td>\n",
              "      <td>532_summaries_keyword_query_keywords</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>543</th>\n",
              "      <td>527</td>\n",
              "      <td>11</td>\n",
              "      <td>527_mhealth_health_functioning_outpatients</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>540</th>\n",
              "      <td>529</td>\n",
              "      <td>11</td>\n",
              "      <td>529_graphlet_graphlets_sampling_mkpgm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>541</th>\n",
              "      <td>535</td>\n",
              "      <td>11</td>\n",
              "      <td>535_patients_patient_care_clinic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>542</th>\n",
              "      <td>526</td>\n",
              "      <td>11</td>\n",
              "      <td>526_vrml_worlds_java3d_semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>547</th>\n",
              "      <td>531</td>\n",
              "      <td>11</td>\n",
              "      <td>531_stream_medusa_astream_resa</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>544</th>\n",
              "      <td>528</td>\n",
              "      <td>11</td>\n",
              "      <td>528_caching_dbcache_servers_web</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>545</th>\n",
              "      <td>525</td>\n",
              "      <td>11</td>\n",
              "      <td>525_volumetric_orbital_slice_medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>546</th>\n",
              "      <td>530</td>\n",
              "      <td>11</td>\n",
              "      <td>530_malware_app_apps_traffic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>548</th>\n",
              "      <td>533</td>\n",
              "      <td>11</td>\n",
              "      <td>533_questions_question_reasonets_answerer</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>549</th>\n",
              "      <td>534</td>\n",
              "      <td>11</td>\n",
              "      <td>534_survival_censored_relapse_risk</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>539</th>\n",
              "      <td>536</td>\n",
              "      <td>11</td>\n",
              "      <td>536_physics_physical_uncertainty_simulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>533</th>\n",
              "      <td>544</td>\n",
              "      <td>11</td>\n",
              "      <td>544_btf_texture_material_synthesis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>537</th>\n",
              "      <td>538</td>\n",
              "      <td>11</td>\n",
              "      <td>538_action_actions_stimulus_stimuli</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>530</th>\n",
              "      <td>541</td>\n",
              "      <td>11</td>\n",
              "      <td>541_flicking_manipulation_multitouch_touch</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>536</th>\n",
              "      <td>548</td>\n",
              "      <td>11</td>\n",
              "      <td>548_voice_rural_india_baang</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>527</th>\n",
              "      <td>542</td>\n",
              "      <td>11</td>\n",
              "      <td>542_web_contents_browsing_semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>528</th>\n",
              "      <td>539</td>\n",
              "      <td>11</td>\n",
              "      <td>539_innovation_discursive_regional_practices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>529</th>\n",
              "      <td>540</td>\n",
              "      <td>11</td>\n",
              "      <td>540_artistic_artworks_inspiration_creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526</th>\n",
              "      <td>537</td>\n",
              "      <td>11</td>\n",
              "      <td>537_sharing_photos_privacy_serendipity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>531</th>\n",
              "      <td>546</td>\n",
              "      <td>11</td>\n",
              "      <td>546_retargeting_scaling_warping_retargeted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>532</th>\n",
              "      <td>543</td>\n",
              "      <td>11</td>\n",
              "      <td>543_feminist_poetical_indigenous_cultural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>534</th>\n",
              "      <td>545</td>\n",
              "      <td>11</td>\n",
              "      <td>545_eating_posts_disorder_content</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>535</th>\n",
              "      <td>547</td>\n",
              "      <td>11</td>\n",
              "      <td>547_multimedia_presentations_databases_presentation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>559</th>\n",
              "      <td>553</td>\n",
              "      <td>10</td>\n",
              "      <td>553_terrain_terrains_mountainous_landforms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>567</th>\n",
              "      <td>549</td>\n",
              "      <td>10</td>\n",
              "      <td>549_evacuation_visualisation_buildings_urban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>566</th>\n",
              "      <td>550</td>\n",
              "      <td>10</td>\n",
              "      <td>550_bitmaps_hashing_compression_bitmap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>565</th>\n",
              "      <td>551</td>\n",
              "      <td>10</td>\n",
              "      <td>551_symmetry_symmetries_intrinsic_symmetric</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>564</th>\n",
              "      <td>552</td>\n",
              "      <td>10</td>\n",
              "      <td>552_matching_supermatching_rigid_matches</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>563</th>\n",
              "      <td>554</td>\n",
              "      <td>10</td>\n",
              "      <td>554_program_recompilation_debugging_stack</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>562</th>\n",
              "      <td>555</td>\n",
              "      <td>10</td>\n",
              "      <td>555_aesthetics_aesthetic_somaesthetics_ambient</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>561</th>\n",
              "      <td>556</td>\n",
              "      <td>10</td>\n",
              "      <td>556_cloud_banking_curation_files</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>560</th>\n",
              "      <td>557</td>\n",
              "      <td>10</td>\n",
              "      <td>557_spectral_clustering_constrained_constraints</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>554</th>\n",
              "      <td>563</td>\n",
              "      <td>10</td>\n",
              "      <td>563_urban_cities_ruins_city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>558</th>\n",
              "      <td>559</td>\n",
              "      <td>10</td>\n",
              "      <td>559_emotion_emotional_affect_emotions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>557</th>\n",
              "      <td>560</td>\n",
              "      <td>10</td>\n",
              "      <td>560_head_hmd_face_robot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>556</th>\n",
              "      <td>561</td>\n",
              "      <td>10</td>\n",
              "      <td>561_copy_paste_pages_browsing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>555</th>\n",
              "      <td>562</td>\n",
              "      <td>10</td>\n",
              "      <td>562_parental_parents_teens_carers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>553</th>\n",
              "      <td>564</td>\n",
              "      <td>10</td>\n",
              "      <td>564_motor_motion_proprioceptive_neural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>552</th>\n",
              "      <td>565</td>\n",
              "      <td>10</td>\n",
              "      <td>565_biometrics_biometric_authentication_fingerprint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>551</th>\n",
              "      <td>566</td>\n",
              "      <td>10</td>\n",
              "      <td>566_driven_metamodel_uidl_mappings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>550</th>\n",
              "      <td>558</td>\n",
              "      <td>10</td>\n",
              "      <td>558_urban_citizens_publics_participatory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>568</th>\n",
              "      <td>567</td>\n",
              "      <td>10</td>\n",
              "      <td>567_contours_contour_branching_triangulation</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count                                                        Name\n",
              "0       -1  29650                           -1_digital_mobile_rendering_touch\n",
              "1        0    693                             0_query_database_queries_schema\n",
              "2        1    658                         1_graphics_graphic_raster_standards\n",
              "3        2    598                          2_flow_vortex_vortices_velocimetry\n",
              "4        3    440           3_multidimensional_dimensional_scatterplots_plots\n",
              "5        4    433                               4_gaze_eye_movements_pointing\n",
              "6        5    396                       5_animation_motion_motions_locomotion\n",
              "7        6    368                      6_frequent_itemsets_mining_association\n",
              "8        7    359                       7_haptic_tactile_vibrotactile_haptics\n",
              "9        8    342                                  8_graphs_layout_graph_link\n",
              "10       9    340                                9_ray_rays_traversal_casting\n",
              "11      10    336              10_fabrication_printing_manufacturing_printers\n",
              "12      11    310                       11_illumination_light_photon_radiance\n",
              "13      12    275         12_recommendation_recommender_factorization_ratings\n",
              "14      13    238                   13_series_subsequence_shapelets_sequences\n",
              "15      14    221             14_category_categorization_categories_exemplars\n",
              "16      15    217                            15_robot_robots_robotic_robotics\n",
              "17      16    215         16_collaboration_groupware_collaborative_developers\n",
              "18      17    214                       17_crowdsourcing_workers_crowd_worker\n",
              "19      18    211                                18_game_games_players_player\n",
              "20      19    204               19_rehabilitation_exercise_exergames_exertion\n",
              "21      20    201              20_transaction_transactions_concurrency_commit\n",
              "22      21    199                           21_gpu_splatting_rendering_meshes\n",
              "23      22    195                           22_driving_driver_vehicle_drivers\n",
              "24      23    195                  23_usability_testing_evaluation_evaluators\n",
              "25      24    188                           24_pragmatic_verb_verbs_syntactic\n",
              "26      25    184                          25_keyboard_keyboards_touch_finger\n",
              "27      26    181                    26_diagrams_diagrammatic_logic_reasoning\n",
              "28      27    178                      27_trajectories_trajectory_spatio_city\n",
              "29      28    176                28_infovis_visualizations_heuristics_studies\n",
              "30      29    167                     29_texture_textures_synthesis_texturing\n",
              "31      30    165                       30_reconstruction_surface_mesh_meshes\n",
              "32      31    165                    31_symbolic_magnitude_numbers_arithmetic\n",
              "33      32    154                      32_label_unlabeled_instance_supervised\n",
              "34      33    141                       33_mobility_trajectory_urban_location\n",
              "35      34    139                34_displays_navigation_display_magnification\n",
              "36      35    138                          35_fluid_fluids_particle_particles\n",
              "37      36    138             36_causal_causation_counterfactual_explanations\n",
              "38      37    134                    37_spline_splines_interpolation_surfaces\n",
              "39      38    134                            38_smart_things_homes_households\n",
              "40      39    134                       39_vessel_ultrasound_vessels_vascular\n",
              "41      40    133               40_ethical_practitioners_researchers_research\n",
              "42      41    132                  41_privacy_private_anonymity_anonymization\n",
              "43      42    132                      42_crowd_crowds_pedestrians_pedestrian\n",
              "44      43    130                              43_lidar_road_driving_vehicles\n",
              "45      44    130                            44_color_colors_palettes_palette\n",
              "46      45    128                           45_shadow_shadows_light_shadowing\n",
              "47      46    125                      46_deformable_contact_elastic_fracture\n",
              "48      47    125                          47_gesture_gestures_gestural_touch\n",
              "49      48    125                          48_gesture_gestures_sign_iconicity\n",
              "50      49    123                              49_twitter_tweets_media_rumors\n",
              "51      50    123            50_interfaces_accessibility_interface_adaptation\n",
              "52      51    122                       51_molecular_molecules_atoms_proteins\n",
              "53      52    121                         52_series_chronoview_trend_analysts\n",
              "54      53    120             53_wikipedia_communities_newcomers_contributors\n",
              "55      54    120                            54_voice_speech_voicemail_voices\n",
              "56      55    118                  55_clustering_clusterings_clusters_cluster\n",
              "57      56    117                                56_touch_finger_fingers_hand\n",
              "58      57    117                             57_gene_genome_genomic_pathways\n",
              "59      58    116                             58_topic_documents_topics_texts\n",
              "60      59    114                          59_solid_solids_boundary_geometric\n",
              "61      60    112                 60_fabrication_textile_printing_stretchable\n",
              "62      61    107                             61_search_web_searching_seeking\n",
              "63      62    106               62_consumption_electricity_heating_households\n",
              "64      63    106                     63_programmers_developers_mashups_reuse\n",
              "65      64    102                            64_urban_buildings_building_city\n",
              "66      65    100                      65_speech_phonetic_spoken_phonological\n",
              "67      66     99                      66_illumination_camera_cameras_defocus\n",
              "69      67     98                                    67_xml_xquery_xpath_twig\n",
              "68      68     98                       68_activity_activities_sensors_sensor\n",
              "70      69     97              69_students_achievement_metacognitive_learners\n",
              "71      70     96            70_classification_categorization_spam_classifier\n",
              "73      71     94                          71_extraction_web_template_wrapper\n",
              "72      72     94                          72_facebook_privacy_friends_social\n",
              "74      73     93                          73_tutoring_tutors_student_courses\n",
              "75      74     91                     74_scientific_parallel_distributed_grid\n",
              "76      75     89                               75_art_artist_digital_artists\n",
              "77      76     86                           76_fractal_fractals_chaos_terrain\n",
              "78      77     86                                      77_reality_vr_mixed_mr\n",
              "79      78     86                      78_attention_search_target_attentional\n",
              "80      79     86                       79_ensemble_weather_climate_ensembles\n",
              "81      80     85                         80_machine_deep_automl_explanations\n",
              "82      81     84                            81_story_narrative_video_stories\n",
              "83      82     84                            82_choice_risky_decision_choices\n",
              "84      83     83                    83_brain_physiological_emotion_emotional\n",
              "85      84     83                  84_classroom_teachers_education_classrooms\n",
              "86      85     82                  85_impaired_visually_sighted_accessibility\n",
              "89      87     81                          87_moral_dilemmas_morality_morally\n",
              "90      86     81           86_subdivision_interpolatory_meshes_interpolating\n",
              "88      89     81        89_correspondence_isometric_correspondences_matching\n",
              "87      88     81              88_segmentation_watershed_superpixel_foresting\n",
              "91      90     80                        90_walking_locomotion_virtual_flying\n",
              "92      91     79                     91_classifiers_class_ensemble_imbalance\n",
              "93      92     79                           92_mesh_polygonal_meshes_collapse\n",
              "94      93     79                93_passwords_password_authentication_surfing\n",
              "95      94     78  94_interruptions_interruption_interruptibility_interrupted\n",
              "96      95     78                      95_volume_volumetric_opacity_rendering\n",
              "97      96     77               96_heritage_archaeological_museum_exhibitions\n",
              "98      97     77                             97_video_videos_frames_browsing\n",
              "99      98     75                           98_compression_meshes_mesh_coding\n",
              "100     99     75                      99_influence_marketing_spread_networks\n",
              "101    100     75                            100_facial_face_animation_speech\n",
              "102    101     74              101_deblurring_denoising_inpainting_resolution\n",
              "105    103     72                            103_email_emails_folders_webmail\n",
              "106    102     72                       102_retrieval_images_image_similarity\n",
              "104    105     72               105_community_communities_networks_modularity\n",
              "103    104     72                       104_outlier_outliers_anomaly_distance\n",
              "108    106     71                    106_diffusion_tensor_tracts_tractography\n",
              "107    107     71               107_metaphors_metaphor_metaphorical_adjective\n",
              "109    108     70                      108_twitter_sentiment_tweets_microblog\n",
              "110    109     69                     109_advertising_bid_bidding_advertisers\n",
              "111    110     68                        110_brdf_reflectance_brdfs_materials\n",
              "112    111     68                             111_sports_soccer_tennis_player\n",
              "113    112     67                    112_conversational_dialogue_agents_agent\n",
              "115    115     67                         115_spiking_neural_neurons_synaptic\n",
              "116    116     67                 116_analogical_analogy_analogies_relational\n",
              "117    113     67                        113_security_cyber_intrusion_traffic\n",
              "114    114     67                     114_clothing_clothes_aesthetic_garments\n",
              "118    117     66          117_precipitation_climate_agriculture_agricultural\n",
              "119    118     65                   118_augmented_reality_prototyping_protoar\n",
              "120    119     65                      119_customer_marketing_customers_sales\n",
              "121    120     65                     120_drift_ensemble_drifting_classifiers\n",
              "124    122     64                     122_video_recognition_videos_descriptor\n",
              "122    123     64                    123_narrative_story_stories_storytelling\n",
              "123    121     64                           121_dynamic_graphs_graph_networks\n",
              "125    124     63                        124_sentence_comprehension_verb_gaze\n",
              "126    125     63                 125_surgery_surgical_endoscopy_laparoscopic\n",
              "127    126     63               126_compiler_cache_multiprocessors_processors\n",
              "128    127     62                         127_web_personalization_usage_pskip\n",
              "129    128     62                128_landmarks_wayfinding_navigation_landmark\n",
              "130    129     61                           129_event_events_records_sentinel\n",
              "131    130     61                         130_word_situational_words_learners\n",
              "132    131     60                        131_museum_museums_visitors_heritage\n",
              "133    132     60                       132_aneurysm_aneurysms_vessel_rupture\n",
              "134    133     60                        133_flow_unsteady_particles_particle\n",
              "135    134     59                             134_trauma_hospital_care_nurses\n",
              "136    135     58            135_wavelet_wavelets_multiresolution_subdivision\n",
              "137    136     58                              136_video_couples_chat_sharing\n",
              "139    139     57                       139_pointing_endpoint_movement_moving\n",
              "140    137     57                          137_creativity_creative_ideas_idea\n",
              "138    138     57       138_dialogue_interlocutors_miscommunication_syntactic\n",
              "141    140     56                  140_descriptors_descriptor_shape_signature\n",
              "142    141     55                    141_entity_entities_named_disambiguation\n",
              "143    142     55                              142_join_spatial_queries_joins\n",
              "144    143     54            143_coordination_interpersonal_synchrony_partner\n",
              "145    144     53                                144_music_musical_songs_song\n",
              "146    145     53                     145_nearest_neighbor_hashing_similarity\n",
              "147    146     52                   146_collision_collisions_deformable_rigid\n",
              "148    147     51                       147_flow_texture_unsteady_streamlines\n",
              "149    148     51                        148_topic_topics_dirichlet_documents\n",
              "150    149     51                         149_software_code_developers_source\n",
              "151    150     51                   150_courses_teaching_education_curriculum\n",
              "154    154     50                             154_analytics_business_vast_big\n",
              "156    151     50                    151_civic_civics_citizens_infrastructure\n",
              "155    152     50                     152_tracking_tracker_trackers_occlusion\n",
              "153    155     50                  155_tabletop_collaboration_groupware_touch\n",
              "152    153     50                               153_plant_trees_plants_leaves\n",
              "157    156     49                          156_verb_noun_syntactic_inflection\n",
              "158    157     48                         157_musical_music_melodic_musicians\n",
              "159    158     48                 158_visflow_datasplash_visdb_visualizations\n",
              "160    159     48                     159_papers_symposium_pacific_pacificvis\n",
              "161    160     48                       160_memory_associative_episodic_items\n",
              "162    161     48                 161_linguistic_language_languages_variation\n",
              "163    162     48                             162_route_map_layout_wayfinding\n",
              "164    163     47                    163_children_child_participatory_ethical\n",
              "165    164     47                           164_diabetes_health_patients_care\n",
              "166    165     47                          165_vehicle_vehicles_planning_road\n",
              "167    166     47                   166_painting_paintings_painterly_artistic\n",
              "168    167     47                  167_subspace_clusters_subspaces_clustering\n",
              "171    172     46                     172_sound_acoustic_propagation_listener\n",
              "172    169     46                       169_parents_parenting_life_caregivers\n",
              "173    168     46                      168_sketch_sketching_sketches_sketched\n",
              "170    171     46                    171_mesh_smoothing_filtering_anisotropic\n",
              "169    170     46                     170_sketching_sketches_sketch_sketchify\n",
              "174    173     45                       173_diagrams_diagrammatic_uml_diagram\n",
              "175    174     45                     174_terrain_terrains_rendering_quadtree\n",
              "176    175     45                        175_matrix_factorization_norm_convex\n",
              "177    176     45                         176_papers_conference_issue_journal\n",
              "178    177     45                        177_optical_displays_mounted_display\n",
              "180    180     44                   180_demand_avoidance_cognitive_adaptivity\n",
              "181    178     44                178_recommendation_location_friends_networks\n",
              "179    179     44                 179_morphing_deformation_shape_deformations\n",
              "182    181     43              181_sensecam_memories_reminiscence_lifelogging\n",
              "183    182     43                        182_musical_music_musicians_creative\n",
              "184    183     43                    183_chatbot_chatbots_chat_conversational\n",
              "185    184     43             184_distributed_convergence_parallel_stochastic\n",
              "186    185     43                      185_reachability_subgraph_graphs_graph\n",
              "187    186     43                    186_autism_autistic_therapy_intervention\n",
              "191    189     42                     189_cognition_cognitive_mind_enactivism\n",
              "192    187     42                              187_video_videos_news_browsing\n",
              "189    191     42                    191_discovery_databases_knowledge_mining\n",
              "190    188     42          188_crowdsensing_privacy_obfuscation_crowdsourcing\n",
              "188    190     42                         190_graph_gnns_convolutional_graphs\n",
              "193    192     41                              192_game_games_players_pokémon\n",
              "194    193     41                       193_biometric_face_fingerprint_facial\n",
              "195    194     41                          194_column_columns_stores_columnar\n",
              "196    195     41               195_collaborative_collaboration_analysts_team\n",
              "197    196     41                        196_museum_visitors_heritage_museums\n",
              "198    197     40                   197_transportation_travel_location_places\n",
              "199    198     40                            198_wrist_finger_forearm_sensors\n",
              "200    199     40                      199_traffic_prediction_travel_temporal\n",
              "201    200     40                             200_privacy_apps_app_smartphone\n",
              "202    201     40                  201_diagrams_diagram_diagrammatic_teachers\n",
              "206    208     39                        208_ontology_ontologies_rdf_semantic\n",
              "208    203     39           203_cultural_psychological_attributions_normative\n",
              "207    204     39                             204_fire_flame_flakes_vorticity\n",
              "209    202     39                      202_graph_graphs_partitioning_subgraph\n",
              "205    206     39                           206_vortex_vortices_flow_unsteady\n",
              "204    207     39                              207_motion_pose_tracking_rigid\n",
              "203    205     39             205_kernel_discriminant_subspace_discriminative\n",
              "214    212     38                       212_feature_selection_subset_features\n",
              "216    211     38                211_indoor_localization_positioning_location\n",
              "215    210     38                  210_occlusion_culling_visibility_occluders\n",
              "210    213     38                 213_skinning_skeleton_deformation_animation\n",
              "213    209     38           209_archaeological_heritage_immersive_archaeology\n",
              "211    215     38                       215_gesture_recognition_gestures_sign\n",
              "212    214     38                214_embedding_network_networks_heterogeneous\n",
              "217    216     37              216_cleaning_repairing_constraints_conformance\n",
              "218    217     37                           217_aware_context_campus_hospital\n",
              "219    218     37                   218_dementia_care_wellbeing_participatory\n",
              "220    219     37                       219_tracking_camera_pose_registration\n",
              "221    220     37            220_ubicomp_ubiquitous_activitydesigner_awarecon\n",
              "222    221     37                     221_dance_dancers_dancer_choreographers\n",
              "228    226     36                     226_students_course_educational_courses\n",
              "232    222     36                    222_touch_visualizations_touchpivot_wimp\n",
              "231    223     36                       223_clipping_polygon_segments_drawing\n",
              "230    224     36                      224_parallel_rendering_mpk_parallelism\n",
              "229    225     36                              225_matting_video_camera_depth\n",
              "227    228     36                      228_health_communities_patients_online\n",
              "226    229     36                      229_insight_solving_hint_metacognitive\n",
              "225    230     36                230_immersive_reality_visualizations_virtual\n",
              "224    231     36               231_skeleton_skeletons_skeletonization_shapes\n",
              "223    227     36                              227_browser_web_browsing_pages\n",
              "233    232     35                         232_neurons_neuronal_confocal_brain\n",
              "234    233     35           233_spreadsheet_spreadsheets_formulas_uncertainty\n",
              "235    234     35                 234_projector_camera_calibration_projection\n",
              "236    235     35                      235_graph_graphs_kernel_classification\n",
              "240    241     34                          241_desktop_paste_windowscape_copy\n",
              "243    236     34                          236_uims_interface_wimp_interfaces\n",
              "241    238     34                     238_privacy_consent_policies_protection\n",
              "242    237     34                   237_topological_topology_points_piecewise\n",
              "239    240     34                     240_streamline_streamlines_seeding_flow\n",
              "238    242     34                   242_spatial_linguistic_languages_language\n",
              "237    239     34       239_translation_multilingual_translations_translators\n",
              "249    247     33            247_multimodal_modality_modalities_multimodality\n",
              "252    246     33                     246_polygons_polygon_surface_visibility\n",
              "251    243     33              243_citation_papers_bibliographic_publications\n",
              "250    244     33               244_conversations_blog_conversation_emailtime\n",
              "246    250     33                            250_lstm_driving_vehicle_traffic\n",
              "248    245     33                        245_particle_particles_rendering_gpu\n",
              "245    251     33                            251_olfactory_odor_smell_arousal\n",
              "244    248     33                        248_scrolling_scroll_scrollbar_flick\n",
              "247    249     33                          249_cloth_deformation_draping_mesh\n",
              "253    252     32                             252_color_grayscale_colors_gray\n",
              "254    253     32                         253_diving_scuba_immersive_sickness\n",
              "260    256     31               256_probabilistic_uncertain_queries_databases\n",
              "262    254     31                           254_videos_lecture_video_lectures\n",
              "261    255     31                   255_sketch_sketches_recognition_sketching\n",
              "263    257     31                 257_intelligence_artificial_checklists_hype\n",
              "259    258     31                         258_breast_cancer_mammogram_nodules\n",
              "257    260     31              260_misconception_teacher_teachers_pedagogical\n",
              "256    261     31                        261_patient_medical_records_clinical\n",
              "255    259     31                             259_dogs_birdhouse_birds_owners\n",
              "258    262     31                   262_cartographic_cartograms_cartogram_map\n",
              "271    269     30                    269_emotions_affective_emotional_emotion\n",
              "276    263     30                             263_finger_fingertip_touch_worn\n",
              "275    264     30                             264_credit_fraud_card_financial\n",
              "274    265     30                                265_topic_topics_news_latent\n",
              "273    266     30                              266_phobias_games_therapy_game\n",
              "272    268     30              268_tensor_boolean_decomposition_factorization\n",
              "268    272     30                      272_subgraph_subgraphs_densest_cliques\n",
              "270    267     30                         267_political_media_citizens_social\n",
              "269    271     30                              271_tweets_twitter_tweet_event\n",
              "267    273     30                    273_disease_alzheimer_brain_connectivity\n",
              "266    274     30                       274_tone_luminance_binocular_contrast\n",
              "265    275     30             275_animation_animations_learners_comprehension\n",
              "264    270     30              270_experimentation_experiments_testing_online\n",
              "283    276     29                   276_treemaps_treemap_treecube_hierarchies\n",
              "281    279     29                   279_convolutional_neural_deep_recognition\n",
              "282    277     29                    277_ranking_question_answering_deepprobe\n",
              "284    278     29           278_programming_demonstration_programmers_program\n",
              "280    283     29                 283_projector_handheld_projected_projection\n",
              "278    280     29                       280_saliency_salient_detection_region\n",
              "277    282     29                     282_game_educational_games_gamification\n",
              "279    281     29                    281_encrypted_encryption_secure_security\n",
              "292    290     28                               290_twitter_news_tweets_rumor\n",
              "298    284     28                           284_appliance_water_homes_thermal\n",
              "297    285     28                285_descriptor_descriptors_texture_butterfly\n",
              "296    286     28            286_communication_intercultural_negotiation_chat\n",
              "295    287     28                               287_ocean_water_sea_mesoscale\n",
              "294    288     28                                 288_mtl_tasks_task_sparsity\n",
              "293    289     28                            289_facial_recognition_face_deep\n",
              "291    292     28                 292_hypermedia_hypertext_documents_document\n",
              "290    293     28                   293_metric_dissimilarity_sparse_distances\n",
              "289    294     28                294_crowdfunding_donations_campaigns_funding\n",
              "288    295     28                                295_logs_bug_traces_workflow\n",
              "287    296     28                      296_credibility_political_guilt_voters\n",
              "286    297     28                       297_clusters_mining_location_geominer\n",
              "285    291     28                          291_motion_motions_capture_warping\n",
              "305    298     27                     298_dyslexia_characters_writing_reading\n",
              "310    299     27         299_classifier_classifiers_classification_analytics\n",
              "309    300     27                          300_underwater_seabed_marine_plume\n",
              "308    301     27                         301_segmentation_mesh_cutting_snake\n",
              "307    302     27                                302_spatio_air_geo_pollution\n",
              "306    303     27              303_motion_biomechanics_motions_motionexplorer\n",
              "299    304     27                 304_home_networking_infrastructure_internet\n",
              "304    305     27                      305_gene_genes_microarray_biclustering\n",
              "303    306     27                   306_sleep_sleeping_circadian_sleepbandits\n",
              "302    307     27                       307_personality_agents_agent_embodied\n",
              "301    308     27                308_cultural_culturally_usability_dimensions\n",
              "300    309     27             309_meetings_telemeeting_openmessenger_informal\n",
              "319    314     26                314_archaeological_roman_restoration_fossils\n",
              "324    316     26                         316_virtual_vr_environments_reality\n",
              "323    310     26                              310_polygons_polygon_hull_logn\n",
              "322    311     26                         311_gaze_saccade_movements_saccades\n",
              "321    312     26                 312_geometric_algebra_quaternions_algebraic\n",
              "320    313     26                   313_blockchain_blockchains_bitcoin_ledger\n",
              "318    315     26                           315_fairness_fair_unfairness_bias\n",
              "316    319     26                             319_app_apps_usage_personalized\n",
              "315    320     26                       320_location_sharing_privacy_concerns\n",
              "314    321     26                           321_façades_urban_façade_geollery\n",
              "313    322     26                             322_ux_experience_managing_uxcb\n",
              "312    323     26                      323_cosmological_halos_universe_cosmic\n",
              "311    318     26                             318_semantic_word_words_lexical\n",
              "317    317     26                       317_naming_languages_categories_words\n",
              "325    324     25                        324_metaphors_temporal_past_duration\n",
              "326    325     25          325_bilingual_bilinguals_monolinguals_bilingualism\n",
              "327    326     25                326_isosurface_isosurfaces_triangles_surface\n",
              "328    327     25                        327_drivers_transit_ridesharing_ride\n",
              "336    328     24               328_transitions_animated_animation_transition\n",
              "333    331     24                         331_drug_patients_readmission_drugs\n",
              "335    329     24                        329_brush_brushes_painting_paintings\n",
              "334    330     24                      330_brain_fmri_connectivity_functional\n",
              "332    333     24            333_construction_building_visualisation_schedule\n",
              "331    334     24                  334_segmentation_spine_vertebral_vertebrae\n",
              "330    332     24                      332_registration_scans_alignment_rigid\n",
              "329    335     24                      335_graphs_evolving_networks_subgraphs\n",
              "343    340     23                   340_courses_learners_instructors_students\n",
              "347    336     23                   336_remote_reality_augmented_telepresence\n",
              "346    337     23                         337_public_displays_display_ambient\n",
              "345    338     23                       338_sampling_disk_hypersphere_packing\n",
              "344    339     23                    339_clustering_networks_clusters_partite\n",
              "342    341     23                     341_editorial_editor_chief_introductory\n",
              "341    343     23                    343_string_strings_similarity_signatures\n",
              "340    344     23                 344_statistical_null_statsplorer_statistics\n",
              "339    345     23                        345_mining_frequent_parallel_itemset\n",
              "338    346     23                   346_aesthetics_websites_website_aesthetic\n",
              "337    342     23                   342_reading_books_comprehension_storybook\n",
              "360    349     22                                  349_flash_storage_ssd_page\n",
              "358    351     22                          351_ink_reading_inkanchor_document\n",
              "359    350     22                          350_garment_wrinkles_cloth_wrinkle\n",
              "355    356     22                          356_lens_lenses_optical_aberration\n",
              "361    348     22                      348_tilings_tiling_ornamental_patterns\n",
              "362    347     22            347_spectator_liveness_improvisation_idiographic\n",
              "356    353     22                 353_remote_video_collaboration_conferencing\n",
              "357    352     22                    352_sensing_smartwatch_soundcraft_sensor\n",
              "354    355     22                              355_trees_tree_pruning_treepod\n",
              "353    361     22                       361_financial_banking_payments_monies\n",
              "352    360     22                        360_television_film_viewing_watching\n",
              "351    354     22       354_archaeological_excavation_photogrammetry_heritage\n",
              "350    358     22                      358_frequent_subgraph_subgraphs_mining\n",
              "349    357     22                             357_simd_pixel_processor_shaded\n",
              "348    359     22                  359_word_phonological_phonotactic_language\n",
              "368    366     21                    366_driving_vehicles_scenarios_maneuvers\n",
              "371    362     21                           362_security_ssl_phishing_browser\n",
              "370    363     21                 363_circuit_circuits_breadboard_electronics\n",
              "369    364     21                             364_tensor_tensors_glyph_glyphs\n",
              "366    368     21        368_watermarking_watermark_watermarks_steganographic\n",
              "367    365     21                     365_seismic_reservoirs_geological_storm\n",
              "365    369     21                          369_bars_glyph_comparison_heatmaps\n",
              "364    370     21                     370_reading_dyslexia_comprehension_font\n",
              "363    367     21                      367_emotions_emotion_empathy_emotional\n",
              "377    377     20           377_illustrations_contours_silhouettes_renderings\n",
              "382    375     20                         375_surgical_surgery_cutting_tissue\n",
              "381    371     20             371_privacy_anonymization_anonymized_publishing\n",
              "380    372     20      372_relational_autocorrelation_dependencies_dependency\n",
              "379    373     20                            373_reward_rewards_bandit_choice\n",
              "378    374     20                    374_fields_symmetry_topological_topology\n",
              "375    379     20                    379_evolution_copying_fitness_creativity\n",
              "374    380     20           380_topology_bifurcations_bifurcation_topological\n",
              "373    381     20                     381_quad_quadrilateral_remeshing_meshes\n",
              "372    376     20                       376_lighting_office_lights_lightshare\n",
              "376    378     20                    378_cubic_algebraic_polynomials_rational\n",
              "389    385     19                             385_game_gameplay_games_players\n",
              "388    386     19                     386_sentiment_opinion_opinions_lexicons\n",
              "392    382     19                         382_event_endpoints_duration_events\n",
              "391    383     19                        383_compression_texture_textures_bpp\n",
              "390    384     19                   384_forecasting_forecast_forecasts_series\n",
              "387    389     19                        389_financial_market_stock_portfolio\n",
              "386    390     19          390_uncertainty_visualizations_uncertain_emptiness\n",
              "385    391     19                       391_battery_power_powerlet_smartphone\n",
              "384    387     19                     387_retinal_glaucoma_fovea_glaucomatous\n",
              "383    388     19                           388_facial_avatar_avatars_emotion\n",
              "404    392     18                     392_teams_team_intergroup_personalities\n",
              "402    396     18                            396_food_eating_snacking_soylent\n",
              "403    395     18                      395_agent_deep_dynamicsexplorer_reward\n",
              "400    394     18                 394_analytic_analytics_analysts_sensemaking\n",
              "405    393     18                   393_explainable_agent_explanations_agents\n",
              "406    397     18                     397_navigation_landmark_obstacle_indoor\n",
              "401    398     18                398_provenance_datamaran_databases_workflows\n",
              "395    402     18                      402_egocentric_judgments_height_person\n",
              "399    400     18                           400_porosity_polymers_porous_pore\n",
              "397    404     18                      404_caricature_face_facial_caricatures\n",
              "396    399     18        399_organizations_business_deconstructivist_managers\n",
              "393    403     18                            403_infants_infant_toddlers_gaze\n",
              "394    401     18                              401_reviews_app_ratings_review\n",
              "398    405     18                        405_link_fraudulent_networks_network\n",
              "416    414     17              414_provenance_sensemaking_annotation_analysts\n",
              "424    413     17                413_messaging_messages_communication_message\n",
              "423    406     17        406_notifications_notification_smartphone_scheduling\n",
              "422    407     17                                407_job_talent_career_salary\n",
              "421    408     17           408_comprehension_trickett_trafton_unconventional\n",
              "420    409     17                            409_remeshing_mesh_meshes_vertex\n",
              "419    410     17                                   410_haze_hazy_sky_removal\n",
              "418    411     17                 411_segmentation_deconvolutional_mri_glioma\n",
              "417    412     17                        412_texture_geometry_textured_camera\n",
              "415    416     17                        416_meditation_bodily_body_wearables\n",
              "413    418     17                                418_rfid_tags_tagged_shopeye\n",
              "412    419     17                              419_gpu_gpus_culling_triangles\n",
              "411    420     17                          420_patent_patents_companies_stock\n",
              "410    421     17                              421_question_answer_answers_qa\n",
              "409    422     17                       422_maintenance_views_updates_refresh\n",
              "408    423     17                         423_hair_hairstyles_hairs_hairstyle\n",
              "407    415     17                       415_debugging_programming_program_vpl\n",
              "414    417     17                       417_clipboards_displays_touch_devices\n",
              "440    432     16                 432_presentation_presentations_slide_slides\n",
              "437    425     16                          425_blending_blends_surfaces_blend\n",
              "438    426     16                         426_play_outdoor_playground_playful\n",
              "439    427     16                        427_food_practices_sustainable_waste\n",
              "435    433     16                             433_cloth_fiber_fabrics_textile\n",
              "441    429     16                 429_manufacturing_golden_industrial_welding\n",
              "442    430     16               430_comics_narratives_narrative_comprehension\n",
              "443    431     16                     431_rural_literacy_literate_educational\n",
              "436    428     16                              428_spam_reviews_spammers_fake\n",
              "425    439     16                              439_knot_knots_knotted_knotpad\n",
              "434    424     16                424_disparity_stereo_projection_stereoscopic\n",
              "429    434     16                          434_sensor_cps_wireless_monitoring\n",
              "426    436     16                            436_skin_insertable_tactile_thin\n",
              "427    437     16          437_diagnostic_judgments_probabilities_disjunction\n",
              "428    438     16                      438_premises_reasoning_belief_logicist\n",
              "433    435     16                  435_watermarking_watermark_watermarks_mesh\n",
              "430    440     16                           440_event_pattern_streams_queries\n",
              "431    441     16                 441_epidemic_influenza_epidemics_infectious\n",
              "432    442     16                            442_skyline_sdc_skylines_skycube\n",
              "453    453     15                    453_camera_videographers_cameras_lecture\n",
              "462    451     15                                 451_csg_solid_scanline_scan\n",
              "461    443     15                 443_assistive_nable_prostheses_disabilities\n",
              "460    444     15                444_developers_proxemics_pairing_experiences\n",
              "459    445     15                            445_cursor_bubble_cursors_target\n",
              "458    446     15                        446_truth_truths_answers_conflicting\n",
              "457    447     15                   447_publications_scholarly_articles_topic\n",
              "456    448     15                              448_faces_face_n170_configural\n",
              "455    449     15                           449_hair_hairs_strands_hairstyles\n",
              "454    450     15                           450_font_fonts_typefaces_typeface\n",
              "451    455     15              455_causal_counterfactual_reasoning_additivity\n",
              "450    456     15                 456_collective_agents_cooperate_cooperation\n",
              "449    457     15                  457_delaunay_triangulation_voronoi_packing\n",
              "448    458     15                     458_hadoop_teradata_analytics_workloads\n",
              "447    459     15                        459_flight_laser_cameras_calibration\n",
              "446    460     15                    460_whiteboard_whiteboards_groupware_sdg\n",
              "445    461     15                                       461_eye_hmms_hmm_mood\n",
              "444    452     15                  452_smale_complexes_decompositions_complex\n",
              "452    454     15                   454_classification_rules_association_rule\n",
              "475    473     14                             473_dbpal_sql_nlidb_translation\n",
              "480    467     14                             467_reading_books_book_notepals\n",
              "477    470     14                      470_hdri_flash_underexposed_brightness\n",
              "478    469     14                           469_cartograms_cartogram_map_maps\n",
              "479    468     14              468_hackathons_hacking_hackerspace_hackability\n",
              "485    462     14                         462_location_keywords_queries_query\n",
              "481    466     14                        466_qsanglyzer_question_qa_questions\n",
              "482    464     14                       464_commerce_product_facebook_cueflik\n",
              "483    463     14                          463_hashing_hash_hamming_retrieval\n",
              "484    472     14            472_category_categorization_inattention_fixation\n",
              "476    471     14                               471_edit_edits_pixels_editing\n",
              "466    477     14                           477_quantum_axiom_classical_logic\n",
              "474    465     14                    465_cascades_diffusion_networks_citation\n",
              "472    483     14                               483_relief_reliefs_depth_mesh\n",
              "471    482     14                                      482_gpus_gpu_cpu_radix\n",
              "470    481     14                   481_parallelism_scheduling_parallel_query\n",
              "469    480     14                               480_sound_hearing_sounds_deaf\n",
              "468    484     14                  484_tensor_degenerate_topological_topology\n",
              "467    478     14                   478_terrain_terrains_elevation_landscapes\n",
              "465    476     14                     476_cooperation_prisoner_dilemma_payoff\n",
              "464    479     14                           479_kernel_margin_cuts3vm_mixture\n",
              "473    475     14   475_sustainability_sustainable_environmental_permaculture\n",
              "463    474     14                     474_calibration_camera_tracking_scanner\n",
              "504    487     13                      487_aircraft_openspace_earth_planetary\n",
              "500    495     13                        495_text_segmentation_ligatures_page\n",
              "501    485     13    485_recommender_explanations_recommendations_explanation\n",
              "503    488     13                   488_halftoning_dither_diffusion_dispersed\n",
              "509    494     13                    494_fallacies_conditionals_logical_logic\n",
              "505    490     13                              490_sound_taste_vowels_meaning\n",
              "506    491     13                 491_operators_filters_structuring_graylevel\n",
              "507    492     13                      492_embodied_embodiment_students_tutor\n",
              "508    493     13                   493_stabilization_video_stabilized_videos\n",
              "498    496     13                       496_stixels_segmentation_deep_deepvid\n",
              "499    489     13             489_radial_interpolation_reconstruction_fitting\n",
              "502    486     13                          486_grading_students_student_essay\n",
              "497    501     13                        501_ideas_inspirations_idea_ideation\n",
              "490    508     13                         508_stock_trading_investment_stocks\n",
              "496    498     13                       498_lighting_light_lights_bendylights\n",
              "486    503     13               503_polygonization_surfaces_triangles_surface\n",
              "487    499     13                    499_distributed_coactive_privacy_selfish\n",
              "489    502     13                            502_ocean_underwater_water_waves\n",
              "488    500     13                     500_drone_drones_somaesthetic_emergency\n",
              "491    504     13                         504_flight_cockpit_command_military\n",
              "492    505     13                 505_survivors_violence_justice_perpetrators\n",
              "493    506     13                           506_rdma_database_servers_storage\n",
              "494    507     13                             507_drug_drugs_diseases_disease\n",
              "495    497     13                        497_counting_streaming_listing_graph\n",
              "519    514     12                 514_blendshape_facial_animation_expressions\n",
              "525    509     12      509_lighting_phosphorescent_photorealistic_reflectance\n",
              "524    516     12                      516_brain_cortical_morphometry_surface\n",
              "523    510     12                     510_shape_shapevae_shapes_functionality\n",
              "522    511     12                    511_personality_priming_trait_psychology\n",
              "521    512     12                   512_menstrual_ovum_fertility_menstruating\n",
              "520    513     12                    513_journal_submissions_papers_submitted\n",
              "518    515     12                    515_impaired_impairments_photos_visually\n",
              "516    519     12                      519_augmented_educational_app_greenhat\n",
              "515    520     12                         520_music_musical_melody_soundtrack\n",
              "514    521     12                       521_photo_photos_sharing_photolurking\n",
              "513    522     12                         522_infants_names_parents_referents\n",
              "512    523     12                          523_bike_station_rebalancing_bikes\n",
              "511    524     12                           524_care_older_elderly_caregivers\n",
              "517    517     12                      517_diagrams_diagram_inductively_zones\n",
              "510    518     12                       518_dataflow_ape_manyvis_architecture\n",
              "538    532     11                        532_summaries_keyword_query_keywords\n",
              "543    527     11                  527_mhealth_health_functioning_outpatients\n",
              "540    529     11                       529_graphlet_graphlets_sampling_mkpgm\n",
              "541    535     11                            535_patients_patient_care_clinic\n",
              "542    526     11                             526_vrml_worlds_java3d_semantic\n",
              "547    531     11                              531_stream_medusa_astream_resa\n",
              "544    528     11                             528_caching_dbcache_servers_web\n",
              "545    525     11                        525_volumetric_orbital_slice_medical\n",
              "546    530     11                                530_malware_app_apps_traffic\n",
              "548    533     11                   533_questions_question_reasonets_answerer\n",
              "549    534     11                          534_survival_censored_relapse_risk\n",
              "539    536     11                 536_physics_physical_uncertainty_simulation\n",
              "533    544     11                          544_btf_texture_material_synthesis\n",
              "537    538     11                         538_action_actions_stimulus_stimuli\n",
              "530    541     11                  541_flicking_manipulation_multitouch_touch\n",
              "536    548     11                                 548_voice_rural_india_baang\n",
              "527    542     11                          542_web_contents_browsing_semantic\n",
              "528    539     11                539_innovation_discursive_regional_practices\n",
              "529    540     11                  540_artistic_artworks_inspiration_creative\n",
              "526    537     11                      537_sharing_photos_privacy_serendipity\n",
              "531    546     11                  546_retargeting_scaling_warping_retargeted\n",
              "532    543     11                   543_feminist_poetical_indigenous_cultural\n",
              "534    545     11                           545_eating_posts_disorder_content\n",
              "535    547     11         547_multimedia_presentations_databases_presentation\n",
              "559    553     10                  553_terrain_terrains_mountainous_landforms\n",
              "567    549     10                549_evacuation_visualisation_buildings_urban\n",
              "566    550     10                      550_bitmaps_hashing_compression_bitmap\n",
              "565    551     10                 551_symmetry_symmetries_intrinsic_symmetric\n",
              "564    552     10                    552_matching_supermatching_rigid_matches\n",
              "563    554     10                   554_program_recompilation_debugging_stack\n",
              "562    555     10              555_aesthetics_aesthetic_somaesthetics_ambient\n",
              "561    556     10                            556_cloud_banking_curation_files\n",
              "560    557     10             557_spectral_clustering_constrained_constraints\n",
              "554    563     10                                 563_urban_cities_ruins_city\n",
              "558    559     10                       559_emotion_emotional_affect_emotions\n",
              "557    560     10                                     560_head_hmd_face_robot\n",
              "556    561     10                               561_copy_paste_pages_browsing\n",
              "555    562     10                           562_parental_parents_teens_carers\n",
              "553    564     10                      564_motor_motion_proprioceptive_neural\n",
              "552    565     10         565_biometrics_biometric_authentication_fingerprint\n",
              "551    566     10                          566_driven_metamodel_uidl_mappings\n",
              "550    558     10                    558_urban_citizens_publics_participatory\n",
              "568    567     10                567_contours_contour_branching_triangulation"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "44iPQbtjq8zq",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2c83c41b-9bbd-4b0a-f376-83af8d440dba"
      },
      "source": [
        "reduce_model = BERTopic(embedding_model=sentence_model, min_topic_size=20).fit(title_abs)\n",
        "reduce_model.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>29958</td>\n",
              "      <td>-1_people_mobile_objects_interactive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1044</td>\n",
              "      <td>0_language_linguistic_lexical_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>614</td>\n",
              "      <td>1_flow_vortex_vortices_velocimetry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>599</td>\n",
              "      <td>2_education_classroom_teaching_courses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>580</td>\n",
              "      <td>3_recommendation_recommender_advertising_ratings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>568</td>\n",
              "      <td>4_multidimensional_scatterplots_plots_dimensions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>526</td>\n",
              "      <td>5_analytics_visualization_visualizations_infovis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>480</td>\n",
              "      <td>6_gaze_eye_attention_movements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>473</td>\n",
              "      <td>7_haptic_tactile_force_vibrotactile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>468</td>\n",
              "      <td>8_classification_class_classifiers_feature</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>446</td>\n",
              "      <td>9_database_query_queries_join</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>442</td>\n",
              "      <td>10_flow_streamlines_vortex_streamline</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>377</td>\n",
              "      <td>11_illumination_light_scattering_photon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>376</td>\n",
              "      <td>12_mining_frequent_itemsets_association</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>282</td>\n",
              "      <td>13_gesture_gestures_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>273</td>\n",
              "      <td>14_ray_rays_traversal_casting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>266</td>\n",
              "      <td>15_ultrasound_vessel_imaging_vessels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>262</td>\n",
              "      <td>16_game_games_players_player</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>259</td>\n",
              "      <td>17_graphics_gks_cgi_phigs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18</td>\n",
              "      <td>256</td>\n",
              "      <td>18_causal_reasoning_beliefs_explanations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19</td>\n",
              "      <td>246</td>\n",
              "      <td>19_fluid_particle_particles_smoke</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>244</td>\n",
              "      <td>20_trajectories_trajectory_spatio_city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21</td>\n",
              "      <td>236</td>\n",
              "      <td>21_rehabilitation_exercise_exertion_game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>236</td>\n",
              "      <td>22_practice_research_designers_practitioners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23</td>\n",
              "      <td>226</td>\n",
              "      <td>23_series_subsequence_patterns_mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24</td>\n",
              "      <td>220</td>\n",
              "      <td>24_texture_textures_synthesis_texturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>25</td>\n",
              "      <td>218</td>\n",
              "      <td>25_category_categorization_categories_exemplars</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>217</td>\n",
              "      <td>26_robot_robots_robotic_robotics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>199</td>\n",
              "      <td>27_transaction_transactions_concurrency_commit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>28</td>\n",
              "      <td>197</td>\n",
              "      <td>28_crowdsourcing_workers_crowd_worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29</td>\n",
              "      <td>194</td>\n",
              "      <td>29_driving_driver_vehicle_drivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>194</td>\n",
              "      <td>30_diagrams_diagrammatic_logic_reasoning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>31</td>\n",
              "      <td>192</td>\n",
              "      <td>31_usability_evaluation_testing_requirements</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>32</td>\n",
              "      <td>189</td>\n",
              "      <td>32_keyboard_keyboards_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>33</td>\n",
              "      <td>186</td>\n",
              "      <td>33_privacy_security_consent_app</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>34</td>\n",
              "      <td>185</td>\n",
              "      <td>34_printing_fabrication_assembly_manufacturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>35</td>\n",
              "      <td>185</td>\n",
              "      <td>35_fabrication_textile_touch_tactile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>36</td>\n",
              "      <td>182</td>\n",
              "      <td>36_voice_speech_audio_spoken</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>37</td>\n",
              "      <td>181</td>\n",
              "      <td>37_urban_buildings_building_city</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38</td>\n",
              "      <td>177</td>\n",
              "      <td>38_sketch_sketching_sketches_drawing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>39</td>\n",
              "      <td>177</td>\n",
              "      <td>39_graph_subgraph_graphs_subgraphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>40</td>\n",
              "      <td>176</td>\n",
              "      <td>40_mobility_trajectories_trajectory_location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>41</td>\n",
              "      <td>171</td>\n",
              "      <td>41_motion_motions_animation_locomotion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>42</td>\n",
              "      <td>169</td>\n",
              "      <td>42_symbolic_magnitude_numbers_number</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>167</td>\n",
              "      <td>43_facial_face_animation_faces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>44</td>\n",
              "      <td>158</td>\n",
              "      <td>44_fairness_deep_explanations_trust</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>45</td>\n",
              "      <td>155</td>\n",
              "      <td>45_influence_diffusion_networks_network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>46</td>\n",
              "      <td>151</td>\n",
              "      <td>46_social_privacy_media_friends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>47</td>\n",
              "      <td>151</td>\n",
              "      <td>47_graph_graphs_network_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>48</td>\n",
              "      <td>149</td>\n",
              "      <td>48_molecules_simulations_cavities_cosmological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>49</td>\n",
              "      <td>148</td>\n",
              "      <td>49_ensemble_weather_climate_ensembles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50</td>\n",
              "      <td>145</td>\n",
              "      <td>50_spline_splines_cubic_surfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>51</td>\n",
              "      <td>145</td>\n",
              "      <td>51_rendering_gpu_splatting_volume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>52</td>\n",
              "      <td>144</td>\n",
              "      <td>52_label_labels_unlabeled_instance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>53</td>\n",
              "      <td>140</td>\n",
              "      <td>53_impaired_visually_tactile_impairments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>54</td>\n",
              "      <td>137</td>\n",
              "      <td>54_communities_wikipedia_community_newcomers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>55</td>\n",
              "      <td>136</td>\n",
              "      <td>55_displays_navigation_display_overview</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>56</td>\n",
              "      <td>134</td>\n",
              "      <td>56_light_illumination_lighting_camera</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>57</td>\n",
              "      <td>133</td>\n",
              "      <td>57_painting_brush_paintings_paint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>58</td>\n",
              "      <td>132</td>\n",
              "      <td>58_privacy_private_preserving_anonymity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>59</td>\n",
              "      <td>130</td>\n",
              "      <td>59_color_colors_palettes_palette</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>60</td>\n",
              "      <td>130</td>\n",
              "      <td>60_smart_homes_living_technologies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61</td>\n",
              "      <td>130</td>\n",
              "      <td>61_twitter_tweets_media_sentiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>62</td>\n",
              "      <td>129</td>\n",
              "      <td>62_art_artist_artistic_creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63</td>\n",
              "      <td>129</td>\n",
              "      <td>63_patient_care_hospital_clinicians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>64</td>\n",
              "      <td>127</td>\n",
              "      <td>64_crowd_crowds_simulation_pedestrians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>65</td>\n",
              "      <td>122</td>\n",
              "      <td>65_shadow_shadows_light_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>66</td>\n",
              "      <td>121</td>\n",
              "      <td>66_clustering_clusters_cluster_clusterings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>67</td>\n",
              "      <td>121</td>\n",
              "      <td>67_attention_visual_target_memory</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>68</td>\n",
              "      <td>120</td>\n",
              "      <td>68_twitter_tweets_media_rumor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>69</td>\n",
              "      <td>118</td>\n",
              "      <td>69_gesture_gestures_sign_language</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>70</td>\n",
              "      <td>118</td>\n",
              "      <td>70_code_programmers_debugging_software</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>71</td>\n",
              "      <td>116</td>\n",
              "      <td>71_deformable_spring_elastic_fracture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>72</td>\n",
              "      <td>114</td>\n",
              "      <td>72_passwords_authentication_password_security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>73</td>\n",
              "      <td>113</td>\n",
              "      <td>73_retrieval_images_similarity_photos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>75</td>\n",
              "      <td>111</td>\n",
              "      <td>75_layout_graph_bundling_graphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>76</td>\n",
              "      <td>111</td>\n",
              "      <td>76_gene_genome_genomic_pedigree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>74</td>\n",
              "      <td>111</td>\n",
              "      <td>74_topic_cloud_visualizations_words</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>77</td>\n",
              "      <td>110</td>\n",
              "      <td>77_lidar_vehicle_road_driving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>78</td>\n",
              "      <td>108</td>\n",
              "      <td>78_series_trend_analytics_visualization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>79</td>\n",
              "      <td>107</td>\n",
              "      <td>79_choice_risky_decision_decisions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>80</td>\n",
              "      <td>106</td>\n",
              "      <td>80_embedding_graph_network_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>81</td>\n",
              "      <td>104</td>\n",
              "      <td>81_walking_virtual_locomotion_navigation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>82</td>\n",
              "      <td>104</td>\n",
              "      <td>82_urban_city_cities_place</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>83</td>\n",
              "      <td>104</td>\n",
              "      <td>83_search_web_tagging_searching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>84</td>\n",
              "      <td>104</td>\n",
              "      <td>84_patient_clinical_patients_medical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>85</td>\n",
              "      <td>104</td>\n",
              "      <td>85_interfaces_accessibility_interface_adaptation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>86</td>\n",
              "      <td>102</td>\n",
              "      <td>86_image_inpainting_denoising_filter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>87</td>\n",
              "      <td>101</td>\n",
              "      <td>87_solid_solids_geometric_polyhedral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>88</td>\n",
              "      <td>101</td>\n",
              "      <td>88_health_diabetes_care_medication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>89</td>\n",
              "      <td>100</td>\n",
              "      <td>89_vehicles_vehicle_driving_traffic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>90</td>\n",
              "      <td>98</td>\n",
              "      <td>90_volume_volumetric_rendering_opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>91</td>\n",
              "      <td>97</td>\n",
              "      <td>91_classification_categorization_clustering_classifier</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>92</td>\n",
              "      <td>96</td>\n",
              "      <td>92_activities_sensor_sensors_food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>93</td>\n",
              "      <td>96</td>\n",
              "      <td>93_segmentation_watershed_superpixel_foresting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>94</td>\n",
              "      <td>96</td>\n",
              "      <td>94_extraction_web_template_wrapper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>95</td>\n",
              "      <td>95</td>\n",
              "      <td>95_consumption_electricity_households_sustainable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>96</td>\n",
              "      <td>91</td>\n",
              "      <td>96_rfid_indoor_location_positioning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>97</td>\n",
              "      <td>91</td>\n",
              "      <td>97_reality_vr_virtual_mixed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>98</td>\n",
              "      <td>90</td>\n",
              "      <td>98_xml_xquery_query_twig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>99</td>\n",
              "      <td>89</td>\n",
              "      <td>99_graphics_hardware_vlsi_architecture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>100</td>\n",
              "      <td>89</td>\n",
              "      <td>100_rendering_graphics_architecture_parallelism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>101</td>\n",
              "      <td>87</td>\n",
              "      <td>101_fractal_fractals_chaos_terrain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>102</td>\n",
              "      <td>87</td>\n",
              "      <td>102_distributed_scientific_parallel_grid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>103</td>\n",
              "      <td>86</td>\n",
              "      <td>103_civic_civics_citizens_practices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>104</td>\n",
              "      <td>86</td>\n",
              "      <td>104_moral_dilemmas_morality_morally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>105</td>\n",
              "      <td>83</td>\n",
              "      <td>105_map_cartographic_geographical_cartography</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>106</td>\n",
              "      <td>82</td>\n",
              "      <td>106_editorial_papers_preface_publication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>107</td>\n",
              "      <td>82</td>\n",
              "      <td>107_topic_topics_dirichlet_latent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>108</td>\n",
              "      <td>81</td>\n",
              "      <td>108_correspondence_isometric_correspondences_matching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>109</td>\n",
              "      <td>81</td>\n",
              "      <td>109_museum_museums_visitors_heritage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>112</td>\n",
              "      <td>80</td>\n",
              "      <td>112_subdivision_surfaces_interpolatory_meshes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>110</td>\n",
              "      <td>80</td>\n",
              "      <td>110_community_communities_networks_network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>111</td>\n",
              "      <td>80</td>\n",
              "      <td>111_landmarks_navigation_wayfinding_spatial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>113</td>\n",
              "      <td>79</td>\n",
              "      <td>113_pointing_target_movement_cursor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>114</td>\n",
              "      <td>79</td>\n",
              "      <td>114_music_musical_sound_melodic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>115</td>\n",
              "      <td>78</td>\n",
              "      <td>115_sentence_comprehension_verb_gaze</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>116</td>\n",
              "      <td>76</td>\n",
              "      <td>116_heritage_archaeological_museum_exhibitions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>117</td>\n",
              "      <td>75</td>\n",
              "      <td>117_analogical_analogy_analogies_relational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>118</td>\n",
              "      <td>75</td>\n",
              "      <td>118_simplification_mesh_meshes_polygonal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>119</td>\n",
              "      <td>72</td>\n",
              "      <td>119_narrative_story_video_stories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>120</td>\n",
              "      <td>72</td>\n",
              "      <td>120_compression_mesh_meshes_coding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>123</td>\n",
              "      <td>71</td>\n",
              "      <td>123_brain_connectivity_neurons_neuroscientists</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>121</td>\n",
              "      <td>71</td>\n",
              "      <td>121_sports_soccer_player_tennis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>122</td>\n",
              "      <td>71</td>\n",
              "      <td>122_battery_energy_sensing_occupancy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>124</td>\n",
              "      <td>69</td>\n",
              "      <td>124_segmentation_image_breast_imaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>125</td>\n",
              "      <td>69</td>\n",
              "      <td>125_chat_chatbot_chatbots_conversations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>126</td>\n",
              "      <td>69</td>\n",
              "      <td>126_diffusion_tensor_tracts_brain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>127</td>\n",
              "      <td>69</td>\n",
              "      <td>127_brdf_reflectance_brdfs_specular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>68</td>\n",
              "      <td>128_conversational_dialogue_agent_agents</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>130</td>\n",
              "      <td>67</td>\n",
              "      <td>130_email_mail_emails_workplace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>129</td>\n",
              "      <td>67</td>\n",
              "      <td>129_parents_care_parenting_health</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>132</td>\n",
              "      <td>67</td>\n",
              "      <td>132_health_communities_patients_teens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>131</td>\n",
              "      <td>67</td>\n",
              "      <td>131_motion_camera_reconstruction_tracking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>135</td>\n",
              "      <td>65</td>\n",
              "      <td>135_gesture_gestures_hand_wrist</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>133</td>\n",
              "      <td>65</td>\n",
              "      <td>133_security_traffic_cyber_intrusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>134</td>\n",
              "      <td>65</td>\n",
              "      <td>134_clothing_clothes_aesthetic_garments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>136</td>\n",
              "      <td>64</td>\n",
              "      <td>136_augmented_reality_virtual_prototyping</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>137</td>\n",
              "      <td>64</td>\n",
              "      <td>137_neural_spiking_neurons_brain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>138</td>\n",
              "      <td>63</td>\n",
              "      <td>138_outlier_outliers_datasets_distance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>139</td>\n",
              "      <td>63</td>\n",
              "      <td>139_narrative_story_storytelling_stories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>142</td>\n",
              "      <td>62</td>\n",
              "      <td>142_collaboration_teams_organizational_collaborative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>141</td>\n",
              "      <td>62</td>\n",
              "      <td>141_dynamic_graphs_graph_network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>143</td>\n",
              "      <td>62</td>\n",
              "      <td>143_tone_images_contrast_image</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>140</td>\n",
              "      <td>62</td>\n",
              "      <td>140_metaphors_metaphor_metaphorical_comprehension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>144</td>\n",
              "      <td>62</td>\n",
              "      <td>144_brain_stress_cognitive_infrared</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>145</td>\n",
              "      <td>61</td>\n",
              "      <td>145_matting_image_camera_stitching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>146</td>\n",
              "      <td>61</td>\n",
              "      <td>146_surgical_surgery_endoscopy_minimally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>147</td>\n",
              "      <td>61</td>\n",
              "      <td>147_collaborative_collaboration_groupware_editing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>148</td>\n",
              "      <td>60</td>\n",
              "      <td>148_drift_ensemble_drifting_streaming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>149</td>\n",
              "      <td>60</td>\n",
              "      <td>149_face_biometric_recognition_descriptor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>150</td>\n",
              "      <td>60</td>\n",
              "      <td>150_math_students_solving_posing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>151</td>\n",
              "      <td>60</td>\n",
              "      <td>151_olfactory_odor_arousal_breathing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>152</td>\n",
              "      <td>59</td>\n",
              "      <td>152_music_musical_songs_song</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>153</td>\n",
              "      <td>59</td>\n",
              "      <td>153_reading_books_ink_book</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>154</td>\n",
              "      <td>59</td>\n",
              "      <td>154_entity_entities_named_disambiguation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>155</td>\n",
              "      <td>59</td>\n",
              "      <td>155_crop_precipitation_forecasting_agriculture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>156</td>\n",
              "      <td>58</td>\n",
              "      <td>156_nearest_neighbor_hashing_similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>157</td>\n",
              "      <td>58</td>\n",
              "      <td>157_animation_animated_motion_graphics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>158</td>\n",
              "      <td>57</td>\n",
              "      <td>158_musical_music_musicians_creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>159</td>\n",
              "      <td>57</td>\n",
              "      <td>159_tree_trees_plant_plants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>160</td>\n",
              "      <td>57</td>\n",
              "      <td>160_customer_marketing_customers_pricing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>161</td>\n",
              "      <td>57</td>\n",
              "      <td>161_location_privacy_crowdsensing_services</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>162</td>\n",
              "      <td>56</td>\n",
              "      <td>162_remeshing_mesh_meshes_quad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>163</td>\n",
              "      <td>56</td>\n",
              "      <td>163_coordination_interpersonal_synchrony_partner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>164</td>\n",
              "      <td>55</td>\n",
              "      <td>164_cleaning_repairing_repair_tuples</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>165</td>\n",
              "      <td>55</td>\n",
              "      <td>165_parallel_cache_compiler_multiprocessors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>166</td>\n",
              "      <td>55</td>\n",
              "      <td>166_shape_descriptor_descriptors_retrieval</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>167</td>\n",
              "      <td>54</td>\n",
              "      <td>167_video_videos_surveillance_frames</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>168</td>\n",
              "      <td>54</td>\n",
              "      <td>168_interruptions_interruption_interruptibility_multitasking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>169</td>\n",
              "      <td>53</td>\n",
              "      <td>169_aneurysm_aneurysms_rupture_vessel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>170</td>\n",
              "      <td>53</td>\n",
              "      <td>170_dialogue_interlocutors_miscommunication_syntactic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>171</td>\n",
              "      <td>52</td>\n",
              "      <td>171_wavelet_wavelets_multiresolution_subdivision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>172</td>\n",
              "      <td>52</td>\n",
              "      <td>172_terrain_terrains_rendering_triangulation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>173</td>\n",
              "      <td>51</td>\n",
              "      <td>173_creativity_creative_ideas_idea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>174</td>\n",
              "      <td>50</td>\n",
              "      <td>174_recognition_video_videos_motion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>175</td>\n",
              "      <td>50</td>\n",
              "      <td>175_messaging_meetings_communication_conversation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>176</td>\n",
              "      <td>48</td>\n",
              "      <td>176_collision_collisions_deformable_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>177</td>\n",
              "      <td>48</td>\n",
              "      <td>177_location_recommendation_friends_locations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>178</td>\n",
              "      <td>47</td>\n",
              "      <td>178_sound_acoustic_listener_reverberation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>179</td>\n",
              "      <td>47</td>\n",
              "      <td>179_subspace_clusters_clustering_subspaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>180</td>\n",
              "      <td>46</td>\n",
              "      <td>180_route_map_wayfinding_travel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>181</td>\n",
              "      <td>46</td>\n",
              "      <td>181_tabletop_collaboration_touch_groupware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>182</td>\n",
              "      <td>45</td>\n",
              "      <td>182_papers_symposium_pacific_pacificvis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>183</td>\n",
              "      <td>45</td>\n",
              "      <td>183_memory_associative_episodic_memories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>184</td>\n",
              "      <td>45</td>\n",
              "      <td>184_developers_source_metrics_visualizations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>186</td>\n",
              "      <td>44</td>\n",
              "      <td>186_skeleton_skeletons_thinning_shapes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>185</td>\n",
              "      <td>44</td>\n",
              "      <td>185_graph_graphs_partitioning_subgraph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>188</td>\n",
              "      <td>44</td>\n",
              "      <td>188_game_games_educational_gamification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>187</td>\n",
              "      <td>44</td>\n",
              "      <td>187_watermarking_watermark_watermarks_scheme</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>191</td>\n",
              "      <td>43</td>\n",
              "      <td>191_children_participatory_child_preschoolers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>189</td>\n",
              "      <td>43</td>\n",
              "      <td>189_video_couples_sharing_chat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>190</td>\n",
              "      <td>43</td>\n",
              "      <td>190_causal_infants_reasoning_evidence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>192</td>\n",
              "      <td>42</td>\n",
              "      <td>192_desktop_monitor_windowscape_display</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>193</td>\n",
              "      <td>41</td>\n",
              "      <td>193_fabrication_digital_prototyping_production</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>194</td>\n",
              "      <td>41</td>\n",
              "      <td>194_spatial_linguistic_geocentric_verbal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>195</td>\n",
              "      <td>41</td>\n",
              "      <td>195_games_game_avatar_phobias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>196</td>\n",
              "      <td>41</td>\n",
              "      <td>196_convergence_descent_gradient_machine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>197</td>\n",
              "      <td>40</td>\n",
              "      <td>197_memories_reminiscence_lifelogging_everyday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>198</td>\n",
              "      <td>40</td>\n",
              "      <td>198_event_events_records_cohorts</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>199</td>\n",
              "      <td>40</td>\n",
              "      <td>199_tracking_tracker_trackers_detection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>204</td>\n",
              "      <td>39</td>\n",
              "      <td>204_occlusion_culling_rendering_visibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>201</td>\n",
              "      <td>39</td>\n",
              "      <td>201_diagrams_students_diagram_teachers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>200</td>\n",
              "      <td>39</td>\n",
              "      <td>200_emotions_emotional_emotion_affective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>203</td>\n",
              "      <td>39</td>\n",
              "      <td>203_teaching_teacher_learners_misconception</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>202</td>\n",
              "      <td>39</td>\n",
              "      <td>202_cognitive_mind_emergence_enactivism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>205</td>\n",
              "      <td>38</td>\n",
              "      <td>205_archaeological_heritage_immersive_archaeology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>206</td>\n",
              "      <td>37</td>\n",
              "      <td>206_hair_hairs_hairstyles_furry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>207</td>\n",
              "      <td>36</td>\n",
              "      <td>207_reconstruction_surface_surfaces_smooth</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>208</td>\n",
              "      <td>36</td>\n",
              "      <td>208_autism_children_intervention_play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>209</td>\n",
              "      <td>36</td>\n",
              "      <td>209_dance_dancers_dancer_choreographers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>210</td>\n",
              "      <td>36</td>\n",
              "      <td>210_ontology_ontologies_rdf_semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>213</td>\n",
              "      <td>36</td>\n",
              "      <td>213_traffic_prediction_travel_passenger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>214</td>\n",
              "      <td>36</td>\n",
              "      <td>214_matrix_factorization_nonnegative_norm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>215</td>\n",
              "      <td>36</td>\n",
              "      <td>215_treemap_treemaps_hierarchical_hierarchy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>216</td>\n",
              "      <td>36</td>\n",
              "      <td>216_projector_camera_calibration_projection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>217</td>\n",
              "      <td>36</td>\n",
              "      <td>217_polygons_polygon_triangulation_vertices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>218</td>\n",
              "      <td>36</td>\n",
              "      <td>218_graphical_specification_graphics_graphic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>211</td>\n",
              "      <td>36</td>\n",
              "      <td>211_optical_displays_mounted_glasses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>212</td>\n",
              "      <td>36</td>\n",
              "      <td>212_graph_graphs_classification_label</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>220</td>\n",
              "      <td>35</td>\n",
              "      <td>220_clipping_algorithm_sutherland_algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>222</td>\n",
              "      <td>35</td>\n",
              "      <td>222_web_browser_browsing_pages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>221</td>\n",
              "      <td>35</td>\n",
              "      <td>221_scrolling_scroll_flick_menus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>219</td>\n",
              "      <td>35</td>\n",
              "      <td>219_disease_alzheimer_biomarkers_connectivity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>226</td>\n",
              "      <td>35</td>\n",
              "      <td>226_spreadsheet_spreadsheets_photospread_formulas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>224</td>\n",
              "      <td>35</td>\n",
              "      <td>224_ubicomp_ubiquitous_activitydesigner_products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>223</td>\n",
              "      <td>35</td>\n",
              "      <td>223_tracking_pose_camera_markerless</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>225</td>\n",
              "      <td>35</td>\n",
              "      <td>225_web_pskip_personalization_crawling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>227</td>\n",
              "      <td>34</td>\n",
              "      <td>227_game_games_players_pokémon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>228</td>\n",
              "      <td>34</td>\n",
              "      <td>228_task_control_switch_cognitive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>229</td>\n",
              "      <td>34</td>\n",
              "      <td>229_skeleton_skinning_animation_skeletal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>230</td>\n",
              "      <td>34</td>\n",
              "      <td>230_multimodal_modality_modalities_interfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>231</td>\n",
              "      <td>34</td>\n",
              "      <td>231_spatial_join_joins_queries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>232</td>\n",
              "      <td>33</td>\n",
              "      <td>232_morphing_shape_deformation_shapes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>233</td>\n",
              "      <td>33</td>\n",
              "      <td>233_construction_visualisation_building_project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>234</td>\n",
              "      <td>32</td>\n",
              "      <td>234_particle_particles_rendering_volume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>235</td>\n",
              "      <td>32</td>\n",
              "      <td>235_insight_solving_hint_subliminal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>236</td>\n",
              "      <td>32</td>\n",
              "      <td>236_neural_deep_convolutional_recognition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>237</td>\n",
              "      <td>32</td>\n",
              "      <td>237_citation_papers_publications_publication</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>238</td>\n",
              "      <td>32</td>\n",
              "      <td>238_collaborative_analysts_collaboration_team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>239</td>\n",
              "      <td>32</td>\n",
              "      <td>239_uims_interface_interfaces_dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>240</td>\n",
              "      <td>32</td>\n",
              "      <td>240_cloth_draping_deformation_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>243</td>\n",
              "      <td>31</td>\n",
              "      <td>243_lstm_driving_vehicle_prediction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>242</td>\n",
              "      <td>31</td>\n",
              "      <td>242_provenance_workflows_workflow_lake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>244</td>\n",
              "      <td>31</td>\n",
              "      <td>244_color_grayscale_colors_gray</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>241</td>\n",
              "      <td>31</td>\n",
              "      <td>241_translation_multilingual_translations_translators</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>245</td>\n",
              "      <td>31</td>\n",
              "      <td>245_labeling_classifier_classifiers_classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>246</td>\n",
              "      <td>30</td>\n",
              "      <td>246_motion_capture_motions_indexing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>247</td>\n",
              "      <td>30</td>\n",
              "      <td>247_geodesic_meshes_coordinates_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>248</td>\n",
              "      <td>30</td>\n",
              "      <td>248_touch_visualizations_displays_touchpivot</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>249</td>\n",
              "      <td>30</td>\n",
              "      <td>249_animation_animated_animations_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>250</td>\n",
              "      <td>30</td>\n",
              "      <td>250_location_travel_places_map</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>251</td>\n",
              "      <td>30</td>\n",
              "      <td>251_video_videos_browsing_history</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>252</td>\n",
              "      <td>30</td>\n",
              "      <td>252_discovery_knowledge_mining_science</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>253</td>\n",
              "      <td>29</td>\n",
              "      <td>253_context_aware_campus_mobile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>254</td>\n",
              "      <td>29</td>\n",
              "      <td>254_saliency_salient_detection_image</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>255</td>\n",
              "      <td>29</td>\n",
              "      <td>255_motor_stimulus_action_actions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>262</td>\n",
              "      <td>28</td>\n",
              "      <td>262_finger_touch_fingertip_touchpad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>256</td>\n",
              "      <td>28</td>\n",
              "      <td>256_encrypted_encryption_secure_security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>258</td>\n",
              "      <td>28</td>\n",
              "      <td>258_experiments_testing_online_metrics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>257</td>\n",
              "      <td>28</td>\n",
              "      <td>257_gene_genes_microarray_biclustering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>260</td>\n",
              "      <td>28</td>\n",
              "      <td>260_columns_columnar_stores_store</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>259</td>\n",
              "      <td>28</td>\n",
              "      <td>259_training_immersive_simulation_trainees</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>261</td>\n",
              "      <td>28</td>\n",
              "      <td>261_facial_recognition_face_deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>263</td>\n",
              "      <td>27</td>\n",
              "      <td>263_immersive_reality_virtual_visualizations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>264</td>\n",
              "      <td>27</td>\n",
              "      <td>264_color_naming_words_colors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>265</td>\n",
              "      <td>27</td>\n",
              "      <td>265_graphs_networks_evolving_subgraphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>266</td>\n",
              "      <td>27</td>\n",
              "      <td>266_underwater_seabed_plume_marine</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>267</td>\n",
              "      <td>27</td>\n",
              "      <td>267_religion_religious_beliefs_supernatural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>270</td>\n",
              "      <td>26</td>\n",
              "      <td>270_hash_query_processor_parallelism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>269</td>\n",
              "      <td>26</td>\n",
              "      <td>269_birdhouse_bird_nurturing_touchscreen</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>271</td>\n",
              "      <td>26</td>\n",
              "      <td>271_segmentation_mesh_cutting_snake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>268</td>\n",
              "      <td>26</td>\n",
              "      <td>268_polygons_surface_polygon_scene</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>272</td>\n",
              "      <td>26</td>\n",
              "      <td>272_blockchain_blockchains_bitcoin_ledger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>276</td>\n",
              "      <td>25</td>\n",
              "      <td>276_cultural_culturally_usability_dimensions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>277</td>\n",
              "      <td>25</td>\n",
              "      <td>277_drivers_transit_passengers_ride</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>274</td>\n",
              "      <td>25</td>\n",
              "      <td>274_crowdfunding_donations_campaign_campaigns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>275</td>\n",
              "      <td>25</td>\n",
              "      <td>275_ocean_water_sea_oceanographic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>273</td>\n",
              "      <td>25</td>\n",
              "      <td>273_achievement_goals_students_mastery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>281</td>\n",
              "      <td>25</td>\n",
              "      <td>281_displays_ambient_studies_pids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>280</td>\n",
              "      <td>25</td>\n",
              "      <td>280_mesh_filtering_smoothing_filter</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>278</td>\n",
              "      <td>25</td>\n",
              "      <td>278_web_search_semantic_visualisation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>282</td>\n",
              "      <td>25</td>\n",
              "      <td>282_geometric_quaternions_algebra_geometry</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>279</td>\n",
              "      <td>25</td>\n",
              "      <td>279_string_strings_similarity_indexing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>283</td>\n",
              "      <td>24</td>\n",
              "      <td>283_schema_schemas_coma_integration</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>284</td>\n",
              "      <td>24</td>\n",
              "      <td>284_reward_options_foraging_rewards</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>285</td>\n",
              "      <td>24</td>\n",
              "      <td>285_metric_dissimilarity_sparse_kernels</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>286</td>\n",
              "      <td>24</td>\n",
              "      <td>286_temporal_speakers_past_metaphors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>287</td>\n",
              "      <td>24</td>\n",
              "      <td>287_tasks_task_mtl_relatedness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>290</td>\n",
              "      <td>23</td>\n",
              "      <td>290_registration_alignment_rigid_deformable</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>288</td>\n",
              "      <td>23</td>\n",
              "      <td>288_tensor_tensors_glyph_glyphs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>289</td>\n",
              "      <td>23</td>\n",
              "      <td>289_sleep_sleeping_circadian_somnolent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>291</td>\n",
              "      <td>22</td>\n",
              "      <td>291_projector_handheld_projection_projected</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>292</td>\n",
              "      <td>22</td>\n",
              "      <td>292_transitions_animated_animation_parser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>293</td>\n",
              "      <td>22</td>\n",
              "      <td>293_flash_nvm_storage_database</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>294</td>\n",
              "      <td>21</td>\n",
              "      <td>294_circuit_circuits_electronics_breadboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>295</td>\n",
              "      <td>21</td>\n",
              "      <td>295_diagrammatic_syntax_codecharts_uml</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>296</td>\n",
              "      <td>21</td>\n",
              "      <td>296_tensor_tensors_decomposition_factorization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>297</td>\n",
              "      <td>21</td>\n",
              "      <td>297_buffer_shading_pixel_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>298</td>\n",
              "      <td>21</td>\n",
              "      <td>298_cultural_evolution_copying_fitness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>299</td>\n",
              "      <td>20</td>\n",
              "      <td>299_movements_saccade_gaze_saccades</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>300</td>\n",
              "      <td>20</td>\n",
              "      <td>300_lens_lenses_ray_optical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>301</td>\n",
              "      <td>20</td>\n",
              "      <td>301_graphical_interfaces_graphic_interface</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count  \\\n",
              "0       -1  29958   \n",
              "1        0   1044   \n",
              "2        1    614   \n",
              "3        2    599   \n",
              "4        3    580   \n",
              "5        4    568   \n",
              "6        5    526   \n",
              "7        6    480   \n",
              "8        7    473   \n",
              "9        8    468   \n",
              "10       9    446   \n",
              "11      10    442   \n",
              "12      11    377   \n",
              "13      12    376   \n",
              "14      13    282   \n",
              "15      14    273   \n",
              "16      15    266   \n",
              "17      16    262   \n",
              "18      17    259   \n",
              "19      18    256   \n",
              "20      19    246   \n",
              "21      20    244   \n",
              "22      21    236   \n",
              "23      22    236   \n",
              "24      23    226   \n",
              "25      24    220   \n",
              "26      25    218   \n",
              "27      26    217   \n",
              "28      27    199   \n",
              "29      28    197   \n",
              "30      29    194   \n",
              "31      30    194   \n",
              "32      31    192   \n",
              "33      32    189   \n",
              "34      33    186   \n",
              "35      34    185   \n",
              "36      35    185   \n",
              "37      36    182   \n",
              "38      37    181   \n",
              "39      38    177   \n",
              "40      39    177   \n",
              "41      40    176   \n",
              "42      41    171   \n",
              "43      42    169   \n",
              "44      43    167   \n",
              "45      44    158   \n",
              "46      45    155   \n",
              "48      46    151   \n",
              "47      47    151   \n",
              "49      48    149   \n",
              "50      49    148   \n",
              "51      50    145   \n",
              "52      51    145   \n",
              "53      52    144   \n",
              "54      53    140   \n",
              "55      54    137   \n",
              "56      55    136   \n",
              "57      56    134   \n",
              "58      57    133   \n",
              "59      58    132   \n",
              "60      59    130   \n",
              "61      60    130   \n",
              "62      61    130   \n",
              "63      62    129   \n",
              "64      63    129   \n",
              "65      64    127   \n",
              "66      65    122   \n",
              "68      66    121   \n",
              "67      67    121   \n",
              "69      68    120   \n",
              "70      69    118   \n",
              "71      70    118   \n",
              "72      71    116   \n",
              "73      72    114   \n",
              "74      73    113   \n",
              "77      75    111   \n",
              "75      76    111   \n",
              "76      74    111   \n",
              "78      77    110   \n",
              "79      78    108   \n",
              "80      79    107   \n",
              "81      80    106   \n",
              "82      81    104   \n",
              "83      82    104   \n",
              "84      83    104   \n",
              "85      84    104   \n",
              "86      85    104   \n",
              "87      86    102   \n",
              "88      87    101   \n",
              "89      88    101   \n",
              "90      89    100   \n",
              "91      90     98   \n",
              "92      91     97   \n",
              "95      92     96   \n",
              "94      93     96   \n",
              "93      94     96   \n",
              "96      95     95   \n",
              "97      96     91   \n",
              "98      97     91   \n",
              "99      98     90   \n",
              "100     99     89   \n",
              "101    100     89   \n",
              "103    101     87   \n",
              "102    102     87   \n",
              "104    103     86   \n",
              "105    104     86   \n",
              "106    105     83   \n",
              "107    106     82   \n",
              "108    107     82   \n",
              "109    108     81   \n",
              "110    109     81   \n",
              "112    112     80   \n",
              "113    110     80   \n",
              "111    111     80   \n",
              "115    113     79   \n",
              "114    114     79   \n",
              "116    115     78   \n",
              "117    116     76   \n",
              "118    117     75   \n",
              "119    118     75   \n",
              "120    119     72   \n",
              "121    120     72   \n",
              "123    123     71   \n",
              "124    121     71   \n",
              "122    122     71   \n",
              "125    124     69   \n",
              "126    125     69   \n",
              "127    126     69   \n",
              "128    127     69   \n",
              "129    128     68   \n",
              "132    130     67   \n",
              "133    129     67   \n",
              "131    132     67   \n",
              "130    131     67   \n",
              "135    135     65   \n",
              "136    133     65   \n",
              "134    134     65   \n",
              "137    136     64   \n",
              "138    137     64   \n",
              "139    138     63   \n",
              "140    139     63   \n",
              "144    142     62   \n",
              "145    141     62   \n",
              "141    143     62   \n",
              "143    140     62   \n",
              "142    144     62   \n",
              "146    145     61   \n",
              "147    146     61   \n",
              "148    147     61   \n",
              "152    148     60   \n",
              "151    149     60   \n",
              "150    150     60   \n",
              "149    151     60   \n",
              "153    152     59   \n",
              "154    153     59   \n",
              "155    154     59   \n",
              "156    155     59   \n",
              "157    156     58   \n",
              "158    157     58   \n",
              "161    158     57   \n",
              "162    159     57   \n",
              "159    160     57   \n",
              "160    161     57   \n",
              "163    162     56   \n",
              "164    163     56   \n",
              "165    164     55   \n",
              "166    165     55   \n",
              "167    166     55   \n",
              "169    167     54   \n",
              "168    168     54   \n",
              "170    169     53   \n",
              "171    170     53   \n",
              "172    171     52   \n",
              "173    172     52   \n",
              "174    173     51   \n",
              "175    174     50   \n",
              "176    175     50   \n",
              "178    176     48   \n",
              "177    177     48   \n",
              "179    178     47   \n",
              "180    179     47   \n",
              "181    180     46   \n",
              "182    181     46   \n",
              "183    182     45   \n",
              "184    183     45   \n",
              "185    184     45   \n",
              "188    186     44   \n",
              "189    185     44   \n",
              "187    188     44   \n",
              "186    187     44   \n",
              "191    191     43   \n",
              "192    189     43   \n",
              "190    190     43   \n",
              "193    192     42   \n",
              "194    193     41   \n",
              "195    194     41   \n",
              "196    195     41   \n",
              "197    196     41   \n",
              "198    197     40   \n",
              "199    198     40   \n",
              "200    199     40   \n",
              "203    204     39   \n",
              "204    201     39   \n",
              "205    200     39   \n",
              "202    203     39   \n",
              "201    202     39   \n",
              "206    205     38   \n",
              "207    206     37   \n",
              "208    207     36   \n",
              "209    208     36   \n",
              "210    209     36   \n",
              "211    210     36   \n",
              "213    213     36   \n",
              "214    214     36   \n",
              "215    215     36   \n",
              "216    216     36   \n",
              "217    217     36   \n",
              "218    218     36   \n",
              "219    211     36   \n",
              "212    212     36   \n",
              "226    220     35   \n",
              "224    222     35   \n",
              "225    221     35   \n",
              "227    219     35   \n",
              "223    226     35   \n",
              "222    224     35   \n",
              "221    223     35   \n",
              "220    225     35   \n",
              "228    227     34   \n",
              "229    228     34   \n",
              "230    229     34   \n",
              "231    230     34   \n",
              "232    231     34   \n",
              "234    232     33   \n",
              "233    233     33   \n",
              "235    234     32   \n",
              "236    235     32   \n",
              "237    236     32   \n",
              "238    237     32   \n",
              "239    238     32   \n",
              "240    239     32   \n",
              "241    240     32   \n",
              "245    243     31   \n",
              "246    242     31   \n",
              "242    244     31   \n",
              "244    241     31   \n",
              "243    245     31   \n",
              "247    246     30   \n",
              "248    247     30   \n",
              "249    248     30   \n",
              "250    249     30   \n",
              "251    250     30   \n",
              "252    251     30   \n",
              "253    252     30   \n",
              "254    253     29   \n",
              "255    254     29   \n",
              "256    255     29   \n",
              "260    262     28   \n",
              "262    256     28   \n",
              "261    258     28   \n",
              "263    257     28   \n",
              "259    260     28   \n",
              "257    259     28   \n",
              "258    261     28   \n",
              "264    263     27   \n",
              "265    264     27   \n",
              "266    265     27   \n",
              "267    266     27   \n",
              "268    267     27   \n",
              "272    270     26   \n",
              "273    269     26   \n",
              "269    271     26   \n",
              "271    268     26   \n",
              "270    272     26   \n",
              "283    276     25   \n",
              "279    277     25   \n",
              "281    274     25   \n",
              "280    275     25   \n",
              "282    273     25   \n",
              "278    281     25   \n",
              "276    280     25   \n",
              "275    278     25   \n",
              "274    282     25   \n",
              "277    279     25   \n",
              "284    283     24   \n",
              "285    284     24   \n",
              "286    285     24   \n",
              "287    286     24   \n",
              "288    287     24   \n",
              "290    290     23   \n",
              "291    288     23   \n",
              "289    289     23   \n",
              "292    291     22   \n",
              "293    292     22   \n",
              "294    293     22   \n",
              "295    294     21   \n",
              "296    295     21   \n",
              "297    296     21   \n",
              "298    297     21   \n",
              "299    298     21   \n",
              "300    299     20   \n",
              "301    300     20   \n",
              "302    301     20   \n",
              "\n",
              "                                                             Name  \n",
              "0                            -1_people_mobile_objects_interactive  \n",
              "1                          0_language_linguistic_lexical_learners  \n",
              "2                              1_flow_vortex_vortices_velocimetry  \n",
              "3                          2_education_classroom_teaching_courses  \n",
              "4                3_recommendation_recommender_advertising_ratings  \n",
              "5                4_multidimensional_scatterplots_plots_dimensions  \n",
              "6                5_analytics_visualization_visualizations_infovis  \n",
              "7                                  6_gaze_eye_attention_movements  \n",
              "8                             7_haptic_tactile_force_vibrotactile  \n",
              "9                      8_classification_class_classifiers_feature  \n",
              "10                                  9_database_query_queries_join  \n",
              "11                          10_flow_streamlines_vortex_streamline  \n",
              "12                        11_illumination_light_scattering_photon  \n",
              "13                        12_mining_frequent_itemsets_association  \n",
              "14                               13_gesture_gestures_touch_finger  \n",
              "15                                  14_ray_rays_traversal_casting  \n",
              "16                           15_ultrasound_vessel_imaging_vessels  \n",
              "17                                   16_game_games_players_player  \n",
              "18                                      17_graphics_gks_cgi_phigs  \n",
              "19                       18_causal_reasoning_beliefs_explanations  \n",
              "20                              19_fluid_particle_particles_smoke  \n",
              "21                         20_trajectories_trajectory_spatio_city  \n",
              "22                       21_rehabilitation_exercise_exertion_game  \n",
              "23                   22_practice_research_designers_practitioners  \n",
              "24                          23_series_subsequence_patterns_mining  \n",
              "25                        24_texture_textures_synthesis_texturing  \n",
              "26                25_category_categorization_categories_exemplars  \n",
              "27                               26_robot_robots_robotic_robotics  \n",
              "28                 27_transaction_transactions_concurrency_commit  \n",
              "29                          28_crowdsourcing_workers_crowd_worker  \n",
              "30                              29_driving_driver_vehicle_drivers  \n",
              "31                       30_diagrams_diagrammatic_logic_reasoning  \n",
              "32                   31_usability_evaluation_testing_requirements  \n",
              "33                             32_keyboard_keyboards_touch_finger  \n",
              "34                                33_privacy_security_consent_app  \n",
              "35                 34_printing_fabrication_assembly_manufacturing  \n",
              "36                           35_fabrication_textile_touch_tactile  \n",
              "37                                   36_voice_speech_audio_spoken  \n",
              "38                               37_urban_buildings_building_city  \n",
              "39                           38_sketch_sketching_sketches_drawing  \n",
              "40                             39_graph_subgraph_graphs_subgraphs  \n",
              "41                   40_mobility_trajectories_trajectory_location  \n",
              "42                         41_motion_motions_animation_locomotion  \n",
              "43                           42_symbolic_magnitude_numbers_number  \n",
              "44                                 43_facial_face_animation_faces  \n",
              "45                            44_fairness_deep_explanations_trust  \n",
              "46                        45_influence_diffusion_networks_network  \n",
              "48                                46_social_privacy_media_friends  \n",
              "47                               47_graph_graphs_network_networks  \n",
              "49                 48_molecules_simulations_cavities_cosmological  \n",
              "50                          49_ensemble_weather_climate_ensembles  \n",
              "51                               50_spline_splines_cubic_surfaces  \n",
              "52                              51_rendering_gpu_splatting_volume  \n",
              "53                             52_label_labels_unlabeled_instance  \n",
              "54                       53_impaired_visually_tactile_impairments  \n",
              "55                   54_communities_wikipedia_community_newcomers  \n",
              "56                        55_displays_navigation_display_overview  \n",
              "57                          56_light_illumination_lighting_camera  \n",
              "58                              57_painting_brush_paintings_paint  \n",
              "59                        58_privacy_private_preserving_anonymity  \n",
              "60                               59_color_colors_palettes_palette  \n",
              "61                             60_smart_homes_living_technologies  \n",
              "62                              61_twitter_tweets_media_sentiment  \n",
              "63                                62_art_artist_artistic_creative  \n",
              "64                            63_patient_care_hospital_clinicians  \n",
              "65                         64_crowd_crowds_simulation_pedestrians  \n",
              "66                              65_shadow_shadows_light_rendering  \n",
              "68                     66_clustering_clusters_cluster_clusterings  \n",
              "67                              67_attention_visual_target_memory  \n",
              "69                                  68_twitter_tweets_media_rumor  \n",
              "70                              69_gesture_gestures_sign_language  \n",
              "71                         70_code_programmers_debugging_software  \n",
              "72                          71_deformable_spring_elastic_fracture  \n",
              "73                  72_passwords_authentication_password_security  \n",
              "74                          73_retrieval_images_similarity_photos  \n",
              "77                                75_layout_graph_bundling_graphs  \n",
              "75                                76_gene_genome_genomic_pedigree  \n",
              "76                            74_topic_cloud_visualizations_words  \n",
              "78                                  77_lidar_vehicle_road_driving  \n",
              "79                        78_series_trend_analytics_visualization  \n",
              "80                             79_choice_risky_decision_decisions  \n",
              "81                            80_embedding_graph_network_networks  \n",
              "82                       81_walking_virtual_locomotion_navigation  \n",
              "83                                     82_urban_city_cities_place  \n",
              "84                                83_search_web_tagging_searching  \n",
              "85                           84_patient_clinical_patients_medical  \n",
              "86               85_interfaces_accessibility_interface_adaptation  \n",
              "87                           86_image_inpainting_denoising_filter  \n",
              "88                           87_solid_solids_geometric_polyhedral  \n",
              "89                             88_health_diabetes_care_medication  \n",
              "90                            89_vehicles_vehicle_driving_traffic  \n",
              "91                         90_volume_volumetric_rendering_opacity  \n",
              "92         91_classification_categorization_clustering_classifier  \n",
              "95                              92_activities_sensor_sensors_food  \n",
              "94                 93_segmentation_watershed_superpixel_foresting  \n",
              "93                             94_extraction_web_template_wrapper  \n",
              "96              95_consumption_electricity_households_sustainable  \n",
              "97                            96_rfid_indoor_location_positioning  \n",
              "98                                    97_reality_vr_virtual_mixed  \n",
              "99                                       98_xml_xquery_query_twig  \n",
              "100                        99_graphics_hardware_vlsi_architecture  \n",
              "101               100_rendering_graphics_architecture_parallelism  \n",
              "103                            101_fractal_fractals_chaos_terrain  \n",
              "102                      102_distributed_scientific_parallel_grid  \n",
              "104                           103_civic_civics_citizens_practices  \n",
              "105                           104_moral_dilemmas_morality_morally  \n",
              "106                 105_map_cartographic_geographical_cartography  \n",
              "107                      106_editorial_papers_preface_publication  \n",
              "108                             107_topic_topics_dirichlet_latent  \n",
              "109         108_correspondence_isometric_correspondences_matching  \n",
              "110                          109_museum_museums_visitors_heritage  \n",
              "112                 112_subdivision_surfaces_interpolatory_meshes  \n",
              "113                    110_community_communities_networks_network  \n",
              "111                   111_landmarks_navigation_wayfinding_spatial  \n",
              "115                           113_pointing_target_movement_cursor  \n",
              "114                               114_music_musical_sound_melodic  \n",
              "116                          115_sentence_comprehension_verb_gaze  \n",
              "117                116_heritage_archaeological_museum_exhibitions  \n",
              "118                   117_analogical_analogy_analogies_relational  \n",
              "119                      118_simplification_mesh_meshes_polygonal  \n",
              "120                             119_narrative_story_video_stories  \n",
              "121                            120_compression_mesh_meshes_coding  \n",
              "123                123_brain_connectivity_neurons_neuroscientists  \n",
              "124                               121_sports_soccer_player_tennis  \n",
              "122                          122_battery_energy_sensing_occupancy  \n",
              "125                         124_segmentation_image_breast_imaging  \n",
              "126                       125_chat_chatbot_chatbots_conversations  \n",
              "127                             126_diffusion_tensor_tracts_brain  \n",
              "128                           127_brdf_reflectance_brdfs_specular  \n",
              "129                      128_conversational_dialogue_agent_agents  \n",
              "132                               130_email_mail_emails_workplace  \n",
              "133                             129_parents_care_parenting_health  \n",
              "131                         132_health_communities_patients_teens  \n",
              "130                     131_motion_camera_reconstruction_tracking  \n",
              "135                               135_gesture_gestures_hand_wrist  \n",
              "136                          133_security_traffic_cyber_intrusion  \n",
              "134                       134_clothing_clothes_aesthetic_garments  \n",
              "137                     136_augmented_reality_virtual_prototyping  \n",
              "138                              137_neural_spiking_neurons_brain  \n",
              "139                        138_outlier_outliers_datasets_distance  \n",
              "140                      139_narrative_story_storytelling_stories  \n",
              "144          142_collaboration_teams_organizational_collaborative  \n",
              "145                              141_dynamic_graphs_graph_network  \n",
              "141                                143_tone_images_contrast_image  \n",
              "143             140_metaphors_metaphor_metaphorical_comprehension  \n",
              "142                           144_brain_stress_cognitive_infrared  \n",
              "146                            145_matting_image_camera_stitching  \n",
              "147                      146_surgical_surgery_endoscopy_minimally  \n",
              "148             147_collaborative_collaboration_groupware_editing  \n",
              "152                         148_drift_ensemble_drifting_streaming  \n",
              "151                     149_face_biometric_recognition_descriptor  \n",
              "150                              150_math_students_solving_posing  \n",
              "149                          151_olfactory_odor_arousal_breathing  \n",
              "153                                  152_music_musical_songs_song  \n",
              "154                                    153_reading_books_ink_book  \n",
              "155                      154_entity_entities_named_disambiguation  \n",
              "156                155_crop_precipitation_forecasting_agriculture  \n",
              "157                       156_nearest_neighbor_hashing_similarity  \n",
              "158                        157_animation_animated_motion_graphics  \n",
              "161                          158_musical_music_musicians_creative  \n",
              "162                                   159_tree_trees_plant_plants  \n",
              "159                      160_customer_marketing_customers_pricing  \n",
              "160                    161_location_privacy_crowdsensing_services  \n",
              "163                                162_remeshing_mesh_meshes_quad  \n",
              "164              163_coordination_interpersonal_synchrony_partner  \n",
              "165                          164_cleaning_repairing_repair_tuples  \n",
              "166                   165_parallel_cache_compiler_multiprocessors  \n",
              "167                    166_shape_descriptor_descriptors_retrieval  \n",
              "169                          167_video_videos_surveillance_frames  \n",
              "168  168_interruptions_interruption_interruptibility_multitasking  \n",
              "170                         169_aneurysm_aneurysms_rupture_vessel  \n",
              "171         170_dialogue_interlocutors_miscommunication_syntactic  \n",
              "172              171_wavelet_wavelets_multiresolution_subdivision  \n",
              "173                  172_terrain_terrains_rendering_triangulation  \n",
              "174                            173_creativity_creative_ideas_idea  \n",
              "175                           174_recognition_video_videos_motion  \n",
              "176             175_messaging_meetings_communication_conversation  \n",
              "178                     176_collision_collisions_deformable_rigid  \n",
              "177                 177_location_recommendation_friends_locations  \n",
              "179                     178_sound_acoustic_listener_reverberation  \n",
              "180                    179_subspace_clusters_clustering_subspaces  \n",
              "181                               180_route_map_wayfinding_travel  \n",
              "182                    181_tabletop_collaboration_touch_groupware  \n",
              "183                       182_papers_symposium_pacific_pacificvis  \n",
              "184                      183_memory_associative_episodic_memories  \n",
              "185                  184_developers_source_metrics_visualizations  \n",
              "188                        186_skeleton_skeletons_thinning_shapes  \n",
              "189                        185_graph_graphs_partitioning_subgraph  \n",
              "187                       188_game_games_educational_gamification  \n",
              "186                  187_watermarking_watermark_watermarks_scheme  \n",
              "191                 191_children_participatory_child_preschoolers  \n",
              "192                                189_video_couples_sharing_chat  \n",
              "190                         190_causal_infants_reasoning_evidence  \n",
              "193                       192_desktop_monitor_windowscape_display  \n",
              "194                193_fabrication_digital_prototyping_production  \n",
              "195                      194_spatial_linguistic_geocentric_verbal  \n",
              "196                                 195_games_game_avatar_phobias  \n",
              "197                      196_convergence_descent_gradient_machine  \n",
              "198                197_memories_reminiscence_lifelogging_everyday  \n",
              "199                              198_event_events_records_cohorts  \n",
              "200                       199_tracking_tracker_trackers_detection  \n",
              "203                    204_occlusion_culling_rendering_visibility  \n",
              "204                        201_diagrams_students_diagram_teachers  \n",
              "205                      200_emotions_emotional_emotion_affective  \n",
              "202                   203_teaching_teacher_learners_misconception  \n",
              "201                       202_cognitive_mind_emergence_enactivism  \n",
              "206             205_archaeological_heritage_immersive_archaeology  \n",
              "207                               206_hair_hairs_hairstyles_furry  \n",
              "208                    207_reconstruction_surface_surfaces_smooth  \n",
              "209                         208_autism_children_intervention_play  \n",
              "210                       209_dance_dancers_dancer_choreographers  \n",
              "211                          210_ontology_ontologies_rdf_semantic  \n",
              "213                       213_traffic_prediction_travel_passenger  \n",
              "214                     214_matrix_factorization_nonnegative_norm  \n",
              "215                   215_treemap_treemaps_hierarchical_hierarchy  \n",
              "216                   216_projector_camera_calibration_projection  \n",
              "217                   217_polygons_polygon_triangulation_vertices  \n",
              "218                  218_graphical_specification_graphics_graphic  \n",
              "219                          211_optical_displays_mounted_glasses  \n",
              "212                         212_graph_graphs_classification_label  \n",
              "226                  220_clipping_algorithm_sutherland_algorithms  \n",
              "224                                222_web_browser_browsing_pages  \n",
              "225                              221_scrolling_scroll_flick_menus  \n",
              "227                 219_disease_alzheimer_biomarkers_connectivity  \n",
              "223             226_spreadsheet_spreadsheets_photospread_formulas  \n",
              "222              224_ubicomp_ubiquitous_activitydesigner_products  \n",
              "221                           223_tracking_pose_camera_markerless  \n",
              "220                        225_web_pskip_personalization_crawling  \n",
              "228                                227_game_games_players_pokémon  \n",
              "229                             228_task_control_switch_cognitive  \n",
              "230                      229_skeleton_skinning_animation_skeletal  \n",
              "231                 230_multimodal_modality_modalities_interfaces  \n",
              "232                                231_spatial_join_joins_queries  \n",
              "234                         232_morphing_shape_deformation_shapes  \n",
              "233               233_construction_visualisation_building_project  \n",
              "235                       234_particle_particles_rendering_volume  \n",
              "236                           235_insight_solving_hint_subliminal  \n",
              "237                     236_neural_deep_convolutional_recognition  \n",
              "238                  237_citation_papers_publications_publication  \n",
              "239                 238_collaborative_analysts_collaboration_team  \n",
              "240                        239_uims_interface_interfaces_dialogue  \n",
              "241                            240_cloth_draping_deformation_mesh  \n",
              "245                           243_lstm_driving_vehicle_prediction  \n",
              "246                        242_provenance_workflows_workflow_lake  \n",
              "242                               244_color_grayscale_colors_gray  \n",
              "244         241_translation_multilingual_translations_translators  \n",
              "243            245_labeling_classifier_classifiers_classification  \n",
              "247                           246_motion_capture_motions_indexing  \n",
              "248                          247_geodesic_meshes_coordinates_mesh  \n",
              "249                  248_touch_visualizations_displays_touchpivot  \n",
              "250                    249_animation_animated_animations_learners  \n",
              "251                                250_location_travel_places_map  \n",
              "252                             251_video_videos_browsing_history  \n",
              "253                        252_discovery_knowledge_mining_science  \n",
              "254                               253_context_aware_campus_mobile  \n",
              "255                          254_saliency_salient_detection_image  \n",
              "256                             255_motor_stimulus_action_actions  \n",
              "260                           262_finger_touch_fingertip_touchpad  \n",
              "262                      256_encrypted_encryption_secure_security  \n",
              "261                        258_experiments_testing_online_metrics  \n",
              "263                        257_gene_genes_microarray_biclustering  \n",
              "259                             260_columns_columnar_stores_store  \n",
              "257                    259_training_immersive_simulation_trainees  \n",
              "258                              261_facial_recognition_face_deep  \n",
              "264                  263_immersive_reality_virtual_visualizations  \n",
              "265                                 264_color_naming_words_colors  \n",
              "266                        265_graphs_networks_evolving_subgraphs  \n",
              "267                            266_underwater_seabed_plume_marine  \n",
              "268                   267_religion_religious_beliefs_supernatural  \n",
              "272                          270_hash_query_processor_parallelism  \n",
              "273                      269_birdhouse_bird_nurturing_touchscreen  \n",
              "269                           271_segmentation_mesh_cutting_snake  \n",
              "271                            268_polygons_surface_polygon_scene  \n",
              "270                     272_blockchain_blockchains_bitcoin_ledger  \n",
              "283                  276_cultural_culturally_usability_dimensions  \n",
              "279                           277_drivers_transit_passengers_ride  \n",
              "281                 274_crowdfunding_donations_campaign_campaigns  \n",
              "280                             275_ocean_water_sea_oceanographic  \n",
              "282                        273_achievement_goals_students_mastery  \n",
              "278                             281_displays_ambient_studies_pids  \n",
              "276                           280_mesh_filtering_smoothing_filter  \n",
              "275                         278_web_search_semantic_visualisation  \n",
              "274                    282_geometric_quaternions_algebra_geometry  \n",
              "277                        279_string_strings_similarity_indexing  \n",
              "284                           283_schema_schemas_coma_integration  \n",
              "285                           284_reward_options_foraging_rewards  \n",
              "286                       285_metric_dissimilarity_sparse_kernels  \n",
              "287                          286_temporal_speakers_past_metaphors  \n",
              "288                                287_tasks_task_mtl_relatedness  \n",
              "290                   290_registration_alignment_rigid_deformable  \n",
              "291                               288_tensor_tensors_glyph_glyphs  \n",
              "289                        289_sleep_sleeping_circadian_somnolent  \n",
              "292                   291_projector_handheld_projection_projected  \n",
              "293                     292_transitions_animated_animation_parser  \n",
              "294                                293_flash_nvm_storage_database  \n",
              "295                   294_circuit_circuits_electronics_breadboard  \n",
              "296                        295_diagrammatic_syntax_codecharts_uml  \n",
              "297                296_tensor_tensors_decomposition_factorization  \n",
              "298                            297_buffer_shading_pixel_rendering  \n",
              "299                        298_cultural_evolution_copying_fitness  \n",
              "300                           299_movements_saccade_gaze_saccades  \n",
              "301                                   300_lens_lenses_ray_optical  \n",
              "302                    301_graphical_interfaces_graphic_interface  "
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m5j1xZ5FxeUC"
      },
      "source": [
        "reduce_model2 = BERTopic(embedding_model=sentence_model, nr_topics=\"auto\").fit(title_abs)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "-v3ydzIwlJuX",
        "outputId": "9d0bdbde-494b-40a9-958b-9c45d999dd49"
      },
      "source": [
        "reduce_model2.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>29977</td>\n",
              "      <td>-1_mobile_social_people_interaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>933</td>\n",
              "      <td>0_language_linguistic_lexical_verb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>824</td>\n",
              "      <td>1_flow_vortex_vortices_fluid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>689</td>\n",
              "      <td>2_graph_graphs_networks_subgraph</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>554</td>\n",
              "      <td>3_mesh_meshes_subdivision_triangle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>521</td>\n",
              "      <td>4_database_query_queries_join</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>519</td>\n",
              "      <td>5_light_illumination_rendering_photon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>513</td>\n",
              "      <td>6_clustering_community_networks_communities</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>498</td>\n",
              "      <td>7_recommendation_recommender_advertising_bid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>450</td>\n",
              "      <td>8_gaze_eye_attention_eyes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>443</td>\n",
              "      <td>9_animation_motion_motions_animated</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>423</td>\n",
              "      <td>10_driving_vehicle_vehicles_driver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>391</td>\n",
              "      <td>11_multidimensional_dimensional_scatterplots_dimensions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>389</td>\n",
              "      <td>12_crowd_crowdsourcing_workers_crowds</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>385</td>\n",
              "      <td>13_series_patterns_subsequence_mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>367</td>\n",
              "      <td>14_game_games_players_player</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>362</td>\n",
              "      <td>15_trajectories_trajectory_mobility_urban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>315</td>\n",
              "      <td>16_patient_health_patients_care</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>296</td>\n",
              "      <td>17_frequent_mining_itemsets_patterns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18</td>\n",
              "      <td>290</td>\n",
              "      <td>18_haptic_tactile_force_vibrotactile</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19</td>\n",
              "      <td>284</td>\n",
              "      <td>19_facial_face_faces_animation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>276</td>\n",
              "      <td>20_creativity_painting_creative_artistic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21</td>\n",
              "      <td>271</td>\n",
              "      <td>21_gesture_gestures_sign_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>262</td>\n",
              "      <td>22_topic_topics_dirichlet_collections</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23</td>\n",
              "      <td>254</td>\n",
              "      <td>23_brain_cognitive_cognition_spiking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24</td>\n",
              "      <td>240</td>\n",
              "      <td>24_graphics_gks_standards_cgi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>25</td>\n",
              "      <td>238</td>\n",
              "      <td>25_diagrams_diagrammatic_diagram_logic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>234</td>\n",
              "      <td>26_category_categorization_categories_generalization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>229</td>\n",
              "      <td>27_visualizations_infovis_visualization_studies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>28</td>\n",
              "      <td>222</td>\n",
              "      <td>28_authentication_passwords_security_attacks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29</td>\n",
              "      <td>217</td>\n",
              "      <td>29_classification_classifiers_classifier_ensemble</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>214</td>\n",
              "      <td>30_robot_robots_robotic_robotics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>31</td>\n",
              "      <td>212</td>\n",
              "      <td>31_fabrication_printing_assembly_manufacturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>32</td>\n",
              "      <td>210</td>\n",
              "      <td>32_causal_counterfactual_explanations_causation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>33</td>\n",
              "      <td>205</td>\n",
              "      <td>33_texture_textures_synthesis_texturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>34</td>\n",
              "      <td>199</td>\n",
              "      <td>34_code_programming_programmers_software</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>35</td>\n",
              "      <td>195</td>\n",
              "      <td>35_memory_attention_task_cognitive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>36</td>\n",
              "      <td>190</td>\n",
              "      <td>36_vessel_vessels_aneurysms_aneurysm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>37</td>\n",
              "      <td>189</td>\n",
              "      <td>37_voice_speech_audio_voices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38</td>\n",
              "      <td>188</td>\n",
              "      <td>38_correspondence_matching_descriptor_correspondences</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>39</td>\n",
              "      <td>186</td>\n",
              "      <td>39_twitter_tweets_microblog_tweet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>40</td>\n",
              "      <td>183</td>\n",
              "      <td>40_weather_climate_ensembles_seismic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>41</td>\n",
              "      <td>175</td>\n",
              "      <td>41_music_musical_listening_musicians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>42</td>\n",
              "      <td>172</td>\n",
              "      <td>42_collaboration_collaborative_teams_team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>172</td>\n",
              "      <td>43_sensor_activities_sensors_sensing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>44</td>\n",
              "      <td>170</td>\n",
              "      <td>44_heritage_archaeological_historic_excavation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>45</td>\n",
              "      <td>168</td>\n",
              "      <td>45_narrative_story_stories_storytelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>46</td>\n",
              "      <td>167</td>\n",
              "      <td>46_color_colors_palette_palettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>47</td>\n",
              "      <td>166</td>\n",
              "      <td>47_transaction_transactions_concurrency_commit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>48</td>\n",
              "      <td>165</td>\n",
              "      <td>48_keyboard_keyboards_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>49</td>\n",
              "      <td>164</td>\n",
              "      <td>49_reality_augmented_vr_virtual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50</td>\n",
              "      <td>158</td>\n",
              "      <td>50_conversational_dialogue_conversations_conversation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>51</td>\n",
              "      <td>157</td>\n",
              "      <td>51_electricity_smart_households_homes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>52</td>\n",
              "      <td>156</td>\n",
              "      <td>52_privacy_private_anonymization_preserving</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>53</td>\n",
              "      <td>154</td>\n",
              "      <td>53_distributed_parallel_experiments_scientific</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>54</td>\n",
              "      <td>152</td>\n",
              "      <td>54_processor_graphics_hardware_processors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>55</td>\n",
              "      <td>146</td>\n",
              "      <td>55_displays_navigation_display_magnification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>56</td>\n",
              "      <td>146</td>\n",
              "      <td>56_urban_buildings_city_building</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>57</td>\n",
              "      <td>145</td>\n",
              "      <td>57_gene_genes_genome_genomic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>58</td>\n",
              "      <td>142</td>\n",
              "      <td>58_deep_machine_learning_convolutional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>59</td>\n",
              "      <td>142</td>\n",
              "      <td>59_ray_rays_casting_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>60</td>\n",
              "      <td>141</td>\n",
              "      <td>60_choice_risky_choices_options</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61</td>\n",
              "      <td>137</td>\n",
              "      <td>61_fluid_fluids_particle_particles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>62</td>\n",
              "      <td>136</td>\n",
              "      <td>62_solid_solids_polyhedral_constraint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63</td>\n",
              "      <td>134</td>\n",
              "      <td>63_video_videos_browsing_content</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>64</td>\n",
              "      <td>132</td>\n",
              "      <td>64_spline_splines_curves_interpolation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>65</td>\n",
              "      <td>129</td>\n",
              "      <td>65_search_web_tagging_searching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>66</td>\n",
              "      <td>128</td>\n",
              "      <td>66_impaired_visually_tactile_impairments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>67</td>\n",
              "      <td>126</td>\n",
              "      <td>67_wikipedia_communities_community_newcomers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>68</td>\n",
              "      <td>125</td>\n",
              "      <td>68_volume_volumetric_rendering_opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>69</td>\n",
              "      <td>123</td>\n",
              "      <td>69_shadow_shadows_light_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>70</td>\n",
              "      <td>122</td>\n",
              "      <td>70_practice_research_ethical_designers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>71</td>\n",
              "      <td>122</td>\n",
              "      <td>71_magnitude_numbers_number_acuity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>72</td>\n",
              "      <td>120</td>\n",
              "      <td>72_classroom_teachers_education_educational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>73</td>\n",
              "      <td>118</td>\n",
              "      <td>73_museum_visitors_museums_exhibition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>74</td>\n",
              "      <td>116</td>\n",
              "      <td>74_route_navigation_map_wayfinding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>75</td>\n",
              "      <td>114</td>\n",
              "      <td>75_sketching_sketch_sketches_drawing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>76</td>\n",
              "      <td>113</td>\n",
              "      <td>76_papers_editorial_conference_symposium</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>77</td>\n",
              "      <td>113</td>\n",
              "      <td>77_tracking_motion_tracker_pose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>78</td>\n",
              "      <td>107</td>\n",
              "      <td>78_reading_books_readers_comprehension</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>79</td>\n",
              "      <td>105</td>\n",
              "      <td>79_extraction_web_template_wrapper</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>80_retrieval_images_similarity_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>81</td>\n",
              "      <td>99</td>\n",
              "      <td>81_segmentation_watershed_superpixel_foresting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>82</td>\n",
              "      <td>99</td>\n",
              "      <td>82_molecules_molecule_simulations_atoms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>83</td>\n",
              "      <td>98</td>\n",
              "      <td>83_brdf_reflectance_brdfs_specular</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>84</td>\n",
              "      <td>98</td>\n",
              "      <td>84_social_privacy_friends_disclosures</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>85</td>\n",
              "      <td>97</td>\n",
              "      <td>85_contact_elastic_fracture_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>86</td>\n",
              "      <td>95</td>\n",
              "      <td>86_ai_insight_solving_agent</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>87</td>\n",
              "      <td>93</td>\n",
              "      <td>87_rfid_indoor_localization_location</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>88</td>\n",
              "      <td>92</td>\n",
              "      <td>88_xml_xquery_query_twig</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>89</td>\n",
              "      <td>91</td>\n",
              "      <td>89_interfaces_accessibility_interface_platform</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>90</td>\n",
              "      <td>91</td>\n",
              "      <td>90_teaching_education_courses_course</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>91</td>\n",
              "      <td>90</td>\n",
              "      <td>91_usability_evaluation_testing_developers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>92</td>\n",
              "      <td>90</td>\n",
              "      <td>92_denoising_smoothing_deblurring_blur</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>93</td>\n",
              "      <td>89</td>\n",
              "      <td>93_matrix_factorization_convergence_distributed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>94</td>\n",
              "      <td>89</td>\n",
              "      <td>94_ocean_underwater_water_seabed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>95</td>\n",
              "      <td>87</td>\n",
              "      <td>95_fractal_fractals_chaos_terrain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>96</td>\n",
              "      <td>87</td>\n",
              "      <td>96_location_recommendation_locations_mobility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>97</td>\n",
              "      <td>86</td>\n",
              "      <td>97_kernel_discriminant_subspace_sparse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>98</td>\n",
              "      <td>86</td>\n",
              "      <td>98_surgical_surgery_haptic_laparoscopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>99</td>\n",
              "      <td>85</td>\n",
              "      <td>99_email_emails_mail_clients</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>100</td>\n",
              "      <td>85</td>\n",
              "      <td>100_pointing_cursor_movement_clutching</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>101</td>\n",
              "      <td>84</td>\n",
              "      <td>101_moral_dilemmas_morality_morally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>102</td>\n",
              "      <td>82</td>\n",
              "      <td>102_analytics_analysts_business_insight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>103</td>\n",
              "      <td>81</td>\n",
              "      <td>103_fields_scalar_topology_geometric</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>104</td>\n",
              "      <td>79</td>\n",
              "      <td>104_privacy_app_apps_policies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>105</td>\n",
              "      <td>77</td>\n",
              "      <td>105_stereo_depth_camera_stereoscopic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>106</td>\n",
              "      <td>74</td>\n",
              "      <td>106_walking_locomotion_virtual_flying</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>107</td>\n",
              "      <td>74</td>\n",
              "      <td>107_political_civic_civics_citizens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>108</td>\n",
              "      <td>73</td>\n",
              "      <td>108_home_aware_context_ubiquitous</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>109</td>\n",
              "      <td>73</td>\n",
              "      <td>109_garment_garments_clothing_clothes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>110</td>\n",
              "      <td>73</td>\n",
              "      <td>110_terrain_terrains_rendering_elevation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>111</td>\n",
              "      <td>73</td>\n",
              "      <td>111_analogical_analogy_analogies_relational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>112</td>\n",
              "      <td>72</td>\n",
              "      <td>112_outlier_outliers_anomaly_streams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>113</td>\n",
              "      <td>71</td>\n",
              "      <td>113_treemap_treemaps_tree_hierarchies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>114</td>\n",
              "      <td>70</td>\n",
              "      <td>114_event_events_records_streams</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>115</td>\n",
              "      <td>69</td>\n",
              "      <td>115_emotional_emotions_emotion_humor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>116</td>\n",
              "      <td>69</td>\n",
              "      <td>116_column_workloads_stores_columns</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>117</td>\n",
              "      <td>69</td>\n",
              "      <td>117_diffusion_tensor_tracts_brain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>118</td>\n",
              "      <td>68</td>\n",
              "      <td>118_collision_deformable_collisions_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>119</td>\n",
              "      <td>67</td>\n",
              "      <td>119_exertion_exergame_exergames_game</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>120</td>\n",
              "      <td>66</td>\n",
              "      <td>120_plant_tree_trees_plants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>121</td>\n",
              "      <td>66</td>\n",
              "      <td>121_interruptions_interruption_interruptibility_interrupted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>122</td>\n",
              "      <td>66</td>\n",
              "      <td>122_aesthetics_aesthetic_somaesthetics_beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>124</td>\n",
              "      <td>64</td>\n",
              "      <td>124_sports_soccer_tennis_player</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>125</td>\n",
              "      <td>64</td>\n",
              "      <td>125_graphical_graphics_graphic_dialogue</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>123</td>\n",
              "      <td>64</td>\n",
              "      <td>123_touch_mobile_displays_display</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>126</td>\n",
              "      <td>63</td>\n",
              "      <td>126_streams_drift_ensemble_drifting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>127</td>\n",
              "      <td>63</td>\n",
              "      <td>127_label_labels_instances_unlabeled</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>62</td>\n",
              "      <td>128_rehabilitation_exercise_exercises_limb</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>129</td>\n",
              "      <td>61</td>\n",
              "      <td>129_projector_camera_calibration_projection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>130</td>\n",
              "      <td>60</td>\n",
              "      <td>130_coordination_interpersonal_synchrony_partner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>131</td>\n",
              "      <td>60</td>\n",
              "      <td>131_metaphor_metaphors_metaphorical_adjective</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>133</th>\n",
              "      <td>132</td>\n",
              "      <td>59</td>\n",
              "      <td>132_flight_virtual_immersive_golf</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>134</th>\n",
              "      <td>133</td>\n",
              "      <td>59</td>\n",
              "      <td>133_matting_video_stitching_panoramic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>138</th>\n",
              "      <td>136</td>\n",
              "      <td>58</td>\n",
              "      <td>136_citation_publications_literature_citations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>140</th>\n",
              "      <td>135</td>\n",
              "      <td>58</td>\n",
              "      <td>135_menu_finger_touch_menus</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>139</th>\n",
              "      <td>134</td>\n",
              "      <td>58</td>\n",
              "      <td>134_nearest_neighbor_search_similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137</th>\n",
              "      <td>138</td>\n",
              "      <td>58</td>\n",
              "      <td>138_transportation_travel_passengers_drivers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>135</th>\n",
              "      <td>137</td>\n",
              "      <td>58</td>\n",
              "      <td>137_math_students_solving_problems</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>136</th>\n",
              "      <td>139</td>\n",
              "      <td>58</td>\n",
              "      <td>139_sound_acoustic_listener_reverberation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>141</th>\n",
              "      <td>140</td>\n",
              "      <td>56</td>\n",
              "      <td>140_tensor_tensors_decomposition_factorization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>142</th>\n",
              "      <td>141</td>\n",
              "      <td>56</td>\n",
              "      <td>141_memory_associative_binding_episodic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>143</th>\n",
              "      <td>142</td>\n",
              "      <td>56</td>\n",
              "      <td>142_question_answering_answer_ranking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>144</th>\n",
              "      <td>143</td>\n",
              "      <td>56</td>\n",
              "      <td>143_marketing_customers_price_pricing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>146</th>\n",
              "      <td>144</td>\n",
              "      <td>55</td>\n",
              "      <td>144_entity_entities_named_disambiguation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>145</th>\n",
              "      <td>145</td>\n",
              "      <td>55</td>\n",
              "      <td>145_wavelet_wavelets_multiresolution_subdivision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>147</th>\n",
              "      <td>146</td>\n",
              "      <td>54</td>\n",
              "      <td>146_video_couples_communication_sharing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>148</th>\n",
              "      <td>147</td>\n",
              "      <td>54</td>\n",
              "      <td>147_credit_financial_fraud_banking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>149</th>\n",
              "      <td>148</td>\n",
              "      <td>54</td>\n",
              "      <td>148_motion_motions_mocap_capture</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>150</th>\n",
              "      <td>149</td>\n",
              "      <td>53</td>\n",
              "      <td>149_segmentation_mesh_segmentations_snake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>151</th>\n",
              "      <td>150</td>\n",
              "      <td>53</td>\n",
              "      <td>150_mind_cultural_religion_religious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>152</th>\n",
              "      <td>151</td>\n",
              "      <td>53</td>\n",
              "      <td>151_students_courses_course_student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>153</th>\n",
              "      <td>152</td>\n",
              "      <td>52</td>\n",
              "      <td>152_tabletop_collaboration_touch_groupware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>154</th>\n",
              "      <td>153</td>\n",
              "      <td>51</td>\n",
              "      <td>153_cartograms_cartogram_map_maps</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>156</th>\n",
              "      <td>154</td>\n",
              "      <td>49</td>\n",
              "      <td>154_meetings_remote_collaboration_conferencing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>155</th>\n",
              "      <td>155</td>\n",
              "      <td>49</td>\n",
              "      <td>155_teaching_teacher_teachers_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>157</th>\n",
              "      <td>156</td>\n",
              "      <td>48</td>\n",
              "      <td>156_pagerank_web_personalized_personalization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>158</th>\n",
              "      <td>157</td>\n",
              "      <td>47</td>\n",
              "      <td>157_cloth_woven_fabrics_fibers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>159</th>\n",
              "      <td>158</td>\n",
              "      <td>47</td>\n",
              "      <td>158_recognition_video_videos_descriptor</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>160</th>\n",
              "      <td>159</td>\n",
              "      <td>47</td>\n",
              "      <td>159_browser_web_browsing_pages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>161</th>\n",
              "      <td>160</td>\n",
              "      <td>47</td>\n",
              "      <td>160_memories_reminiscence_narratives_photos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>162</th>\n",
              "      <td>161</td>\n",
              "      <td>46</td>\n",
              "      <td>161_provenance_lakes_datamaran_workflows</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>163</th>\n",
              "      <td>162</td>\n",
              "      <td>46</td>\n",
              "      <td>162_cultural_culture_evolution_culturally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>166</th>\n",
              "      <td>164</td>\n",
              "      <td>44</td>\n",
              "      <td>164_watermarking_watermark_watermarks_steganographic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>164</th>\n",
              "      <td>165</td>\n",
              "      <td>44</td>\n",
              "      <td>165_children_child_comicboarding_team</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>165</th>\n",
              "      <td>163</td>\n",
              "      <td>44</td>\n",
              "      <td>163_discovery_knowledge_mining_databases</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>169</th>\n",
              "      <td>166</td>\n",
              "      <td>43</td>\n",
              "      <td>166_rule_rules_association_fuzzy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>170</th>\n",
              "      <td>167</td>\n",
              "      <td>43</td>\n",
              "      <td>167_temporal_duration_events_spatial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>167</th>\n",
              "      <td>168</td>\n",
              "      <td>43</td>\n",
              "      <td>168_retinal_lens_lenses_glaucoma</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>168</th>\n",
              "      <td>169</td>\n",
              "      <td>43</td>\n",
              "      <td>169_touch_finger_fingers_hand</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>174</th>\n",
              "      <td>172</td>\n",
              "      <td>42</td>\n",
              "      <td>172_occlusion_culling_occluders_visibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>175</th>\n",
              "      <td>171</td>\n",
              "      <td>42</td>\n",
              "      <td>171_morphing_deformation_shape_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>171</th>\n",
              "      <td>173</td>\n",
              "      <td>42</td>\n",
              "      <td>173_achievement_students_exam_learners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>173</th>\n",
              "      <td>170</td>\n",
              "      <td>42</td>\n",
              "      <td>170_ontology_ontologies_rdf_semantic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>172</th>\n",
              "      <td>174</td>\n",
              "      <td>42</td>\n",
              "      <td>174_autism_children_therapy_intervention</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>176</th>\n",
              "      <td>175</td>\n",
              "      <td>41</td>\n",
              "      <td>175_embedding_node_network_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>177</th>\n",
              "      <td>176</td>\n",
              "      <td>41</td>\n",
              "      <td>176_schema_schemas_integration_ontology</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>178</th>\n",
              "      <td>177</td>\n",
              "      <td>41</td>\n",
              "      <td>177_optical_displays_display_mounted</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>179</th>\n",
              "      <td>178</td>\n",
              "      <td>40</td>\n",
              "      <td>178_tutors_tutoring_pedagogical_educational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>180</th>\n",
              "      <td>179</td>\n",
              "      <td>39</td>\n",
              "      <td>179_spatial_meaning_geocentric_verbal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>181</th>\n",
              "      <td>180</td>\n",
              "      <td>39</td>\n",
              "      <td>180_point_clouds_reconstruction_cloud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>182</th>\n",
              "      <td>181</td>\n",
              "      <td>39</td>\n",
              "      <td>181_saliency_salient_detection_region</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>183</th>\n",
              "      <td>182</td>\n",
              "      <td>39</td>\n",
              "      <td>182_flash_storage_disk_page</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>184</th>\n",
              "      <td>183</td>\n",
              "      <td>39</td>\n",
              "      <td>183_dataflow_driven_tools_protovis</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>185</th>\n",
              "      <td>184</td>\n",
              "      <td>39</td>\n",
              "      <td>184_breast_cancer_fcn_deep</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>186</th>\n",
              "      <td>185</td>\n",
              "      <td>39</td>\n",
              "      <td>185_diagrams_diagram_teachers_diagrammatic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>189</th>\n",
              "      <td>186</td>\n",
              "      <td>38</td>\n",
              "      <td>186_skeleton_skeletons_thinning_skeletonization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>188</th>\n",
              "      <td>187</td>\n",
              "      <td>38</td>\n",
              "      <td>187_cleaning_repairing_constraints_tuples</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>187</th>\n",
              "      <td>188</td>\n",
              "      <td>38</td>\n",
              "      <td>188_dance_dancers_dancer_choreographers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>190</th>\n",
              "      <td>189</td>\n",
              "      <td>37</td>\n",
              "      <td>189_immersive_reality_visualizations_virtual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>191</th>\n",
              "      <td>190</td>\n",
              "      <td>37</td>\n",
              "      <td>190_gpu_gpus_cpu_radix</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>192</th>\n",
              "      <td>191</td>\n",
              "      <td>37</td>\n",
              "      <td>191_parents_parenting_child_bereavement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>193</th>\n",
              "      <td>192</td>\n",
              "      <td>37</td>\n",
              "      <td>192_movements_gaze_saccade_intentionality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>200</th>\n",
              "      <td>193</td>\n",
              "      <td>36</td>\n",
              "      <td>193_forest_pest_bristle_spatio</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>194</td>\n",
              "      <td>36</td>\n",
              "      <td>194_lighting_lights_light_illumination</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>195</td>\n",
              "      <td>36</td>\n",
              "      <td>195_particle_particles_rendering_volume</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>196</td>\n",
              "      <td>36</td>\n",
              "      <td>196_desktop_monitor_copy_windowscape</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>197</td>\n",
              "      <td>36</td>\n",
              "      <td>197_clipping_segment_algorithm_algorithms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>198</td>\n",
              "      <td>36</td>\n",
              "      <td>198_skeleton_skinning_animation_skeletal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>194</th>\n",
              "      <td>199</td>\n",
              "      <td>36</td>\n",
              "      <td>199_dogs_birdhouse_bird_owners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>201</th>\n",
              "      <td>200</td>\n",
              "      <td>35</td>\n",
              "      <td>200_ubicomp_ubiquitous_activitydesigner_technologies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>202</th>\n",
              "      <td>201</td>\n",
              "      <td>35</td>\n",
              "      <td>201_histograms_histogram_query_random</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>203</th>\n",
              "      <td>202</td>\n",
              "      <td>35</td>\n",
              "      <td>202_spreadsheet_spreadsheets_photospread_formulas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>204</th>\n",
              "      <td>203</td>\n",
              "      <td>34</td>\n",
              "      <td>203_stock_trading_financial_market</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>206</th>\n",
              "      <td>206</td>\n",
              "      <td>33</td>\n",
              "      <td>206_link_links_prediction_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>207</th>\n",
              "      <td>204</td>\n",
              "      <td>33</td>\n",
              "      <td>204_spatial_clusters_mining_discovering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>205</th>\n",
              "      <td>205</td>\n",
              "      <td>33</td>\n",
              "      <td>205_tone_luminance_binocular_contrast</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>210</th>\n",
              "      <td>208</td>\n",
              "      <td>32</td>\n",
              "      <td>208_multimodal_multimodality_interfaces_multitasking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>208</th>\n",
              "      <td>209</td>\n",
              "      <td>32</td>\n",
              "      <td>209_chatbot_chatbots_chat_conversations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>209</th>\n",
              "      <td>207</td>\n",
              "      <td>32</td>\n",
              "      <td>207_neurons_microscopy_neuronal_confocal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>211</th>\n",
              "      <td>210</td>\n",
              "      <td>31</td>\n",
              "      <td>210_exchange_sharing_hosts_dissemination</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>212</th>\n",
              "      <td>211</td>\n",
              "      <td>31</td>\n",
              "      <td>211_dementia_care_disability_wellbeing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>213</th>\n",
              "      <td>212</td>\n",
              "      <td>31</td>\n",
              "      <td>212_uims_interface_interfaces_uls</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>214</th>\n",
              "      <td>213</td>\n",
              "      <td>31</td>\n",
              "      <td>213_hair_hairs_hairstyles_hairstyle</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>215</th>\n",
              "      <td>214</td>\n",
              "      <td>30</td>\n",
              "      <td>214_translation_multilingual_translations_translators</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>216</th>\n",
              "      <td>215</td>\n",
              "      <td>30</td>\n",
              "      <td>215_disease_alzheimer_brain_connectivity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>217</th>\n",
              "      <td>216</td>\n",
              "      <td>29</td>\n",
              "      <td>216_feature_selection_features_subset</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>218</th>\n",
              "      <td>217</td>\n",
              "      <td>29</td>\n",
              "      <td>217_videos_lecture_lectures_educational</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>219</th>\n",
              "      <td>218</td>\n",
              "      <td>29</td>\n",
              "      <td>218_apps_usage_mobileminer_personalized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>220</th>\n",
              "      <td>219</td>\n",
              "      <td>28</td>\n",
              "      <td>219_things_agency_dome_thing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>221</th>\n",
              "      <td>220</td>\n",
              "      <td>28</td>\n",
              "      <td>220_construction_visualisation_building_project</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>222</th>\n",
              "      <td>221</td>\n",
              "      <td>28</td>\n",
              "      <td>221_metric_dissimilarity_sparse_instances</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>223</th>\n",
              "      <td>222</td>\n",
              "      <td>28</td>\n",
              "      <td>222_encrypted_encryption_secure_security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>225</th>\n",
              "      <td>225</td>\n",
              "      <td>27</td>\n",
              "      <td>225_string_strings_similarity_query</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>226</th>\n",
              "      <td>223</td>\n",
              "      <td>27</td>\n",
              "      <td>223_credibility_witness_evidence_guilt</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>224</th>\n",
              "      <td>224</td>\n",
              "      <td>27</td>\n",
              "      <td>224_conformal_curvature_mesh_meshes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>228</th>\n",
              "      <td>228</td>\n",
              "      <td>26</td>\n",
              "      <td>228_bayesian_statistical_null_statistics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>229</th>\n",
              "      <td>229</td>\n",
              "      <td>26</td>\n",
              "      <td>229_sleep_sleeping_circadian_sleepbandits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>230</th>\n",
              "      <td>226</td>\n",
              "      <td>26</td>\n",
              "      <td>226_blockchain_blockchains_bitcoin_ledger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>227</th>\n",
              "      <td>227</td>\n",
              "      <td>26</td>\n",
              "      <td>227_crowdfunding_donations_campaigns_fundraising</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>234</th>\n",
              "      <td>234</td>\n",
              "      <td>25</td>\n",
              "      <td>234_splatting_volume_rendering_splats</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>237</th>\n",
              "      <td>230</td>\n",
              "      <td>25</td>\n",
              "      <td>230_scrolling_scroll_flick_scrollbar</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>236</th>\n",
              "      <td>231</td>\n",
              "      <td>25</td>\n",
              "      <td>231_remote_omnidirectional_reality_augmented</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>235</th>\n",
              "      <td>232</td>\n",
              "      <td>25</td>\n",
              "      <td>232_changing_shape_interfaces_affordances</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>233</th>\n",
              "      <td>235</td>\n",
              "      <td>25</td>\n",
              "      <td>235_fairness_fair_unfairness_bias</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>232</th>\n",
              "      <td>236</td>\n",
              "      <td>25</td>\n",
              "      <td>236_logs_traces_workflow_events</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>231</th>\n",
              "      <td>233</td>\n",
              "      <td>25</td>\n",
              "      <td>233_care_menstrual_fertility_ovum</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>238</th>\n",
              "      <td>237</td>\n",
              "      <td>24</td>\n",
              "      <td>237_emoji_emojis_emoticons_emotional</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>239</th>\n",
              "      <td>238</td>\n",
              "      <td>24</td>\n",
              "      <td>238_façades_urban_façade_geollery</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>240</th>\n",
              "      <td>239</td>\n",
              "      <td>24</td>\n",
              "      <td>239_hypermedia_hypertext_hyperpro_protocols</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>241</th>\n",
              "      <td>240</td>\n",
              "      <td>23</td>\n",
              "      <td>240_tilings_patterns_tiling_ornamental</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>242</th>\n",
              "      <td>241</td>\n",
              "      <td>23</td>\n",
              "      <td>241_circuit_circuits_electronics_breadboard</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>243</th>\n",
              "      <td>242</td>\n",
              "      <td>23</td>\n",
              "      <td>242_olfactory_smell_odor_breathing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>246</th>\n",
              "      <td>244</td>\n",
              "      <td>22</td>\n",
              "      <td>244_cosmological_halos_universe_halo</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>247</th>\n",
              "      <td>243</td>\n",
              "      <td>22</td>\n",
              "      <td>243_relational_bayesian_networks_dependency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>245</th>\n",
              "      <td>246</td>\n",
              "      <td>22</td>\n",
              "      <td>246_datasplash_database_visualcloud_polyarchy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>244</th>\n",
              "      <td>245</td>\n",
              "      <td>22</td>\n",
              "      <td>245_physical_physics_simulation_liquids</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>248</th>\n",
              "      <td>247</td>\n",
              "      <td>21</td>\n",
              "      <td>247_uncertainty_circle_estimates_uncertain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249</th>\n",
              "      <td>248</td>\n",
              "      <td>21</td>\n",
              "      <td>248_illustrations_art_rendering_surfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>250</th>\n",
              "      <td>249</td>\n",
              "      <td>20</td>\n",
              "      <td>249_smoke_grid_vortex_resolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>251</th>\n",
              "      <td>250</td>\n",
              "      <td>20</td>\n",
              "      <td>250_assistive_disabilities_technology_autonomy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>252</th>\n",
              "      <td>251</td>\n",
              "      <td>20</td>\n",
              "      <td>251_displays_display_pids_studies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>253</th>\n",
              "      <td>252</td>\n",
              "      <td>20</td>\n",
              "      <td>252_food_practices_sustainable_waste</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>258</th>\n",
              "      <td>254</td>\n",
              "      <td>19</td>\n",
              "      <td>254_skyline_skylines_skycube_queries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>261</th>\n",
              "      <td>253</td>\n",
              "      <td>19</td>\n",
              "      <td>253_haze_hazy_image_removal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>260</th>\n",
              "      <td>255</td>\n",
              "      <td>19</td>\n",
              "      <td>255_topology_bifurcations_topological_bifurcation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>259</th>\n",
              "      <td>256</td>\n",
              "      <td>19</td>\n",
              "      <td>256_halftoning_dither_image_halftone</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>255</th>\n",
              "      <td>260</td>\n",
              "      <td>19</td>\n",
              "      <td>260_notification_notifications_smartphone_interruptibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>257</th>\n",
              "      <td>258</td>\n",
              "      <td>19</td>\n",
              "      <td>258_sustainability_sustainable_environmental_fiction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>256</th>\n",
              "      <td>259</td>\n",
              "      <td>19</td>\n",
              "      <td>259_organizations_visualizations_business_visualization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>254</th>\n",
              "      <td>257</td>\n",
              "      <td>19</td>\n",
              "      <td>257_ideas_creative_inspirations_idea</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>266</th>\n",
              "      <td>261</td>\n",
              "      <td>18</td>\n",
              "      <td>261_spam_reviews_spammers_fake</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>268</th>\n",
              "      <td>263</td>\n",
              "      <td>18</td>\n",
              "      <td>263_battery_usage_mobile_smartphones</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>267</th>\n",
              "      <td>262</td>\n",
              "      <td>18</td>\n",
              "      <td>262_agents_characters_scripting_embodied</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>265</th>\n",
              "      <td>264</td>\n",
              "      <td>18</td>\n",
              "      <td>264_blending_surfaces_blend_blends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>262</th>\n",
              "      <td>265</td>\n",
              "      <td>18</td>\n",
              "      <td>265_navigation_indoor_pedestrian_buildings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>263</th>\n",
              "      <td>267</td>\n",
              "      <td>18</td>\n",
              "      <td>267_phobias_therapy_reality_pain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>264</th>\n",
              "      <td>266</td>\n",
              "      <td>18</td>\n",
              "      <td>266_egocentric_judgments_person_allocentric</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>275</th>\n",
              "      <td>273</td>\n",
              "      <td>17</td>\n",
              "      <td>273_play_outdoor_playing_playground</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>269</th>\n",
              "      <td>274</td>\n",
              "      <td>17</td>\n",
              "      <td>274_choices_others_intergenerational_distributive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>270</th>\n",
              "      <td>268</td>\n",
              "      <td>17</td>\n",
              "      <td>268_bitmap_bitmaps_indexes_index</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>271</th>\n",
              "      <td>269</td>\n",
              "      <td>17</td>\n",
              "      <td>269_patent_patents_companies_stock</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>272</th>\n",
              "      <td>270</td>\n",
              "      <td>17</td>\n",
              "      <td>270_machines_classifiers_svm_svms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>271</td>\n",
              "      <td>17</td>\n",
              "      <td>271_porosity_polymers_porous_pore</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>274</th>\n",
              "      <td>272</td>\n",
              "      <td>17</td>\n",
              "      <td>272_maintenance_updates_update_database</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>276</th>\n",
              "      <td>275</td>\n",
              "      <td>16</td>\n",
              "      <td>275_shading_pixel_aliasing_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>277</th>\n",
              "      <td>276</td>\n",
              "      <td>16</td>\n",
              "      <td>276_crop_agriculture_agricultural_remote</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>278</th>\n",
              "      <td>277</td>\n",
              "      <td>16</td>\n",
              "      <td>277_morse_smale_decompositions_topological</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>279</th>\n",
              "      <td>278</td>\n",
              "      <td>16</td>\n",
              "      <td>278_knot_knots_knotted_knotpad</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>286</th>\n",
              "      <td>280</td>\n",
              "      <td>15</td>\n",
              "      <td>280_multimedia_databases_database_dbms</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>284</th>\n",
              "      <td>286</td>\n",
              "      <td>15</td>\n",
              "      <td>286_presentation_presentations_slide_slides</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>288</th>\n",
              "      <td>281</td>\n",
              "      <td>15</td>\n",
              "      <td>281_cohousing_living_homes_reuse</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>285</th>\n",
              "      <td>282</td>\n",
              "      <td>15</td>\n",
              "      <td>282_registration_indoor_3d_scanners</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>287</th>\n",
              "      <td>279</td>\n",
              "      <td>15</td>\n",
              "      <td>279_font_fonts_typefaces_typeface</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>283</th>\n",
              "      <td>284</td>\n",
              "      <td>15</td>\n",
              "      <td>284_cubic_algebraic_polynomials_equations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>281</th>\n",
              "      <td>283</td>\n",
              "      <td>15</td>\n",
              "      <td>283_relief_reliefs_depth_details</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>280</th>\n",
              "      <td>285</td>\n",
              "      <td>15</td>\n",
              "      <td>285_cell_cells_microscopy_lineages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>282</th>\n",
              "      <td>287</td>\n",
              "      <td>15</td>\n",
              "      <td>287_scanline_scan_geometry_cst</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>294</th>\n",
              "      <td>294</td>\n",
              "      <td>14</td>\n",
              "      <td>294_messaging_communication_messages_conversation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>299</th>\n",
              "      <td>288</td>\n",
              "      <td>14</td>\n",
              "      <td>288_commerce_product_baidu_facebook</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>298</th>\n",
              "      <td>289</td>\n",
              "      <td>14</td>\n",
              "      <td>289_lighting_carvings_byzantine_light</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>297</th>\n",
              "      <td>290</td>\n",
              "      <td>14</td>\n",
              "      <td>290_industrial_golden_manufacturing_tinplate</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>296</th>\n",
              "      <td>291</td>\n",
              "      <td>14</td>\n",
              "      <td>291_hmms_hmm_emhmm_mood</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>295</th>\n",
              "      <td>292</td>\n",
              "      <td>14</td>\n",
              "      <td>292_epidemic_influenza_epidemics_infectious</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>293</th>\n",
              "      <td>295</td>\n",
              "      <td>14</td>\n",
              "      <td>295_truth_truths_sources_conflicting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>292</th>\n",
              "      <td>296</td>\n",
              "      <td>14</td>\n",
              "      <td>296_thickness_orbital_slice_ultrasound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>291</th>\n",
              "      <td>297</td>\n",
              "      <td>14</td>\n",
              "      <td>297_hackathons_hacking_hackerspace_hackability</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>290</th>\n",
              "      <td>298</td>\n",
              "      <td>14</td>\n",
              "      <td>298_quantum_probability_classical_axiom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>289</th>\n",
              "      <td>293</td>\n",
              "      <td>14</td>\n",
              "      <td>293_edit_patch_pixels_edits</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>305</th>\n",
              "      <td>306</td>\n",
              "      <td>13</td>\n",
              "      <td>306_sampling_meshes_surfaces_packing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>310</th>\n",
              "      <td>302</td>\n",
              "      <td>13</td>\n",
              "      <td>302_personas_persona_designers_conjoint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>309</th>\n",
              "      <td>299</td>\n",
              "      <td>13</td>\n",
              "      <td>299_job_career_salary_careers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>308</th>\n",
              "      <td>300</td>\n",
              "      <td>13</td>\n",
              "      <td>300_symmetries_intrinsic_gisifs_symmetric</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>306</th>\n",
              "      <td>303</td>\n",
              "      <td>13</td>\n",
              "      <td>303_drone_drones_somaesthetic_emergency</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>307</th>\n",
              "      <td>301</td>\n",
              "      <td>13</td>\n",
              "      <td>301_hashing_hash_retrieval_hamming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>304</th>\n",
              "      <td>305</td>\n",
              "      <td>13</td>\n",
              "      <td>305_gui_layout_layouts_constraint</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>302</th>\n",
              "      <td>308</td>\n",
              "      <td>13</td>\n",
              "      <td>308_camera_stylecam_video_motion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>301</th>\n",
              "      <td>309</td>\n",
              "      <td>13</td>\n",
              "      <td>309_gantt_schedules_timeline_schedule</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>300</th>\n",
              "      <td>304</td>\n",
              "      <td>13</td>\n",
              "      <td>304_retargeting_warping_image_scaling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>303</th>\n",
              "      <td>307</td>\n",
              "      <td>13</td>\n",
              "      <td>307_segmentation_mri_glioma_imaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>311</th>\n",
              "      <td>310</td>\n",
              "      <td>12</td>\n",
              "      <td>310_bike_station_rebalancing_bikes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>312</th>\n",
              "      <td>311</td>\n",
              "      <td>12</td>\n",
              "      <td>311_handwriting_style_characters_cartoon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>313</th>\n",
              "      <td>312</td>\n",
              "      <td>12</td>\n",
              "      <td>312_reviews_app_review_credibility</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>314</th>\n",
              "      <td>313</td>\n",
              "      <td>12</td>\n",
              "      <td>313_augmented_educational_app_greenhat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>315</th>\n",
              "      <td>314</td>\n",
              "      <td>12</td>\n",
              "      <td>314_personalization_personalized_customization_commerce</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>320</th>\n",
              "      <td>316</td>\n",
              "      <td>11</td>\n",
              "      <td>316_tangible_tangibles_sensing_thinsight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>323</th>\n",
              "      <td>315</td>\n",
              "      <td>11</td>\n",
              "      <td>315_body_wearable_wearables_mindfulness</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>322</th>\n",
              "      <td>317</td>\n",
              "      <td>11</td>\n",
              "      <td>317_reassembly_fractured_fragments_assembly</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>321</th>\n",
              "      <td>318</td>\n",
              "      <td>11</td>\n",
              "      <td>318_whiteboard_whiteboards_sticky_workspace</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>317</th>\n",
              "      <td>322</td>\n",
              "      <td>11</td>\n",
              "      <td>322_stabilization_video_videos_stabilized</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>319</th>\n",
              "      <td>320</td>\n",
              "      <td>11</td>\n",
              "      <td>320_photo_photos_sharing_photoware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>318</th>\n",
              "      <td>321</td>\n",
              "      <td>11</td>\n",
              "      <td>321_grading_students_grade_student</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>316</th>\n",
              "      <td>319</td>\n",
              "      <td>11</td>\n",
              "      <td>319_isosurface_tree_ptot_octree</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>324</th>\n",
              "      <td>323</td>\n",
              "      <td>10</td>\n",
              "      <td>323_fire_flame_fires_flakes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>325</th>\n",
              "      <td>324</td>\n",
              "      <td>10</td>\n",
              "      <td>324_skin_skintillates_skinmarks_thin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>326</th>\n",
              "      <td>325</td>\n",
              "      <td>10</td>\n",
              "      <td>325_survival_censored_relapse_remission</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>327</th>\n",
              "      <td>326</td>\n",
              "      <td>10</td>\n",
              "      <td>326_scent_interapplication_intertwine_browser</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>328</th>\n",
              "      <td>327</td>\n",
              "      <td>10</td>\n",
              "      <td>327_groupware_discotech_concurrency_reconnection</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count                                                         Name\n",
              "0       -1  29977                          -1_mobile_social_people_interaction\n",
              "1        0    933                           0_language_linguistic_lexical_verb\n",
              "2        1    824                                 1_flow_vortex_vortices_fluid\n",
              "3        2    689                             2_graph_graphs_networks_subgraph\n",
              "4        3    554                           3_mesh_meshes_subdivision_triangle\n",
              "5        4    521                                4_database_query_queries_join\n",
              "6        5    519                        5_light_illumination_rendering_photon\n",
              "7        6    513                  6_clustering_community_networks_communities\n",
              "8        7    498                 7_recommendation_recommender_advertising_bid\n",
              "9        8    450                                    8_gaze_eye_attention_eyes\n",
              "10       9    443                          9_animation_motion_motions_animated\n",
              "11      10    423                           10_driving_vehicle_vehicles_driver\n",
              "12      11    391      11_multidimensional_dimensional_scatterplots_dimensions\n",
              "13      12    389                        12_crowd_crowdsourcing_workers_crowds\n",
              "14      13    385                        13_series_patterns_subsequence_mining\n",
              "15      14    367                                 14_game_games_players_player\n",
              "16      15    362                    15_trajectories_trajectory_mobility_urban\n",
              "17      16    315                              16_patient_health_patients_care\n",
              "18      17    296                         17_frequent_mining_itemsets_patterns\n",
              "19      18    290                         18_haptic_tactile_force_vibrotactile\n",
              "20      19    284                               19_facial_face_faces_animation\n",
              "21      20    276                     20_creativity_painting_creative_artistic\n",
              "22      21    271                              21_gesture_gestures_sign_speech\n",
              "23      22    262                        22_topic_topics_dirichlet_collections\n",
              "24      23    254                         23_brain_cognitive_cognition_spiking\n",
              "25      24    240                                24_graphics_gks_standards_cgi\n",
              "26      25    238                       25_diagrams_diagrammatic_diagram_logic\n",
              "27      26    234         26_category_categorization_categories_generalization\n",
              "28      27    229              27_visualizations_infovis_visualization_studies\n",
              "29      28    222                 28_authentication_passwords_security_attacks\n",
              "30      29    217            29_classification_classifiers_classifier_ensemble\n",
              "31      30    214                             30_robot_robots_robotic_robotics\n",
              "32      31    212               31_fabrication_printing_assembly_manufacturing\n",
              "33      32    210              32_causal_counterfactual_explanations_causation\n",
              "34      33    205                      33_texture_textures_synthesis_texturing\n",
              "35      34    199                     34_code_programming_programmers_software\n",
              "36      35    195                           35_memory_attention_task_cognitive\n",
              "37      36    190                         36_vessel_vessels_aneurysms_aneurysm\n",
              "38      37    189                                 37_voice_speech_audio_voices\n",
              "39      38    188        38_correspondence_matching_descriptor_correspondences\n",
              "40      39    186                            39_twitter_tweets_microblog_tweet\n",
              "41      40    183                         40_weather_climate_ensembles_seismic\n",
              "42      41    175                         41_music_musical_listening_musicians\n",
              "43      42    172                    42_collaboration_collaborative_teams_team\n",
              "44      43    172                         43_sensor_activities_sensors_sensing\n",
              "45      44    170               44_heritage_archaeological_historic_excavation\n",
              "46      45    168                      45_narrative_story_stories_storytelling\n",
              "47      46    167                             46_color_colors_palette_palettes\n",
              "48      47    166               47_transaction_transactions_concurrency_commit\n",
              "49      48    165                           48_keyboard_keyboards_touch_finger\n",
              "50      49    164                              49_reality_augmented_vr_virtual\n",
              "51      50    158        50_conversational_dialogue_conversations_conversation\n",
              "52      51    157                        51_electricity_smart_households_homes\n",
              "53      52    156                  52_privacy_private_anonymization_preserving\n",
              "54      53    154               53_distributed_parallel_experiments_scientific\n",
              "55      54    152                    54_processor_graphics_hardware_processors\n",
              "56      55    146                 55_displays_navigation_display_magnification\n",
              "57      56    146                             56_urban_buildings_city_building\n",
              "58      57    145                                 57_gene_genes_genome_genomic\n",
              "59      58    142                       58_deep_machine_learning_convolutional\n",
              "60      59    142                                59_ray_rays_casting_rendering\n",
              "61      60    141                              60_choice_risky_choices_options\n",
              "62      61    137                           61_fluid_fluids_particle_particles\n",
              "63      62    136                        62_solid_solids_polyhedral_constraint\n",
              "64      63    134                             63_video_videos_browsing_content\n",
              "65      64    132                       64_spline_splines_curves_interpolation\n",
              "66      65    129                              65_search_web_tagging_searching\n",
              "67      66    128                     66_impaired_visually_tactile_impairments\n",
              "68      67    126                 67_wikipedia_communities_community_newcomers\n",
              "69      68    125                       68_volume_volumetric_rendering_opacity\n",
              "70      69    123                            69_shadow_shadows_light_rendering\n",
              "72      70    122                       70_practice_research_ethical_designers\n",
              "71      71    122                           71_magnitude_numbers_number_acuity\n",
              "73      72    120                  72_classroom_teachers_education_educational\n",
              "74      73    118                        73_museum_visitors_museums_exhibition\n",
              "75      74    116                           74_route_navigation_map_wayfinding\n",
              "76      75    114                         75_sketching_sketch_sketches_drawing\n",
              "77      76    113                     76_papers_editorial_conference_symposium\n",
              "78      77    113                              77_tracking_motion_tracker_pose\n",
              "79      78    107                       78_reading_books_readers_comprehension\n",
              "80      79    105                           79_extraction_web_template_wrapper\n",
              "81      80    100                         80_retrieval_images_similarity_query\n",
              "83      81     99               81_segmentation_watershed_superpixel_foresting\n",
              "82      82     99                      82_molecules_molecule_simulations_atoms\n",
              "85      83     98                           83_brdf_reflectance_brdfs_specular\n",
              "84      84     98                        84_social_privacy_friends_disclosures\n",
              "86      85     97                            85_contact_elastic_fracture_rigid\n",
              "87      86     95                                  86_ai_insight_solving_agent\n",
              "88      87     93                         87_rfid_indoor_localization_location\n",
              "89      88     92                                     88_xml_xquery_query_twig\n",
              "90      89     91               89_interfaces_accessibility_interface_platform\n",
              "91      90     91                         90_teaching_education_courses_course\n",
              "92      91     90                   91_usability_evaluation_testing_developers\n",
              "93      92     90                       92_denoising_smoothing_deblurring_blur\n",
              "95      93     89              93_matrix_factorization_convergence_distributed\n",
              "94      94     89                             94_ocean_underwater_water_seabed\n",
              "96      95     87                            95_fractal_fractals_chaos_terrain\n",
              "97      96     87                96_location_recommendation_locations_mobility\n",
              "98      97     86                       97_kernel_discriminant_subspace_sparse\n",
              "99      98     86                      98_surgical_surgery_haptic_laparoscopic\n",
              "100     99     85                                 99_email_emails_mail_clients\n",
              "101    100     85                       100_pointing_cursor_movement_clutching\n",
              "102    101     84                          101_moral_dilemmas_morality_morally\n",
              "103    102     82                      102_analytics_analysts_business_insight\n",
              "104    103     81                         103_fields_scalar_topology_geometric\n",
              "105    104     79                                104_privacy_app_apps_policies\n",
              "106    105     77                         105_stereo_depth_camera_stereoscopic\n",
              "107    106     74                        106_walking_locomotion_virtual_flying\n",
              "108    107     74                          107_political_civic_civics_citizens\n",
              "109    108     73                            108_home_aware_context_ubiquitous\n",
              "110    109     73                        109_garment_garments_clothing_clothes\n",
              "111    110     73                     110_terrain_terrains_rendering_elevation\n",
              "112    111     73                  111_analogical_analogy_analogies_relational\n",
              "113    112     72                         112_outlier_outliers_anomaly_streams\n",
              "114    113     71                        113_treemap_treemaps_tree_hierarchies\n",
              "115    114     70                             114_event_events_records_streams\n",
              "116    115     69                         115_emotional_emotions_emotion_humor\n",
              "117    116     69                          116_column_workloads_stores_columns\n",
              "118    117     69                            117_diffusion_tensor_tracts_brain\n",
              "119    118     68                    118_collision_deformable_collisions_rigid\n",
              "120    119     67                         119_exertion_exergame_exergames_game\n",
              "121    120     66                                  120_plant_tree_trees_plants\n",
              "122    121     66  121_interruptions_interruption_interruptibility_interrupted\n",
              "123    122     66                122_aesthetics_aesthetic_somaesthetics_beauty\n",
              "126    124     64                              124_sports_soccer_tennis_player\n",
              "124    125     64                      125_graphical_graphics_graphic_dialogue\n",
              "125    123     64                            123_touch_mobile_displays_display\n",
              "128    126     63                          126_streams_drift_ensemble_drifting\n",
              "127    127     63                         127_label_labels_instances_unlabeled\n",
              "129    128     62                   128_rehabilitation_exercise_exercises_limb\n",
              "130    129     61                  129_projector_camera_calibration_projection\n",
              "131    130     60             130_coordination_interpersonal_synchrony_partner\n",
              "132    131     60                131_metaphor_metaphors_metaphorical_adjective\n",
              "133    132     59                            132_flight_virtual_immersive_golf\n",
              "134    133     59                        133_matting_video_stitching_panoramic\n",
              "138    136     58               136_citation_publications_literature_citations\n",
              "140    135     58                                  135_menu_finger_touch_menus\n",
              "139    134     58                       134_nearest_neighbor_search_similarity\n",
              "137    138     58                 138_transportation_travel_passengers_drivers\n",
              "135    137     58                           137_math_students_solving_problems\n",
              "136    139     58                    139_sound_acoustic_listener_reverberation\n",
              "141    140     56               140_tensor_tensors_decomposition_factorization\n",
              "142    141     56                      141_memory_associative_binding_episodic\n",
              "143    142     56                        142_question_answering_answer_ranking\n",
              "144    143     56                        143_marketing_customers_price_pricing\n",
              "146    144     55                     144_entity_entities_named_disambiguation\n",
              "145    145     55             145_wavelet_wavelets_multiresolution_subdivision\n",
              "147    146     54                      146_video_couples_communication_sharing\n",
              "148    147     54                           147_credit_financial_fraud_banking\n",
              "149    148     54                             148_motion_motions_mocap_capture\n",
              "150    149     53                    149_segmentation_mesh_segmentations_snake\n",
              "151    150     53                         150_mind_cultural_religion_religious\n",
              "152    151     53                          151_students_courses_course_student\n",
              "153    152     52                   152_tabletop_collaboration_touch_groupware\n",
              "154    153     51                            153_cartograms_cartogram_map_maps\n",
              "156    154     49               154_meetings_remote_collaboration_conferencing\n",
              "155    155     49                       155_teaching_teacher_teachers_learners\n",
              "157    156     48                156_pagerank_web_personalized_personalization\n",
              "158    157     47                               157_cloth_woven_fabrics_fibers\n",
              "159    158     47                      158_recognition_video_videos_descriptor\n",
              "160    159     47                               159_browser_web_browsing_pages\n",
              "161    160     47                  160_memories_reminiscence_narratives_photos\n",
              "162    161     46                     161_provenance_lakes_datamaran_workflows\n",
              "163    162     46                    162_cultural_culture_evolution_culturally\n",
              "166    164     44         164_watermarking_watermark_watermarks_steganographic\n",
              "164    165     44                        165_children_child_comicboarding_team\n",
              "165    163     44                     163_discovery_knowledge_mining_databases\n",
              "169    166     43                             166_rule_rules_association_fuzzy\n",
              "170    167     43                         167_temporal_duration_events_spatial\n",
              "167    168     43                             168_retinal_lens_lenses_glaucoma\n",
              "168    169     43                                169_touch_finger_fingers_hand\n",
              "174    172     42                   172_occlusion_culling_occluders_visibility\n",
              "175    171     42                          171_morphing_deformation_shape_mesh\n",
              "171    173     42                       173_achievement_students_exam_learners\n",
              "173    170     42                         170_ontology_ontologies_rdf_semantic\n",
              "172    174     42                     174_autism_children_therapy_intervention\n",
              "176    175     41                          175_embedding_node_network_networks\n",
              "177    176     41                      176_schema_schemas_integration_ontology\n",
              "178    177     41                         177_optical_displays_display_mounted\n",
              "179    178     40                  178_tutors_tutoring_pedagogical_educational\n",
              "180    179     39                        179_spatial_meaning_geocentric_verbal\n",
              "181    180     39                        180_point_clouds_reconstruction_cloud\n",
              "182    181     39                        181_saliency_salient_detection_region\n",
              "183    182     39                                  182_flash_storage_disk_page\n",
              "184    183     39                           183_dataflow_driven_tools_protovis\n",
              "185    184     39                                   184_breast_cancer_fcn_deep\n",
              "186    185     39                   185_diagrams_diagram_teachers_diagrammatic\n",
              "189    186     38              186_skeleton_skeletons_thinning_skeletonization\n",
              "188    187     38                    187_cleaning_repairing_constraints_tuples\n",
              "187    188     38                      188_dance_dancers_dancer_choreographers\n",
              "190    189     37                 189_immersive_reality_visualizations_virtual\n",
              "191    190     37                                       190_gpu_gpus_cpu_radix\n",
              "192    191     37                      191_parents_parenting_child_bereavement\n",
              "193    192     37                    192_movements_gaze_saccade_intentionality\n",
              "200    193     36                               193_forest_pest_bristle_spatio\n",
              "199    194     36                       194_lighting_lights_light_illumination\n",
              "198    195     36                      195_particle_particles_rendering_volume\n",
              "197    196     36                         196_desktop_monitor_copy_windowscape\n",
              "196    197     36                    197_clipping_segment_algorithm_algorithms\n",
              "195    198     36                     198_skeleton_skinning_animation_skeletal\n",
              "194    199     36                               199_dogs_birdhouse_bird_owners\n",
              "201    200     35         200_ubicomp_ubiquitous_activitydesigner_technologies\n",
              "202    201     35                        201_histograms_histogram_query_random\n",
              "203    202     35            202_spreadsheet_spreadsheets_photospread_formulas\n",
              "204    203     34                           203_stock_trading_financial_market\n",
              "206    206     33                           206_link_links_prediction_networks\n",
              "207    204     33                      204_spatial_clusters_mining_discovering\n",
              "205    205     33                        205_tone_luminance_binocular_contrast\n",
              "210    208     32         208_multimodal_multimodality_interfaces_multitasking\n",
              "208    209     32                      209_chatbot_chatbots_chat_conversations\n",
              "209    207     32                     207_neurons_microscopy_neuronal_confocal\n",
              "211    210     31                     210_exchange_sharing_hosts_dissemination\n",
              "212    211     31                       211_dementia_care_disability_wellbeing\n",
              "213    212     31                            212_uims_interface_interfaces_uls\n",
              "214    213     31                          213_hair_hairs_hairstyles_hairstyle\n",
              "215    214     30        214_translation_multilingual_translations_translators\n",
              "216    215     30                     215_disease_alzheimer_brain_connectivity\n",
              "217    216     29                        216_feature_selection_features_subset\n",
              "218    217     29                      217_videos_lecture_lectures_educational\n",
              "219    218     29                      218_apps_usage_mobileminer_personalized\n",
              "220    219     28                                 219_things_agency_dome_thing\n",
              "221    220     28              220_construction_visualisation_building_project\n",
              "222    221     28                    221_metric_dissimilarity_sparse_instances\n",
              "223    222     28                     222_encrypted_encryption_secure_security\n",
              "225    225     27                          225_string_strings_similarity_query\n",
              "226    223     27                       223_credibility_witness_evidence_guilt\n",
              "224    224     27                          224_conformal_curvature_mesh_meshes\n",
              "228    228     26                     228_bayesian_statistical_null_statistics\n",
              "229    229     26                    229_sleep_sleeping_circadian_sleepbandits\n",
              "230    226     26                    226_blockchain_blockchains_bitcoin_ledger\n",
              "227    227     26             227_crowdfunding_donations_campaigns_fundraising\n",
              "234    234     25                        234_splatting_volume_rendering_splats\n",
              "237    230     25                         230_scrolling_scroll_flick_scrollbar\n",
              "236    231     25                 231_remote_omnidirectional_reality_augmented\n",
              "235    232     25                    232_changing_shape_interfaces_affordances\n",
              "233    235     25                            235_fairness_fair_unfairness_bias\n",
              "232    236     25                              236_logs_traces_workflow_events\n",
              "231    233     25                            233_care_menstrual_fertility_ovum\n",
              "238    237     24                         237_emoji_emojis_emoticons_emotional\n",
              "239    238     24                            238_façades_urban_façade_geollery\n",
              "240    239     24                  239_hypermedia_hypertext_hyperpro_protocols\n",
              "241    240     23                       240_tilings_patterns_tiling_ornamental\n",
              "242    241     23                  241_circuit_circuits_electronics_breadboard\n",
              "243    242     23                           242_olfactory_smell_odor_breathing\n",
              "246    244     22                         244_cosmological_halos_universe_halo\n",
              "247    243     22                  243_relational_bayesian_networks_dependency\n",
              "245    246     22                246_datasplash_database_visualcloud_polyarchy\n",
              "244    245     22                      245_physical_physics_simulation_liquids\n",
              "248    247     21                   247_uncertainty_circle_estimates_uncertain\n",
              "249    248     21                     248_illustrations_art_rendering_surfaces\n",
              "250    249     20                             249_smoke_grid_vortex_resolution\n",
              "251    250     20               250_assistive_disabilities_technology_autonomy\n",
              "252    251     20                            251_displays_display_pids_studies\n",
              "253    252     20                         252_food_practices_sustainable_waste\n",
              "258    254     19                         254_skyline_skylines_skycube_queries\n",
              "261    253     19                                  253_haze_hazy_image_removal\n",
              "260    255     19            255_topology_bifurcations_topological_bifurcation\n",
              "259    256     19                         256_halftoning_dither_image_halftone\n",
              "255    260     19   260_notification_notifications_smartphone_interruptibility\n",
              "257    258     19         258_sustainability_sustainable_environmental_fiction\n",
              "256    259     19      259_organizations_visualizations_business_visualization\n",
              "254    257     19                         257_ideas_creative_inspirations_idea\n",
              "266    261     18                               261_spam_reviews_spammers_fake\n",
              "268    263     18                         263_battery_usage_mobile_smartphones\n",
              "267    262     18                     262_agents_characters_scripting_embodied\n",
              "265    264     18                           264_blending_surfaces_blend_blends\n",
              "262    265     18                   265_navigation_indoor_pedestrian_buildings\n",
              "263    267     18                             267_phobias_therapy_reality_pain\n",
              "264    266     18                  266_egocentric_judgments_person_allocentric\n",
              "275    273     17                          273_play_outdoor_playing_playground\n",
              "269    274     17            274_choices_others_intergenerational_distributive\n",
              "270    268     17                             268_bitmap_bitmaps_indexes_index\n",
              "271    269     17                           269_patent_patents_companies_stock\n",
              "272    270     17                            270_machines_classifiers_svm_svms\n",
              "273    271     17                            271_porosity_polymers_porous_pore\n",
              "274    272     17                      272_maintenance_updates_update_database\n",
              "276    275     16                         275_shading_pixel_aliasing_rendering\n",
              "277    276     16                     276_crop_agriculture_agricultural_remote\n",
              "278    277     16                   277_morse_smale_decompositions_topological\n",
              "279    278     16                               278_knot_knots_knotted_knotpad\n",
              "286    280     15                       280_multimedia_databases_database_dbms\n",
              "284    286     15                  286_presentation_presentations_slide_slides\n",
              "288    281     15                             281_cohousing_living_homes_reuse\n",
              "285    282     15                          282_registration_indoor_3d_scanners\n",
              "287    279     15                            279_font_fonts_typefaces_typeface\n",
              "283    284     15                    284_cubic_algebraic_polynomials_equations\n",
              "281    283     15                             283_relief_reliefs_depth_details\n",
              "280    285     15                           285_cell_cells_microscopy_lineages\n",
              "282    287     15                               287_scanline_scan_geometry_cst\n",
              "294    294     14            294_messaging_communication_messages_conversation\n",
              "299    288     14                          288_commerce_product_baidu_facebook\n",
              "298    289     14                        289_lighting_carvings_byzantine_light\n",
              "297    290     14                 290_industrial_golden_manufacturing_tinplate\n",
              "296    291     14                                      291_hmms_hmm_emhmm_mood\n",
              "295    292     14                  292_epidemic_influenza_epidemics_infectious\n",
              "293    295     14                         295_truth_truths_sources_conflicting\n",
              "292    296     14                       296_thickness_orbital_slice_ultrasound\n",
              "291    297     14               297_hackathons_hacking_hackerspace_hackability\n",
              "290    298     14                      298_quantum_probability_classical_axiom\n",
              "289    293     14                                  293_edit_patch_pixels_edits\n",
              "305    306     13                         306_sampling_meshes_surfaces_packing\n",
              "310    302     13                      302_personas_persona_designers_conjoint\n",
              "309    299     13                                299_job_career_salary_careers\n",
              "308    300     13                    300_symmetries_intrinsic_gisifs_symmetric\n",
              "306    303     13                      303_drone_drones_somaesthetic_emergency\n",
              "307    301     13                           301_hashing_hash_retrieval_hamming\n",
              "304    305     13                            305_gui_layout_layouts_constraint\n",
              "302    308     13                             308_camera_stylecam_video_motion\n",
              "301    309     13                        309_gantt_schedules_timeline_schedule\n",
              "300    304     13                        304_retargeting_warping_image_scaling\n",
              "303    307     13                          307_segmentation_mri_glioma_imaging\n",
              "311    310     12                           310_bike_station_rebalancing_bikes\n",
              "312    311     12                     311_handwriting_style_characters_cartoon\n",
              "313    312     12                           312_reviews_app_review_credibility\n",
              "314    313     12                       313_augmented_educational_app_greenhat\n",
              "315    314     12      314_personalization_personalized_customization_commerce\n",
              "320    316     11                     316_tangible_tangibles_sensing_thinsight\n",
              "323    315     11                      315_body_wearable_wearables_mindfulness\n",
              "322    317     11                  317_reassembly_fractured_fragments_assembly\n",
              "321    318     11                  318_whiteboard_whiteboards_sticky_workspace\n",
              "317    322     11                    322_stabilization_video_videos_stabilized\n",
              "319    320     11                           320_photo_photos_sharing_photoware\n",
              "318    321     11                           321_grading_students_grade_student\n",
              "316    319     11                              319_isosurface_tree_ptot_octree\n",
              "324    323     10                                  323_fire_flame_fires_flakes\n",
              "325    324     10                         324_skin_skintillates_skinmarks_thin\n",
              "326    325     10                      325_survival_censored_relapse_remission\n",
              "327    326     10                326_scent_interapplication_intertwine_browser\n",
              "328    327     10             327_groupware_discotech_concurrency_reconnection"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "RBAP8d3zFsLg",
        "outputId": "16f05780-71f5-4719-8265-13222dc2b871"
      },
      "source": [
        "reduce_model2 = BERTopic(embedding_model=sentence_model, min_topic_size=30, nr_topics=\"auto\").fit(title_abs)\n",
        "reduce_model2.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Topic</th>\n",
              "      <th>Count</th>\n",
              "      <th>Name</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>-1</td>\n",
              "      <td>30957</td>\n",
              "      <td>-1_design_system_users_user</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0</td>\n",
              "      <td>1319</td>\n",
              "      <td>0_flow_fluid_vortex_jet</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>1136</td>\n",
              "      <td>1_language_word_linguistic_lexical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>2</td>\n",
              "      <td>854</td>\n",
              "      <td>2_visualization_topic_visual_visualizations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3</td>\n",
              "      <td>836</td>\n",
              "      <td>3_recommendation_recommender_recommendations_users</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>4</td>\n",
              "      <td>830</td>\n",
              "      <td>4_graph_graphs_network_networks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>5</td>\n",
              "      <td>734</td>\n",
              "      <td>5_shape_mesh_meshes_subdivision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>6</td>\n",
              "      <td>732</td>\n",
              "      <td>6_game_games_sports_play</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>7</td>\n",
              "      <td>732</td>\n",
              "      <td>7_light_illumination_rendering_lighting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>8</td>\n",
              "      <td>694</td>\n",
              "      <td>8_database_query_queries_join</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>9</td>\n",
              "      <td>550</td>\n",
              "      <td>9_dimensional_visualization_multidimensional_scatterplots</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>10</td>\n",
              "      <td>524</td>\n",
              "      <td>10_motion_animation_motions_animations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>11</td>\n",
              "      <td>497</td>\n",
              "      <td>11_music_musical_voice_sound</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>12</td>\n",
              "      <td>496</td>\n",
              "      <td>12_education_educational_teaching_classroom</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>13</td>\n",
              "      <td>490</td>\n",
              "      <td>13_driving_vehicle_vehicles_driver</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>14</td>\n",
              "      <td>461</td>\n",
              "      <td>14_gesture_gestures_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>15</td>\n",
              "      <td>449</td>\n",
              "      <td>15_classification_class_feature_kernel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>16</td>\n",
              "      <td>448</td>\n",
              "      <td>16_gaze_eye_attention_head</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>17</td>\n",
              "      <td>433</td>\n",
              "      <td>17_haptic_tactile_force_virtual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>18</td>\n",
              "      <td>419</td>\n",
              "      <td>18_rendering_graphics_gpu_splatting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>19</td>\n",
              "      <td>411</td>\n",
              "      <td>19_mining_frequent_itemsets_rules</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>20</td>\n",
              "      <td>406</td>\n",
              "      <td>20_image_images_retrieval_recognition</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>21</td>\n",
              "      <td>399</td>\n",
              "      <td>21_software_programmers_collaboration_developers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>22</td>\n",
              "      <td>379</td>\n",
              "      <td>22_brain_cognitive_attention_visual</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>23</td>\n",
              "      <td>365</td>\n",
              "      <td>23_trajectory_trajectories_mobility_urban</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>24</td>\n",
              "      <td>347</td>\n",
              "      <td>24_graphics_graphic_standards_phigs</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>25</td>\n",
              "      <td>338</td>\n",
              "      <td>25_series_time_patterns_mining</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>26</td>\n",
              "      <td>327</td>\n",
              "      <td>26_fabrication_printing_print_manufacturing</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>27</td>\n",
              "      <td>303</td>\n",
              "      <td>27_smart_activities_context_interfaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>28</td>\n",
              "      <td>301</td>\n",
              "      <td>28_vessel_imaging_ultrasound_clinical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>29</td>\n",
              "      <td>290</td>\n",
              "      <td>29_texture_textures_synthesis_image</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>30</td>\n",
              "      <td>290</td>\n",
              "      <td>30_decision_choice_risk_risky</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>32</th>\n",
              "      <td>31</td>\n",
              "      <td>285</td>\n",
              "      <td>31_weather_visualization_climate_ocean</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>33</th>\n",
              "      <td>32</td>\n",
              "      <td>279</td>\n",
              "      <td>32_ray_rays_traversal_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>34</th>\n",
              "      <td>33</td>\n",
              "      <td>276</td>\n",
              "      <td>33_twitter_tweets_media_sentiment</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>35</th>\n",
              "      <td>34</td>\n",
              "      <td>273</td>\n",
              "      <td>34_creativity_painting_art_creative</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>36</th>\n",
              "      <td>35</td>\n",
              "      <td>273</td>\n",
              "      <td>35_causal_beliefs_evidence_belief</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>37</th>\n",
              "      <td>36</td>\n",
              "      <td>262</td>\n",
              "      <td>36_privacy_security_private_protection</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>38</th>\n",
              "      <td>37</td>\n",
              "      <td>253</td>\n",
              "      <td>37_urban_city_building_buildings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>39</th>\n",
              "      <td>38</td>\n",
              "      <td>240</td>\n",
              "      <td>38_transaction_transactions_concurrency_distributed</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>40</th>\n",
              "      <td>39</td>\n",
              "      <td>235</td>\n",
              "      <td>39_displays_display_navigation_lenses</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>41</th>\n",
              "      <td>40</td>\n",
              "      <td>220</td>\n",
              "      <td>40_search_web_information_pages</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>42</th>\n",
              "      <td>41</td>\n",
              "      <td>220</td>\n",
              "      <td>41_category_categories_categorization_similarity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>43</th>\n",
              "      <td>42</td>\n",
              "      <td>219</td>\n",
              "      <td>42_crowdsourcing_workers_crowd_worker</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>44</th>\n",
              "      <td>43</td>\n",
              "      <td>216</td>\n",
              "      <td>43_patient_patients_care_clinical</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>45</th>\n",
              "      <td>44</td>\n",
              "      <td>215</td>\n",
              "      <td>44_diagrams_diagrammatic_diagram_logic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>46</th>\n",
              "      <td>45</td>\n",
              "      <td>207</td>\n",
              "      <td>45_color_colors_palette_palettes</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>47</th>\n",
              "      <td>46</td>\n",
              "      <td>206</td>\n",
              "      <td>46_hci_design_research_practice</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49</th>\n",
              "      <td>47</td>\n",
              "      <td>204</td>\n",
              "      <td>47_robot_robots_robotic_robotics</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>48</th>\n",
              "      <td>48</td>\n",
              "      <td>204</td>\n",
              "      <td>48_label_labels_unlabeled_classification</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50</th>\n",
              "      <td>49</td>\n",
              "      <td>188</td>\n",
              "      <td>49_keyboard_keyboards_touch_finger</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>51</th>\n",
              "      <td>50</td>\n",
              "      <td>188</td>\n",
              "      <td>50_sketching_sketches_drawing_design</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>52</th>\n",
              "      <td>51</td>\n",
              "      <td>184</td>\n",
              "      <td>51_facial_face_animation_faces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>53</th>\n",
              "      <td>52</td>\n",
              "      <td>175</td>\n",
              "      <td>52_machine_fairness_deep_explanations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>54</th>\n",
              "      <td>53</td>\n",
              "      <td>169</td>\n",
              "      <td>53_papers_conference_issue_editorial</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>55</th>\n",
              "      <td>54</td>\n",
              "      <td>169</td>\n",
              "      <td>54_heritage_museum_visitors_museums</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>56</th>\n",
              "      <td>55</td>\n",
              "      <td>168</td>\n",
              "      <td>55_number_symbolic_magnitude_numbers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>57</th>\n",
              "      <td>56</td>\n",
              "      <td>165</td>\n",
              "      <td>56_facebook_social_privacy_friends</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>58</th>\n",
              "      <td>57</td>\n",
              "      <td>165</td>\n",
              "      <td>57_influence_social_networks_network</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>59</th>\n",
              "      <td>58</td>\n",
              "      <td>158</td>\n",
              "      <td>58_walking_virtual_locomotion_reality</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>60</th>\n",
              "      <td>59</td>\n",
              "      <td>154</td>\n",
              "      <td>59_reality_augmented_virtual_interaction</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>61</th>\n",
              "      <td>60</td>\n",
              "      <td>147</td>\n",
              "      <td>60_molecules_atoms_molecule_halos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>62</th>\n",
              "      <td>61</td>\n",
              "      <td>145</td>\n",
              "      <td>61_memory_insight_solving_task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>63</th>\n",
              "      <td>62</td>\n",
              "      <td>144</td>\n",
              "      <td>62_spline_splines_curves_cubic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>64</th>\n",
              "      <td>63</td>\n",
              "      <td>141</td>\n",
              "      <td>63_clustering_clusters_cluster_clusterings</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>66</th>\n",
              "      <td>64</td>\n",
              "      <td>134</td>\n",
              "      <td>64_impaired_visually_tactile_impairments</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>65</th>\n",
              "      <td>65</td>\n",
              "      <td>134</td>\n",
              "      <td>65_distributed_parallel_scientific_convergence</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>67</th>\n",
              "      <td>66</td>\n",
              "      <td>129</td>\n",
              "      <td>66_wikipedia_communities_community_newcomers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>68</th>\n",
              "      <td>67</td>\n",
              "      <td>127</td>\n",
              "      <td>67_metaphors_metaphor_analogical_analogy</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>69</th>\n",
              "      <td>68</td>\n",
              "      <td>127</td>\n",
              "      <td>68_crowd_crowds_simulation_pedestrians</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>70</th>\n",
              "      <td>69</td>\n",
              "      <td>126</td>\n",
              "      <td>69_conversational_dialogue_agent_conversation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>71</th>\n",
              "      <td>70</td>\n",
              "      <td>125</td>\n",
              "      <td>70_tracking_camera_tracker_pose</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>72</th>\n",
              "      <td>71</td>\n",
              "      <td>124</td>\n",
              "      <td>71_shadow_shadows_light_rendering</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>73</th>\n",
              "      <td>72</td>\n",
              "      <td>113</td>\n",
              "      <td>72_narrative_story_stories_storytelling</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>74</th>\n",
              "      <td>73</td>\n",
              "      <td>112</td>\n",
              "      <td>73_authentication_passwords_password_security</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75</th>\n",
              "      <td>74</td>\n",
              "      <td>110</td>\n",
              "      <td>74_students_math_solving_achievement</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>76</th>\n",
              "      <td>75</td>\n",
              "      <td>105</td>\n",
              "      <td>75_health_patients_self_online</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>77</th>\n",
              "      <td>76</td>\n",
              "      <td>105</td>\n",
              "      <td>76_route_map_navigation_wayfinding</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>78</th>\n",
              "      <td>77</td>\n",
              "      <td>105</td>\n",
              "      <td>77_gene_genome_genomic_visualization</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>79</th>\n",
              "      <td>78</td>\n",
              "      <td>104</td>\n",
              "      <td>78_image_smoothing_denoising_inpainting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>80</th>\n",
              "      <td>79</td>\n",
              "      <td>103</td>\n",
              "      <td>79_construction_visualisation_building_heritage</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>81</th>\n",
              "      <td>80</td>\n",
              "      <td>100</td>\n",
              "      <td>80_solid_solids_boundary_polyhedral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>82</th>\n",
              "      <td>81</td>\n",
              "      <td>97</td>\n",
              "      <td>81_electricity_households_heating_smart</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>83</th>\n",
              "      <td>82</td>\n",
              "      <td>91</td>\n",
              "      <td>82_fractal_fractals_compression_chaos</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>84</th>\n",
              "      <td>83</td>\n",
              "      <td>88</td>\n",
              "      <td>83_memories_diary_life_everyday</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>85</th>\n",
              "      <td>84</td>\n",
              "      <td>87</td>\n",
              "      <td>84_civic_civics_infrastructure_citizens</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>86</th>\n",
              "      <td>85</td>\n",
              "      <td>81</td>\n",
              "      <td>85_xml_query_xquery_queries</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>87</th>\n",
              "      <td>86</td>\n",
              "      <td>79</td>\n",
              "      <td>86_moral_dilemmas_judgment_harm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>88</th>\n",
              "      <td>87</td>\n",
              "      <td>78</td>\n",
              "      <td>87_volume_volumetric_rendering_opacity</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>89</th>\n",
              "      <td>88</td>\n",
              "      <td>77</td>\n",
              "      <td>88_pointing_target_movement_targets</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>90</th>\n",
              "      <td>89</td>\n",
              "      <td>71</td>\n",
              "      <td>89_indoor_location_positioning_rfid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>91</th>\n",
              "      <td>90</td>\n",
              "      <td>70</td>\n",
              "      <td>90_diffusion_tensor_tracts_brain</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>92</th>\n",
              "      <td>91</td>\n",
              "      <td>68</td>\n",
              "      <td>91_ontology_schema_ontologies_schemas</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>93</th>\n",
              "      <td>92</td>\n",
              "      <td>65</td>\n",
              "      <td>92_email_emails_mail_inbox</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>94</th>\n",
              "      <td>93</td>\n",
              "      <td>64</td>\n",
              "      <td>93_security_traffic_cyber_intrusion</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>95</th>\n",
              "      <td>94</td>\n",
              "      <td>62</td>\n",
              "      <td>94_outlier_outliers_datasets_distance</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>96</th>\n",
              "      <td>95</td>\n",
              "      <td>60</td>\n",
              "      <td>95_video_videos_frames_temporal</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>97</th>\n",
              "      <td>96</td>\n",
              "      <td>59</td>\n",
              "      <td>96_tree_trees_plant_plants</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>98</th>\n",
              "      <td>97</td>\n",
              "      <td>59</td>\n",
              "      <td>97_entity_entities_name_disambiguation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>100</th>\n",
              "      <td>98</td>\n",
              "      <td>58</td>\n",
              "      <td>98_interruptions_interruption_interruptibility_task</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>99</th>\n",
              "      <td>99</td>\n",
              "      <td>58</td>\n",
              "      <td>99_coordination_interpersonal_synchrony_actions</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>101</th>\n",
              "      <td>100</td>\n",
              "      <td>57</td>\n",
              "      <td>100_terrain_rendering_terrains_resolution</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>102</th>\n",
              "      <td>101</td>\n",
              "      <td>57</td>\n",
              "      <td>101_stream_drift_ensemble_drifting</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>103</th>\n",
              "      <td>102</td>\n",
              "      <td>55</td>\n",
              "      <td>102_cartograms_map_maps_cartographic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>104</th>\n",
              "      <td>103</td>\n",
              "      <td>55</td>\n",
              "      <td>103_design_clothing_clothes_designers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>105</th>\n",
              "      <td>104</td>\n",
              "      <td>54</td>\n",
              "      <td>104_skeleton_skeletons_segmentation_mesh</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>106</th>\n",
              "      <td>105</td>\n",
              "      <td>52</td>\n",
              "      <td>105_matrix_factorization_nonnegative_matrices</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>107</th>\n",
              "      <td>106</td>\n",
              "      <td>52</td>\n",
              "      <td>106_parallel_compiler_cache_parallelism</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>108</th>\n",
              "      <td>107</td>\n",
              "      <td>50</td>\n",
              "      <td>107_event_events_sentinel_ranking</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>109</th>\n",
              "      <td>108</td>\n",
              "      <td>49</td>\n",
              "      <td>108_wavelet_wavelets_multiresolution_subdivision</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>110</th>\n",
              "      <td>109</td>\n",
              "      <td>48</td>\n",
              "      <td>109_children_participatory_child_technologies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>111</th>\n",
              "      <td>110</td>\n",
              "      <td>48</td>\n",
              "      <td>110_tabletop_collaboration_touch_groupware</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>112</th>\n",
              "      <td>111</td>\n",
              "      <td>46</td>\n",
              "      <td>111_collision_collisions_deformable_rigid</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>113</th>\n",
              "      <td>112</td>\n",
              "      <td>45</td>\n",
              "      <td>112_chatbot_chatbots_chat_conversation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>114</th>\n",
              "      <td>113</td>\n",
              "      <td>45</td>\n",
              "      <td>113_hair_hairs_cloth_hairstyles</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>115</th>\n",
              "      <td>114</td>\n",
              "      <td>45</td>\n",
              "      <td>114_watermarking_watermark_watermarks_attacks</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>116</th>\n",
              "      <td>115</td>\n",
              "      <td>44</td>\n",
              "      <td>115_surgical_surgery_laparoscopic_minimally</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>118</th>\n",
              "      <td>116</td>\n",
              "      <td>43</td>\n",
              "      <td>116_subspace_clustering_clusters_subspaces</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>117</th>\n",
              "      <td>117</td>\n",
              "      <td>43</td>\n",
              "      <td>117_location_recommendation_friends_locations</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>119</th>\n",
              "      <td>118</td>\n",
              "      <td>42</td>\n",
              "      <td>118_parents_parenting_child_life</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>120</th>\n",
              "      <td>119</td>\n",
              "      <td>40</td>\n",
              "      <td>119_location_privacy_crowdsensing_obfuscation</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>121</th>\n",
              "      <td>120</td>\n",
              "      <td>39</td>\n",
              "      <td>120_dance_dancers_dancer_choreographers</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>122</th>\n",
              "      <td>121</td>\n",
              "      <td>37</td>\n",
              "      <td>121_line_clipping_algorithms_polygon</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>123</th>\n",
              "      <td>122</td>\n",
              "      <td>36</td>\n",
              "      <td>122_occlusion_culling_rendering_occluded</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>124</th>\n",
              "      <td>123</td>\n",
              "      <td>35</td>\n",
              "      <td>123_multimodal_modality_modalities_speech</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>125</th>\n",
              "      <td>124</td>\n",
              "      <td>35</td>\n",
              "      <td>124_religious_dreaming_religion_cultural</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>126</th>\n",
              "      <td>125</td>\n",
              "      <td>35</td>\n",
              "      <td>125_spreadsheet_spreadsheets_web_programming</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>127</th>\n",
              "      <td>126</td>\n",
              "      <td>35</td>\n",
              "      <td>126_cleaning_repairing_repair_tuples</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>128</th>\n",
              "      <td>127</td>\n",
              "      <td>34</td>\n",
              "      <td>127_polygons_polygon_hull_algorithm</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>129</th>\n",
              "      <td>128</td>\n",
              "      <td>34</td>\n",
              "      <td>128_spatial_languages_across_meaning</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>130</th>\n",
              "      <td>129</td>\n",
              "      <td>32</td>\n",
              "      <td>129_ubicomp_ubiquitous_design_activitydesigner</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>131</th>\n",
              "      <td>130</td>\n",
              "      <td>31</td>\n",
              "      <td>130_meetings_communication_informal_messaging</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>132</th>\n",
              "      <td>131</td>\n",
              "      <td>30</td>\n",
              "      <td>131_provenance_lakes_workflows_lake</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "     Topic  Count                                                       Name\n",
              "0       -1  30957                                -1_design_system_users_user\n",
              "1        0   1319                                    0_flow_fluid_vortex_jet\n",
              "2        1   1136                         1_language_word_linguistic_lexical\n",
              "3        2    854                2_visualization_topic_visual_visualizations\n",
              "4        3    836         3_recommendation_recommender_recommendations_users\n",
              "5        4    830                            4_graph_graphs_network_networks\n",
              "6        5    734                            5_shape_mesh_meshes_subdivision\n",
              "7        6    732                                   6_game_games_sports_play\n",
              "8        7    732                    7_light_illumination_rendering_lighting\n",
              "9        8    694                              8_database_query_queries_join\n",
              "10       9    550  9_dimensional_visualization_multidimensional_scatterplots\n",
              "11      10    524                     10_motion_animation_motions_animations\n",
              "12      11    497                               11_music_musical_voice_sound\n",
              "13      12    496                12_education_educational_teaching_classroom\n",
              "14      13    490                         13_driving_vehicle_vehicles_driver\n",
              "15      14    461                           14_gesture_gestures_touch_finger\n",
              "16      15    449                     15_classification_class_feature_kernel\n",
              "17      16    448                                 16_gaze_eye_attention_head\n",
              "18      17    433                            17_haptic_tactile_force_virtual\n",
              "19      18    419                        18_rendering_graphics_gpu_splatting\n",
              "20      19    411                          19_mining_frequent_itemsets_rules\n",
              "21      20    406                      20_image_images_retrieval_recognition\n",
              "22      21    399           21_software_programmers_collaboration_developers\n",
              "23      22    379                        22_brain_cognitive_attention_visual\n",
              "24      23    365                  23_trajectory_trajectories_mobility_urban\n",
              "25      24    347                        24_graphics_graphic_standards_phigs\n",
              "26      25    338                             25_series_time_patterns_mining\n",
              "27      26    327                26_fabrication_printing_print_manufacturing\n",
              "28      27    303                     27_smart_activities_context_interfaces\n",
              "29      28    301                      28_vessel_imaging_ultrasound_clinical\n",
              "30      29    290                        29_texture_textures_synthesis_image\n",
              "31      30    290                              30_decision_choice_risk_risky\n",
              "32      31    285                     31_weather_visualization_climate_ocean\n",
              "33      32    279                            32_ray_rays_traversal_rendering\n",
              "34      33    276                          33_twitter_tweets_media_sentiment\n",
              "35      34    273                        34_creativity_painting_art_creative\n",
              "36      35    273                          35_causal_beliefs_evidence_belief\n",
              "37      36    262                     36_privacy_security_private_protection\n",
              "38      37    253                           37_urban_city_building_buildings\n",
              "39      38    240        38_transaction_transactions_concurrency_distributed\n",
              "40      39    235                      39_displays_display_navigation_lenses\n",
              "41      40    220                            40_search_web_information_pages\n",
              "42      41    220           41_category_categories_categorization_similarity\n",
              "43      42    219                      42_crowdsourcing_workers_crowd_worker\n",
              "44      43    216                          43_patient_patients_care_clinical\n",
              "45      44    215                     44_diagrams_diagrammatic_diagram_logic\n",
              "46      45    207                           45_color_colors_palette_palettes\n",
              "47      46    206                            46_hci_design_research_practice\n",
              "49      47    204                           47_robot_robots_robotic_robotics\n",
              "48      48    204                   48_label_labels_unlabeled_classification\n",
              "50      49    188                         49_keyboard_keyboards_touch_finger\n",
              "51      50    188                       50_sketching_sketches_drawing_design\n",
              "52      51    184                             51_facial_face_animation_faces\n",
              "53      52    175                      52_machine_fairness_deep_explanations\n",
              "54      53    169                       53_papers_conference_issue_editorial\n",
              "55      54    169                        54_heritage_museum_visitors_museums\n",
              "56      55    168                       55_number_symbolic_magnitude_numbers\n",
              "57      56    165                         56_facebook_social_privacy_friends\n",
              "58      57    165                       57_influence_social_networks_network\n",
              "59      58    158                      58_walking_virtual_locomotion_reality\n",
              "60      59    154                   59_reality_augmented_virtual_interaction\n",
              "61      60    147                          60_molecules_atoms_molecule_halos\n",
              "62      61    145                             61_memory_insight_solving_task\n",
              "63      62    144                             62_spline_splines_curves_cubic\n",
              "64      63    141                 63_clustering_clusters_cluster_clusterings\n",
              "66      64    134                   64_impaired_visually_tactile_impairments\n",
              "65      65    134             65_distributed_parallel_scientific_convergence\n",
              "67      66    129               66_wikipedia_communities_community_newcomers\n",
              "68      67    127                   67_metaphors_metaphor_analogical_analogy\n",
              "69      68    127                     68_crowd_crowds_simulation_pedestrians\n",
              "70      69    126              69_conversational_dialogue_agent_conversation\n",
              "71      70    125                            70_tracking_camera_tracker_pose\n",
              "72      71    124                          71_shadow_shadows_light_rendering\n",
              "73      72    113                    72_narrative_story_stories_storytelling\n",
              "74      73    112              73_authentication_passwords_password_security\n",
              "75      74    110                       74_students_math_solving_achievement\n",
              "76      75    105                             75_health_patients_self_online\n",
              "77      76    105                         76_route_map_navigation_wayfinding\n",
              "78      77    105                       77_gene_genome_genomic_visualization\n",
              "79      78    104                    78_image_smoothing_denoising_inpainting\n",
              "80      79    103            79_construction_visualisation_building_heritage\n",
              "81      80    100                        80_solid_solids_boundary_polyhedral\n",
              "82      81     97                    81_electricity_households_heating_smart\n",
              "83      82     91                      82_fractal_fractals_compression_chaos\n",
              "84      83     88                            83_memories_diary_life_everyday\n",
              "85      84     87                    84_civic_civics_infrastructure_citizens\n",
              "86      85     81                                85_xml_query_xquery_queries\n",
              "87      86     79                            86_moral_dilemmas_judgment_harm\n",
              "88      87     78                     87_volume_volumetric_rendering_opacity\n",
              "89      88     77                        88_pointing_target_movement_targets\n",
              "90      89     71                        89_indoor_location_positioning_rfid\n",
              "91      90     70                           90_diffusion_tensor_tracts_brain\n",
              "92      91     68                      91_ontology_schema_ontologies_schemas\n",
              "93      92     65                                 92_email_emails_mail_inbox\n",
              "94      93     64                        93_security_traffic_cyber_intrusion\n",
              "95      94     62                      94_outlier_outliers_datasets_distance\n",
              "96      95     60                            95_video_videos_frames_temporal\n",
              "97      96     59                                 96_tree_trees_plant_plants\n",
              "98      97     59                     97_entity_entities_name_disambiguation\n",
              "100     98     58        98_interruptions_interruption_interruptibility_task\n",
              "99      99     58            99_coordination_interpersonal_synchrony_actions\n",
              "101    100     57                  100_terrain_rendering_terrains_resolution\n",
              "102    101     57                         101_stream_drift_ensemble_drifting\n",
              "103    102     55                       102_cartograms_map_maps_cartographic\n",
              "104    103     55                      103_design_clothing_clothes_designers\n",
              "105    104     54                   104_skeleton_skeletons_segmentation_mesh\n",
              "106    105     52              105_matrix_factorization_nonnegative_matrices\n",
              "107    106     52                    106_parallel_compiler_cache_parallelism\n",
              "108    107     50                          107_event_events_sentinel_ranking\n",
              "109    108     49           108_wavelet_wavelets_multiresolution_subdivision\n",
              "110    109     48              109_children_participatory_child_technologies\n",
              "111    110     48                 110_tabletop_collaboration_touch_groupware\n",
              "112    111     46                  111_collision_collisions_deformable_rigid\n",
              "113    112     45                     112_chatbot_chatbots_chat_conversation\n",
              "114    113     45                            113_hair_hairs_cloth_hairstyles\n",
              "115    114     45              114_watermarking_watermark_watermarks_attacks\n",
              "116    115     44                115_surgical_surgery_laparoscopic_minimally\n",
              "118    116     43                 116_subspace_clustering_clusters_subspaces\n",
              "117    117     43              117_location_recommendation_friends_locations\n",
              "119    118     42                           118_parents_parenting_child_life\n",
              "120    119     40              119_location_privacy_crowdsensing_obfuscation\n",
              "121    120     39                    120_dance_dancers_dancer_choreographers\n",
              "122    121     37                       121_line_clipping_algorithms_polygon\n",
              "123    122     36                   122_occlusion_culling_rendering_occluded\n",
              "124    123     35                  123_multimodal_modality_modalities_speech\n",
              "125    124     35                   124_religious_dreaming_religion_cultural\n",
              "126    125     35               125_spreadsheet_spreadsheets_web_programming\n",
              "127    126     35                       126_cleaning_repairing_repair_tuples\n",
              "128    127     34                        127_polygons_polygon_hull_algorithm\n",
              "129    128     34                       128_spatial_languages_across_meaning\n",
              "130    129     32             129_ubicomp_ubiquitous_design_activitydesigner\n",
              "131    130     31              130_meetings_communication_informal_messaging\n",
              "132    131     30                        131_provenance_lakes_workflows_lake"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 667
        },
        "id": "lAq5XiGEI4ZS",
        "outputId": "c00d7d1b-57c4-4416-84b4-326abec1efec"
      },
      "source": [
        "reduce_model2.visualize_topics()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"0e24f0c5-9f2e-40b5-9347-af569f797967\" class=\"plotly-graph-div\" style=\"height:650px; width:650px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0e24f0c5-9f2e-40b5-9347-af569f797967\")) {                    Plotly.newPlot(                        \"0e24f0c5-9f2e-40b5-9347-af569f797967\",                        [{\"customdata\": [[11.868684768676758, 3.1604151725769043, 0, \"flow | fluid | vortex | jet | vortices\", 1319], [2.7606041431427, -4.349071025848389, 1, \"language | word | linguistic | lexical | verb\", 1136], [-6.535739898681641, 9.788803100585938, 2, \"visualization | topic | visual | visualizations | analytics\", 854], [0.3964632749557495, 4.811205863952637, 3, \"recommendation | recommender | recommendations | users | advertising\", 836], [3.6578328609466553, 11.465657234191895, 4, \"graph | graphs | network | networks | community\", 830], [8.44188404083252, 7.765594482421875, 5, \"shape | mesh | meshes | subdivision | shapes\", 734], [-6.443212985992432, 3.5590553283691406, 6, \"game | games | sports | play | gaming\", 732], [11.775043487548828, 3.0646865367889404, 7, \"light | illumination | rendering | lighting | photon\", 732], [15.862780570983887, 11.847551345825195, 8, \"database | query | queries | join | sql\", 694], [3.7424938678741455, 11.57839298248291, 9, \"dimensional | visualization | multidimensional | scatterplots | dimensions\", 550], [7.897171974182129, 7.720460891723633, 10, \"motion | animation | motions | animations | animated\", 524], [-6.205014705657959, 3.4935336112976074, 11, \"music | musical | voice | sound | audio\", 497], [-1.1663753986358643, -9.120412826538086, 12, \"education | educational | teaching | classroom | teachers\", 496], [-6.485058307647705, 3.3261451721191406, 13, \"driving | vehicle | vehicles | driver | road\", 490], [3.6795248985290527, 0.5402659773826599, 14, \"gesture | gestures | touch | finger | hand\", 461], [0.3242672085762024, 4.884665489196777, 15, \"classification | class | feature | kernel | classifiers\", 449], [-6.335267543792725, 3.3481290340423584, 16, \"gaze | eye | attention | head | movements\", 448], [-6.944188594818115, 2.8746626377105713, 17, \"haptic | tactile | force | virtual | vibrotactile\", 433], [12.726420402526855, 6.789253234863281, 18, \"rendering | graphics | gpu | splatting | meshes\", 419], [3.554155111312866, 9.45654010772705, 19, \"mining | frequent | itemsets | rules | association\", 411], [3.6357901096343994, 9.278410911560059, 20, \"image | images | retrieval | recognition | similarity\", 406], [-6.551287651062012, 10.001723289489746, 21, \"software | programmers | collaboration | developers | collaborative\", 399], [-6.378607749938965, 3.5199828147888184, 22, \"brain | cognitive | attention | visual | memory\", 379], [3.558591842651367, 11.027233123779297, 23, \"trajectory | trajectories | mobility | urban | transportation\", 365], [-5.6023030281066895, 10.080282211303711, 24, \"graphics | graphic | standards | phigs | device\", 347], [3.3749916553497314, 11.154727935791016, 25, \"series | time | patterns | mining | clustering\", 338], [8.50310230255127, 8.14198112487793, 26, \"fabrication | printing | print | manufacturing | digital\", 327], [-5.8299150466918945, 10.022055625915527, 27, \"smart | activities | context | interfaces | homes\", 303], [9.053102493286133, 9.256786346435547, 28, \"vessel | imaging | ultrasound | clinical | vessels\", 301], [8.341508865356445, 7.929600238800049, 29, \"texture | textures | synthesis | image | surface\", 290], [-5.855447769165039, -5.3004536628723145, 30, \"decision | choice | risk | risky | decisions\", 290], [3.632979154586792, 10.949606895446777, 31, \"weather | visualization | climate | ocean | ensembles\", 285], [12.591283798217773, 6.9215474128723145, 32, \"ray | rays | traversal | rendering | casting\", 279], [-7.267782211303711, 15.964272499084473, 33, \"twitter | tweets | media | sentiment | tweet\", 276], [8.324955940246582, 7.9045891761779785, 34, \"creativity | painting | art | creative | artistic\", 273], [-5.748463153839111, -5.193476676940918, 35, \"causal | beliefs | evidence | belief | explanations\", 273], [-7.32440185546875, 10.271029472351074, 36, \"privacy | security | private | protection | anonymity\", 262], [8.462368965148926, 8.163976669311523, 37, \"urban | city | building | buildings | cities\", 253], [15.862753868103027, 11.84752368927002, 38, \"transaction | transactions | concurrency | distributed | workloads\", 240], [-6.762753009796143, 3.1054389476776123, 39, \"displays | display | navigation | lenses | optical\", 235], [-6.531688690185547, 10.017546653747559, 40, \"search | web | information | pages | browsing\", 220], [2.7241194248199463, -4.3124165534973145, 41, \"category | categories | categorization | similarity | exemplars\", 220], [-7.2069268226623535, 10.227423667907715, 42, \"crowdsourcing | workers | crowd | worker | tasks\", 219], [-7.3897385597229, 15.551200866699219, 43, \"patient | patients | care | clinical | hospital\", 216], [3.432169198989868, 9.715310096740723, 44, \"diagrams | diagrammatic | diagram | logic | reasoning\", 215], [8.762940406799316, 8.197704315185547, 45, \"color | colors | palette | palettes | colour\", 207], [6.43979024887085, 27.620853424072266, 46, \"hci | design | research | practice | designers\", 206], [-1.0834094285964966, 8.659132957458496, 47, \"robot | robots | robotic | robotics | interaction\", 204], [0.424080491065979, 4.782667636871338, 48, \"label | labels | unlabeled | classification | labeled\", 204], [3.6711528301239014, 0.5468394160270691, 49, \"keyboard | keyboards | touch | finger | handwriting\", 188], [8.45375919342041, 8.052485466003418, 50, \"sketching | sketches | drawing | design | drawings\", 188], [7.986983299255371, 7.762218952178955, 51, \"facial | face | animation | faces | blendshape\", 184], [-7.1292548179626465, 10.123591423034668, 52, \"machine | fairness | deep | explanations | trust\", 175], [-5.527196407318115, 9.975396156311035, 53, \"papers | conference | issue | editorial | symposium\", 169], [-0.32911571860313416, 20.162586212158203, 54, \"heritage | museum | visitors | museums | exhibition\", 169], [-1.1200344562530518, -9.076762199401855, 55, \"number | symbolic | magnitude | numbers | arithmetic\", 168], [-7.299008846282959, 15.956918716430664, 56, \"facebook | social | privacy | friends | sites\", 165], [3.63911771774292, 9.504327774047852, 57, \"influence | social | networks | network | diffusion\", 165], [-6.893718719482422, 2.9287712574005127, 58, \"walking | virtual | locomotion | reality | immersive\", 158], [-5.591194152832031, 10.018115997314453, 59, \"reality | augmented | virtual | interaction | environment\", 154], [3.9524333477020264, 11.787609100341797, 60, \"molecules | atoms | molecule | halos | structures\", 147], [3.020061492919922, -4.60844087600708, 61, \"memory | insight | solving | task | cognitive\", 145], [14.589229583740234, -7.700401306152344, 62, \"spline | splines | curves | cubic | surfaces\", 144], [3.388451337814331, 9.720592498779297, 63, \"clustering | clusters | cluster | clusterings | similarity\", 141], [-6.363117694854736, 3.3777353763580322, 64, \"impaired | visually | tactile | impairments | sighted\", 134], [12.68430233001709, 6.833373069763184, 65, \"distributed | parallel | scientific | convergence | algorithms\", 134], [-7.35420560836792, 16.074541091918945, 66, \"wikipedia | communities | community | newcomers | leadership\", 129], [2.4735562801361084, -4.060645580291748, 67, \"metaphors | metaphor | analogical | analogy | metaphorical\", 127], [8.171136856079102, 8.169933319091797, 68, \"crowd | crowds | simulation | pedestrians | pedestrian\", 127], [-1.1162188053131104, 8.691009521484375, 69, \"conversational | dialogue | agent | conversation | conversations\", 126], [9.242505073547363, 7.959481716156006, 70, \"tracking | camera | tracker | pose | calibration\", 125], [11.545699119567871, 2.8332502841949463, 71, \"shadow | shadows | light | rendering | scenes\", 124], [-6.571671962738037, 10.044303894042969, 72, \"narrative | story | stories | storytelling | storyline\", 113], [-7.483659744262695, 10.39300537109375, 73, \"authentication | passwords | password | security | surfing\", 112], [-1.083357810974121, -9.039263725280762, 74, \"students | math | solving | achievement | learning\", 110], [-7.301525592803955, 15.70393180847168, 75, \"health | patients | self | online | communities\", 105], [-6.866877555847168, 3.073136568069458, 76, \"route | map | navigation | wayfinding | spatial\", 105], [3.965106964111328, 11.745704650878906, 77, \"gene | genome | genomic | visualization | biologists\", 105], [8.832569122314453, 7.794466495513916, 78, \"image | smoothing | denoising | inpainting | filter\", 104], [-0.3772040605545044, 20.196086883544922, 79, \"construction | visualisation | building | heritage | archaeological\", 103], [14.586947441101074, -7.702823162078857, 80, \"solid | solids | boundary | polyhedral | surfaces\", 100], [-5.926206111907959, 10.086041450500488, 81, \"electricity | households | heating | smart | sustainable\", 97], [8.412659645080566, 8.274903297424316, 82, \"fractal | fractals | compression | chaos | terrain\", 91], [-7.239865303039551, 15.706220626831055, 83, \"memories | diary | life | everyday | couples\", 88], [6.423999786376953, 27.604999542236328, 84, \"civic | civics | infrastructure | citizens | participation\", 87], [5.609729766845703, 19.836599349975586, 85, \"xml | query | xquery | queries | twig\", 81], [-5.737010478973389, -5.181972503662109, 86, \"moral | dilemmas | judgment | harm | morality\", 79], [8.871850967407227, 8.944318771362305, 87, \"volume | volumetric | rendering | opacity | visualization\", 78], [3.6792304515838623, 0.5404726266860962, 88, \"pointing | target | movement | targets | endpoint\", 77], [9.336784362792969, 7.958555221557617, 89, \"indoor | location | positioning | rfid | fingerprinting\", 71], [8.929154396057129, 9.09412956237793, 90, \"diffusion | tensor | tracts | brain | fibers\", 70], [5.539397716522217, 19.90680503845215, 91, \"ontology | schema | ontologies | schemas | rdf\", 68], [-3.337188720703125, 0.27987778186798096, 92, \"email | emails | mail | inbox | folders\", 65], [3.1896018981933594, 11.335395812988281, 93, \"security | traffic | cyber | intrusion | attack\", 64], [3.4542832374572754, 9.654950141906738, 94, \"outlier | outliers | datasets | distance | anomaly\", 62], [8.896445274353027, 8.934627532958984, 95, \"video | videos | frames | temporal | browsing\", 60], [8.418513298034668, 8.516043663024902, 96, \"tree | trees | plant | plants | branches\", 59], [0.6458214521408081, 4.557700157165527, 97, \"entity | entities | name | disambiguation | named\", 59], [-3.3371689319610596, 0.2799298167228699, 98, \"interruptions | interruption | interruptibility | task | interrupted\", 58], [2.943784713745117, -4.532383918762207, 99, \"coordination | interpersonal | synchrony | actions | partner\", 58], [11.483664512634277, 2.772289752960205, 100, \"terrain | rendering | terrains | resolution | texture\", 57], [3.8511974811553955, 9.726228713989258, 101, \"stream | drift | ensemble | drifting | mining\", 57], [3.6677815914154053, 11.556946754455566, 102, \"cartograms | map | maps | cartographic | cartography\", 55], [6.526102542877197, 27.707212448120117, 103, \"design | clothing | clothes | designers | garments\", 55], [3.59574818611145, 9.459925651550293, 104, \"skeleton | skeletons | segmentation | mesh | thinning\", 54], [3.466625928878784, 9.609652519226074, 105, \"matrix | factorization | nonnegative | matrices | norm\", 52], [12.736969947814941, 6.781201362609863, 106, \"parallel | compiler | cache | parallelism | multiprocessors\", 52], [3.141235589981079, 11.273677825927734, 107, \"event | events | sentinel | ranking | visualization\", 50], [14.59022331237793, -7.69925594329834, 108, \"wavelet | wavelets | multiresolution | subdivision | biorthogonal\", 49], [6.155886173248291, 27.33679962158203, 109, \"children | participatory | child | technologies | preschoolers\", 48], [-7.324131488800049, 2.765577554702759, 110, \"tabletop | collaboration | touch | groupware | collaborative\", 48], [11.508856773376465, 2.7985987663269043, 111, \"collision | collisions | deformable | rigid | deforming\", 46], [-1.1470123529434204, 8.720987319946289, 112, \"chatbot | chatbots | chat | conversation | conversational\", 45], [11.557623863220215, 2.8459651470184326, 113, \"hair | hairs | cloth | hairstyles | furry\", 45], [8.843070030212402, 7.724420070648193, 114, \"watermarking | watermark | watermarks | attacks | scheme\", 45], [9.14622688293457, 9.334461212158203, 115, \"surgical | surgery | laparoscopic | minimally | haptic\", 44], [3.4937033653259277, 9.645392417907715, 116, \"subspace | clustering | clusters | subspaces | overlapping\", 43], [0.23658835887908936, 4.974249839782715, 117, \"location | recommendation | friends | locations | networks\", 43], [-7.250686168670654, 15.681413650512695, 118, \"parents | parenting | child | life | bereaved\", 42], [0.10759016126394272, 5.1058502197265625, 119, \"location | privacy | crowdsensing | obfuscation | crowd\", 40], [6.16538143157959, 27.346166610717773, 120, \"dance | dancers | dancer | choreographers | choreographer\", 39], [19.11229705810547, -0.1338152140378952, 121, \"line | clipping | algorithms | polygon | segments\", 37], [11.342437744140625, 2.6311755180358887, 122, \"occlusion | culling | rendering | occluded | occluders\", 36], [-7.40950345993042, 2.692598581314087, 123, \"multimodal | modality | modalities | speech | interfaces\", 35], [2.597790241241455, -4.185831546783447, 124, \"religious | dreaming | religion | cultural | normative\", 35], [5.480823040008545, 19.96533966064453, 125, \"spreadsheet | spreadsheets | web | programming | excel\", 35], [0.7015551924705505, 4.502266883850098, 126, \"cleaning | repairing | repair | tuples | quality\", 35], [19.112289428710938, -0.1338028758764267, 127, \"polygons | polygon | hull | algorithm | algorithms\", 34], [2.4048421382904053, -3.991408586502075, 128, \"spatial | languages | across | meaning | relations\", 34], [6.554628372192383, 27.73563003540039, 129, \"ubicomp | ubiquitous | design | activitydesigner | prototypes\", 32], [-7.395902156829834, 2.7111778259277344, 130, \"meetings | communication | informal | messaging | collaboration\", 31], [5.707022666931152, 19.739303588867188, 131, \"provenance | lakes | workflows | lake | datamaran\", 30]], \"hovertemplate\": \"<b>Topic %{customdata[2]}</b><br>Words: %{customdata[3]}<br>Size: %{customdata[4]}\", \"legendgroup\": \"\", \"marker\": {\"color\": \"#B0BEC5\", \"line\": {\"color\": \"DarkSlateGrey\", \"width\": 2}, \"size\": [1319, 1136, 854, 836, 830, 734, 732, 732, 694, 550, 524, 497, 496, 490, 461, 449, 448, 433, 419, 411, 406, 399, 379, 365, 347, 338, 327, 303, 301, 290, 290, 285, 279, 276, 273, 273, 262, 253, 240, 235, 220, 220, 219, 216, 215, 207, 206, 204, 204, 188, 188, 184, 175, 169, 169, 168, 165, 165, 158, 154, 147, 145, 144, 141, 134, 134, 129, 127, 127, 126, 125, 124, 113, 112, 110, 105, 105, 105, 104, 103, 100, 97, 91, 88, 87, 81, 79, 78, 77, 71, 70, 68, 65, 64, 62, 60, 59, 59, 58, 58, 57, 57, 55, 55, 54, 52, 52, 50, 49, 48, 48, 46, 45, 45, 45, 44, 43, 43, 42, 40, 39, 37, 36, 35, 35, 35, 35, 34, 34, 32, 31, 30], \"sizemode\": \"area\", \"sizeref\": 0.824375, \"symbol\": \"circle\"}, \"mode\": \"markers\", \"name\": \"\", \"orientation\": \"v\", \"showlegend\": false, \"type\": \"scatter\", \"x\": [11.868684768676758, 2.7606041431427, -6.535739898681641, 0.3964632749557495, 3.6578328609466553, 8.44188404083252, -6.443212985992432, 11.775043487548828, 15.862780570983887, 3.7424938678741455, 7.897171974182129, -6.205014705657959, -1.1663753986358643, -6.485058307647705, 3.6795248985290527, 0.3242672085762024, -6.335267543792725, -6.944188594818115, 12.726420402526855, 3.554155111312866, 3.6357901096343994, -6.551287651062012, -6.378607749938965, 3.558591842651367, -5.6023030281066895, 3.3749916553497314, 8.50310230255127, -5.8299150466918945, 9.053102493286133, 8.341508865356445, -5.855447769165039, 3.632979154586792, 12.591283798217773, -7.267782211303711, 8.324955940246582, -5.748463153839111, -7.32440185546875, 8.462368965148926, 15.862753868103027, -6.762753009796143, -6.531688690185547, 2.7241194248199463, -7.2069268226623535, -7.3897385597229, 3.432169198989868, 8.762940406799316, 6.43979024887085, -1.0834094285964966, 0.424080491065979, 3.6711528301239014, 8.45375919342041, 7.986983299255371, -7.1292548179626465, -5.527196407318115, -0.32911571860313416, -1.1200344562530518, -7.299008846282959, 3.63911771774292, -6.893718719482422, -5.591194152832031, 3.9524333477020264, 3.020061492919922, 14.589229583740234, 3.388451337814331, -6.363117694854736, 12.68430233001709, -7.35420560836792, 2.4735562801361084, 8.171136856079102, -1.1162188053131104, 9.242505073547363, 11.545699119567871, -6.571671962738037, -7.483659744262695, -1.083357810974121, -7.301525592803955, -6.866877555847168, 3.965106964111328, 8.832569122314453, -0.3772040605545044, 14.586947441101074, -5.926206111907959, 8.412659645080566, -7.239865303039551, 6.423999786376953, 5.609729766845703, -5.737010478973389, 8.871850967407227, 3.6792304515838623, 9.336784362792969, 8.929154396057129, 5.539397716522217, -3.337188720703125, 3.1896018981933594, 3.4542832374572754, 8.896445274353027, 8.418513298034668, 0.6458214521408081, -3.3371689319610596, 2.943784713745117, 11.483664512634277, 3.8511974811553955, 3.6677815914154053, 6.526102542877197, 3.59574818611145, 3.466625928878784, 12.736969947814941, 3.141235589981079, 14.59022331237793, 6.155886173248291, -7.324131488800049, 11.508856773376465, -1.1470123529434204, 11.557623863220215, 8.843070030212402, 9.14622688293457, 3.4937033653259277, 0.23658835887908936, -7.250686168670654, 0.10759016126394272, 6.16538143157959, 19.11229705810547, 11.342437744140625, -7.40950345993042, 2.597790241241455, 5.480823040008545, 0.7015551924705505, 19.112289428710938, 2.4048421382904053, 6.554628372192383, -7.395902156829834, 5.707022666931152], \"xaxis\": \"x\", \"y\": [3.1604151725769043, -4.349071025848389, 9.788803100585938, 4.811205863952637, 11.465657234191895, 7.765594482421875, 3.5590553283691406, 3.0646865367889404, 11.847551345825195, 11.57839298248291, 7.720460891723633, 3.4935336112976074, -9.120412826538086, 3.3261451721191406, 0.5402659773826599, 4.884665489196777, 3.3481290340423584, 2.8746626377105713, 6.789253234863281, 9.45654010772705, 9.278410911560059, 10.001723289489746, 3.5199828147888184, 11.027233123779297, 10.080282211303711, 11.154727935791016, 8.14198112487793, 10.022055625915527, 9.256786346435547, 7.929600238800049, -5.3004536628723145, 10.949606895446777, 6.9215474128723145, 15.964272499084473, 7.9045891761779785, -5.193476676940918, 10.271029472351074, 8.163976669311523, 11.84752368927002, 3.1054389476776123, 10.017546653747559, -4.3124165534973145, 10.227423667907715, 15.551200866699219, 9.715310096740723, 8.197704315185547, 27.620853424072266, 8.659132957458496, 4.782667636871338, 0.5468394160270691, 8.052485466003418, 7.762218952178955, 10.123591423034668, 9.975396156311035, 20.162586212158203, -9.076762199401855, 15.956918716430664, 9.504327774047852, 2.9287712574005127, 10.018115997314453, 11.787609100341797, -4.60844087600708, -7.700401306152344, 9.720592498779297, 3.3777353763580322, 6.833373069763184, 16.074541091918945, -4.060645580291748, 8.169933319091797, 8.691009521484375, 7.959481716156006, 2.8332502841949463, 10.044303894042969, 10.39300537109375, -9.039263725280762, 15.70393180847168, 3.073136568069458, 11.745704650878906, 7.794466495513916, 20.196086883544922, -7.702823162078857, 10.086041450500488, 8.274903297424316, 15.706220626831055, 27.604999542236328, 19.836599349975586, -5.181972503662109, 8.944318771362305, 0.5404726266860962, 7.958555221557617, 9.09412956237793, 19.90680503845215, 0.27987778186798096, 11.335395812988281, 9.654950141906738, 8.934627532958984, 8.516043663024902, 4.557700157165527, 0.2799298167228699, -4.532383918762207, 2.772289752960205, 9.726228713989258, 11.556946754455566, 27.707212448120117, 9.459925651550293, 9.609652519226074, 6.781201362609863, 11.273677825927734, -7.69925594329834, 27.33679962158203, 2.765577554702759, 2.7985987663269043, 8.720987319946289, 2.8459651470184326, 7.724420070648193, 9.334461212158203, 9.645392417907715, 4.974249839782715, 15.681413650512695, 5.1058502197265625, 27.346166610717773, -0.1338152140378952, 2.6311755180358887, 2.692598581314087, -4.185831546783447, 19.96533966064453, 4.502266883850098, -0.1338028758764267, -3.991408586502075, 27.73563003540039, 2.7111778259277344, 19.739303588867188], \"yaxis\": \"y\"}],                        {\"annotations\": [{\"showarrow\": false, \"text\": \"D1\", \"x\": -8.6062087059021, \"y\": 10.703749895095825, \"yshift\": 10}, {\"showarrow\": false, \"text\": \"D2\", \"x\": 6.686466455459594, \"xshift\": 10, \"y\": 31.895974540710448}], \"height\": 650, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"legend\": {\"itemsizing\": \"constant\", \"tracegroupgap\": 0}, \"margin\": {\"t\": 60}, \"shapes\": [{\"line\": {\"color\": \"#CFD8DC\", \"width\": 2}, \"type\": \"line\", \"x0\": 6.686466455459594, \"x1\": 6.686466455459594, \"y0\": -10.4884747505188, \"y1\": 31.895974540710448}, {\"line\": {\"color\": \"#9E9E9E\", \"width\": 2}, \"type\": \"line\", \"x0\": -8.6062087059021, \"x1\": 21.979141616821288, \"y0\": 10.703749895095825, \"y1\": 10.703749895095825}], \"sliders\": [{\"active\": 0, \"pad\": {\"t\": 50}, \"steps\": [{\"args\": [{\"marker.color\": [[\"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 0\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 1\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 2\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 3\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 4\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 5\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 6\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 7\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 8\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 9\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 10\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 11\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 12\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 13\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 14\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 15\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 16\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 17\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 18\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 19\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 20\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 21\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 22\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 23\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 24\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 25\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 26\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 27\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 28\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 29\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 30\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 31\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 32\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 33\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 34\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 35\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 36\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 37\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 38\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 39\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 40\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 41\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 42\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 43\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 44\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 45\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 46\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 47\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 48\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 49\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 50\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 51\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 52\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 53\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 54\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 55\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 56\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 57\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 58\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 59\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 60\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 61\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 62\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 63\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 64\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 65\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 66\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 67\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 68\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 69\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 70\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 71\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 72\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 73\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 74\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 75\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 76\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 77\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 78\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 79\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 80\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 81\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 82\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 83\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 84\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 85\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 86\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 87\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 88\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 89\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 90\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 91\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 92\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 93\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 94\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 95\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 96\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 97\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 98\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 99\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 100\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 101\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 102\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 103\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 104\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 105\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 106\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 107\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 108\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 109\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 110\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 111\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 112\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 113\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 114\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 115\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 116\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 117\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 118\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 119\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 120\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 121\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 122\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 123\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 124\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 125\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 126\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 127\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 128\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\", \"#B0BEC5\"]]}], \"label\": \"Topic 129\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\", \"#B0BEC5\"]]}], \"label\": \"Topic 130\", \"method\": \"update\"}, {\"args\": [{\"marker.color\": [[\"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"#B0BEC5\", \"red\"]]}], \"label\": \"Topic 131\", \"method\": \"update\"}]}], \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"rgb(36,36,36)\"}, \"error_y\": {\"color\": \"rgb(36,36,36)\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"rgb(36,36,36)\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"rgb(36,36,36)\"}, \"baxis\": {\"endlinecolor\": \"rgb(36,36,36)\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"rgb(36,36,36)\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.6}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}, \"colorscale\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"rgb(237,237,237)\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"rgb(217,217,217)\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 1, \"tickcolor\": \"rgb(36,36,36)\", \"ticks\": \"outside\"}}, \"colorscale\": {\"diverging\": [[0.0, \"rgb(103,0,31)\"], [0.1, \"rgb(178,24,43)\"], [0.2, \"rgb(214,96,77)\"], [0.3, \"rgb(244,165,130)\"], [0.4, \"rgb(253,219,199)\"], [0.5, \"rgb(247,247,247)\"], [0.6, \"rgb(209,229,240)\"], [0.7, \"rgb(146,197,222)\"], [0.8, \"rgb(67,147,195)\"], [0.9, \"rgb(33,102,172)\"], [1.0, \"rgb(5,48,97)\"]], \"sequential\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]], \"sequentialminus\": [[0.0, \"#440154\"], [0.1111111111111111, \"#482878\"], [0.2222222222222222, \"#3e4989\"], [0.3333333333333333, \"#31688e\"], [0.4444444444444444, \"#26828e\"], [0.5555555555555556, \"#1f9e89\"], [0.6666666666666666, \"#35b779\"], [0.7777777777777778, \"#6ece58\"], [0.8888888888888888, \"#b5de2b\"], [1.0, \"#fde725\"]]}, \"colorway\": [\"#1F77B4\", \"#FF7F0E\", \"#2CA02C\", \"#D62728\", \"#9467BD\", \"#8C564B\", \"#E377C2\", \"#7F7F7F\", \"#BCBD22\", \"#17BECF\"], \"font\": {\"color\": \"rgb(36,36,36)\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"rgb(232,232,232)\", \"gridwidth\": 2, \"linecolor\": \"rgb(36,36,36)\", \"showbackground\": true, \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\", \"zeroline\": false, \"zerolinecolor\": \"rgb(36,36,36)\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"rgb(232,232,232)\", \"gridwidth\": 2, \"linecolor\": \"rgb(36,36,36)\", \"showbackground\": true, \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\", \"zeroline\": false, \"zerolinecolor\": \"rgb(36,36,36)\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"rgb(232,232,232)\", \"gridwidth\": 2, \"linecolor\": \"rgb(36,36,36)\", \"showbackground\": true, \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\", \"zeroline\": false, \"zerolinecolor\": \"rgb(36,36,36)\"}}, \"shapedefaults\": {\"fillcolor\": \"black\", \"line\": {\"width\": 0}, \"opacity\": 0.3}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\"}, \"baxis\": {\"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\", \"title\": {\"standoff\": 15}, \"zeroline\": false, \"zerolinecolor\": \"rgb(36,36,36)\"}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"rgb(232,232,232)\", \"linecolor\": \"rgb(36,36,36)\", \"showgrid\": false, \"showline\": true, \"ticks\": \"outside\", \"title\": {\"standoff\": 15}, \"zeroline\": false, \"zerolinecolor\": \"rgb(36,36,36)\"}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Intertopic Distance Map\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.95, \"yanchor\": \"top\"}, \"width\": 650, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 1.0], \"range\": [-8.6062087059021, 21.979141616821288], \"title\": {\"text\": \"\"}, \"visible\": false}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.0, 1.0], \"range\": [-10.4884747505188, 31.895974540710448], \"title\": {\"text\": \"\"}, \"visible\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0e24f0c5-9f2e-40b5-9347-af569f797967');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "hOC60mBnJIwT",
        "outputId": "788b22f8-97c3-48b0-d9e7-ece449bcd9bc"
      },
      "source": [
        "reduce_model2.visualize_hierarchy()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"0054685c-f518-426e-b1cf-5b01e1502ca4\" class=\"plotly-graph-div\" style=\"height:600px; width:1000px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"0054685c-f518-426e-b1cf-5b01e1502ca4\")) {                    Plotly.newPlot(                        \"0054685c-f518-426e-b1cf-5b01e1502ca4\",                        [{\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.17485890779850344, 0.17485890779850344, 0.0], \"xaxis\": \"x\", \"y\": [-5.0, -5.0, -15.0, -15.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.16515839759230325, 0.16515839759230325, 0.0], \"xaxis\": \"x\", \"y\": [-25.0, -25.0, -35.0, -35.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.16597932701845083, 0.16597932701845083, 0.0], \"xaxis\": \"x\", \"y\": [-55.0, -55.0, -65.0, -65.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.20563641440332037, 0.20563641440332037, 0.16597932701845083], \"xaxis\": \"x\", \"y\": [-45.0, -45.0, -60.0, -60.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.16515839759230325, 0.23605599198164087, 0.23605599198164087, 0.20563641440332037], \"xaxis\": \"x\", \"y\": [-30.0, -30.0, -52.5, -52.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.17485890779850344, 0.2999720101139824, 0.2999720101139824, 0.23605599198164087], \"xaxis\": \"x\", \"y\": [-10.0, -10.0, -41.25, -41.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15280172551403032, 0.15280172551403032, 0.0], \"xaxis\": \"x\", \"y\": [-75.0, -75.0, -85.0, -85.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13317886992962863, 0.13317886992962863, 0.0], \"xaxis\": \"x\", \"y\": [-105.0, -105.0, -115.0, -115.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1593059756359724, 0.1593059756359724, 0.13317886992962863], \"xaxis\": \"x\", \"y\": [-95.0, -95.0, -110.0, -110.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.15280172551403032, 0.23972812010739747, 0.23972812010739747, 0.1593059756359724], \"xaxis\": \"x\", \"y\": [-80.0, -80.0, -102.5, -102.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.14118780722343396, 0.14118780722343396, 0.0], \"xaxis\": \"x\", \"y\": [-135.0, -135.0, -145.0, -145.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1960478116774795, 0.1960478116774795, 0.14118780722343396], \"xaxis\": \"x\", \"y\": [-125.0, -125.0, -140.0, -140.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.22222617225496127, 0.22222617225496127, 0.0], \"xaxis\": \"x\", \"y\": [-155.0, -155.0, -165.0, -165.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1960478116774795, 0.319719696114872, 0.319719696114872, 0.22222617225496127], \"xaxis\": \"x\", \"y\": [-132.5, -132.5, -160.0, -160.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.23972812010739747, 0.3408028233227461, 0.3408028233227461, 0.319719696114872], \"xaxis\": \"x\", \"y\": [-91.25, -91.25, -146.25, -146.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(61,153,112)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.2999720101139824, 0.4057082632071199, 0.4057082632071199, 0.3408028233227461], \"xaxis\": \"x\", \"y\": [-25.625, -25.625, -118.75, -118.75], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.16266368551943286, 0.16266368551943286, 0.0], \"xaxis\": \"x\", \"y\": [-175.0, -175.0, -185.0, -185.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.10281912403813312, 0.10281912403813312, 0.0], \"xaxis\": \"x\", \"y\": [-195.0, -195.0, -205.0, -205.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.11783430682662602, 0.11783430682662602, 0.0], \"xaxis\": \"x\", \"y\": [-225.0, -225.0, -235.0, -235.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.17310539890395704, 0.17310539890395704, 0.11783430682662602], \"xaxis\": \"x\", \"y\": [-215.0, -215.0, -230.0, -230.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.10281912403813312, 0.1889494745763911, 0.1889494745763911, 0.17310539890395704], \"xaxis\": \"x\", \"y\": [-200.0, -200.0, -222.5, -222.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.16266368551943286, 0.24733971609652397, 0.24733971609652397, 0.1889494745763911], \"xaxis\": \"x\", \"y\": [-180.0, -180.0, -211.25, -211.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1768538448172071, 0.1768538448172071, 0.0], \"xaxis\": \"x\", \"y\": [-245.0, -245.0, -255.0, -255.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18680857497283754, 0.18680857497283754, 0.0], \"xaxis\": \"x\", \"y\": [-265.0, -265.0, -275.0, -275.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1768538448172071, 0.22438107777307523, 0.22438107777307523, 0.18680857497283754], \"xaxis\": \"x\", \"y\": [-250.0, -250.0, -270.0, -270.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1629351921666718, 0.1629351921666718, 0.0], \"xaxis\": \"x\", \"y\": [-285.0, -285.0, -295.0, -295.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1514264351267559, 0.1514264351267559, 0.0], \"xaxis\": \"x\", \"y\": [-305.0, -305.0, -315.0, -315.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15763396389989268, 0.15763396389989268, 0.0], \"xaxis\": \"x\", \"y\": [-325.0, -325.0, -335.0, -335.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1514264351267559, 0.20433102890451008, 0.20433102890451008, 0.15763396389989268], \"xaxis\": \"x\", \"y\": [-310.0, -310.0, -330.0, -330.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1629351921666718, 0.25182987029560405, 0.25182987029560405, 0.20433102890451008], \"xaxis\": \"x\", \"y\": [-290.0, -290.0, -320.0, -320.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.22438107777307523, 0.2741128468406493, 0.2741128468406493, 0.25182987029560405], \"xaxis\": \"x\", \"y\": [-260.0, -260.0, -305.0, -305.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.24733971609652397, 0.38885445851115047, 0.38885445851115047, 0.2741128468406493], \"xaxis\": \"x\", \"y\": [-195.625, -195.625, -282.5, -282.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.14074113235927269, 0.14074113235927269, 0.0], \"xaxis\": \"x\", \"y\": [-365.0, -365.0, -375.0, -375.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1775397619005731, 0.1775397619005731, 0.14074113235927269], \"xaxis\": \"x\", \"y\": [-355.0, -355.0, -370.0, -370.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.19347696070538, 0.19347696070538, 0.1775397619005731], \"xaxis\": \"x\", \"y\": [-345.0, -345.0, -362.5, -362.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.14349166905887267, 0.14349166905887267, 0.0], \"xaxis\": \"x\", \"y\": [-395.0, -395.0, -405.0, -405.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18718424696384295, 0.18718424696384295, 0.14349166905887267], \"xaxis\": \"x\", \"y\": [-385.0, -385.0, -400.0, -400.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1425031665252787, 0.1425031665252787, 0.0], \"xaxis\": \"x\", \"y\": [-415.0, -415.0, -425.0, -425.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13332720110185597, 0.13332720110185597, 0.0], \"xaxis\": \"x\", \"y\": [-445.0, -445.0, -455.0, -455.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13882631787527772, 0.13882631787527772, 0.13332720110185597], \"xaxis\": \"x\", \"y\": [-435.0, -435.0, -450.0, -450.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13974102491338003, 0.13974102491338003, 0.0], \"xaxis\": \"x\", \"y\": [-465.0, -465.0, -475.0, -475.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.13882631787527772, 0.1952714442398025, 0.1952714442398025, 0.13974102491338003], \"xaxis\": \"x\", \"y\": [-442.5, -442.5, -470.0, -470.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1425031665252787, 0.2219470309707934, 0.2219470309707934, 0.1952714442398025], \"xaxis\": \"x\", \"y\": [-420.0, -420.0, -456.25, -456.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.18718424696384295, 0.28193494320357104, 0.28193494320357104, 0.2219470309707934], \"xaxis\": \"x\", \"y\": [-392.5, -392.5, -438.125, -438.125], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.19347696070538, 0.36499153288170805, 0.36499153288170805, 0.28193494320357104], \"xaxis\": \"x\", \"y\": [-353.75, -353.75, -415.3125, -415.3125], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15129730411344988, 0.15129730411344988, 0.0], \"xaxis\": \"x\", \"y\": [-485.0, -485.0, -495.0, -495.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.12364395326482862, 0.12364395326482862, 0.0], \"xaxis\": \"x\", \"y\": [-515.0, -515.0, -525.0, -525.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15827106691814835, 0.15827106691814835, 0.12364395326482862], \"xaxis\": \"x\", \"y\": [-505.0, -505.0, -520.0, -520.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.15129730411344988, 0.1803640234440341, 0.1803640234440341, 0.15827106691814835], \"xaxis\": \"x\", \"y\": [-490.0, -490.0, -512.5, -512.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13632655613490002, 0.13632655613490002, 0.0], \"xaxis\": \"x\", \"y\": [-545.0, -545.0, -555.0, -555.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.17601912281804605, 0.17601912281804605, 0.13632655613490002], \"xaxis\": \"x\", \"y\": [-535.0, -535.0, -550.0, -550.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1264009387418465, 0.1264009387418465, 0.0], \"xaxis\": \"x\", \"y\": [-565.0, -565.0, -575.0, -575.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13876328738865468, 0.13876328738865468, 0.0], \"xaxis\": \"x\", \"y\": [-585.0, -585.0, -595.0, -595.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1264009387418465, 0.20603791119703224, 0.20603791119703224, 0.13876328738865468], \"xaxis\": \"x\", \"y\": [-570.0, -570.0, -590.0, -590.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.17601912281804605, 0.24965848709307942, 0.24965848709307942, 0.20603791119703224], \"xaxis\": \"x\", \"y\": [-542.5, -542.5, -580.0, -580.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1803640234440341, 0.3023781338401038, 0.3023781338401038, 0.24965848709307942], \"xaxis\": \"x\", \"y\": [-501.25, -501.25, -561.25, -561.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.13625266955848817, 0.13625266955848817, 0.0], \"xaxis\": \"x\", \"y\": [-605.0, -605.0, -615.0, -615.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18239084594446228, 0.18239084594446228, 0.0], \"xaxis\": \"x\", \"y\": [-625.0, -625.0, -635.0, -635.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.13625266955848817, 0.22737654756595993, 0.22737654756595993, 0.18239084594446228], \"xaxis\": \"x\", \"y\": [-610.0, -610.0, -630.0, -630.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1336968627481289, 0.1336968627481289, 0.0], \"xaxis\": \"x\", \"y\": [-655.0, -655.0, -665.0, -665.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1897971804942442, 0.1897971804942442, 0.1336968627481289], \"xaxis\": \"x\", \"y\": [-645.0, -645.0, -660.0, -660.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18129833746591395, 0.18129833746591395, 0.0], \"xaxis\": \"x\", \"y\": [-675.0, -675.0, -685.0, -685.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.20391159333208092, 0.20391159333208092, 0.0], \"xaxis\": \"x\", \"y\": [-695.0, -695.0, -705.0, -705.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.18129833746591395, 0.26688647371957963, 0.26688647371957963, 0.20391159333208092], \"xaxis\": \"x\", \"y\": [-680.0, -680.0, -700.0, -700.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1897971804942442, 0.32388424413480654, 0.32388424413480654, 0.26688647371957963], \"xaxis\": \"x\", \"y\": [-652.5, -652.5, -690.0, -690.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.22737654756595993, 0.42038488071052066, 0.42038488071052066, 0.32388424413480654], \"xaxis\": \"x\", \"y\": [-620.0, -620.0, -671.25, -671.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.3023781338401038, 0.5409912882610275, 0.5409912882610275, 0.42038488071052066], \"xaxis\": \"x\", \"y\": [-531.25, -531.25, -645.625, -645.625], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.36499153288170805, 0.6251462465459292, 0.6251462465459292, 0.5409912882610275], \"xaxis\": \"x\", \"y\": [-384.53125, -384.53125, -588.4375, -588.4375], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(255,65,54)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.38885445851115047, 0.7094353002093795, 0.7094353002093795, 0.6251462465459292], \"xaxis\": \"x\", \"y\": [-239.0625, -239.0625, -486.484375, -486.484375], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(0,116,217)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.4057082632071199, 1.0174639117199804, 1.0174639117199804, 0.7094353002093795], \"xaxis\": \"x\", \"y\": [-72.1875, -72.1875, -362.7734375, -362.7734375], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.23687047094751335, 0.23687047094751335, 0.0], \"xaxis\": \"x\", \"y\": [-715.0, -715.0, -725.0, -725.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2821958998466855, 0.2821958998466855, 0.0], \"xaxis\": \"x\", \"y\": [-735.0, -735.0, -745.0, -745.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.23687047094751335, 0.3297940260000526, 0.3297940260000526, 0.2821958998466855], \"xaxis\": \"x\", \"y\": [-720.0, -720.0, -740.0, -740.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2516308601887702, 0.2516308601887702, 0.0], \"xaxis\": \"x\", \"y\": [-765.0, -765.0, -775.0, -775.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.28217059638943853, 0.28217059638943853, 0.2516308601887702], \"xaxis\": \"x\", \"y\": [-755.0, -755.0, -770.0, -770.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.16421939036629546, 0.16421939036629546, 0.0], \"xaxis\": \"x\", \"y\": [-805.0, -805.0, -815.0, -815.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.19035990123852145, 0.19035990123852145, 0.16421939036629546], \"xaxis\": \"x\", \"y\": [-795.0, -795.0, -810.0, -810.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.31601620980633377, 0.31601620980633377, 0.19035990123852145], \"xaxis\": \"x\", \"y\": [-785.0, -785.0, -802.5, -802.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.28217059638943853, 0.3928001570485426, 0.3928001570485426, 0.31601620980633377], \"xaxis\": \"x\", \"y\": [-762.5, -762.5, -793.75, -793.75], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.3297940260000526, 0.5171520309911269, 0.5171520309911269, 0.3928001570485426], \"xaxis\": \"x\", \"y\": [-730.0, -730.0, -778.125, -778.125], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.20165329149057543, 0.20165329149057543, 0.0], \"xaxis\": \"x\", \"y\": [-825.0, -825.0, -835.0, -835.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.17634443556202264, 0.17634443556202264, 0.0], \"xaxis\": \"x\", \"y\": [-855.0, -855.0, -865.0, -865.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2100229369774829, 0.2100229369774829, 0.17634443556202264], \"xaxis\": \"x\", \"y\": [-845.0, -845.0, -860.0, -860.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.20165329149057543, 0.2889720791602374, 0.2889720791602374, 0.2100229369774829], \"xaxis\": \"x\", \"y\": [-830.0, -830.0, -852.5, -852.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.21716343843366556, 0.21716343843366556, 0.0], \"xaxis\": \"x\", \"y\": [-875.0, -875.0, -885.0, -885.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.16900748828863346, 0.16900748828863346, 0.0], \"xaxis\": \"x\", \"y\": [-895.0, -895.0, -905.0, -905.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15802513065994656, 0.15802513065994656, 0.0], \"xaxis\": \"x\", \"y\": [-925.0, -925.0, -935.0, -935.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.19774275871712194, 0.19774275871712194, 0.15802513065994656], \"xaxis\": \"x\", \"y\": [-915.0, -915.0, -930.0, -930.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.16900748828863346, 0.2463786375681496, 0.2463786375681496, 0.19774275871712194], \"xaxis\": \"x\", \"y\": [-900.0, -900.0, -922.5, -922.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.21716343843366556, 0.35668853418892454, 0.35668853418892454, 0.2463786375681496], \"xaxis\": \"x\", \"y\": [-880.0, -880.0, -911.25, -911.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.2889720791602374, 0.5699777552343704, 0.5699777552343704, 0.35668853418892454], \"xaxis\": \"x\", \"y\": [-841.25, -841.25, -895.625, -895.625], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.23301148575893244, 0.23301148575893244, 0.0], \"xaxis\": \"x\", \"y\": [-955.0, -955.0, -965.0, -965.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.26252253709591933, 0.26252253709591933, 0.23301148575893244], \"xaxis\": \"x\", \"y\": [-945.0, -945.0, -960.0, -960.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.19437249991104139, 0.19437249991104139, 0.0], \"xaxis\": \"x\", \"y\": [-975.0, -975.0, -985.0, -985.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.23706431306980272, 0.23706431306980272, 0.0], \"xaxis\": \"x\", \"y\": [-995.0, -995.0, -1005.0, -1005.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.19437249991104139, 0.2812638989161642, 0.2812638989161642, 0.23706431306980272], \"xaxis\": \"x\", \"y\": [-980.0, -980.0, -1000.0, -1000.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.26252253709591933, 0.356241553294524, 0.356241553294524, 0.2812638989161642], \"xaxis\": \"x\", \"y\": [-952.5, -952.5, -990.0, -990.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.176300550548384, 0.176300550548384, 0.0], \"xaxis\": \"x\", \"y\": [-1025.0, -1025.0, -1035.0, -1035.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.1980731922646849, 0.1980731922646849, 0.176300550548384], \"xaxis\": \"x\", \"y\": [-1015.0, -1015.0, -1030.0, -1030.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18625272690269423, 0.18625272690269423, 0.0], \"xaxis\": \"x\", \"y\": [-1045.0, -1045.0, -1055.0, -1055.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.17370389747091153, 0.17370389747091153, 0.0], \"xaxis\": \"x\", \"y\": [-1065.0, -1065.0, -1075.0, -1075.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2057777966357485, 0.2057777966357485, 0.0], \"xaxis\": \"x\", \"y\": [-1085.0, -1085.0, -1095.0, -1095.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.17370389747091153, 0.26055052298618364, 0.26055052298618364, 0.2057777966357485], \"xaxis\": \"x\", \"y\": [-1070.0, -1070.0, -1090.0, -1090.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.18625272690269423, 0.27523807177398546, 0.27523807177398546, 0.26055052298618364], \"xaxis\": \"x\", \"y\": [-1050.0, -1050.0, -1080.0, -1080.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.1980731922646849, 0.37147369448182443, 0.37147369448182443, 0.27523807177398546], \"xaxis\": \"x\", \"y\": [-1022.5, -1022.5, -1065.0, -1065.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.15823959258741457, 0.15823959258741457, 0.0], \"xaxis\": \"x\", \"y\": [-1115.0, -1115.0, -1125.0, -1125.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2428976535299892, 0.2428976535299892, 0.15823959258741457], \"xaxis\": \"x\", \"y\": [-1105.0, -1105.0, -1120.0, -1120.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.18533204401657852, 0.18533204401657852, 0.0], \"xaxis\": \"x\", \"y\": [-1135.0, -1135.0, -1145.0, -1145.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.24607566114576299, 0.24607566114576299, 0.0], \"xaxis\": \"x\", \"y\": [-1155.0, -1155.0, -1165.0, -1165.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.18533204401657852, 0.3351297796188212, 0.3351297796188212, 0.24607566114576299], \"xaxis\": \"x\", \"y\": [-1140.0, -1140.0, -1160.0, -1160.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.2428976535299892, 0.4047827895222168, 0.4047827895222168, 0.3351297796188212], \"xaxis\": \"x\", \"y\": [-1112.5, -1112.5, -1150.0, -1150.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.37147369448182443, 0.5040658478019403, 0.5040658478019403, 0.4047827895222168], \"xaxis\": \"x\", \"y\": [-1043.75, -1043.75, -1131.25, -1131.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.356241553294524, 0.7020492054365801, 0.7020492054365801, 0.5040658478019403], \"xaxis\": \"x\", \"y\": [-971.25, -971.25, -1087.5, -1087.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.5699777552343704, 0.7922297439674633, 0.7922297439674633, 0.7020492054365801], \"xaxis\": \"x\", \"y\": [-868.4375, -868.4375, -1029.375, -1029.375], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(35,205,205)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.5171520309911269, 0.9913888828215338, 0.9913888828215338, 0.7922297439674633], \"xaxis\": \"x\", \"y\": [-754.0625, -754.0625, -948.90625, -948.90625], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2339646500591663, 0.2339646500591663, 0.0], \"xaxis\": \"x\", \"y\": [-1215.0, -1215.0, -1225.0, -1225.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.28101551984829276, 0.28101551984829276, 0.2339646500591663], \"xaxis\": \"x\", \"y\": [-1205.0, -1205.0, -1220.0, -1220.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2824604784836586, 0.2824604784836586, 0.0], \"xaxis\": \"x\", \"y\": [-1235.0, -1235.0, -1245.0, -1245.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.28101551984829276, 0.3281604493775168, 0.3281604493775168, 0.2824604784836586], \"xaxis\": \"x\", \"y\": [-1212.5, -1212.5, -1240.0, -1240.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.3689587369463336, 0.3689587369463336, 0.3281604493775168], \"xaxis\": \"x\", \"y\": [-1195.0, -1195.0, -1226.25, -1226.25], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.4048996602954457, 0.4048996602954457, 0.3689587369463336], \"xaxis\": \"x\", \"y\": [-1185.0, -1185.0, -1210.625, -1210.625], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2747652461201109, 0.2747652461201109, 0.0], \"xaxis\": \"x\", \"y\": [-1255.0, -1255.0, -1265.0, -1265.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.2810451944199943, 0.2810451944199943, 0.0], \"xaxis\": \"x\", \"y\": [-1285.0, -1285.0, -1295.0, -1295.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.3543390582100749, 0.3543390582100749, 0.2810451944199943], \"xaxis\": \"x\", \"y\": [-1275.0, -1275.0, -1290.0, -1290.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.2747652461201109, 0.40416046278740325, 0.40416046278740325, 0.3543390582100749], \"xaxis\": \"x\", \"y\": [-1260.0, -1260.0, -1282.5, -1282.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.31262097594340077, 0.31262097594340077, 0.0], \"xaxis\": \"x\", \"y\": [-1315.0, -1315.0, -1325.0, -1325.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 0.4989325985865548, 0.4989325985865548, 0.31262097594340077], \"xaxis\": \"x\", \"y\": [-1305.0, -1305.0, -1320.0, -1320.0], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.40416046278740325, 0.6713366128677332, 0.6713366128677332, 0.4989325985865548], \"xaxis\": \"x\", \"y\": [-1271.25, -1271.25, -1312.5, -1312.5], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(133,20,75)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.4048996602954457, 0.8795516640309876, 0.8795516640309876, 0.6713366128677332], \"xaxis\": \"x\", \"y\": [-1197.8125, -1197.8125, -1291.875, -1291.875], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(0,116,217)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.0, 1.1348864863775494, 1.1348864863775494, 0.8795516640309876], \"xaxis\": \"x\", \"y\": [-1175.0, -1175.0, -1244.84375, -1244.84375], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(0,116,217)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [0.9913888828215338, 1.7460036334143136, 1.7460036334143136, 1.1348864863775494], \"xaxis\": \"x\", \"y\": [-851.484375, -851.484375, -1209.921875, -1209.921875], \"yaxis\": \"y\"}, {\"hoverinfo\": \"text\", \"marker\": {\"color\": \"rgb(0,116,217)\"}, \"mode\": \"lines\", \"type\": \"scatter\", \"x\": [1.0174639117199804, 2.7951365241194464, 2.7951365241194464, 1.7460036334143136], \"xaxis\": \"x\", \"y\": [-217.48046875, -217.48046875, -1030.703125, -1030.703125], \"yaxis\": \"y\"}],                        {\"autosize\": false, \"height\": 600, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"hovermode\": \"closest\", \"plot_bgcolor\": \"#ECEFF1\", \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Hierarchical Clustering\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.95, \"yanchor\": \"top\"}, \"width\": 1000, \"xaxis\": {\"mirror\": \"allticks\", \"rangemode\": \"tozero\", \"showgrid\": false, \"showline\": true, \"showticklabels\": true, \"ticks\": \"outside\", \"type\": \"linear\", \"zeroline\": false}, \"yaxis\": {\"mirror\": \"allticks\", \"rangemode\": \"tozero\", \"showgrid\": false, \"showline\": true, \"showticklabels\": true, \"tickmode\": \"array\", \"ticks\": \"outside\", \"ticktext\": [\"0_flow_fluid_vortex\", \"28_vessel_imaging_ultrasound\", \"111_collision_collisions_de...\", \"122_occlusion_culling_rende...\", \"80_solid_solids_boundary\", \"32_ray_rays_traversal\", \"50_sketching_sketches_drawing\", \"82_fractal_fractals_compres...\", \"108_wavelet_wavelets_multir...\", \"62_spline_splines_curves\", \"5_shape_mesh_meshes\", \"104_skeleton_skeletons_segm...\", \"100_terrain_rendering_terra...\", \"102_cartograms_map_maps\", \"127_polygons_polygon_hull\", \"70_tracking_camera_tracker\", \"78_image_smoothing_denoising\", \"27_smart_activities_context\", \"117_location_recommendation...\", \"52_machine_fairness_deep\", \"61_memory_insight_solving\", \"57_influence_social_networks\", \"-1_design_system_users\", \"40_search_web_information\", \"46_hci_design_research\", \"75_health_patients_self\", \"53_papers_conference_issue\", \"74_students_math_solving\", \"83_memories_diary_life\", \"99_coordination_interperson...\", \"21_software_programmers_col...\", \"110_tabletop_collaboration_...\", \"56_facebook_social_privacy\", \"66_wikipedia_communities_co...\", \"58_walking_virtual_locomotion\", \"88_pointing_target_movement\", \"59_reality_augmented_virtual\", \"64_impaired_visually_tactile\", \"20_image_images_retrieval\", \"18_rendering_graphics_gpu\", \"29_texture_textures_synthesis\", \"60_molecules_atoms_molecule\", \"90_diffusion_tensor_tracts\", \"55_number_symbolic_magnitude\", \"24_graphics_graphic_standards\", \"121_line_clipping_algorithms\", \"39_displays_display_navigat...\", \"87_volume_volumetric_render...\", \"25_series_time_patterns\", \"101_stream_drift_ensemble\", \"65_distributed_parallel_sci...\", \"77_gene_genome_genomic\", \"96_tree_trees_plant\", \"94_outlier_outliers_datasets\", \"105_matrix_factorization_no...\", \"116_subspace_clustering_clu...\", \"8_database_query_queries\", \"19_mining_frequent_itemsets\", \"15_classification_class_fea...\", \"41_category_categories_cate...\", \"76_route_map_navigation\", \"128_spatial_languages_across\", \"23_trajectory_trajectories_...\", \"89_indoor_location_position...\", \"79_construction_visualisati...\", \"2_visualization_topic_visual\", \"9_dimensional_visualization...\", \"4_graph_graphs_network\", \"44_diagrams_diagrammatic_di...\", \"31_weather_visualization_cl...\", \"107_event_events_sentinel\", \"11_music_musical_voice\", \"34_creativity_painting_art\", \"17_haptic_tactile_force\", \"49_keyboard_keyboards_touch\", \"115_surgical_surgery_laparo...\", \"26_fabrication_printing_print\", \"113_hair_hairs_cloth\", \"103_design_clothing_clothes\", \"45_color_colors_palette\", \"7_light_illumination_render...\", \"71_shadow_shadows_light\", \"92_email_emails_mail\", \"130_meetings_communication_...\", \"124_religious_dreaming_reli...\", \"1_language_word_linguistic\", \"67_metaphors_metaphor_analo...\", \"10_motion_animation_motions\", \"95_video_videos_frames\", \"14_gesture_gestures_touch\", \"123_multimodal_modality_mod...\", \"51_facial_face_animation\", \"16_gaze_eye_attention\", \"22_brain_cognitive_attention\", \"129_ubicomp_ubiquitous_design\", \"54_heritage_museum_visitors\", \"84_civic_civics_infrastruct...\", \"109_children_participatory_...\", \"118_parents_parenting_child\", \"35_causal_beliefs_evidence\", \"86_moral_dilemmas_judgment\", \"68_crowd_crowds_simulation\", \"42_crowdsourcing_workers_cr...\", \"119_location_privacy_crowds...\", \"38_transaction_transactions...\", \"93_security_traffic_cyber\", \"3_recommendation_recommende...\", \"30_decision_choice_risk\", \"81_electricity_households_h...\", \"126_cleaning_repairing_repair\", \"97_entity_entities_name\", \"85_xml_query_xquery\", \"91_ontology_schema_ontologies\", \"48_label_labels_unlabeled\", \"63_clustering_clusters_clus...\", \"106_parallel_compiler_cache\", \"114_watermarking_watermark_...\", \"112_chatbot_chatbots_chat\", \"120_dance_dancers_dancer\", \"98_interruptions_interrupti...\", \"33_twitter_tweets_media\", \"69_conversational_dialogue_...\", \"72_narrative_story_stories\", \"6_game_games_sports\", \"12_education_educational_te...\", \"125_spreadsheet_spreadsheet...\", \"131_provenance_lakes_workfl...\", \"43_patient_patients_care\", \"36_privacy_security_private\", \"73_authentication_passwords...\", \"47_robot_robots_robotic\", \"13_driving_vehicle_vehicles\", \"37_urban_city_building\"], \"tickvals\": [-5.0, -15.0, -25.0, -35.0, -45.0, -55.0, -65.0, -75.0, -85.0, -95.0, -105.0, -115.0, -125.0, -135.0, -145.0, -155.0, -165.0, -175.0, -185.0, -195.0, -205.0, -215.0, -225.0, -235.0, -245.0, -255.0, -265.0, -275.0, -285.0, -295.0, -305.0, -315.0, -325.0, -335.0, -345.0, -355.0, -365.0, -375.0, -385.0, -395.0, -405.0, -415.0, -425.0, -435.0, -445.0, -455.0, -465.0, -475.0, -485.0, -495.0, -505.0, -515.0, -525.0, -535.0, -545.0, -555.0, -565.0, -575.0, -585.0, -595.0, -605.0, -615.0, -625.0, -635.0, -645.0, -655.0, -665.0, -675.0, -685.0, -695.0, -705.0, -715.0, -725.0, -735.0, -745.0, -755.0, -765.0, -775.0, -785.0, -795.0, -805.0, -815.0, -825.0, -835.0, -845.0, -855.0, -865.0, -875.0, -885.0, -895.0, -905.0, -915.0, -925.0, -935.0, -945.0, -955.0, -965.0, -975.0, -985.0, -995.0, -1005.0, -1015.0, -1025.0, -1035.0, -1045.0, -1055.0, -1065.0, -1075.0, -1085.0, -1095.0, -1105.0, -1115.0, -1125.0, -1135.0, -1145.0, -1155.0, -1165.0, -1175.0, -1185.0, -1195.0, -1205.0, -1215.0, -1225.0, -1235.0, -1245.0, -1255.0, -1265.0, -1275.0, -1285.0, -1295.0, -1305.0, -1315.0, -1325.0], \"type\": \"linear\", \"zeroline\": false}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('0054685c-f518-426e-b1cf-5b01e1502ca4');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 617
        },
        "id": "N9vzMPhhJuRx",
        "outputId": "d0bd9784-cca0-4f3f-afc4-ecd0f362d87d"
      },
      "source": [
        "reduce_model2.visualize_barchart()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"9e37d1b4-7ba7-4007-8074-a0f58f84ebcd\" class=\"plotly-graph-div\" style=\"height:600px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9e37d1b4-7ba7-4007-8074-a0f58f84ebcd\")) {                    Plotly.newPlot(                        \"9e37d1b4-7ba7-4007-8074-a0f58f84ebcd\",                        [{\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.00812219339029751, 0.010757307349596313, 0.014872184683317384, 0.016846857033500133, 0.034877479358464046], \"xaxis\": \"x\", \"y\": [\"vortices  \", \"jet  \", \"vortex  \", \"fluid  \", \"flow  \"], \"yaxis\": \"y\"}, {\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.0074024438852824835, 0.008421185838041228, 0.010154506356954465, 0.021373397790192518, 0.021627367635129947], \"xaxis\": \"x2\", \"y\": [\"verb  \", \"lexical  \", \"linguistic  \", \"word  \", \"language  \"], \"yaxis\": \"y2\"}, {\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.010962033556569904, 0.011416331963999198, 0.01272565310886845, 0.015188194813632296, 0.019846943765942895], \"xaxis\": \"x3\", \"y\": [\"analytics  \", \"visualizations  \", \"visual  \", \"topic  \", \"visualization  \"], \"yaxis\": \"y3\"}, {\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.007301099773862471, 0.008046855120247479, 0.008692096250854674, 0.015366766851646662, 0.02044677424151193], \"xaxis\": \"x4\", \"y\": [\"advertising  \", \"users  \", \"recommendations  \", \"recommender  \", \"recommendation  \"], \"yaxis\": \"y4\"}, {\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.008521848129229452, 0.016343718068530123, 0.016693807953635526, 0.025442927585748527, 0.03881946393643109], \"xaxis\": \"x5\", \"y\": [\"community  \", \"networks  \", \"network  \", \"graphs  \", \"graph  \"], \"yaxis\": \"y5\"}, {\"orientation\": \"h\", \"type\": \"bar\", \"x\": [0.010466097372276651, 0.01269372104559105, 0.01318636091873257, 0.016514287308550275, 0.018586282277007614], \"xaxis\": \"x6\", \"y\": [\"shapes  \", \"subdivision  \", \"meshes  \", \"mesh  \", \"shape  \"], \"yaxis\": \"y6\"}],                        {\"annotations\": [{\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 0\", \"x\": 0.11666666666666665, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 1\", \"x\": 0.49999999999999994, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 2\", \"x\": 0.8833333333333333, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 1.0, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 3\", \"x\": 0.11666666666666665, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.425, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 4\", \"x\": 0.49999999999999994, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.425, \"yanchor\": \"bottom\", \"yref\": \"paper\"}, {\"font\": {\"size\": 16}, \"showarrow\": false, \"text\": \"Topic 5\", \"x\": 0.8833333333333333, \"xanchor\": \"center\", \"xref\": \"paper\", \"y\": 0.425, \"yanchor\": \"bottom\", \"yref\": \"paper\"}], \"height\": 600, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Topic Word Scores\", \"x\": 0.15, \"xanchor\": \"center\", \"y\": 0.95, \"yanchor\": \"top\"}, \"width\": 800, \"xaxis\": {\"anchor\": \"y\", \"domain\": [0.0, 0.2333333333333333], \"matches\": \"x4\", \"showgrid\": true, \"showticklabels\": false}, \"xaxis2\": {\"anchor\": \"y2\", \"domain\": [0.3833333333333333, 0.6166666666666666], \"matches\": \"x5\", \"showgrid\": true, \"showticklabels\": false}, \"xaxis3\": {\"anchor\": \"y3\", \"domain\": [0.7666666666666666, 0.9999999999999999], \"matches\": \"x6\", \"showgrid\": true, \"showticklabels\": false}, \"xaxis4\": {\"anchor\": \"y4\", \"domain\": [0.0, 0.2333333333333333], \"showgrid\": true}, \"xaxis5\": {\"anchor\": \"y5\", \"domain\": [0.3833333333333333, 0.6166666666666666], \"showgrid\": true}, \"xaxis6\": {\"anchor\": \"y6\", \"domain\": [0.7666666666666666, 0.9999999999999999], \"showgrid\": true}, \"yaxis\": {\"anchor\": \"x\", \"domain\": [0.575, 1.0], \"showgrid\": true}, \"yaxis2\": {\"anchor\": \"x2\", \"domain\": [0.575, 1.0], \"showgrid\": true}, \"yaxis3\": {\"anchor\": \"x3\", \"domain\": [0.575, 1.0], \"showgrid\": true}, \"yaxis4\": {\"anchor\": \"x4\", \"domain\": [0.0, 0.425], \"showgrid\": true}, \"yaxis5\": {\"anchor\": \"x5\", \"domain\": [0.0, 0.425], \"showgrid\": true}, \"yaxis6\": {\"anchor\": \"x6\", \"domain\": [0.0, 0.425], \"showgrid\": true}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9e37d1b4-7ba7-4007-8074-a0f58f84ebcd');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 817
        },
        "id": "Z0tITOihJ8uH",
        "outputId": "a1aa8e9d-0a1e-4627-971d-a99ea0c011ef"
      },
      "source": [
        "reduce_model2.visualize_heatmap()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"e52a9ceb-7893-48a9-8ef6-88fe3d989cd3\" class=\"plotly-graph-div\" style=\"height:800px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"e52a9ceb-7893-48a9-8ef6-88fe3d989cd3\")) {                    Plotly.newPlot(                        \"e52a9ceb-7893-48a9-8ef6-88fe3d989cd3\",                        [{\"coloraxis\": \"coloraxis\", \"hovertemplate\": \"x: %{x}<br>y: %{y}<br>Similarity Score: %{z}<extra></extra>\", \"name\": \"0\", \"type\": \"heatmap\", \"x\": [\"-1_design_system_users\", \"0_flow_fluid_vortex\", \"1_language_word_linguistic\", \"2_visualization_topic_visual\", \"3_recommendation_recommende...\", \"4_graph_graphs_network\", \"5_shape_mesh_meshes\", \"6_game_games_sports\", \"7_light_illumination_render...\", \"8_database_query_queries\", \"9_dimensional_visualization...\", \"10_motion_animation_motions\", \"11_music_musical_voice\", \"12_education_educational_te...\", \"13_driving_vehicle_vehicles\", \"14_gesture_gestures_touch\", \"15_classification_class_fea...\", \"16_gaze_eye_attention\", \"17_haptic_tactile_force\", \"18_rendering_graphics_gpu\", \"19_mining_frequent_itemsets\", \"20_image_images_retrieval\", \"21_software_programmers_col...\", \"22_brain_cognitive_attention\", \"23_trajectory_trajectories_...\", \"24_graphics_graphic_standards\", \"25_series_time_patterns\", \"26_fabrication_printing_print\", \"27_smart_activities_context\", \"28_vessel_imaging_ultrasound\", \"29_texture_textures_synthesis\", \"30_decision_choice_risk\", \"31_weather_visualization_cl...\", \"32_ray_rays_traversal\", \"33_twitter_tweets_media\", \"34_creativity_painting_art\", \"35_causal_beliefs_evidence\", \"36_privacy_security_private\", \"37_urban_city_building\", \"38_transaction_transactions...\", \"39_displays_display_navigat...\", \"40_search_web_information\", \"41_category_categories_cate...\", \"42_crowdsourcing_workers_cr...\", \"43_patient_patients_care\", \"44_diagrams_diagrammatic_di...\", \"45_color_colors_palette\", \"46_hci_design_research\", \"47_robot_robots_robotic\", \"48_label_labels_unlabeled\", \"49_keyboard_keyboards_touch\", \"50_sketching_sketches_drawing\", \"51_facial_face_animation\", \"52_machine_fairness_deep\", \"53_papers_conference_issue\", \"54_heritage_museum_visitors\", \"55_number_symbolic_magnitude\", \"56_facebook_social_privacy\", \"57_influence_social_networks\", \"58_walking_virtual_locomotion\", \"59_reality_augmented_virtual\", \"60_molecules_atoms_molecule\", \"61_memory_insight_solving\", \"62_spline_splines_curves\", \"63_clustering_clusters_clus...\", \"64_impaired_visually_tactile\", \"65_distributed_parallel_sci...\", \"66_wikipedia_communities_co...\", \"67_metaphors_metaphor_analo...\", \"68_crowd_crowds_simulation\", \"69_conversational_dialogue_...\", \"70_tracking_camera_tracker\", \"71_shadow_shadows_light\", \"72_narrative_story_stories\", \"73_authentication_passwords...\", \"74_students_math_solving\", \"75_health_patients_self\", \"76_route_map_navigation\", \"77_gene_genome_genomic\", \"78_image_smoothing_denoising\", \"79_construction_visualisati...\", \"80_solid_solids_boundary\", \"81_electricity_households_h...\", \"82_fractal_fractals_compres...\", \"83_memories_diary_life\", \"84_civic_civics_infrastruct...\", \"85_xml_query_xquery\", \"86_moral_dilemmas_judgment\", \"87_volume_volumetric_render...\", \"88_pointing_target_movement\", \"89_indoor_location_position...\", \"90_diffusion_tensor_tracts\", \"91_ontology_schema_ontologies\", \"92_email_emails_mail\", \"93_security_traffic_cyber\", \"94_outlier_outliers_datasets\", \"95_video_videos_frames\", \"96_tree_trees_plant\", \"97_entity_entities_name\", \"98_interruptions_interrupti...\", \"99_coordination_interperson...\", \"100_terrain_rendering_terra...\", \"101_stream_drift_ensemble\", \"102_cartograms_map_maps\", \"103_design_clothing_clothes\", \"104_skeleton_skeletons_segm...\", \"105_matrix_factorization_no...\", \"106_parallel_compiler_cache\", \"107_event_events_sentinel\", \"108_wavelet_wavelets_multir...\", \"109_children_participatory_...\", \"110_tabletop_collaboration_...\", \"111_collision_collisions_de...\", \"112_chatbot_chatbots_chat\", \"113_hair_hairs_cloth\", \"114_watermarking_watermark_...\", \"115_surgical_surgery_laparo...\", \"116_subspace_clustering_clu...\", \"117_location_recommendation...\", \"118_parents_parenting_child\", \"119_location_privacy_crowds...\", \"120_dance_dancers_dancer\", \"121_line_clipping_algorithms\", \"122_occlusion_culling_rende...\", \"123_multimodal_modality_mod...\", \"124_religious_dreaming_reli...\", \"125_spreadsheet_spreadsheet...\", \"126_cleaning_repairing_repair\", \"127_polygons_polygon_hull\", \"128_spatial_languages_across\", \"129_ubicomp_ubiquitous_design\", \"130_meetings_communication_...\", \"131_provenance_lakes_workfl...\"], \"xaxis\": \"x\", \"y\": [\"-1_design_system_users\", \"0_flow_fluid_vortex\", \"1_language_word_linguistic\", \"2_visualization_topic_visual\", \"3_recommendation_recommende...\", \"4_graph_graphs_network\", \"5_shape_mesh_meshes\", \"6_game_games_sports\", \"7_light_illumination_render...\", \"8_database_query_queries\", \"9_dimensional_visualization...\", \"10_motion_animation_motions\", \"11_music_musical_voice\", \"12_education_educational_te...\", \"13_driving_vehicle_vehicles\", \"14_gesture_gestures_touch\", \"15_classification_class_fea...\", \"16_gaze_eye_attention\", \"17_haptic_tactile_force\", \"18_rendering_graphics_gpu\", \"19_mining_frequent_itemsets\", \"20_image_images_retrieval\", \"21_software_programmers_col...\", \"22_brain_cognitive_attention\", \"23_trajectory_trajectories_...\", \"24_graphics_graphic_standards\", \"25_series_time_patterns\", \"26_fabrication_printing_print\", \"27_smart_activities_context\", \"28_vessel_imaging_ultrasound\", \"29_texture_textures_synthesis\", \"30_decision_choice_risk\", \"31_weather_visualization_cl...\", \"32_ray_rays_traversal\", \"33_twitter_tweets_media\", \"34_creativity_painting_art\", \"35_causal_beliefs_evidence\", \"36_privacy_security_private\", \"37_urban_city_building\", \"38_transaction_transactions...\", \"39_displays_display_navigat...\", \"40_search_web_information\", \"41_category_categories_cate...\", \"42_crowdsourcing_workers_cr...\", \"43_patient_patients_care\", \"44_diagrams_diagrammatic_di...\", \"45_color_colors_palette\", \"46_hci_design_research\", \"47_robot_robots_robotic\", \"48_label_labels_unlabeled\", \"49_keyboard_keyboards_touch\", \"50_sketching_sketches_drawing\", \"51_facial_face_animation\", \"52_machine_fairness_deep\", \"53_papers_conference_issue\", \"54_heritage_museum_visitors\", \"55_number_symbolic_magnitude\", \"56_facebook_social_privacy\", \"57_influence_social_networks\", \"58_walking_virtual_locomotion\", \"59_reality_augmented_virtual\", \"60_molecules_atoms_molecule\", \"61_memory_insight_solving\", \"62_spline_splines_curves\", \"63_clustering_clusters_clus...\", \"64_impaired_visually_tactile\", \"65_distributed_parallel_sci...\", \"66_wikipedia_communities_co...\", \"67_metaphors_metaphor_analo...\", \"68_crowd_crowds_simulation\", \"69_conversational_dialogue_...\", \"70_tracking_camera_tracker\", \"71_shadow_shadows_light\", \"72_narrative_story_stories\", \"73_authentication_passwords...\", \"74_students_math_solving\", \"75_health_patients_self\", \"76_route_map_navigation\", \"77_gene_genome_genomic\", \"78_image_smoothing_denoising\", \"79_construction_visualisati...\", \"80_solid_solids_boundary\", \"81_electricity_households_h...\", \"82_fractal_fractals_compres...\", \"83_memories_diary_life\", \"84_civic_civics_infrastruct...\", \"85_xml_query_xquery\", \"86_moral_dilemmas_judgment\", \"87_volume_volumetric_render...\", \"88_pointing_target_movement\", \"89_indoor_location_position...\", \"90_diffusion_tensor_tracts\", \"91_ontology_schema_ontologies\", \"92_email_emails_mail\", \"93_security_traffic_cyber\", \"94_outlier_outliers_datasets\", \"95_video_videos_frames\", \"96_tree_trees_plant\", \"97_entity_entities_name\", \"98_interruptions_interrupti...\", \"99_coordination_interperson...\", \"100_terrain_rendering_terra...\", \"101_stream_drift_ensemble\", \"102_cartograms_map_maps\", \"103_design_clothing_clothes\", \"104_skeleton_skeletons_segm...\", \"105_matrix_factorization_no...\", \"106_parallel_compiler_cache\", \"107_event_events_sentinel\", \"108_wavelet_wavelets_multir...\", \"109_children_participatory_...\", \"110_tabletop_collaboration_...\", \"111_collision_collisions_de...\", \"112_chatbot_chatbots_chat\", \"113_hair_hairs_cloth\", \"114_watermarking_watermark_...\", \"115_surgical_surgery_laparo...\", \"116_subspace_clustering_clu...\", \"117_location_recommendation...\", \"118_parents_parenting_child\", \"119_location_privacy_crowds...\", \"120_dance_dancers_dancer\", \"121_line_clipping_algorithms\", \"122_occlusion_culling_rende...\", \"123_multimodal_modality_mod...\", \"124_religious_dreaming_reli...\", \"125_spreadsheet_spreadsheet...\", \"126_cleaning_repairing_repair\", \"127_polygons_polygon_hull\", \"128_spatial_languages_across\", \"129_ubicomp_ubiquitous_design\", \"130_meetings_communication_...\", \"131_provenance_lakes_workfl...\"], \"yaxis\": \"y\", \"z\": [[1.0000000000000002, 0.9280862345152312, 0.9308921902637898, 0.9510887003809022, 0.9442970468259466, 0.9335255797241443, 0.9338573074558705, 0.9028387572692538, 0.9031766141189197, 0.944517096631218, 0.9430204468943526, 0.9057173866402095, 0.8905985616134874, 0.9072070745841986, 0.8913842743093392, 0.9270791936980725, 0.9505115523782197, 0.9242545271713031, 0.8932991442545508, 0.9311366720246417, 0.9507755219487977, 0.9405997518370465, 0.9579020421574153, 0.9237278089619533, 0.936112765703171, 0.9543320017890107, 0.9585674527856953, 0.9019475703680995, 0.9593329710747053, 0.9279133968863771, 0.9434354844051134, 0.9402723341331245, 0.9184564777386186, 0.9260323102790213, 0.9019066129095427, 0.895530330184293, 0.9049866003282422, 0.9195459961378138, 0.9050632581514856, 0.9372048354832646, 0.9548957885299205, 0.9608555459593137, 0.9410219214703548, 0.933056600864431, 0.9021541178874304, 0.9269792508079, 0.9145656812085842, 0.9636317981469261, 0.86411744643697, 0.9241986385396513, 0.910683962018092, 0.9343350595240796, 0.9236765826853757, 0.9545833494018969, 0.946612570759327, 0.9189732273776972, 0.9537605562306805, 0.9631363088568979, 0.959546618546236, 0.933868659201277, 0.9499038678844024, 0.9480027948922807, 0.958614120585834, 0.9251362405076575, 0.923783326144968, 0.9428324095298006, 0.9553505042089653, 0.9477742787554353, 0.9258416187325023, 0.9233902489293847, 0.8988434273071643, 0.9120452514382975, 0.9082415987080087, 0.8716033158575267, 0.9000421726396871, 0.9508989229294271, 0.9583457991778078, 0.9366359204385152, 0.94747377133164, 0.9177196850888995, 0.9421515791091273, 0.9267116772798754, 0.9281920282512057, 0.920317159964323, 0.9454967247360047, 0.9212877654930772, 0.9204056457574823, 0.9025907900054657, 0.9460103987163249, 0.9514438185250375, 0.9227613421052279, 0.9405306222810663, 0.918651583535533, 0.9330467075505937, 0.9334341400633859, 0.9324633604448811, 0.9163462228489039, 0.9404766611689402, 0.9136054446086744, 0.8939746898371853, 0.9486987527177749, 0.9059184877903231, 0.9413151001290947, 0.919733183250204, 0.9338279546295947, 0.9197210163070888, 0.9410042142986494, 0.9265866927116064, 0.9281534419724249, 0.9301558455369912, 0.9216074550290796, 0.9500150703917882, 0.9313981601769936, 0.8277540514511157, 0.8885805309407172, 0.907790153187011, 0.9109653783548588, 0.9380951167880164, 0.9615450929846505, 0.9144170244971022, 0.939653249177625, 0.8669308947130476, 0.9500337992544176, 0.9215918762475691, 0.9279829124778807, 0.9123211711021413, 0.8953021522553767, 0.9326375688771151, 0.9185295348878981, 0.9393349005814209, 0.9355196836100225, 0.9313855477711477, 0.8951145621211425], [0.9280862345152312, 1.0000000000000009, 0.8986299611242596, 0.9129116961549253, 0.8751323992469938, 0.896835155563285, 0.914252389885633, 0.8819274401399151, 0.8866150863778257, 0.9043411862515371, 0.9166009707524756, 0.9083258187415133, 0.8729999154773206, 0.8626881917040301, 0.87934844478869, 0.8945756978150208, 0.9093784020868856, 0.9036142861705098, 0.8745247356932251, 0.9094945441468659, 0.9028803640063343, 0.9051775916866616, 0.9005660228307542, 0.8841169455928954, 0.913320995801211, 0.9149422010854084, 0.9399245767814448, 0.8784784281219675, 0.9084079956301656, 0.9428727149533821, 0.9189541715392693, 0.8994312112240137, 0.9139379748100553, 0.9057996391044366, 0.8742193605985853, 0.8691607631171009, 0.8665428560838875, 0.863880951194949, 0.8748293245242801, 0.9061155403288774, 0.9142473481115405, 0.9116000627662706, 0.9026158295036983, 0.8913900728946713, 0.873226488497987, 0.9047173591146384, 0.8992135560005144, 0.9177837426394915, 0.8299444746051128, 0.8836907357865861, 0.861888638987344, 0.9036818564116067, 0.8919099775169337, 0.9201795676087849, 0.9259285027290189, 0.8669628316340626, 0.9246094351240703, 0.9012043904352643, 0.9254899723979749, 0.9164588044356394, 0.9108404361851593, 0.9177869181810506, 0.9206166596095653, 0.8962641265449609, 0.8941337730286933, 0.8992758777363963, 0.9275408610980846, 0.9024872965260385, 0.899406298003143, 0.9115087145246366, 0.8765430510538684, 0.888888516953386, 0.9011514338511694, 0.8594070187921385, 0.8398735345525765, 0.9219099321629716, 0.9171071140900481, 0.9017710489929114, 0.9146706189033045, 0.904023999151873, 0.9009896878226257, 0.9140352435592892, 0.907245922590158, 0.9163580772179174, 0.9117088289303552, 0.8693590628425699, 0.8620377501693044, 0.8766747428414559, 0.940312042731023, 0.924153954012289, 0.8831700125466702, 0.9323823912367899, 0.8704213898078706, 0.9026044971871761, 0.9012519979312498, 0.9149282176203741, 0.9157925026068455, 0.9214374688757848, 0.8765495806956394, 0.8743508560641947, 0.9152501976179137, 0.8926968954652126, 0.9431824640791113, 0.8841162268907963, 0.8879984640191988, 0.8916247180400656, 0.9120461607852182, 0.8931951715926609, 0.9223229871161054, 0.9211267955514699, 0.8576186504126748, 0.9019018379913689, 0.9189780653189628, 0.8012650648264935, 0.8673003606353693, 0.8850518405570467, 0.8956473195365633, 0.9098455896094302, 0.8984707525747679, 0.8783674745212566, 0.8927336155443026, 0.8478842695452049, 0.9256132639217991, 0.9056017634604401, 0.8863251355615854, 0.8881727268337349, 0.8505491546172083, 0.8984039741379624, 0.8822362694632937, 0.9024213071991092, 0.8655465861988658, 0.8968003008714606, 0.8531838847095721], [0.9308921902637898, 0.8986299611242596, 0.9999999999999998, 0.9269076490381631, 0.9037833414987493, 0.8981552065338794, 0.9030274605772822, 0.8837609319150793, 0.8819076334636398, 0.9119188512121754, 0.9131015192877143, 0.8916735363070982, 0.9064745800742995, 0.900806663696522, 0.869470064593828, 0.9214898990703495, 0.9402901540075213, 0.9173547731034484, 0.8830699626070373, 0.9056146065761691, 0.9203815429430383, 0.9315837017924908, 0.9128034226270967, 0.9260582659764415, 0.8986543877527858, 0.9255153964576506, 0.9287316912911776, 0.8601236162494383, 0.9203143148700239, 0.8950449152828073, 0.9268490033351449, 0.9016134599462573, 0.9032557258839176, 0.8973505758245847, 0.9276854605040081, 0.8788426655508752, 0.8905786284427492, 0.8644640331390495, 0.8602450637220601, 0.8966716260621452, 0.9128669583843921, 0.934487795686194, 0.94088300483519, 0.8997672122509243, 0.8604806591833706, 0.9156623723189217, 0.8940592391939206, 0.8975635181532251, 0.8495016634589385, 0.9298402920477061, 0.909515979289153, 0.8907420677072526, 0.9201282309455685, 0.9457611462513569, 0.9259093055435859, 0.8891979655533325, 0.9413930345777615, 0.930052763179508, 0.9234306585588902, 0.9056667036264939, 0.9222934298948843, 0.9209338584676985, 0.9409690394252312, 0.8979372466178023, 0.8980285099886314, 0.9239389558093174, 0.9229535761596672, 0.9287784350635546, 0.9416009992934024, 0.8874370139693374, 0.9319642892868566, 0.8856931113323357, 0.8876124303019245, 0.8945695971597426, 0.8652578754309498, 0.9273791196841978, 0.9205823754871668, 0.903299245437467, 0.9273409190440766, 0.9013005331622482, 0.8996127949347252, 0.8973384165763207, 0.8854085548204824, 0.9032613149481326, 0.932103788777272, 0.8840548272219391, 0.8957361747425493, 0.8992919738041066, 0.9147307519054462, 0.9315883541887706, 0.8809573914345226, 0.9253205877263176, 0.9143351133459849, 0.910703316171732, 0.9008699991263218, 0.9118572086656149, 0.8972738329430787, 0.9298361735089178, 0.9305014544049597, 0.8631457333859607, 0.9261235912341822, 0.8913070153680862, 0.9122213386067508, 0.8910188690467973, 0.8828071685445609, 0.8953577761608407, 0.9248827158398001, 0.9063533497757137, 0.9080841078235399, 0.9199139305653554, 0.8943597831367506, 0.9116563245681033, 0.9030988173301862, 0.8524973184544244, 0.8781557055767466, 0.8855076203665827, 0.8837993849205023, 0.9285091012664201, 0.9147562850762978, 0.9032153334225896, 0.8913977921120764, 0.8658486318039511, 0.9232671935337848, 0.9078054449126076, 0.9323863676566486, 0.9313320584879771, 0.8501461731937687, 0.8899852706597399, 0.8849727601702779, 0.9364938253530395, 0.876013155888869, 0.91691689822446, 0.850551953645073], [0.9510887003809022, 0.9129116961549253, 0.9269076490381631, 1.0000000000000002, 0.9245069051898243, 0.928901091613073, 0.918014086965281, 0.8895916106398016, 0.8988094424919628, 0.9293102475364255, 0.9738389708776057, 0.9007135128122156, 0.8817573602817018, 0.9082908376286806, 0.874267986659519, 0.9064331800488863, 0.935449263018777, 0.9245328558416205, 0.8785286983082294, 0.9312346423664406, 0.937816969952358, 0.9325596087272849, 0.9372568245554443, 0.9254816014761339, 0.9281566112978809, 0.9519649379805358, 0.9453835498411415, 0.8830265915169744, 0.9408035547865405, 0.9184963636749509, 0.9339387730588702, 0.9208596690625911, 0.9380466492346714, 0.9201551297478203, 0.8999147542445671, 0.9131425664646018, 0.9077283811139285, 0.8996051141145953, 0.8972571170984069, 0.9064310148037926, 0.9608167895357769, 0.9468100955550323, 0.945166278383115, 0.90657849114662, 0.8742748731222807, 0.9350978408643045, 0.9170765666611493, 0.930247342680681, 0.8355488065142486, 0.9146192674553625, 0.8969984651992032, 0.9262541667685149, 0.9050545421296876, 0.9429555176619329, 0.9527167695432259, 0.9192873342736194, 0.9365319467100514, 0.9400012222304496, 0.9378689545601755, 0.920421578304668, 0.9352665661969765, 0.9224908557252458, 0.9431349299981695, 0.9049357369509092, 0.9209697259775562, 0.9340824812713747, 0.9322197661824433, 0.9410583538507866, 0.9297633179926119, 0.902534049785337, 0.8888497105744652, 0.8950122783521938, 0.9106172820987518, 0.9023346638923327, 0.8672730946753595, 0.9322230932737045, 0.9349782864151848, 0.930432163403856, 0.9421797003262229, 0.9132736755617227, 0.9476118474270184, 0.9060576184728775, 0.9053452871976226, 0.9247419480235787, 0.9330561688897172, 0.9033730377275023, 0.908854823917552, 0.8841675776227429, 0.9531197675179968, 0.9376438790364579, 0.9107915330937737, 0.9281055676028958, 0.9173525512704938, 0.9133387330041449, 0.9203170402237193, 0.9290476865265334, 0.9231671181276262, 0.9325055169727812, 0.9085068540054146, 0.87465683308074, 0.9268802185765679, 0.9158737295590648, 0.9384013136767729, 0.9293704639052432, 0.9090396150176587, 0.9131075484050348, 0.9189138946644402, 0.8983949474400513, 0.9349513781979227, 0.9254228252599332, 0.9071593774038824, 0.9349775735793592, 0.9026215798896493, 0.8284027313332636, 0.8809539137211182, 0.9080466701565388, 0.8825859909007614, 0.9388878930465087, 0.9452406721643598, 0.897718377972744, 0.923105198856215, 0.8632304635222269, 0.937922445981782, 0.9216322884172543, 0.9153054531709506, 0.9124222200782921, 0.8941847103118884, 0.9063592291970006, 0.9168208784207392, 0.9407360903714092, 0.8987328822761373, 0.9180932288880201, 0.9013339229460682], [0.9442970468259466, 0.8751323992469938, 0.9037833414987493, 0.9245069051898243, 1.0000000000000007, 0.9085743854284813, 0.8925831470770111, 0.8908690501799978, 0.8699477441672401, 0.9285574520341235, 0.9054848561711193, 0.8604941912107782, 0.8628451061157691, 0.8863876749980213, 0.8597675889174256, 0.8913854270704122, 0.9273747978859062, 0.8905834598356839, 0.8530403409737854, 0.9048253879325829, 0.9396604451655997, 0.9162870469492804, 0.9278631342313187, 0.8885240405430248, 0.8894175602148261, 0.9246520874359699, 0.9173571864148004, 0.8685098591516168, 0.9241793679738346, 0.8946765641924124, 0.917454869681755, 0.9403252326555029, 0.8993542818339142, 0.8967747533113408, 0.8876674430493515, 0.8727206041356707, 0.915067274140694, 0.8966934420117035, 0.8544098317563844, 0.911539302513013, 0.9134652245540895, 0.9456509829635733, 0.9294846735706058, 0.9199513944229901, 0.871810188138287, 0.9046673449678437, 0.8890183081774335, 0.9310177057210423, 0.8480774718884476, 0.9156116902095255, 0.8805996413546041, 0.9077776876604684, 0.8855974104204123, 0.9402507945015186, 0.9173093567348238, 0.8924554337429207, 0.915983227674617, 0.9418416200941009, 0.9365102430184788, 0.8964223190023702, 0.9083985569104159, 0.9068328354332449, 0.9280055875157834, 0.9077418239585219, 0.8904255189667919, 0.9163378906676373, 0.9222766579053958, 0.9385993337392218, 0.8956928581360889, 0.8940520815967766, 0.8858902817594803, 0.881661981695332, 0.8636321727318779, 0.8594102448241128, 0.8818803987212515, 0.9185837412098937, 0.9321955309122553, 0.9098134199679335, 0.9093163479531725, 0.9003855378616272, 0.9054705910723325, 0.8887710597461097, 0.8992330343071937, 0.8955627852513981, 0.9145930444848895, 0.8997191391738426, 0.9084735364707636, 0.8965129202784833, 0.9019305774827068, 0.9227968214444432, 0.8931670790693299, 0.9156176889882577, 0.9093874364049868, 0.9020997187348051, 0.8978590868509031, 0.9098423584532074, 0.8825178325370806, 0.9106776009910724, 0.8932746645288996, 0.8601154594862511, 0.9064539593302692, 0.8772887886259408, 0.9177208875098295, 0.8971329298945896, 0.9145103097485994, 0.8910769165320491, 0.9174249742291252, 0.8875143923829804, 0.8955087210404167, 0.8958799669821034, 0.8844062018370323, 0.9195942153441499, 0.885810806052408, 0.7977962741603565, 0.8620233541439722, 0.8806550861054324, 0.8672576732440027, 0.8966630819982144, 0.9677669475123142, 0.8926166658707695, 0.9110726504304282, 0.8496646761303875, 0.9271635196512201, 0.8863117519125746, 0.8875605559816373, 0.8980400457461888, 0.8613525937104185, 0.9111322771938916, 0.8846547701026126, 0.8965665856824976, 0.9079472383145256, 0.9129050544371353, 0.8902680485035999], [0.9335255797241443, 0.896835155563285, 0.8981552065338794, 0.928901091613073, 0.9085743854284813, 1.0000000000000009, 0.932182445796516, 0.9032505147532162, 0.8711340959880918, 0.9240260451271829, 0.9300652504193968, 0.8835569420907219, 0.8560775738816103, 0.864608943851134, 0.8679880250505261, 0.8814031238718549, 0.9125400386777026, 0.8890193975968013, 0.8525726570198635, 0.9253323368985151, 0.9306656647784088, 0.9145688252175899, 0.9256026744350153, 0.9062509744555568, 0.9121896364292283, 0.9498608761421548, 0.9316058585142764, 0.8878760671777722, 0.9218058230778124, 0.9100848717060831, 0.9152256320697947, 0.8937325826760371, 0.893452838006427, 0.9099559818922063, 0.8862191758848199, 0.8705980289056383, 0.8976354836497819, 0.8888013382568007, 0.8909702342707526, 0.9040284569815803, 0.9269466394296922, 0.9392919630810501, 0.9107872427651504, 0.8990012552032195, 0.8624142993349025, 0.9454959225479608, 0.9048340559628492, 0.9079150279253603, 0.8471746532549564, 0.9050639369168109, 0.8594243203454837, 0.91730329918567, 0.8968794467595667, 0.9298533125819473, 0.9302753884795696, 0.8748298640356234, 0.9361427845696102, 0.9359104080634978, 0.9648144504922472, 0.9191048828918628, 0.9221157797621089, 0.9289717290703814, 0.9283658879552724, 0.9109384096336854, 0.9086253316263038, 0.9036058592065161, 0.9412448869302958, 0.9309915142512679, 0.9112096465505606, 0.9027967467090319, 0.8551400002607102, 0.8862745340884919, 0.8916731915079277, 0.8672162323864103, 0.8535381527356741, 0.9234038125325456, 0.9235259631838761, 0.9243586772022286, 0.9427238336118475, 0.8918048616397417, 0.9280412817003285, 0.9120034818939147, 0.9057325650277006, 0.9173644269088008, 0.9122276218387873, 0.8990933925475176, 0.8987509484336765, 0.8692645638532076, 0.9317468976705366, 0.9186825746215008, 0.8948866662691356, 0.9296540481790125, 0.9100380425149873, 0.8984683188017911, 0.9150602280854887, 0.9065839834591876, 0.8971647233672567, 0.9434372461771012, 0.9005486381142326, 0.8476930667089358, 0.9291452419976141, 0.9053952954774129, 0.9117835733517691, 0.9253345643152274, 0.894565211699358, 0.9300218958193164, 0.9268063977950076, 0.9067273343518779, 0.9072883591291561, 0.9186975445663705, 0.8882675183029565, 0.915992286462995, 0.9035130835149446, 0.7876672195440836, 0.8742091837306608, 0.9093822087728507, 0.8725889533026536, 0.9166738381450006, 0.9329326260343911, 0.899089189739807, 0.9016313448514508, 0.8426090968086588, 0.929478739587309, 0.8920253805930739, 0.869647334526901, 0.8892772721985251, 0.8670523489467846, 0.9040614235094472, 0.93856491358165, 0.9213500564340107, 0.8949460995127961, 0.9027893628149317, 0.8822285192331997], [0.9338573074558705, 0.914252389885633, 0.9030274605772822, 0.918014086965281, 0.8925831470770111, 0.932182445796516, 1.0000000000000004, 0.8801062746169797, 0.9034768433097078, 0.9315337359513609, 0.9408525956413829, 0.9259083926556825, 0.8902090455500602, 0.8447073490414453, 0.8795569245516057, 0.9165151540989, 0.9318503063093858, 0.8944155697331461, 0.8989260415867606, 0.9557799160223525, 0.9253052620926827, 0.9386380635577245, 0.9090799437589361, 0.9086386548959138, 0.9252971838253051, 0.9581614318947391, 0.9332346469318484, 0.9129545037351613, 0.9333890762163558, 0.9169687651595624, 0.9539841894146431, 0.90370370269224, 0.9058085261127015, 0.9250633383593984, 0.8527483274869114, 0.8926599066905734, 0.8729664056411597, 0.8771923101736474, 0.9063783462816943, 0.8837993006945167, 0.9387594017676031, 0.9301484396937593, 0.9241029707204615, 0.895835603458217, 0.8603786366288941, 0.9300219746468787, 0.9237138420404222, 0.9127321701493378, 0.876914434675605, 0.918428269986811, 0.8867194468966392, 0.9425153478010817, 0.9278964638490704, 0.9278496638907048, 0.9130434467141374, 0.8683286948840367, 0.947614349164387, 0.926197301926089, 0.9302016408531868, 0.9362126055656834, 0.9309470994871752, 0.94596218498969, 0.9301450130147719, 0.9583307238570021, 0.927855567562627, 0.9299639315209622, 0.9357728344987719, 0.9047509267231909, 0.908045696595699, 0.916233690076594, 0.8426832875736593, 0.9285133714335054, 0.9092665692784757, 0.8302758244008344, 0.8551777615533157, 0.9207392254042523, 0.9279076823495075, 0.9344335773095267, 0.9347543796725066, 0.9252996660297185, 0.9343474680960452, 0.9495919659353158, 0.9111748144546408, 0.9312901174717276, 0.9138015745231882, 0.8763489978995729, 0.907910447634674, 0.8710977483413349, 0.9480078197021393, 0.9378050866332189, 0.927037938582071, 0.9430811659092282, 0.9085454535842185, 0.8852113617047547, 0.8920277544896578, 0.9276829237113944, 0.8921535564281552, 0.9485072008201927, 0.8931386790275493, 0.8408948957336471, 0.9246281557982426, 0.9476774335600577, 0.9204450327619462, 0.9306485877828865, 0.9173116402682907, 0.9655767378601264, 0.9408229076111037, 0.9021454407039319, 0.8977961438008242, 0.9469933517026756, 0.8903808172699359, 0.9142434595796, 0.9437883356106307, 0.7705646107082287, 0.9142180563419005, 0.9102719318916812, 0.905737299819116, 0.9372719793327774, 0.9247140407402846, 0.8916483603555936, 0.9127803601297397, 0.8453520942038706, 0.9402479548789039, 0.9265321163386088, 0.9053868220156329, 0.8920278595656993, 0.8787574173034254, 0.9243771775562817, 0.9597513643274908, 0.9410643580179673, 0.8652827580784449, 0.8808284589985761, 0.8554545067139392], [0.9028387572692538, 0.8819274401399151, 0.8837609319150793, 0.8895916106398016, 0.8908690501799978, 0.9032505147532162, 0.8801062746169797, 1.0, 0.8531749111632235, 0.8829153571454927, 0.8692866473988542, 0.8974520725284696, 0.8722658983905799, 0.8836959627832572, 0.8393805178956228, 0.8836846591866578, 0.884533896480486, 0.8754561466601466, 0.8541531339925561, 0.8965714801006254, 0.8926312781861911, 0.8732903340706368, 0.9071644003367191, 0.8709425540629929, 0.8687498953257863, 0.9014049946462781, 0.9115732834897828, 0.850181204217274, 0.8950877823754367, 0.8626147186920137, 0.8821952930987654, 0.8944629895263639, 0.8707252801571814, 0.897344672615859, 0.8712337940652178, 0.8826044926963733, 0.8660484485264486, 0.845801580036659, 0.8285937685632342, 0.8901482688210886, 0.8859241196318579, 0.9010070262591561, 0.8947485928544321, 0.8778564517392955, 0.8203500532354984, 0.9041211468098573, 0.8694671354509, 0.8950561921914204, 0.8346222424417977, 0.8569452161027519, 0.8792095038429344, 0.8871021402531378, 0.872262889990546, 0.9095515585675646, 0.912677777509622, 0.8909514623930895, 0.9033242971253725, 0.9018646152506788, 0.9057946908801072, 0.9074190940173, 0.8982189305266757, 0.8792069924352629, 0.9087709377069538, 0.8714071961649831, 0.8389605097583354, 0.8797373618002136, 0.8919329658304288, 0.918449383876464, 0.8948962689884713, 0.8814922502185174, 0.8781945732091386, 0.8764394267081637, 0.8745958826071637, 0.9064117158229785, 0.8560053068186984, 0.9108180796380511, 0.8914696067739978, 0.8702086862484032, 0.8891830980204621, 0.8599264242492227, 0.8820720590864218, 0.8508056422392649, 0.8647513133160869, 0.8940391260266205, 0.9142099340191352, 0.8832951371277079, 0.8643720312496238, 0.8763271979268791, 0.8967442564949839, 0.8972861833787151, 0.8555486550247088, 0.8707709883526146, 0.8684564496975503, 0.8695414014706719, 0.8955881010255764, 0.864993860603499, 0.9129827583364214, 0.9003110473299727, 0.8673156500564545, 0.8542534463648108, 0.9152619087880672, 0.8792658533717831, 0.8900794915601075, 0.8513801551238788, 0.8917863810605138, 0.8841591430213588, 0.8699015861748032, 0.8640996166522167, 0.9017785676430634, 0.8839801996818936, 0.8683277634733244, 0.9064415032629188, 0.8936971217367852, 0.8402475514503542, 0.8420392131462968, 0.8593612431701505, 0.8449392470996804, 0.8522733771159152, 0.8890165159770371, 0.868539029578588, 0.8664629826905049, 0.8998948819551229, 0.8922971019163061, 0.8766460088639431, 0.8648148290933896, 0.888244084430614, 0.8256063653090686, 0.8587476994010819, 0.8569953023702056, 0.8706753218464538, 0.8886936637553451, 0.9026564935888235, 0.8430153401770181], [0.9031766141189197, 0.8866150863778257, 0.8819076334636398, 0.8988094424919628, 0.8699477441672401, 0.8711340959880918, 0.9034768433097078, 0.8531749111632235, 0.9999999999999992, 0.8765601820567643, 0.8994207505948886, 0.878886772359607, 0.8872379496190288, 0.863314841319426, 0.8834735438148456, 0.8868693542031711, 0.8887967702819919, 0.9173964220942832, 0.8910561479465646, 0.9420897832028431, 0.8720115064717087, 0.9122448264495794, 0.8737723967746456, 0.9014284608787002, 0.8815374379352772, 0.9260005744826196, 0.8943375257725764, 0.898440959294833, 0.91345945623257, 0.8882736861366394, 0.9350435369322527, 0.8923259206206249, 0.9083732972978248, 0.938448567550768, 0.841096483141973, 0.9087556879019254, 0.8651099838595158, 0.8318095940364889, 0.8781399226620906, 0.8618843984061471, 0.9447330495812182, 0.902249629598509, 0.8928313697214397, 0.8821386590957057, 0.8390997734526852, 0.8913798998574436, 0.9370829048079427, 0.8900911791414151, 0.829929904811225, 0.8713292803151939, 0.8727906765103002, 0.9003733070101904, 0.9072947046996905, 0.9144298879609343, 0.8950279460187002, 0.8692924356919514, 0.9229801140310591, 0.8918507486191283, 0.8936433034077085, 0.9133087705173122, 0.9330423666552898, 0.9150237643647466, 0.9088563246556597, 0.9047572232610358, 0.8477742455771359, 0.9324703022900147, 0.8994878093673689, 0.8708269921315477, 0.8971758551125927, 0.8998402930742209, 0.8458157471193086, 0.9042130404997561, 0.9528603923443287, 0.8423956657731629, 0.8296399453406935, 0.9004112732050784, 0.8965870021493284, 0.8969083113054952, 0.8938198835292083, 0.9306739476837546, 0.9097652671658326, 0.9066996701637167, 0.8958845796403676, 0.8872116823809004, 0.9042004088780933, 0.8590516538790937, 0.8550986858749341, 0.8725429029899564, 0.9394823527086794, 0.9081719851951372, 0.8977454685002736, 0.9099702133690755, 0.8422960467982512, 0.8696884637395066, 0.8736173729463507, 0.8693867511979934, 0.9004320342451394, 0.9111922356837336, 0.8372549798485698, 0.8560299969876867, 0.896931774314194, 0.9171962048326961, 0.8903195735592218, 0.8815083150855967, 0.9065765037135349, 0.883328463855328, 0.8925682854008552, 0.8785350245127026, 0.8759655338232032, 0.8983993939642896, 0.8649741531372859, 0.8946297001557317, 0.9011968895349192, 0.7555441023953119, 0.9119748284862066, 0.8755687854651679, 0.8822321314543331, 0.8810161333863025, 0.8932150860866197, 0.8656663276352515, 0.8871517920000712, 0.8421360828731757, 0.9123341086486092, 0.9221448409972041, 0.9133143496769965, 0.8836824374948954, 0.8280417526552757, 0.8884825634876925, 0.8875816747653351, 0.9019842593923938, 0.8572032330553748, 0.8680115134795984, 0.8135935139442736], [0.944517096631218, 0.9043411862515371, 0.9119188512121754, 0.9293102475364255, 0.9285574520341235, 0.9240260451271829, 0.9315337359513609, 0.8829153571454927, 0.8765601820567643, 1.0000000000000007, 0.927067908763793, 0.8817312791448897, 0.8707323198159083, 0.8632553640728937, 0.8564670846722939, 0.8967058990332608, 0.9380441295034183, 0.8881153721573882, 0.8688933472927528, 0.9273641226668308, 0.9609840783955351, 0.9387589823775377, 0.9277378930437271, 0.8966869462917103, 0.9039028722688353, 0.9392849765631148, 0.9437653489562088, 0.8850557759597587, 0.9310137692060133, 0.9137801166377127, 0.9287373991578257, 0.9193522126329353, 0.9038877349970361, 0.9206306818261097, 0.8809795671429734, 0.8675981008407627, 0.8985249787819451, 0.9016632805460988, 0.8812640466481301, 0.9274703993666544, 0.9309026905596806, 0.9634863076281258, 0.9356412679048022, 0.9085018014449435, 0.8855762997959685, 0.9274721029816246, 0.8895153673196234, 0.9267769972428722, 0.8496688335977046, 0.9232139626565139, 0.8866050957698647, 0.9232810001621662, 0.9067742960299591, 0.9379789420380317, 0.9266108945671987, 0.8881281092975457, 0.9395828617040691, 0.9370198307263266, 0.9283733359923881, 0.9133262782336052, 0.9249005319696351, 0.9343542893486099, 0.9468686090385726, 0.9226970566547559, 0.9194239500387542, 0.9146219494247765, 0.9451974231815699, 0.9301066393521781, 0.9148593514558019, 0.8995120300334274, 0.8770870618615639, 0.9079329545821825, 0.8906752686286185, 0.8593078428326713, 0.8846991760189827, 0.9291987377679403, 0.9441568181736021, 0.9182443826907368, 0.9432967102618445, 0.9092595420333103, 0.9218243328732955, 0.9183304480026756, 0.9052274898011088, 0.9129940184050457, 0.9370265931336256, 0.8811266786441148, 0.9579450017215068, 0.8686558506502493, 0.9214883633628133, 0.9278758715088651, 0.9095386891036762, 0.9268872266941071, 0.9455956592938716, 0.9134931755397306, 0.9140798282200177, 0.9335732302626377, 0.9038151929860585, 0.9407678569937868, 0.9134905101511572, 0.8600508689116132, 0.9147950397964986, 0.9039649505283623, 0.9436941862628396, 0.9135331174806428, 0.8990643397436415, 0.9167731508507896, 0.9354714522238583, 0.9168933022032585, 0.9283741227804364, 0.928516437964468, 0.8713643546110192, 0.9237717708059582, 0.9188167973068155, 0.8071828678302472, 0.8757179681107579, 0.8986305932033862, 0.9018295969450283, 0.9364489008602624, 0.9324870874724872, 0.8969202882453694, 0.9096865448340798, 0.8474932949300172, 0.9369057427205936, 0.9163075935589999, 0.9017712339221204, 0.8971323855765702, 0.8981304397545377, 0.9415919335544572, 0.915305301743671, 0.9220709020491228, 0.9057981428528468, 0.9021216962672429, 0.9096171779092703], [0.9430204468943526, 0.9166009707524756, 0.9131015192877143, 0.9738389708776057, 0.9054848561711193, 0.9300652504193968, 0.9408525956413829, 0.8692866473988542, 0.8994207505948886, 0.927067908763793, 1.0000000000000009, 0.9073749274724578, 0.8757650915467107, 0.8739418631171112, 0.8703770330375196, 0.9088364702383867, 0.9332282963398534, 0.9105927358890429, 0.8867990129071092, 0.9377275207511915, 0.9347635979429184, 0.9339414684382132, 0.926097568076572, 0.9174891519798221, 0.9311880765806104, 0.9598176853866514, 0.9452350867152433, 0.8900699181615543, 0.9389524842476765, 0.9211564360213699, 0.9391291769945255, 0.9107086741820447, 0.9390656361453379, 0.9217651922918155, 0.879838707604951, 0.8979492431780015, 0.9087977095440489, 0.8967130828075102, 0.9069892379245035, 0.9026959912191025, 0.9608591373442908, 0.9346273591571964, 0.9373179936071305, 0.8987139434266451, 0.8674539418420524, 0.9430069206037585, 0.9213472557186908, 0.9207698839032575, 0.8466798042215437, 0.9081981710130334, 0.8880958059752156, 0.929620387808284, 0.9042678808738168, 0.9315481774058125, 0.9381105060323639, 0.8993559410278495, 0.9456431932308655, 0.9297011317116697, 0.9395699780849099, 0.9249203758333934, 0.9364773907197577, 0.9300265292494589, 0.9322763563909571, 0.927890039709858, 0.9382599584502717, 0.9285565820483727, 0.9329824867537269, 0.9263263517460725, 0.930447046636283, 0.9000180859700159, 0.86449188096592, 0.901408165481218, 0.9052522327177556, 0.8721603556513715, 0.8545606177883827, 0.91869125160818, 0.9340894662138461, 0.9384203852618446, 0.9431330194628937, 0.9145120449850036, 0.9529611017987414, 0.919653531330839, 0.9151027482883292, 0.9489222130456454, 0.924198671144129, 0.8959413725335732, 0.9086908964238589, 0.8782817539338676, 0.9543030298490209, 0.9431546962407819, 0.9213267155316588, 0.9398679577386169, 0.9169913283068357, 0.9097241995183447, 0.9064838045585382, 0.93787501803832, 0.9029712301514163, 0.9427502430337262, 0.8979638776578114, 0.8587888120835028, 0.9327726449662881, 0.9255944803962004, 0.9321158229389248, 0.946751764435148, 0.9058599891673461, 0.928306681230589, 0.9358626477107418, 0.9021460319565842, 0.9255666200039515, 0.9416532645120503, 0.8982975581153586, 0.930456097573398, 0.9147978780164493, 0.7909248586799333, 0.8903803087345452, 0.9097673017882002, 0.8770540252715684, 0.9541190923278625, 0.9359832661187615, 0.9024473763870096, 0.9206844750537986, 0.856025262805458, 0.9375300736620674, 0.9186984681739466, 0.9114805556444008, 0.9087658737381026, 0.901465582780481, 0.9097784030156626, 0.9303457477147581, 0.9547996614904805, 0.8804286598052318, 0.9018629414734194, 0.8930881097354735], [0.9057173866402095, 0.9083258187415133, 0.8916735363070982, 0.9007135128122156, 0.8604941912107782, 0.8835569420907219, 0.9259083926556825, 0.8974520725284696, 0.878886772359607, 0.8817312791448897, 0.9073749274724578, 1.0, 0.9108763390568271, 0.8460817273038862, 0.8561831426106155, 0.9327595819178038, 0.8972164396546757, 0.8953675082000606, 0.9213327256719002, 0.9289954659492109, 0.8855490210776363, 0.9111252419408136, 0.8896257189316968, 0.9001349178465574, 0.8997556583245117, 0.9288252933798093, 0.932632046716894, 0.8683624861601218, 0.9096234815487352, 0.8760069262083449, 0.9273812656429516, 0.875296360161213, 0.9021592258486164, 0.8961796741244853, 0.8497565019006308, 0.8867810316342204, 0.8565012701551562, 0.8196397724481719, 0.8435621680396059, 0.8727772954968996, 0.9211386810453019, 0.9013492228911544, 0.8816651666166999, 0.8516707650642502, 0.8046323072194029, 0.9023806363697752, 0.889005338250303, 0.8660740453202425, 0.8890422172102814, 0.86304930810346, 0.8861449330787677, 0.8999600321081704, 0.9084273283008101, 0.9055173174562043, 0.8986503096052316, 0.8661021162514588, 0.9154887915449362, 0.8836376979138482, 0.9028604512403884, 0.9452824424333347, 0.9088509656300915, 0.8985270394615079, 0.9103416554613928, 0.9206131742136076, 0.8810319902620088, 0.8999572152502787, 0.9011045411635938, 0.8788234561084602, 0.8966988518816844, 0.8890879168216105, 0.8759062622502937, 0.9273903030054658, 0.8948991817958223, 0.8628473211141384, 0.8092396999647105, 0.8985154160913433, 0.884005460352726, 0.8968221375646085, 0.9037756966190524, 0.9024361258905077, 0.8978514781434771, 0.8784903995350744, 0.8798558904176235, 0.9095974442351558, 0.9080019224709649, 0.8385892193231391, 0.8549818436373581, 0.8508924223746768, 0.9200313006025195, 0.9309616219827265, 0.8866092088056914, 0.9152185455243325, 0.8595148516402544, 0.8732100145231161, 0.8643846784151509, 0.8815133251397654, 0.9331762942310527, 0.9105329048560831, 0.8524772923620492, 0.8592739761706354, 0.9293410201679151, 0.9145823656828742, 0.9110777858426516, 0.8922780124239652, 0.8753406261507426, 0.9182441814563164, 0.8966381745509735, 0.8917279640757216, 0.8927017862455345, 0.9258608612333209, 0.8497176413049056, 0.8987911152475137, 0.9208579888458104, 0.8142720016678154, 0.8705349650568696, 0.8676547801944237, 0.8649931086822737, 0.9010306932978159, 0.8841456645958531, 0.8566984008877052, 0.8635408909945359, 0.8823983833186972, 0.9064571841248985, 0.9079843297413563, 0.9015930773237233, 0.8844069985918073, 0.850068097320368, 0.8657817353084435, 0.8930122908300918, 0.9052256900045457, 0.8405078297343278, 0.8799667546502075, 0.8140472299188409], [0.8905985616134874, 0.8729999154773206, 0.9064745800742995, 0.8817573602817018, 0.8628451061157691, 0.8560775738816103, 0.8902090455500602, 0.8722658983905799, 0.8872379496190288, 0.8707323198159083, 0.8757650915467107, 0.9108763390568271, 0.9999999999999999, 0.8549242819862939, 0.8253566674798019, 0.909391587027801, 0.8821751362118352, 0.8714224113111713, 0.8973513954624373, 0.890591726950521, 0.8789542377146399, 0.8891870614932074, 0.8606614037580285, 0.8820188225754066, 0.8684006272338394, 0.8979263482064451, 0.9069582650159633, 0.8642599395210924, 0.8938361703256799, 0.8626866789009395, 0.9184643780941882, 0.8622308910686795, 0.8928251586863715, 0.8772604877647454, 0.875052822964676, 0.9176127808999623, 0.8394367063525062, 0.8223675325572146, 0.8364792566970609, 0.8527674314905244, 0.8877496629457602, 0.8914641150613296, 0.8837765411697383, 0.8529368625851901, 0.8079048622308279, 0.8794408770420858, 0.8849370165287039, 0.8649221968434502, 0.8267479447987913, 0.8549204262365204, 0.8894710245387858, 0.8724338296350418, 0.9057414634629055, 0.8920408516785516, 0.8966094617682191, 0.8924747000992561, 0.9059539883437334, 0.8917747615174114, 0.8837345380671328, 0.8976532277702608, 0.8926999201738195, 0.8842327983277157, 0.8902643405544508, 0.9010865925875282, 0.8600044941072342, 0.8938804099204888, 0.8708798981122157, 0.8834680825270596, 0.8953917937898253, 0.8601622821638567, 0.888620751677006, 0.8802186725538448, 0.8774671507233969, 0.8733181811857673, 0.8214169560497006, 0.8831435482328707, 0.8785201724166938, 0.8693142136441094, 0.8828120883261991, 0.893881303307863, 0.8801734455247382, 0.8753762497646069, 0.8743069245816124, 0.8887169563033855, 0.9114124849763905, 0.8560223579112091, 0.8396721388982621, 0.8632671160031177, 0.8887345100865292, 0.8888979280891136, 0.8737093062808453, 0.8936021564257209, 0.8477324156137651, 0.8749131949667412, 0.8588569799366179, 0.8679724811012326, 0.9049677338226736, 0.892251861118666, 0.8562795775422747, 0.8486188215027588, 0.9130883312226367, 0.882011058522111, 0.8851440829645655, 0.8526810480788103, 0.8905712636221983, 0.8896660029322797, 0.8961561420900556, 0.8596628107425913, 0.8772754164902616, 0.9172779068916468, 0.8531945120669268, 0.8864295610433561, 0.876759060756713, 0.8291801540583299, 0.8957128519159775, 0.8795369993008522, 0.8584428382556167, 0.8853899635496507, 0.8770847127927411, 0.8643930296075378, 0.8572556268849415, 0.8845312295927948, 0.8955892352171247, 0.8682605891353825, 0.919299713280909, 0.9018251438123495, 0.8147730625757992, 0.8600792880518623, 0.858586918109345, 0.8797491103885415, 0.8404250873517163, 0.8907540835391202, 0.8093283037815828], [0.9072070745841986, 0.8626881917040301, 0.900806663696522, 0.9082908376286806, 0.8863876749980213, 0.864608943851134, 0.8447073490414453, 0.8836959627832572, 0.863314841319426, 0.8632553640728937, 0.8739418631171112, 0.8460817273038862, 0.8549242819862939, 1.0, 0.8370201541029553, 0.8616422210700415, 0.8958014368168408, 0.8893467122612909, 0.833504745426185, 0.8665748697507736, 0.8784869393051855, 0.8699222861218154, 0.9097108561628714, 0.8867340361536508, 0.8698096102866218, 0.8830286583912492, 0.8917704232917787, 0.8292449063589734, 0.896145992845986, 0.8471507513600625, 0.8753621597381556, 0.8810281195540031, 0.8706085927831827, 0.8783399572840177, 0.8699662709037453, 0.8542052428210409, 0.8671152539784903, 0.8415133496975945, 0.8471696924598137, 0.865425679536328, 0.8947362121541065, 0.8953960260635369, 0.8969820598746387, 0.8773696752597884, 0.8572919437606873, 0.8775861507365783, 0.85972329142962, 0.9015990589335705, 0.7943411901312012, 0.8768691218044438, 0.8501314470896548, 0.8630175349534165, 0.8708245906124367, 0.9085677800918548, 0.8967112429782033, 0.906497175050935, 0.8917801282544853, 0.9106578474630427, 0.8970833380371979, 0.8796404014624283, 0.9007625450362614, 0.8763138507138882, 0.9188043670304622, 0.8460389138809287, 0.8362353406422366, 0.9059203675158528, 0.8894628545468098, 0.9079524274421243, 0.888097241456703, 0.8514695577610722, 0.8879075250654773, 0.8334938187077803, 0.859552374802343, 0.8760291121563616, 0.8365241243333894, 0.9532909334117593, 0.903773731125646, 0.8729433740645721, 0.8765804245287572, 0.8501832205199458, 0.8888383675917215, 0.8523444506195657, 0.8665883897754284, 0.8504857369870187, 0.9167914596410283, 0.892440794413757, 0.849783657477243, 0.8788107455559294, 0.8867026787314862, 0.8899477682387851, 0.8471635457305119, 0.8760745293498194, 0.858514714327701, 0.9008739039299762, 0.8708109318131113, 0.8595033815827766, 0.8820722172016896, 0.8782664156169042, 0.8545835000757278, 0.8664312793657728, 0.8976924947074033, 0.8529608146461001, 0.8873986158974085, 0.8413720720574511, 0.8641216351431312, 0.8368831858551214, 0.8648558750732525, 0.8588673157791793, 0.8771300576231005, 0.8551787378960066, 0.928546935622086, 0.896221272269148, 0.8410410020184577, 0.8424946911487727, 0.8309765395150668, 0.832563677337816, 0.8549536388845685, 0.8658583147318447, 0.895610023831775, 0.8979172932001126, 0.8605696622067501, 0.8762940693343317, 0.8845091188326335, 0.8491554587553315, 0.8833870221983057, 0.8978457629657752, 0.829713067524742, 0.8606488785688169, 0.8340696344146903, 0.8732630130163115, 0.857480881369486, 0.9077537561932915, 0.8359755345459801], [0.8913842743093392, 0.87934844478869, 0.869470064593828, 0.874267986659519, 0.8597675889174256, 0.8679880250505261, 0.8795569245516057, 0.8393805178956228, 0.8834735438148456, 0.8564670846722939, 0.8703770330375196, 0.8561831426106155, 0.8253566674798019, 0.8370201541029553, 1.0000000000000002, 0.8487778727923905, 0.8858160593050268, 0.8999655603157394, 0.8499602457080391, 0.8767302017992373, 0.8748046504659852, 0.8863118504000889, 0.8608841551230157, 0.879623838051824, 0.9233804454897786, 0.8968276469948451, 0.8836253396400163, 0.844797355879646, 0.9031707872999767, 0.8697987765557454, 0.8736514785811035, 0.8798341564176562, 0.8698206427218454, 0.8717904119505963, 0.8236612709459912, 0.8086969764651285, 0.8482592456410788, 0.8408948775811229, 0.9019732163734429, 0.8492484422677814, 0.9082021648397195, 0.8807577071280875, 0.8741883787671808, 0.8740786742276674, 0.8240550384210825, 0.879928261800118, 0.8628637433955169, 0.8691875350052466, 0.8636498647382902, 0.8686794225599004, 0.847694037792696, 0.86291749861442, 0.8740121297516372, 0.9113241194796947, 0.8540936716475441, 0.8190325131401167, 0.8909311866255291, 0.8651508410682024, 0.8788017833521952, 0.9203321310058465, 0.8930159679944781, 0.8877759677563541, 0.8927724826252332, 0.8743024933326615, 0.8541764883060111, 0.9068075875182271, 0.8914265392638699, 0.8591492629683738, 0.8500631648533038, 0.9010930451704919, 0.8088872273625971, 0.8940445714253666, 0.8707345939516383, 0.7917457190072055, 0.8287357192511684, 0.8854661933678, 0.8704134291372023, 0.9223041982794494, 0.877529852603059, 0.8773681082797206, 0.8792874231923831, 0.8639435603472834, 0.8725939562670433, 0.8590736626971687, 0.8627661573186762, 0.8634575055292144, 0.8229665687097047, 0.8362833673561052, 0.8905434473315297, 0.9028002663740098, 0.902726277187554, 0.8863976023147672, 0.8394476460615996, 0.8449155603218604, 0.8795155398516855, 0.8790761851094907, 0.867276364113698, 0.8863763170383374, 0.8633141473734713, 0.8392893807177435, 0.8710435554756172, 0.8960941374270076, 0.8861124118820408, 0.8875845192013105, 0.8488133552238207, 0.8614168246946574, 0.8819763904035136, 0.8643019338411532, 0.8657114857883147, 0.8699524053853047, 0.8546118433565146, 0.8543531779338547, 0.8902724880310162, 0.7140501359892968, 0.864155187510165, 0.8438690728455931, 0.8645477934255364, 0.8866746039585472, 0.9013909857504263, 0.8308276420208979, 0.892732790380663, 0.7845050852766287, 0.8984071676543809, 0.8850570599239703, 0.850765517269354, 0.8318500486865543, 0.7974254146144296, 0.872854403936957, 0.8964974928948601, 0.9060833220303228, 0.8403844021898736, 0.8371369606829023, 0.7918311858749606], [0.9270791936980725, 0.8945756978150208, 0.9214898990703495, 0.9064331800488863, 0.8913854270704122, 0.8814031238718549, 0.9165151540989, 0.8836846591866578, 0.8868693542031711, 0.8967058990332608, 0.9088364702383867, 0.9327595819178038, 0.909391587027801, 0.8616422210700415, 0.8487778727923905, 1.0, 0.907568693781065, 0.9255485010003031, 0.9383963952709672, 0.9172490367984678, 0.9010138603307756, 0.9204532037255319, 0.9118713092090867, 0.9187436371936908, 0.8910921466047008, 0.9289420493248085, 0.9196048485356954, 0.8948137621608128, 0.9436847353033593, 0.8969104211396027, 0.9343778597944559, 0.8858630200073969, 0.8763338429663041, 0.9034535212532497, 0.8705348293129421, 0.8944753466918938, 0.8492802461535854, 0.8451629573189612, 0.8428825349928324, 0.893905526792087, 0.9299872708775735, 0.9189670077927033, 0.9062190002637829, 0.8831582570631828, 0.8428479458664966, 0.9021173023282302, 0.9029487109895273, 0.8989377293620018, 0.8924371075738682, 0.884091665668792, 0.9471869967737737, 0.9215118437092322, 0.9214088705973464, 0.9171215500369656, 0.9107056427704155, 0.8850913685651931, 0.9278923347945298, 0.910906567620873, 0.9062528991346671, 0.9275556141742689, 0.9208832838904892, 0.9112217167168055, 0.9262396803543886, 0.9050528102525129, 0.8823362577027468, 0.9365021486345739, 0.9015784587012705, 0.8989976578899567, 0.919825799735312, 0.8810314307815471, 0.9001639098842024, 0.9238089985322299, 0.8974229404121314, 0.8678460961964942, 0.8697807270330743, 0.9059563832614056, 0.9114863181649269, 0.9003778702779763, 0.9002684497575827, 0.9059772889252806, 0.9039023748524373, 0.8970050824164882, 0.8883358506152079, 0.9076306429622502, 0.9185995473917125, 0.8594072930959805, 0.8679712207503143, 0.8773098550314081, 0.9139938006182646, 0.9534074052406749, 0.9048972765853251, 0.9209707211483251, 0.8771048371663178, 0.8946765867258932, 0.8886869325881923, 0.8919977805791651, 0.9057884318786558, 0.9038772420762538, 0.8737590750604975, 0.8722967793528283, 0.941336938680405, 0.8939196838775219, 0.8961146563957033, 0.8941663502689149, 0.9102308552897245, 0.9170657694800486, 0.9029495287673914, 0.8907824707103991, 0.8868589869021752, 0.9117969169975669, 0.8811481139482527, 0.9435196873697702, 0.915314176715104, 0.8262318084940017, 0.9039428047972604, 0.8853107005774982, 0.8863351960668189, 0.8996114935650372, 0.9080927278179844, 0.871269621882126, 0.8851156095395851, 0.8772242715632218, 0.9202524299198749, 0.9136335824895077, 0.9367630258212715, 0.9024248471605933, 0.8667138219444408, 0.8729159014691068, 0.890224394173935, 0.9099773136678697, 0.8712423782018396, 0.9093985417632454, 0.8253126386534722], [0.9505115523782197, 0.9093784020868856, 0.9402901540075213, 0.935449263018777, 0.9273747978859062, 0.9125400386777026, 0.9318503063093858, 0.884533896480486, 0.8887967702819919, 0.9380441295034183, 0.9332282963398534, 0.8972164396546757, 0.8821751362118352, 0.8958014368168408, 0.8858160593050268, 0.907568693781065, 1.0000000000000009, 0.9127777928857026, 0.8597684042285161, 0.923522395432059, 0.9643110258002993, 0.9710391984195942, 0.9306505631803528, 0.9300678237777106, 0.9127425669650475, 0.9399913120763383, 0.9563278266188581, 0.8703574900033737, 0.9357859578438372, 0.9205668239419624, 0.9508127408528317, 0.9325555897635273, 0.9300846609244549, 0.9184173164635528, 0.8928292639805642, 0.8723751319159745, 0.9021881055820853, 0.899910707975897, 0.878509523975878, 0.9145701922113225, 0.924663239140098, 0.9432167982838214, 0.967265131917583, 0.9065652032375974, 0.8854755375418857, 0.9135510062794893, 0.9066580571177936, 0.9255952984975826, 0.8590212574581904, 0.9713937047531201, 0.8903084233691572, 0.9088146963352782, 0.9215578612183388, 0.9697189000067654, 0.933736039033672, 0.8859154914919752, 0.9536604910812426, 0.9369793662196141, 0.9303492660910555, 0.9040010771562108, 0.9135156895766976, 0.9321219009935522, 0.9549607346653318, 0.9269834347196799, 0.9475625139139561, 0.9180968349369624, 0.9512626856230365, 0.9224376529233613, 0.9075314174730771, 0.9042856859381448, 0.8748512016092018, 0.9185684691780158, 0.8981607461988815, 0.8453177943937947, 0.8825292599615191, 0.9482021793235571, 0.9406182883211001, 0.9104912430145204, 0.9421805887552973, 0.9344273313432843, 0.9140027137391215, 0.9223348354799684, 0.910183736090413, 0.9267310754732394, 0.923633179243162, 0.8828611664527185, 0.9071834963278838, 0.880466319225082, 0.9295114065826384, 0.9345275020235605, 0.9056316672177298, 0.9401466203904478, 0.9147428277704511, 0.9064727797476579, 0.9320109872130447, 0.9508634221740804, 0.8996145759727294, 0.950694008222332, 0.920421766606963, 0.8531375434131141, 0.9172323800629781, 0.9123971133275895, 0.9558693694647966, 0.9108139989302123, 0.8895401979746749, 0.9294124022892793, 0.9462998807206058, 0.9332799799122431, 0.917848287317107, 0.9480012659162227, 0.9064123386968603, 0.9158983695682741, 0.9207960316359656, 0.7991463730108741, 0.8758843976154106, 0.9008831579889877, 0.8995646890650834, 0.963073962400522, 0.9352055359192789, 0.8953545029300327, 0.9098551423873322, 0.8415446016824122, 0.9456384474138873, 0.9187637355257927, 0.9204835364327534, 0.909012262746544, 0.8825904058739477, 0.9196994737963761, 0.9120527673743042, 0.926798916037994, 0.8872736646187765, 0.9070022006141791, 0.8787039679192016], [0.9242545271713031, 0.9036142861705098, 0.9173547731034484, 0.9245328558416205, 0.8905834598356839, 0.8890193975968013, 0.8944155697331461, 0.8754561466601466, 0.9173964220942832, 0.8881153721573882, 0.9105927358890429, 0.8953675082000606, 0.8714224113111713, 0.8893467122612909, 0.8999655603157394, 0.9255485010003031, 0.9127777928857026, 0.9999999999999996, 0.897025881746023, 0.9107671510434523, 0.8922098557643622, 0.9189552583503589, 0.9045609598043841, 0.9457816373637793, 0.8950249859854772, 0.9205153682679157, 0.909505045583272, 0.8626434670101925, 0.9167935418099927, 0.9097161455923057, 0.9124561038957456, 0.9014139899778008, 0.8997581903439476, 0.9177803821009516, 0.8635792174825915, 0.8803371068606587, 0.8726599275676052, 0.8451814706839835, 0.8574277538815953, 0.8670607113865425, 0.9453761601612778, 0.9184680836981063, 0.9109139365557553, 0.8995826738251775, 0.8617191460599206, 0.900675793977831, 0.9071723002562312, 0.8982092130202946, 0.865032259035805, 0.8947030996823875, 0.9077579227977525, 0.9046942796076465, 0.9331378079884027, 0.9341232855514611, 0.9097791050952798, 0.883978554833563, 0.9252538714981715, 0.9054972200680664, 0.9120097073558402, 0.9213775569549905, 0.9224384838192806, 0.9168935833709014, 0.9381716896617176, 0.8762490089926867, 0.8709848731178336, 0.9374123613210792, 0.9055806064504378, 0.8983137467878277, 0.9036875235684737, 0.9052705330199418, 0.8827759361093144, 0.918792644779081, 0.9112983682230665, 0.8603642102800406, 0.8429044702417021, 0.9262545158478356, 0.9152377052147589, 0.9119976828162419, 0.9149935869289721, 0.9055133138755237, 0.9019334508747935, 0.8864735448047999, 0.8681422715492446, 0.8928689486852366, 0.9106174308312658, 0.8708838356036358, 0.8599091144335228, 0.8796515241611457, 0.9282710785996873, 0.9490610805555629, 0.8955986306595871, 0.9271755590871236, 0.864143319597724, 0.884282554791896, 0.8914176335859112, 0.8949579037876333, 0.9106693405919162, 0.9069933289031983, 0.8949988719841577, 0.8623858976351024, 0.9154972595127396, 0.8857853622736752, 0.913705234747413, 0.8928040092555806, 0.8782825177708542, 0.8905970627318064, 0.9000871385193961, 0.8831517593938523, 0.8959551628217497, 0.885645307187384, 0.8933303615388274, 0.9147471245886903, 0.8951342903232864, 0.7850686777196134, 0.8961426730172299, 0.868655204654934, 0.8891679744594109, 0.9032608011003052, 0.9101087002274546, 0.8812870477033635, 0.8969611844135987, 0.8486955744316893, 0.9214652605059651, 0.9255312389926449, 0.9080782276931747, 0.8915510983679625, 0.8403732305568032, 0.8761522464234289, 0.8869339139041172, 0.9132677143362938, 0.8532827612668361, 0.891527551875551, 0.8303144313482962], [0.8932991442545508, 0.8745247356932251, 0.8830699626070373, 0.8785286983082294, 0.8530403409737854, 0.8525726570198635, 0.8989260415867606, 0.8541531339925561, 0.8910561479465646, 0.8688933472927528, 0.8867990129071092, 0.9213327256719002, 0.8973513954624373, 0.833504745426185, 0.8499602457080391, 0.9383963952709672, 0.8597684042285161, 0.897025881746023, 0.9999999999999998, 0.9007892967124043, 0.8533765961018378, 0.8794119824254866, 0.8573474420404584, 0.9009830730731547, 0.865729407094934, 0.9016911418006105, 0.8786774277549988, 0.8673405920539616, 0.912578929502314, 0.8605676372691151, 0.9046092095677043, 0.860736133267045, 0.8667231164098198, 0.8742529433338591, 0.8224079342940451, 0.8709307588564766, 0.839975551766156, 0.8115678257602097, 0.8254796986820248, 0.8432713842611833, 0.9216073078265719, 0.893733510267158, 0.8593362477750488, 0.8484925762677518, 0.8081063007163717, 0.8737226735815864, 0.8836100253042383, 0.8584741023548854, 0.8878823452451999, 0.8308161561479244, 0.9073324369044753, 0.8680992932890792, 0.8961866072487357, 0.8828183554284508, 0.8640040536334174, 0.8598021064977763, 0.8955320514270232, 0.8696107842715612, 0.8844994884963716, 0.9346369673041185, 0.9247274947066393, 0.8936401390078836, 0.8975017016741136, 0.8920278571510988, 0.8337425084765332, 0.9367726139202721, 0.86637188857623, 0.8554025238015277, 0.9009203041245064, 0.858281076868796, 0.8555721074342253, 0.8868319772621702, 0.87319076288577, 0.8203325865513305, 0.8123391835517999, 0.8786967995509637, 0.8783665306461064, 0.880052132229104, 0.8721003286211342, 0.8703692637115722, 0.8799757893985616, 0.8771039553399336, 0.8638143748882344, 0.8825984685596332, 0.8859976005754003, 0.8324121294768454, 0.8341562307260822, 0.852919773597527, 0.9041960299303481, 0.9129746395631326, 0.8829343281097862, 0.8979741610193119, 0.8446998267001655, 0.8579549757882704, 0.8472695426654919, 0.8461451639302215, 0.8871705350166416, 0.865083759557691, 0.8316240501896212, 0.8523813419336465, 0.9202901675220623, 0.883424993894091, 0.8612077902331274, 0.8674363989823664, 0.8772795057144906, 0.8703304795304581, 0.8768137454262646, 0.8519123995729705, 0.8590082529648551, 0.8790426413175282, 0.8325179960516137, 0.9052162899679915, 0.9034364912974704, 0.769231556815827, 0.8818084124329109, 0.8467120046433319, 0.8812640638680562, 0.8634940130698265, 0.871005841159101, 0.833516701168775, 0.8503536555539841, 0.8548135935661171, 0.8765360735428293, 0.8814569827081503, 0.9268050719986906, 0.8661638056204786, 0.8099516588510223, 0.8436048732277963, 0.8653366059668675, 0.8946393554188331, 0.8304748978557217, 0.8585494536920384, 0.7908595686127715], [0.9311366720246417, 0.9094945441468659, 0.9056146065761691, 0.9312346423664406, 0.9048253879325829, 0.9253323368985151, 0.9557799160223525, 0.8965714801006254, 0.9420897832028431, 0.9273641226668308, 0.9377275207511915, 0.9289954659492109, 0.890591726950521, 0.8665748697507736, 0.8767302017992373, 0.9172490367984678, 0.923522395432059, 0.9107671510434523, 0.9007892967124043, 1.0000000000000009, 0.9113853239443398, 0.94971242187639, 0.9156556220753056, 0.9105436130303394, 0.897936506724314, 0.9751383250599408, 0.929684709256704, 0.9238344644961568, 0.9202221509914665, 0.9204129468481239, 0.9694040086179186, 0.9052421249944751, 0.9165802530360014, 0.9507010473678688, 0.8670318273546304, 0.923139001284333, 0.8772518081498276, 0.8604579559778707, 0.8891492064316352, 0.8871074668356862, 0.9558596770155616, 0.9410605347980057, 0.9120758214769605, 0.8916152208267092, 0.8551891212884335, 0.9250321144027851, 0.9298200169522253, 0.9086335287944698, 0.8537816502917817, 0.9004237376214903, 0.8937788413685624, 0.9455505392150251, 0.9300455867553157, 0.9385459519932696, 0.9251643325206087, 0.880031698522476, 0.9423309867768931, 0.922836440110339, 0.923773325542867, 0.9361593087913679, 0.941135055592698, 0.9330285360653086, 0.930467709364849, 0.9552210084851867, 0.9013275864144579, 0.933549231490411, 0.938595561966532, 0.9079549274877903, 0.917411361838731, 0.9125575198189383, 0.8680901563117067, 0.9228640161964502, 0.9368200658013064, 0.8620523857329159, 0.8524335699640676, 0.9222324576140708, 0.9198363648963584, 0.9222571923320748, 0.9284569925525876, 0.9562364835029455, 0.9360139741318918, 0.926517540112336, 0.895763740193446, 0.9318446076666245, 0.9182652454278821, 0.873000625644407, 0.911341793727, 0.8760283780238349, 0.9669539945688108, 0.9317519770572534, 0.9088764653933548, 0.936458073667026, 0.8904707602576455, 0.9028732630502687, 0.8925689262779286, 0.9010375662680881, 0.9228875951245084, 0.9436080141186747, 0.8628537832775611, 0.8408465823854274, 0.9169016627180329, 0.9559249722656227, 0.9144283657518166, 0.9308942702002831, 0.916751552427092, 0.9345774092508186, 0.9215300356415758, 0.9243074344706762, 0.8945097497391528, 0.9495039782750906, 0.8778929952473745, 0.9239267918563162, 0.9278095098112213, 0.7876968062288746, 0.9069241334246615, 0.9123894793814823, 0.9036392217881926, 0.9161419732231559, 0.9160695413272066, 0.8823414726725824, 0.8996073268741503, 0.8667131078913872, 0.9480433454336435, 0.945384545630732, 0.9130193656108618, 0.8957455474312068, 0.885230662078011, 0.9156213534279803, 0.9361305250224269, 0.9257189757734253, 0.8836359784403537, 0.8869675273186852, 0.8603395502341515], [0.9507755219487977, 0.9028803640063343, 0.9203815429430383, 0.937816969952358, 0.9396604451655997, 0.9306656647784088, 0.9253052620926827, 0.8926312781861911, 0.8720115064717087, 0.9609840783955351, 0.9347635979429184, 0.8855490210776363, 0.8789542377146399, 0.8784869393051855, 0.8748046504659852, 0.9010138603307756, 0.9643110258002993, 0.8922098557643622, 0.8533765961018378, 0.9113853239443398, 1.0000000000000004, 0.9455717328437302, 0.9334134443327392, 0.9117335569900953, 0.9147797552463863, 0.9374953756773801, 0.9601681432595705, 0.8849072510612477, 0.9399992365855737, 0.9205756640112808, 0.9340235736021659, 0.9289308545027004, 0.9233260162622733, 0.9187604974104582, 0.886499226532848, 0.8756596981314115, 0.9190675388260456, 0.9154496610521914, 0.8891490335532631, 0.9308305290051212, 0.9241246619480807, 0.9540769895190273, 0.9498113144959338, 0.9134839799262651, 0.888725631907229, 0.9295334898055115, 0.8957372065891791, 0.9350192869125864, 0.854812555274066, 0.9495074498866357, 0.8905387444982451, 0.9197158010503601, 0.8958116543368191, 0.9537739694721047, 0.9313778498412033, 0.9009768546119898, 0.9482446348392103, 0.9389761162533685, 0.9364744030522453, 0.9088194612459825, 0.9143305878679021, 0.9335148006536209, 0.9512168549843625, 0.9178333364913641, 0.9436291116075339, 0.9134760250971741, 0.9455163530671327, 0.9384834207155708, 0.910834675059997, 0.905903516473906, 0.8661728735560874, 0.9077325768796284, 0.8875913446588525, 0.8631153485146814, 0.8856794541074293, 0.9393497025677685, 0.9440204204837881, 0.9187256139196267, 0.9463477621785426, 0.9138764060576224, 0.9278877520123723, 0.9186541606003805, 0.918401267308098, 0.9288123405841591, 0.9341092262220955, 0.8958873988988961, 0.9298964758584489, 0.8759773437111895, 0.9209041699248594, 0.9310601036559696, 0.9137096187467987, 0.9287547867061923, 0.9352498174405068, 0.9018885943215359, 0.9281017427767022, 0.9509175869305448, 0.8963099958890091, 0.9488528266825358, 0.9243693697214276, 0.8681629578352711, 0.9196263687874707, 0.9014014993518911, 0.9569132835190534, 0.9181046700374094, 0.9075161386439964, 0.9293456357004073, 0.9414284275700691, 0.9183690243364966, 0.9373117605108389, 0.9380322708375612, 0.8946325186788154, 0.9248390827530042, 0.9228720121174413, 0.7978852694008343, 0.8737960283012284, 0.8994589577658754, 0.8876652390819362, 0.9525761113045211, 0.9471821873988054, 0.9006023791217347, 0.9185267368069607, 0.8492066443211382, 0.9477662398612757, 0.911404156083204, 0.8904638204124072, 0.906387493312617, 0.9041647226444266, 0.9407948945891901, 0.9223436484898777, 0.9253322810793441, 0.9123096235572207, 0.9080627408212611, 0.9183048291837383], [0.9405997518370465, 0.9051775916866616, 0.9315837017924908, 0.9325596087272849, 0.9162870469492804, 0.9145688252175899, 0.9386380635577245, 0.8732903340706368, 0.9122448264495794, 0.9387589823775377, 0.9339414684382132, 0.9111252419408136, 0.8891870614932074, 0.8699222861218154, 0.8863118504000889, 0.9204532037255319, 0.9710391984195942, 0.9189552583503589, 0.8794119824254866, 0.94971242187639, 0.9455717328437302, 1.0000000000000009, 0.9151540102158093, 0.9363947885865063, 0.9008332459765982, 0.9516344103203297, 0.9438259861751352, 0.8992252180049035, 0.9344993592035462, 0.9248699379756613, 0.9734547268235179, 0.9103683932671828, 0.9114230569651199, 0.9277342172871952, 0.8806540572006687, 0.8973078151199911, 0.8856277392892394, 0.8789080112316441, 0.8785992520872, 0.901672291405634, 0.9429198946390327, 0.9500748652432445, 0.947166840372904, 0.8963280933029879, 0.8697207942356148, 0.91555837621336, 0.9234638168710936, 0.9137920866972293, 0.8762514446111904, 0.9528938924883106, 0.9054460645653002, 0.9209749373152908, 0.9364720866929643, 0.9585133957447639, 0.9262942412109745, 0.8817439459950372, 0.9513475400212978, 0.9305879712997239, 0.9216578512304132, 0.9142582238586354, 0.9234711147478326, 0.9320739143873659, 0.9488863101242239, 0.9269753181296684, 0.9395609282813987, 0.9335299214387629, 0.9486444512666985, 0.9135981502112117, 0.9106557636744861, 0.8985003436880658, 0.8605929085754764, 0.9429988161952728, 0.9081859931929492, 0.8472865977772754, 0.8818835339245167, 0.9301519837504095, 0.9314378195042458, 0.9200067128354898, 0.9342623788225974, 0.9704531227024481, 0.9225561233022966, 0.9229070071960916, 0.9025865880370706, 0.9280361945258716, 0.917006102827342, 0.8645285532152098, 0.907386155781877, 0.8651870518423531, 0.9411476480240345, 0.9380338435248441, 0.9186390458709385, 0.9547628728783025, 0.9054296747942523, 0.8980965146125338, 0.9165723446777702, 0.9352698177246241, 0.9170584824825305, 0.9464567819472538, 0.9047736357816722, 0.8325797616922385, 0.9125906470198708, 0.9281222976536746, 0.9357621272773674, 0.9323207187089454, 0.9031915674847646, 0.9377484308989313, 0.9490940386218778, 0.9295540969427255, 0.9036774910029706, 0.9483371261212595, 0.8819476993102815, 0.911129761442933, 0.9193499717906634, 0.7829254634623519, 0.8949731147364307, 0.9166265537805508, 0.9073187782625152, 0.9527858392316966, 0.9306863411591064, 0.8793083506137549, 0.9050926110930697, 0.8464577580690654, 0.9453584464879483, 0.9393245985764501, 0.9256892276651048, 0.8989639471601972, 0.8758794010503297, 0.9232976983916162, 0.9209152784439147, 0.9332222399853765, 0.8740312895491215, 0.8910193658883052, 0.8725604722434871], [0.9579020421574153, 0.9005660228307542, 0.9128034226270967, 0.9372568245554443, 0.9278631342313187, 0.9256026744350153, 0.9090799437589361, 0.9071644003367191, 0.8737723967746456, 0.9277378930437271, 0.926097568076572, 0.8896257189316968, 0.8606614037580285, 0.9097108561628714, 0.8608841551230157, 0.9118713092090867, 0.9306505631803528, 0.9045609598043841, 0.8573474420404584, 0.9156556220753056, 0.9334134443327392, 0.9151540102158093, 0.9999999999999992, 0.9058102909094505, 0.9011246678375805, 0.9403115488170259, 0.9361971281994709, 0.8895342556818229, 0.9488511594512923, 0.9012936140273419, 0.9202642918621617, 0.9174306081477019, 0.9050194832273567, 0.9090726788517608, 0.8883998957198677, 0.8869154469272498, 0.9051833945609823, 0.9070443686938187, 0.8824472118377251, 0.9386579447373816, 0.9269997647667185, 0.9391874691745274, 0.9303788536075233, 0.9399441157400418, 0.8836208208758543, 0.9216739008824664, 0.8941298141344605, 0.9497916419360756, 0.8559884852494357, 0.9072674945781778, 0.8908346557005808, 0.9285066584923662, 0.8977210961492341, 0.9475151639618594, 0.9421015162879524, 0.908219302972398, 0.9329953614884607, 0.9563007579008783, 0.9439384618706872, 0.9174130222493965, 0.930318052436655, 0.9262937317604251, 0.9520019400540058, 0.8953260661592098, 0.9114287552328313, 0.9213882220271066, 0.9535112363831836, 0.9534396894513233, 0.9130234186819141, 0.9182121631502784, 0.9001877693754124, 0.8964648116493584, 0.9010569430881412, 0.8860948523166563, 0.899234751151772, 0.9447240088780215, 0.9435454937112241, 0.9091404170054534, 0.933594712644277, 0.89929267736197, 0.9350511726365934, 0.9003658992192605, 0.916302008823098, 0.9051176082752196, 0.9425214627914835, 0.9187754823591446, 0.9098122803487878, 0.9008891028767034, 0.9242553738537258, 0.9355769011855577, 0.9033564881753782, 0.9131409625035514, 0.9184508899085122, 0.9243421834694894, 0.9271088809512901, 0.9206668130418018, 0.9080207752677023, 0.925383687935889, 0.9037459293677859, 0.8941042602737675, 0.9450086211228961, 0.8911504352877087, 0.9332908669841324, 0.902148285419947, 0.914177302673829, 0.9017534326503408, 0.9193800752277295, 0.9297482690638226, 0.9219559473793408, 0.9119386210617942, 0.921664238190411, 0.9647358222177489, 0.9092894272763371, 0.8510675886671497, 0.8622780698726186, 0.8981963326226573, 0.8789038969364471, 0.919522081239124, 0.9401118070576219, 0.9142260005839169, 0.9289468194062627, 0.8722786802330112, 0.931676688951395, 0.9124658602572342, 0.8981422787801517, 0.9085229818039711, 0.9033466971550385, 0.9340566775473623, 0.9032962201205776, 0.9207484220682728, 0.930263792212579, 0.9564581554968921, 0.907193874826425], [0.9237278089619533, 0.8841169455928954, 0.9260582659764415, 0.9254816014761339, 0.8885240405430248, 0.9062509744555568, 0.9086386548959138, 0.8709425540629929, 0.9014284608787002, 0.8966869462917103, 0.9174891519798221, 0.9001349178465574, 0.8820188225754066, 0.8867340361536508, 0.879623838051824, 0.9187436371936908, 0.9300678237777106, 0.9457816373637793, 0.9009830730731547, 0.9105436130303394, 0.9117335569900953, 0.9363947885865063, 0.9058102909094505, 0.9999999999999993, 0.8962059683835399, 0.9251993050140165, 0.919765332358633, 0.8619707800646281, 0.9320031107517708, 0.9011926687221206, 0.9282063232910966, 0.8995566715482805, 0.9038797662785689, 0.8988596720079228, 0.8736744041744505, 0.8856455824577567, 0.8910237191411949, 0.8503334768960376, 0.8655896601117862, 0.8841408486398985, 0.9386561726928266, 0.9217459241009724, 0.9328235972527472, 0.8899408838000606, 0.862210312487514, 0.9080504890632328, 0.9074045552611585, 0.8952287369471678, 0.8744710619933638, 0.9097352662470293, 0.8979962569361422, 0.9009772965319055, 0.9243093261582916, 0.944199591750135, 0.9033977490901505, 0.8809995753131884, 0.9395177602428179, 0.9130115576847859, 0.9263144203018222, 0.9269627423430927, 0.9310326673690321, 0.928146716610359, 0.9646849589052664, 0.8961011384668659, 0.89258337266078, 0.9424688815395528, 0.9184914857662857, 0.8977558138531959, 0.9206518507556123, 0.8982237326892787, 0.877431234443751, 0.9076628405502287, 0.894675097145637, 0.8616281461836292, 0.843891536666195, 0.9274087288712423, 0.9225176344110589, 0.9074519153096974, 0.9270945356641259, 0.9155505574768709, 0.9120214460483744, 0.9038491461346017, 0.8933989090257113, 0.907279503885409, 0.9265307680438899, 0.8737204729893115, 0.8618721411138439, 0.8859358890790856, 0.9252038281657644, 0.9384904194397669, 0.8920531566761467, 0.9490034276069972, 0.8886636244361796, 0.880162122438437, 0.9030624692003814, 0.8992883775138223, 0.9044974819535229, 0.9187968878370533, 0.9001020405172466, 0.864695645659703, 0.9307604110310268, 0.8901835008428343, 0.9143035822771391, 0.9032673505245113, 0.8839824113613535, 0.9106637698771123, 0.9181024923536143, 0.9111753744629735, 0.898470177787373, 0.9159070604752843, 0.9025738866875166, 0.9158277864228854, 0.8994119243688649, 0.7936407403206939, 0.8844378145140528, 0.8790034590563983, 0.8768599448709424, 0.9229975381445501, 0.9115669362399701, 0.8971920514273763, 0.8902418834314105, 0.8546766349334671, 0.9156588379904052, 0.9158671697819598, 0.9247480242986112, 0.9186558243074775, 0.8476962652780831, 0.8843534716150719, 0.8951809354115223, 0.9296506763945986, 0.8746535910624593, 0.8896653340406975, 0.8299027825825585], [0.936112765703171, 0.913320995801211, 0.8986543877527858, 0.9281566112978809, 0.8894175602148261, 0.9121896364292283, 0.9252971838253051, 0.8687498953257863, 0.8815374379352772, 0.9039028722688353, 0.9311880765806104, 0.8997556583245117, 0.8684006272338394, 0.8698096102866218, 0.9233804454897786, 0.8910921466047008, 0.9127425669650475, 0.8950249859854772, 0.865729407094934, 0.897936506724314, 0.9147797552463863, 0.9008332459765982, 0.9011246678375805, 0.8962059683835399, 1.0000000000000002, 0.923692153036558, 0.9420869518766419, 0.875351809855548, 0.9466542668532203, 0.8974458711566798, 0.9031251360859088, 0.9132238856621485, 0.9150204395567277, 0.9034120494410718, 0.8849510112379024, 0.852609991320501, 0.8752856671939417, 0.8904014050440788, 0.9523943726239008, 0.9035278230327372, 0.9317163946911853, 0.9211404646651042, 0.9176488902525095, 0.9003691541122273, 0.8624664207130491, 0.9138144480504568, 0.8855201447547838, 0.9138508033614496, 0.8653453656666703, 0.8929643140809598, 0.8596654288162711, 0.8986837572170145, 0.8823858596895514, 0.9152363484265318, 0.9129520167018057, 0.8904987146639411, 0.9314697887211509, 0.9160858973450773, 0.933683533449034, 0.9459401341617715, 0.9287312900006591, 0.9185869223512604, 0.9230157373243091, 0.9083473834694905, 0.9121755499522225, 0.9196738734536223, 0.9270331193355502, 0.9149244065178211, 0.8998036387572856, 0.9192447012242434, 0.8577032356285523, 0.9074747929376539, 0.8993736745302372, 0.8570503273869794, 0.8454698795247559, 0.9168502246462157, 0.9203628878999549, 0.967042142843438, 0.9222709494100882, 0.8790402296798958, 0.9387714068840888, 0.9053142791253244, 0.9229233115954281, 0.9063615622492783, 0.9252291077729508, 0.9176477675846416, 0.8794456758346939, 0.8652074361377862, 0.9188002838467252, 0.9371754763610691, 0.9459916892931819, 0.9231287108709503, 0.8924013521845773, 0.8954121048502421, 0.8970601382207071, 0.9299836653421993, 0.8942862262629071, 0.92654376576953, 0.8969778826030731, 0.8806983323328057, 0.924668218116771, 0.9260336713650006, 0.9335639138604905, 0.9307267071822631, 0.8924503710376177, 0.9186934937962917, 0.9115745464129622, 0.8800922319840312, 0.9246384185693893, 0.9088917084849829, 0.8980364298603178, 0.9021638637240208, 0.9211280864190925, 0.790654185045009, 0.874779096091237, 0.8738693383327276, 0.8716451945653672, 0.9315396926614427, 0.9511102830805114, 0.8906791990396532, 0.9394169178200662, 0.8322054100234346, 0.9263959268983196, 0.8968861725453253, 0.8854315442990915, 0.8918854786671506, 0.8489259559036386, 0.895720885124996, 0.9369961691878583, 0.9553620174311468, 0.880469950176404, 0.8967284034074108, 0.8501731565661532], [0.9543320017890107, 0.9149422010854084, 0.9255153964576506, 0.9519649379805358, 0.9246520874359699, 0.9498608761421548, 0.9581614318947391, 0.9014049946462781, 0.9260005744826196, 0.9392849765631148, 0.9598176853866514, 0.9288252933798093, 0.8979263482064451, 0.8830286583912492, 0.8968276469948451, 0.9289420493248085, 0.9399913120763383, 0.9205153682679157, 0.9016911418006105, 0.9751383250599408, 0.9374953756773801, 0.9516344103203297, 0.9403115488170259, 0.9251993050140165, 0.923692153036558, 0.9999999999999999, 0.9523278231658653, 0.9283511509312721, 0.9472561654920305, 0.9309711351419464, 0.9618838939277443, 0.923696909099759, 0.9290200978260916, 0.9459572539742223, 0.8870103651175983, 0.9121796030592633, 0.9057704514047119, 0.8931607989373177, 0.904298159613563, 0.9104436531208292, 0.9695742052805638, 0.9563159449641776, 0.930828248813232, 0.9043708917878641, 0.8791771033158926, 0.9522721529247394, 0.9369038327108995, 0.9330321585354733, 0.8732174321841776, 0.9140567519638405, 0.9133917683325044, 0.9519731933736746, 0.9275665781207987, 0.9503909913191425, 0.9477614439119966, 0.8921680290614894, 0.9610083655503439, 0.9399978253173465, 0.9455819220785642, 0.9434084124401325, 0.9489317987199241, 0.9466674060957827, 0.9446281969234195, 0.9556438014539507, 0.9210976940312204, 0.9461890872385017, 0.9491159475264435, 0.9309139303550893, 0.9329772784340414, 0.9169538722149961, 0.8773585906825863, 0.9268216547385811, 0.9234471370655709, 0.8760187719993725, 0.876943173701818, 0.9361084678996845, 0.9435946146819434, 0.9430451826159714, 0.9531415735894296, 0.9416156323065189, 0.9510020026342161, 0.9376288109091755, 0.9259100556415379, 0.9392870378994251, 0.93236306098384, 0.9027141300337562, 0.9176521220058012, 0.8937797643794266, 0.9636326166192464, 0.9531952161076678, 0.927198008215132, 0.9421756928541366, 0.9221541183722877, 0.91476483006955, 0.9158854555473572, 0.9247104881807745, 0.9234932274820871, 0.9593209173567985, 0.8977201923573597, 0.8647186324775946, 0.9404253357246701, 0.9458104860726966, 0.930524156226501, 0.9470194633229974, 0.9263988383383714, 0.9434834562566772, 0.9365827381689684, 0.928565674450725, 0.9198474878309415, 0.956026471640289, 0.9061769388116157, 0.9412225912881997, 0.9289480945531043, 0.7949148417189984, 0.9061805761692449, 0.9242965751424349, 0.9076949504115982, 0.9331471824902363, 0.9431137481390437, 0.9061187078438331, 0.919674644396321, 0.8692434561710058, 0.9622125481002215, 0.930165309015667, 0.9203815777597364, 0.9118327228709211, 0.9142429449685958, 0.9271068699797254, 0.9450051363561423, 0.9463917611486562, 0.899345026164091, 0.9098415996329655, 0.8814807683092376], [0.9585674527856953, 0.9399245767814448, 0.9287316912911776, 0.9453835498411415, 0.9173571864148004, 0.9316058585142764, 0.9332346469318484, 0.9115732834897828, 0.8943375257725764, 0.9437653489562088, 0.9452350867152433, 0.932632046716894, 0.9069582650159633, 0.8917704232917787, 0.8836253396400163, 0.9196048485356954, 0.9563278266188581, 0.909505045583272, 0.8786774277549988, 0.929684709256704, 0.9601681432595705, 0.9438259861751352, 0.9361971281994709, 0.919765332358633, 0.9420869518766419, 0.9523278231658653, 0.9999999999999997, 0.9013700914762646, 0.9471500956364458, 0.9358339894763291, 0.9440379767853324, 0.9288949622245005, 0.944097972113852, 0.9324891097738873, 0.9006023429375523, 0.8937226322715326, 0.9089666677119321, 0.9011947763065897, 0.8915226220456592, 0.9454293650687712, 0.9364685966964046, 0.9518372188597144, 0.9463540303601261, 0.8978556404118445, 0.8842224231834694, 0.9341304768894225, 0.9110728144411839, 0.939758319897979, 0.8638968776486009, 0.9233002608410721, 0.8914394060409923, 0.9246927585374458, 0.9074372366608211, 0.9505701428946485, 0.9626370358747719, 0.9013264438498867, 0.9620043643759401, 0.9309104230735664, 0.9457932315434795, 0.9350077630126913, 0.9294458828692861, 0.9393317954971225, 0.9553903366400469, 0.9314023504401279, 0.937810970808197, 0.9151905750449589, 0.9587862779786276, 0.937104202121831, 0.92957920284393, 0.9067422045795377, 0.8926544722822338, 0.9190598858062414, 0.9121556032020528, 0.8978191396653981, 0.869600472972019, 0.9443890787356195, 0.9441024424843988, 0.9290873618398253, 0.9548399661565834, 0.9215444344743635, 0.9300217460882264, 0.92016303065947, 0.9307681563879269, 0.9446615982073687, 0.9520333499559532, 0.8982370553544485, 0.9087249998399778, 0.8887528564419289, 0.9486375029519817, 0.9484117140470589, 0.9169971565248742, 0.9458296572533447, 0.919742885579518, 0.9204922020207715, 0.9344251688957027, 0.9512539880976538, 0.94042425987753, 0.9544413396182032, 0.913363228074018, 0.9003524574067756, 0.9472403635128814, 0.918717025070845, 0.968145469930009, 0.9172159326672579, 0.906348720452729, 0.9297472315004438, 0.9377079420997037, 0.9304853271514085, 0.9553541686112028, 0.9539610887079709, 0.8953802467860158, 0.9287953479867527, 0.9354881839826531, 0.8300065862687374, 0.8833515220509474, 0.9139960186805526, 0.9012295017646355, 0.953849933985702, 0.9381196886330829, 0.9075773970206171, 0.911329925874475, 0.8788363204472486, 0.9541844998667044, 0.9175818864092007, 0.9136721490526682, 0.9188725687980023, 0.8902185821674199, 0.9314413621091854, 0.9148707979788935, 0.9354919415630447, 0.9112060470276189, 0.9269071015350967, 0.8916300678726136], [0.9019475703680995, 0.8784784281219675, 0.8601236162494383, 0.8830265915169744, 0.8685098591516168, 0.8878760671777722, 0.9129545037351613, 0.850181204217274, 0.898440959294833, 0.8850557759597587, 0.8900699181615543, 0.8683624861601218, 0.8642599395210924, 0.8292449063589734, 0.844797355879646, 0.8948137621608128, 0.8703574900033737, 0.8626434670101925, 0.8673405920539616, 0.9238344644961568, 0.8849072510612477, 0.8992252180049035, 0.8895342556818229, 0.8619707800646281, 0.875351809855548, 0.9283511509312721, 0.9013700914762646, 0.9999999999999999, 0.9073409541650937, 0.906279409401994, 0.9233598297623502, 0.8778282100589059, 0.8661028061104876, 0.908044921445222, 0.8333381316311907, 0.9205975593176083, 0.8369546328459678, 0.835193187067089, 0.8643955949124241, 0.8818722730598078, 0.9135986538715822, 0.9084942437688159, 0.8776819922220193, 0.8793537248339147, 0.8411737092618522, 0.887324788956873, 0.9183097672926096, 0.9097639833229921, 0.8362805643857129, 0.8609241633984455, 0.8845031482927642, 0.9239587812793554, 0.8716494472121574, 0.8956822387341224, 0.9149176323411381, 0.8663766806767581, 0.9140992026450059, 0.8854397291656266, 0.8946640844952625, 0.8950087537436974, 0.9070827587146003, 0.9156132252821173, 0.8965828759070454, 0.895367969014268, 0.8674940656609975, 0.904357739088954, 0.9014419398591677, 0.8895876815446275, 0.8746891251023183, 0.8733895342071469, 0.816137051863945, 0.8847642831147309, 0.8986338020054341, 0.8343179656496917, 0.8301030124038145, 0.8915622475738233, 0.8944760420210451, 0.8933691516314883, 0.8955858746679848, 0.9024322719772333, 0.9089626776568794, 0.9105630380631156, 0.8897399562518249, 0.8893941585910223, 0.8934423549328399, 0.8551017745505142, 0.8755676491575333, 0.8402960146453118, 0.9232661520711313, 0.8987436549922161, 0.8988519416468375, 0.9007005573783091, 0.8527172599981309, 0.8668351968781663, 0.8611148988396586, 0.8697864923213966, 0.8761228708892184, 0.9006670518764816, 0.8403392778422137, 0.8282453772988807, 0.8909939071160948, 0.8831535456458833, 0.8828716281261672, 0.8888788330548658, 0.9361332259942954, 0.8934805455132968, 0.8780342525909897, 0.8729274965976344, 0.8690697496924908, 0.8781850287472741, 0.8443996663660881, 0.9051185880840553, 0.8851559236197981, 0.7537216880280805, 0.8931060565934625, 0.890387430071749, 0.8872113221454222, 0.8709966858253011, 0.8902750978686007, 0.8450559150923493, 0.8797147823640553, 0.8361456289975974, 0.91907598399423, 0.8970298199961482, 0.8692021024406427, 0.8552927848328937, 0.8731269357713536, 0.901788111456075, 0.889631008284122, 0.8779483577154066, 0.8764229270829872, 0.87379691261808, 0.8511510219267399], [0.9593329710747053, 0.9084079956301656, 0.9203143148700239, 0.9408035547865405, 0.9241793679738346, 0.9218058230778124, 0.9333890762163558, 0.8950877823754367, 0.91345945623257, 0.9310137692060133, 0.9389524842476765, 0.9096234815487352, 0.8938361703256799, 0.896145992845986, 0.9031707872999767, 0.9436847353033593, 0.9357859578438372, 0.9167935418099927, 0.912578929502314, 0.9202221509914665, 0.9399992365855737, 0.9344993592035462, 0.9488511594512923, 0.9320031107517708, 0.9466542668532203, 0.9472561654920305, 0.9471500956364458, 0.9073409541650937, 0.9999999999999989, 0.9122260678542666, 0.9353797983766712, 0.9240567757818215, 0.9184614671422404, 0.9228802019419254, 0.8801092417281767, 0.8907782276487464, 0.8954277849346601, 0.9151395011221637, 0.9239348006276894, 0.9284407386759737, 0.9536228450793074, 0.949498201957409, 0.9426064133915089, 0.9252162285282179, 0.88354931003007, 0.9291522584233658, 0.9222942634454587, 0.9487110107850688, 0.9079929665384633, 0.9186242209216446, 0.9190431566540384, 0.9286080427080147, 0.916941849276331, 0.948292071478972, 0.9284183487080896, 0.9177142555205143, 0.9463473061817379, 0.9478802173709355, 0.9412866728011889, 0.9538556141560338, 0.9587385103523385, 0.941949739745367, 0.9557517241226493, 0.9145577636274338, 0.9204449567872313, 0.9551481174825598, 0.942594457143235, 0.9406451052727035, 0.9295958241179451, 0.9161174309618907, 0.8881352758392276, 0.9296801589157503, 0.9167718786463439, 0.8684562572755481, 0.8981736926861931, 0.9350078948234213, 0.9542285774119607, 0.9483553323147428, 0.9382590166981416, 0.9114659505131111, 0.9539745375048535, 0.9263611297528369, 0.9537368888479509, 0.919302253706393, 0.953400551837604, 0.9171401976357777, 0.9096000280424784, 0.8987347700156276, 0.9337041283616565, 0.9564923778482278, 0.9618078208009944, 0.9342977232321737, 0.9303050722016912, 0.9083895116871153, 0.9303394985982967, 0.9297688462068006, 0.9111711112118597, 0.9362926756124303, 0.9104442312051724, 0.9082449946386242, 0.9539950830387383, 0.9180234385139808, 0.9375325953645459, 0.9259516380647936, 0.9423455554526682, 0.9289278555843871, 0.9285580892320755, 0.9133199590715713, 0.927850087501453, 0.9241439931267599, 0.9224438314841507, 0.9504087749308396, 0.926121297192039, 0.819723787562731, 0.9049715314295615, 0.9087883906582751, 0.8995970301942863, 0.9337994027428129, 0.9638621505947668, 0.9135547709554876, 0.9471350613914136, 0.8689485300107797, 0.9384927580597601, 0.9216737628124123, 0.9367640396923462, 0.9140689810701677, 0.8772504728882021, 0.9306025581414137, 0.9257926547822631, 0.9554953068903081, 0.926557028956535, 0.9278022751547623, 0.8844533788604105], [0.9279133968863771, 0.9428727149533821, 0.8950449152828073, 0.9184963636749509, 0.8946765641924124, 0.9100848717060831, 0.9169687651595624, 0.8626147186920137, 0.8882736861366394, 0.9137801166377127, 0.9211564360213699, 0.8760069262083449, 0.8626866789009395, 0.8471507513600625, 0.8697987765557454, 0.8969104211396027, 0.9205668239419624, 0.9097161455923057, 0.8605676372691151, 0.9204129468481239, 0.9205756640112808, 0.9248699379756613, 0.9012936140273419, 0.9011926687221206, 0.8974458711566798, 0.9309711351419464, 0.9358339894763291, 0.906279409401994, 0.9122260678542666, 0.9999999999999993, 0.9274449021020452, 0.9169057239216754, 0.9027372491617185, 0.9301044782176402, 0.853119175783313, 0.8763120049223017, 0.8864849439839917, 0.8718564417444128, 0.8687464116738566, 0.9025040584305133, 0.9222039408966429, 0.9288199997388528, 0.9105181477705209, 0.8873235202994835, 0.9269469743237034, 0.9085917199449925, 0.9059134590734953, 0.9269402927345214, 0.8324232004889633, 0.9062228683472608, 0.867186065554676, 0.9112350375948824, 0.8945258703657752, 0.929105000312043, 0.9323757060682332, 0.8676714671605634, 0.9318834658926601, 0.9012438140606511, 0.9220516846906663, 0.8976589831007763, 0.9058590597339973, 0.9349749265526105, 0.9276350949739106, 0.9051259474251663, 0.9006489400299631, 0.9131114166147206, 0.9210521124316352, 0.9040109849141117, 0.8934344212334173, 0.8962349268896779, 0.8557010161630421, 0.8931545645124114, 0.8959309130947904, 0.8540728624147444, 0.8482226124937913, 0.9150133272477381, 0.9459148822454325, 0.9041148927322677, 0.9338325504853154, 0.9221189607740305, 0.9057623559563721, 0.9224558549822891, 0.8957251455945656, 0.9161873528985272, 0.9117192926568525, 0.8671168625430336, 0.8802629661325791, 0.8778204769397084, 0.9421659416427002, 0.9251851550769632, 0.8920966811404147, 0.9456349942360761, 0.8764417796172984, 0.8910660460530779, 0.9086748604696026, 0.9163338873960906, 0.894884694644549, 0.9346964856489283, 0.8874799628612173, 0.8498633523521253, 0.9075455724720957, 0.891094637282817, 0.9279050206137147, 0.8965763256679299, 0.8967958535093575, 0.9143693961412713, 0.9073979316584336, 0.888451698276231, 0.9230071269909388, 0.9271012950334476, 0.8671418897971347, 0.90747459299093, 0.911571659504628, 0.7648355792366754, 0.890784804955788, 0.9088154430613469, 0.9311648493263569, 0.9170065586952578, 0.9088534095828819, 0.8936017401015764, 0.8936641252198805, 0.8419474505646727, 0.9432577557760548, 0.916882698743986, 0.8935013750163067, 0.8930464025324578, 0.8612098043444766, 0.9135366916234655, 0.8889264894747546, 0.8996142299362869, 0.8726045467333952, 0.8925198509275373, 0.857808252959061], [0.9434354844051134, 0.9189541715392693, 0.9268490033351449, 0.9339387730588702, 0.917454869681755, 0.9152256320697947, 0.9539841894146431, 0.8821952930987654, 0.9350435369322527, 0.9287373991578257, 0.9391291769945255, 0.9273812656429516, 0.9184643780941882, 0.8753621597381556, 0.8736514785811035, 0.9343778597944559, 0.9508127408528317, 0.9124561038957456, 0.9046092095677043, 0.9694040086179186, 0.9340235736021659, 0.9734547268235179, 0.9202642918621617, 0.9282063232910966, 0.9031251360859088, 0.9618838939277443, 0.9440379767853324, 0.9233598297623502, 0.9353797983766712, 0.9274449021020452, 0.9999999999999998, 0.912208612444853, 0.9255465055339402, 0.9346531926537757, 0.881613116404243, 0.9279876651772001, 0.8851199706641466, 0.8792661966124042, 0.8863266993112902, 0.9059614807515001, 0.9502069004731228, 0.946774040715879, 0.936785239164071, 0.8950247268170768, 0.8660732209801367, 0.9217654087908205, 0.9435429556159832, 0.9232067158918358, 0.8547736883732909, 0.9251485501895857, 0.9038168950145621, 0.9402483108150194, 0.9431965412819804, 0.9501162143048896, 0.9327221838552112, 0.8965307929531605, 0.9494925476149259, 0.9409676860316707, 0.9309263872322335, 0.9246659305478161, 0.9370180283341287, 0.9491170393667221, 0.945072716547255, 0.9432266816363633, 0.9218478423585935, 0.9395636765962392, 0.9403764950216953, 0.9167187913504103, 0.919202093368805, 0.9048460017626663, 0.8755305945560827, 0.9193032567959694, 0.9327516341890448, 0.8659109004845776, 0.875859956426695, 0.9283485767441484, 0.934422506143805, 0.918700248070289, 0.9337108130962366, 0.9659569034010974, 0.9351987746087851, 0.9432319835674703, 0.9170648721099599, 0.9410257433274858, 0.9306463461661909, 0.8766568631715663, 0.9022442393346957, 0.8863448414360028, 0.9559480379405956, 0.9358484703584797, 0.9086456823397416, 0.9530331992202826, 0.8986638292130086, 0.9054030277571412, 0.911983276926555, 0.917268869027271, 0.9255046261620495, 0.9490645123980188, 0.875709948757103, 0.8426850120042564, 0.9261665893641039, 0.9426442615862117, 0.9296493374711008, 0.9262360540058707, 0.9328806009514812, 0.9357912950947085, 0.9446584834039851, 0.9290588426950601, 0.9005277555490367, 0.9565875818497356, 0.8859351165699079, 0.9255107293952721, 0.9266741155257987, 0.7999666313243335, 0.9223842991261565, 0.9272346824526853, 0.9066863325871023, 0.93906858041369, 0.9260306592118468, 0.8878661240091794, 0.9021765047875806, 0.8739453719010404, 0.944660285247537, 0.9403025040718878, 0.933794544006504, 0.9140478649204143, 0.8817404301932749, 0.9256182404740825, 0.9236931895007566, 0.9308113761542316, 0.8830521472538503, 0.9000379667764064, 0.8676027918688743], [0.9402723341331245, 0.8994312112240137, 0.9016134599462573, 0.9208596690625911, 0.9403252326555029, 0.8937325826760371, 0.90370370269224, 0.8944629895263639, 0.8923259206206249, 0.9193522126329353, 0.9107086741820447, 0.875296360161213, 0.8622308910686795, 0.8810281195540031, 0.8798341564176562, 0.8858630200073969, 0.9325555897635273, 0.9014139899778008, 0.860736133267045, 0.9052421249944751, 0.9289308545027004, 0.9103683932671828, 0.9174306081477019, 0.8995566715482805, 0.9132238856621485, 0.923696909099759, 0.9288949622245005, 0.8778282100589059, 0.9240567757818215, 0.9169057239216754, 0.912208612444853, 1.0000000000000009, 0.9126855371086624, 0.9195887728014168, 0.8613228082670841, 0.8692727293578599, 0.9337068231626778, 0.8868170967140643, 0.8657252192858308, 0.9240587734210717, 0.9218392160591454, 0.9359289990344696, 0.9243237871163368, 0.9110386065230573, 0.8896609323985144, 0.9185377115862805, 0.9014624170683857, 0.934440323632888, 0.8496114198262957, 0.9098648767681757, 0.8735956729779392, 0.9074293681140662, 0.8848314332866083, 0.9511895557753507, 0.9206565758975511, 0.8731663091745356, 0.9320976497485355, 0.915877922881368, 0.9292482579828121, 0.9068346843622144, 0.9147947293052816, 0.9241917504330426, 0.9450502090778743, 0.9096901771393577, 0.8841868018879605, 0.9141812861050127, 0.9250012240201004, 0.9163733622467669, 0.8979256366779046, 0.9072390503321355, 0.8848327340639475, 0.8866502725765766, 0.8907558902021216, 0.8634517884584857, 0.8697344124133726, 0.9345147956426104, 0.9330273080336979, 0.9220883615724408, 0.9222061736764174, 0.8996433605358616, 0.9046151157230496, 0.9092298820031073, 0.9059449001136518, 0.9072069802957524, 0.9219862877246806, 0.9024161539214688, 0.8856737023503394, 0.9176555321777093, 0.9136901526653947, 0.9265559341977461, 0.8973409154495611, 0.9172871079644236, 0.8826212126311695, 0.889541767781602, 0.9090349261134909, 0.9092696891054511, 0.8791013111429686, 0.9308587222903706, 0.8893969105191384, 0.868402914275521, 0.9159127912638524, 0.8994895446842064, 0.9270765354642543, 0.8916140442275674, 0.899344195421215, 0.8944263604305251, 0.9120462265555298, 0.892658397157414, 0.9217871648882155, 0.9049147949673195, 0.8848057715516446, 0.9115216476357386, 0.9157850899031761, 0.7826814433734361, 0.86247247925617, 0.8722138747369736, 0.898131929788728, 0.9004915316085566, 0.9406834270574599, 0.9067781981077997, 0.9096836956091119, 0.8331398374444521, 0.9350158171674038, 0.8913355737128874, 0.9044325008648489, 0.9078243462515774, 0.8698087266494126, 0.9140143077553323, 0.886093976135064, 0.9144541578474598, 0.8919945679973755, 0.906718058324276, 0.8504739982165173], [0.9184564777386186, 0.9139379748100553, 0.9032557258839176, 0.9380466492346714, 0.8993542818339142, 0.893452838006427, 0.9058085261127015, 0.8707252801571814, 0.9083732972978248, 0.9038877349970361, 0.9390656361453379, 0.9021592258486164, 0.8928251586863715, 0.8706085927831827, 0.8698206427218454, 0.8763338429663041, 0.9300846609244549, 0.8997581903439476, 0.8667231164098198, 0.9165802530360014, 0.9233260162622733, 0.9114230569651199, 0.9050194832273567, 0.9038797662785689, 0.9150204395567277, 0.9290200978260916, 0.944097972113852, 0.8661028061104876, 0.9184614671422404, 0.9027372491617185, 0.9255465055339402, 0.9126855371086624, 0.9999999999999993, 0.9040145954999521, 0.8964458982410234, 0.882889452472994, 0.9069818910368521, 0.8750536250913895, 0.8983292269098928, 0.8883339356041803, 0.9254701427213707, 0.9150875971330317, 0.9215436929042139, 0.890742994606555, 0.8521186979798736, 0.9055627325320765, 0.894895991842148, 0.9060088841445312, 0.8259283053203698, 0.9000088421295012, 0.8560375299889738, 0.8953514193487819, 0.8950913291577297, 0.93462801314567, 0.9316883432567344, 0.8938463338856033, 0.9273898199702374, 0.9104320010426309, 0.9226903360495091, 0.916201887221806, 0.9161251843305639, 0.9153076089401393, 0.923120183412013, 0.9127286541873777, 0.9073109643313906, 0.8999552293123869, 0.9190865494907163, 0.9141658216418793, 0.9085891969034205, 0.9143715393131114, 0.8765929363846302, 0.8827137404194161, 0.9115370709583517, 0.874172377332531, 0.8283626941766316, 0.9113126227756349, 0.9166516124479963, 0.9101144152903665, 0.9213275657474376, 0.9036711282086504, 0.9266397923825596, 0.898637512613059, 0.9283915187457517, 0.9235911046299139, 0.9244713469631191, 0.8907689716755545, 0.8804274074376282, 0.8761182296240806, 0.9306374422831054, 0.9059609248727511, 0.9029142905889427, 0.9159852101976823, 0.895192722771971, 0.8930337196682969, 0.9003062961222678, 0.9194202436665834, 0.8991776176669619, 0.9285697848858718, 0.8815812938800762, 0.8628428483857411, 0.9119108478081203, 0.9229852411112585, 0.9448854871156673, 0.9099966729220886, 0.8808785549485016, 0.8940517186962436, 0.9078415148960135, 0.8909652350143726, 0.9249116327662893, 0.9297707703794347, 0.8849056585654679, 0.8958917542162744, 0.9002034213465646, 0.7998066494482131, 0.8795262747547729, 0.8773828450315662, 0.8578215237161911, 0.9285027738581724, 0.9184355389464529, 0.8897260380842507, 0.9069737355939997, 0.8456808000890693, 0.9162618138602547, 0.9022249329213176, 0.889803113292892, 0.9085029727202161, 0.8590308119763478, 0.8986361529021138, 0.8954792661385528, 0.9245327470468314, 0.8754945880961134, 0.9066366213730073, 0.8740065644884085], [0.9260323102790213, 0.9057996391044366, 0.8973505758245847, 0.9201551297478203, 0.8967747533113408, 0.9099559818922063, 0.9250633383593984, 0.897344672615859, 0.938448567550768, 0.9206306818261097, 0.9217651922918155, 0.8961796741244853, 0.8772604877647454, 0.8783399572840177, 0.8717904119505963, 0.9034535212532497, 0.9184173164635528, 0.9177803821009516, 0.8742529433338591, 0.9507010473678688, 0.9187604974104582, 0.9277342172871952, 0.9090726788517608, 0.8988596720079228, 0.9034120494410718, 0.9459572539742223, 0.9324891097738873, 0.908044921445222, 0.9228802019419254, 0.9301044782176402, 0.9346531926537757, 0.9195887728014168, 0.9040145954999521, 1.0000000000000002, 0.8601066230900578, 0.9074010233657154, 0.8885381010013633, 0.8662985790329436, 0.8857015747002799, 0.8982776307024136, 0.9438247156429486, 0.9430669505034395, 0.9166257973394009, 0.9004658929140823, 0.881470346449569, 0.9300829943277663, 0.913167041655125, 0.9142278652746987, 0.8497641823392417, 0.8952028414341635, 0.884455475079079, 0.9264865665192972, 0.9080290761141676, 0.9287457887581172, 0.9290641139507247, 0.8922554306002435, 0.9456967441854623, 0.914403609759903, 0.9120274261677641, 0.9192686705212415, 0.9255852577936912, 0.9353207230387409, 0.9334813302053466, 0.9162731366446125, 0.882025292987711, 0.9295342622733382, 0.9227398614225502, 0.9073372315050935, 0.9127406865719963, 0.908053591238446, 0.8567439061373834, 0.9132455598166436, 0.9391676167378009, 0.8737304567865614, 0.8621572994304907, 0.9343434796843675, 0.9298627501200025, 0.9199635570273669, 0.9195777400920919, 0.9176093754526087, 0.9255493756620546, 0.9269765344086924, 0.891472706460572, 0.9189475345802045, 0.9231912362127631, 0.8855034490688025, 0.9109815103197438, 0.8751878353485311, 0.9548721120036345, 0.931055287873369, 0.9057033032949111, 0.9266623641011037, 0.8836707689482723, 0.8999942472716534, 0.9077937400324879, 0.9007422845733796, 0.9107688180796492, 0.93232249804104, 0.8829924378107573, 0.8621012022607765, 0.9144390691371478, 0.9235770083524415, 0.916829212095738, 0.9067124591826398, 0.9084406932691295, 0.9242404634738549, 0.9045659403792052, 0.900433816791809, 0.9179427991992744, 0.9192620735907399, 0.8878714048128922, 0.9230356941807236, 0.9285244677862594, 0.7789756218514566, 0.8868851282251149, 0.8881239770904611, 0.9063620711180808, 0.9030979143445118, 0.9115378793670252, 0.892594076923761, 0.899285947110654, 0.8644171997660817, 0.9424788060625898, 0.9295205212081515, 0.9021669027223215, 0.8978331005228539, 0.876704507567091, 0.9200464157478042, 0.9105976277229075, 0.9123445438140434, 0.877035982580338, 0.8975366702386154, 0.866961817753173], [0.9019066129095427, 0.8742193605985853, 0.9276854605040081, 0.8999147542445671, 0.8876674430493515, 0.8862191758848199, 0.8527483274869114, 0.8712337940652178, 0.841096483141973, 0.8809795671429734, 0.879838707604951, 0.8497565019006308, 0.875052822964676, 0.8699662709037453, 0.8236612709459912, 0.8705348293129421, 0.8928292639805642, 0.8635792174825915, 0.8224079342940451, 0.8670318273546304, 0.886499226532848, 0.8806540572006687, 0.8883998957198677, 0.8736744041744505, 0.8849510112379024, 0.8870103651175983, 0.9006023429375523, 0.8333381316311907, 0.8801092417281767, 0.853119175783313, 0.881613116404243, 0.8613228082670841, 0.8964458982410234, 0.8601066230900578, 1.0000000000000007, 0.8533197356844189, 0.8571081825082917, 0.8597959211815224, 0.8461264169799073, 0.884967678296104, 0.8722826240100806, 0.9079318488269872, 0.8953688710825967, 0.9015433570710046, 0.8349043227167677, 0.876670716175622, 0.8391247088281846, 0.8689579504013314, 0.7907857117851755, 0.8708993288192446, 0.8655046699826446, 0.8548855236391066, 0.8791398260951819, 0.8987161963873556, 0.9144456500379619, 0.8839101890258568, 0.9024246147414692, 0.9291182144179274, 0.9215815002065352, 0.8681016985183726, 0.8779941053282333, 0.8810935216102569, 0.8906896070138525, 0.8599825504919927, 0.8555604604874696, 0.8665904939939109, 0.8972515423663043, 0.9285522273427889, 0.9078598263934512, 0.8872237105693104, 0.90933304998827, 0.8333903775790041, 0.860082224205966, 0.9035559195321101, 0.8392646978943139, 0.8801131027976095, 0.8953475032729197, 0.8702728590190466, 0.8832814374667801, 0.8533494695171798, 0.8716522203122051, 0.8629487802679795, 0.8629938625636746, 0.87650676591114, 0.9092379678714608, 0.911726737448102, 0.8719211369486572, 0.8707746388371409, 0.8730183236541379, 0.8783293476001528, 0.842251723787413, 0.883811812799995, 0.8746123321209183, 0.9149257386282811, 0.8921863045900954, 0.8790801444592105, 0.8710403237318542, 0.8891313498233242, 0.8902655356248224, 0.8290242001251371, 0.9034373617224568, 0.8589415124216077, 0.8801564188693333, 0.8582821697814746, 0.8532982742980967, 0.8598985133074295, 0.880938550727663, 0.8688400783696907, 0.8902873955036488, 0.8851510050449123, 0.8685137912346007, 0.8891058594049773, 0.8597714037975952, 0.8676478703463386, 0.8406546351888762, 0.8670551047629829, 0.8287878102075452, 0.8784487165146455, 0.8953151183472181, 0.873748788188706, 0.888517288964294, 0.8466347360405488, 0.8778828595196038, 0.8531735680586106, 0.8737111921808745, 0.913524165805632, 0.833721619876443, 0.8510545512545893, 0.8510365701921838, 0.8909707062580421, 0.8812583607689745, 0.9160169550314559, 0.8477254056687287], [0.895530330184293, 0.8691607631171009, 0.8788426655508752, 0.9131425664646018, 0.8727206041356707, 0.8705980289056383, 0.8926599066905734, 0.8826044926963733, 0.9087556879019254, 0.8675981008407627, 0.8979492431780015, 0.8867810316342204, 0.9176127808999623, 0.8542052428210409, 0.8086969764651285, 0.8944753466918938, 0.8723751319159745, 0.8803371068606587, 0.8709307588564766, 0.923139001284333, 0.8756596981314115, 0.8973078151199911, 0.8869154469272498, 0.8856455824577567, 0.852609991320501, 0.9121796030592633, 0.8937226322715326, 0.9205975593176083, 0.8907782276487464, 0.8763120049223017, 0.9279876651772001, 0.8692727293578599, 0.882889452472994, 0.9074010233657154, 0.8533197356844189, 0.9999999999999996, 0.8452368536373258, 0.8188992421805715, 0.849023547205745, 0.856037022157689, 0.9061880987071532, 0.8936198482984626, 0.8881591982858505, 0.873611737269816, 0.8137048368177897, 0.8887921995324772, 0.922271217534804, 0.8973183151635181, 0.8066202501689196, 0.8488065477545399, 0.8870935652916525, 0.9168510474177759, 0.8882997744158672, 0.897340035428728, 0.9194234521838751, 0.9229502717828699, 0.9079246086733181, 0.8951332454706046, 0.8872293408251273, 0.8860940054948031, 0.9052738125110712, 0.8901613214085313, 0.9019478667291234, 0.8819457028903676, 0.8506228457982741, 0.898153859479745, 0.8787906592469765, 0.906790981601876, 0.9075504885628276, 0.8665365786773509, 0.8535064277072639, 0.8706487655039755, 0.9046099059756997, 0.8845336147765516, 0.8194803525790502, 0.8918457050275991, 0.8821839431354946, 0.8704789271450932, 0.8826334706596863, 0.9066364109383696, 0.9166548764986899, 0.8813320484403202, 0.8661219380415051, 0.9047579237285278, 0.9089968332228515, 0.8706809600354742, 0.8633381729693708, 0.8691563322071747, 0.9235723944687211, 0.8944236953322755, 0.86266662165426, 0.8906512608254222, 0.8531840118848533, 0.8678390717781933, 0.8528524339332252, 0.8540993944265156, 0.8938881112078909, 0.891641785004373, 0.8508512509439854, 0.8224905962814599, 0.894948929317725, 0.8832317676719645, 0.8755665135381778, 0.8737233027218506, 0.9376796833461913, 0.8880709265745155, 0.8760533812882686, 0.86027868397929, 0.8686788931615619, 0.893311808907668, 0.8548885240021135, 0.9094232061556126, 0.8693916304744294, 0.8011588977517496, 0.8868513858545646, 0.8830630407339627, 0.850248440069753, 0.8677665998101874, 0.8806872549040394, 0.8486718293348373, 0.8681712744177875, 0.8969081904429924, 0.8997282509996709, 0.9025619794358395, 0.8910167707338669, 0.9004649743475497, 0.8427599542801802, 0.8693881650212106, 0.87033082018913, 0.878204113405959, 0.8674718089191202, 0.8805329901266541, 0.860281722296231], [0.9049866003282422, 0.8665428560838875, 0.8905786284427492, 0.9077283811139285, 0.915067274140694, 0.8976354836497819, 0.8729664056411597, 0.8660484485264486, 0.8651099838595158, 0.8985249787819451, 0.9087977095440489, 0.8565012701551562, 0.8394367063525062, 0.8671152539784903, 0.8482592456410788, 0.8492802461535854, 0.9021881055820853, 0.8726599275676052, 0.839975551766156, 0.8772518081498276, 0.9190675388260456, 0.8856277392892394, 0.9051833945609823, 0.8910237191411949, 0.8752856671939417, 0.9057704514047119, 0.9089666677119321, 0.8369546328459678, 0.8954277849346601, 0.8864849439839917, 0.8851199706641466, 0.9337068231626778, 0.9069818910368521, 0.8885381010013633, 0.8571081825082917, 0.8452368536373258, 1.0, 0.883007689897742, 0.8450752758020221, 0.8991188008846445, 0.8988970053216037, 0.9121606057466936, 0.9029680069868193, 0.8910971531890022, 0.8675331557183577, 0.930168433923598, 0.8593766284198233, 0.9026794070886065, 0.8136186199596576, 0.8822560209063274, 0.8275460928252361, 0.8820212045339917, 0.858968573453423, 0.9382506069780543, 0.893401715576388, 0.8653260193756128, 0.9076938832415647, 0.901979832161512, 0.92388542427802, 0.8832607771378762, 0.9068369080965801, 0.9012231635923447, 0.9247048784066922, 0.883529208333317, 0.8749837302158733, 0.8924650087970727, 0.9012204342510081, 0.9032971552678538, 0.9127132588336981, 0.8794108796259728, 0.8736042478322273, 0.8563659364408865, 0.8716455585901535, 0.8848276432362138, 0.8479971855289243, 0.9069239620192779, 0.9156371785957084, 0.8859119259732465, 0.90884670265166, 0.877374702659539, 0.9014653231878836, 0.8755978709748684, 0.8900940078470229, 0.9011522263203814, 0.9181302874490287, 0.8898508725489516, 0.8767941759469589, 0.9163553514682659, 0.8871337431148287, 0.8987307017205047, 0.8600679834571452, 0.9030741034906605, 0.901040498601911, 0.8855258803838443, 0.8991366171274331, 0.8949013929015576, 0.8636905813385489, 0.9142521666549837, 0.8883164268421758, 0.8524112332934719, 0.9082096525428704, 0.8588223293839653, 0.9104680678817176, 0.8814083279911802, 0.8692844475743735, 0.870600328568578, 0.9006730620738946, 0.864921920488227, 0.9162497996153607, 0.8922550683248506, 0.8710165394540323, 0.8908609227123392, 0.8837173182270209, 0.783167247161372, 0.8380471518721484, 0.860714068449485, 0.8479879247298212, 0.8944385564387775, 0.9103547425727884, 0.915483452171477, 0.8866581187432487, 0.8316126928263478, 0.8980493762806662, 0.8792399552410988, 0.8661056223549783, 0.9207269680320723, 0.8529390544745763, 0.906230085750208, 0.8590350563399844, 0.908303817941404, 0.8723945659505355, 0.8938627109249007, 0.8648553615345576], [0.9195459961378138, 0.863880951194949, 0.8644640331390495, 0.8996051141145953, 0.8966934420117035, 0.8888013382568007, 0.8771923101736474, 0.845801580036659, 0.8318095940364889, 0.9016632805460988, 0.8967130828075102, 0.8196397724481719, 0.8223675325572146, 0.8415133496975945, 0.8408948775811229, 0.8451629573189612, 0.899910707975897, 0.8451814706839835, 0.8115678257602097, 0.8604579559778707, 0.9154496610521914, 0.8789080112316441, 0.9070443686938187, 0.8503334768960376, 0.8904014050440788, 0.8931607989373177, 0.9011947763065897, 0.835193187067089, 0.9151395011221637, 0.8718564417444128, 0.8792661966124042, 0.8868170967140643, 0.8750536250913895, 0.8662985790329436, 0.8597959211815224, 0.8188992421805715, 0.883007689897742, 1.0, 0.8724184853940498, 0.8973811410071122, 0.8922928278369806, 0.9081310319347172, 0.8893060730332645, 0.8950575320040759, 0.8759139312767191, 0.8851490236672321, 0.8435541582514166, 0.9141530979910806, 0.7980011838145802, 0.8740569421672372, 0.8380633920881839, 0.8718819801673435, 0.8579200171234687, 0.9058272003189696, 0.8829026614520975, 0.8659978455915116, 0.8794674621874903, 0.9369132963362045, 0.8980797428864054, 0.8642479140751819, 0.8868815095570193, 0.8882769062622626, 0.8929813181417586, 0.868222296902113, 0.8822870638917785, 0.8834333938854516, 0.9016786555266127, 0.9030422706800707, 0.8592192121757226, 0.874876623990013, 0.8264776879127192, 0.8446101867266866, 0.8487180280731216, 0.8179916812742434, 0.9198291342597629, 0.877070007935409, 0.9254254033529438, 0.8892527315556904, 0.901458934710311, 0.8576326210921295, 0.9014632432836364, 0.8762504432694568, 0.9063684271748884, 0.884629275338821, 0.8967846711431935, 0.8994464537763283, 0.892210149268984, 0.8763193947190935, 0.8756243909761916, 0.8771834729295049, 0.8877351577852628, 0.8798072430510293, 0.906338455913285, 0.8806479074658523, 0.929217632672126, 0.8990967295129909, 0.8388448184469809, 0.892770266370208, 0.8684282196561361, 0.85328256796754, 0.8822536369617884, 0.8460117594909577, 0.8979368887872317, 0.8749792983577873, 0.8840995770377968, 0.8624154336363142, 0.8906221937097105, 0.8721545270286868, 0.8867777503597852, 0.8841395952436126, 0.877752084388244, 0.8835477719038194, 0.8810989447832204, 0.7659371012784012, 0.8339254342065371, 0.9081000090586573, 0.8571354742882695, 0.8989541471679636, 0.917836823422462, 0.8982418880519935, 0.939755411693745, 0.7863911951398628, 0.8959654598052711, 0.8662322420403255, 0.8469347258238223, 0.8719099465029161, 0.8456877525994763, 0.9178372066295564, 0.8840034537772989, 0.8990035491049093, 0.8991909983196769, 0.8724759679891856, 0.8846361520777299], [0.9050632581514856, 0.8748293245242801, 0.8602450637220601, 0.8972571170984069, 0.8544098317563844, 0.8909702342707526, 0.9063783462816943, 0.8285937685632342, 0.8781399226620906, 0.8812640466481301, 0.9069892379245035, 0.8435621680396059, 0.8364792566970609, 0.8471696924598137, 0.9019732163734429, 0.8428825349928324, 0.878509523975878, 0.8574277538815953, 0.8254796986820248, 0.8891492064316352, 0.8891490335532631, 0.8785992520872, 0.8824472118377251, 0.8655896601117862, 0.9523943726239008, 0.904298159613563, 0.8915226220456592, 0.8643955949124241, 0.9239348006276894, 0.8687464116738566, 0.8863266993112902, 0.8657252192858308, 0.8983292269098928, 0.8857015747002799, 0.8461264169799073, 0.849023547205745, 0.8450752758020221, 0.8724184853940498, 0.9999999999999998, 0.8557215882322184, 0.9055166282390285, 0.8933925042630076, 0.8815241518769213, 0.8944066163579244, 0.8503762512653318, 0.8878518339157313, 0.8657545999227312, 0.897294578493134, 0.8262151491310771, 0.862110767387796, 0.8273680004380697, 0.8888856535028371, 0.8678481483361162, 0.8925233399078647, 0.8803088950686891, 0.8813119056287135, 0.90146291793215, 0.9043889007790745, 0.900900225384589, 0.914425498672736, 0.9097086493382853, 0.8958010753410979, 0.8920190449766245, 0.8873501363615233, 0.889182489981348, 0.8991603584577895, 0.8984262021002349, 0.8993406889235058, 0.8709954289528573, 0.9112319248898586, 0.8118370517107548, 0.8679527233833431, 0.8790433555636644, 0.8187124240700013, 0.8234538427300815, 0.8888988184030625, 0.9040044081416084, 0.9419049838211291, 0.8885738787525591, 0.8705978592912584, 0.9542247545858185, 0.8961975904667674, 0.9146807477526506, 0.8847628241966297, 0.8909854534454693, 0.9186323138625851, 0.8680004643573993, 0.8430861445877499, 0.9063489044311768, 0.8861075174173709, 0.9384304082932162, 0.8867286040341622, 0.8758136768078627, 0.863858143951407, 0.8718648087917049, 0.8915919951695246, 0.8490514283538344, 0.9065161796939697, 0.8643584787924062, 0.834570112315032, 0.8851538291090771, 0.9190926676465985, 0.8895044619446246, 0.9222718628463898, 0.8950289057459326, 0.8969042473726592, 0.8820597326992707, 0.8524273263219306, 0.8883358699016438, 0.8896895553213121, 0.8901380904521533, 0.8764886986138349, 0.8843896753135287, 0.7394333561929037, 0.8628463684113278, 0.85889748309619, 0.849822317147155, 0.904505047128119, 0.925955161001197, 0.8679264276349026, 0.9372187334264903, 0.8140700090394332, 0.896767172515674, 0.8883229217903228, 0.8450050636168509, 0.8664311460009704, 0.8374445365348276, 0.8944819101011621, 0.9334930632163445, 0.938314051283952, 0.8687236972026143, 0.8593147662952442, 0.8557757637586065], [0.9372048354832646, 0.9061155403288774, 0.8966716260621452, 0.9064310148037926, 0.911539302513013, 0.9040284569815803, 0.8837993006945167, 0.8901482688210886, 0.8618843984061471, 0.9274703993666544, 0.9026959912191025, 0.8727772954968996, 0.8527674314905244, 0.865425679536328, 0.8492484422677814, 0.893905526792087, 0.9145701922113225, 0.8670607113865425, 0.8432713842611833, 0.8871074668356862, 0.9308305290051212, 0.901672291405634, 0.9386579447373816, 0.8841408486398985, 0.9035278230327372, 0.9104436531208292, 0.9454293650687712, 0.8818722730598078, 0.9284407386759737, 0.9025040584305133, 0.9059614807515001, 0.9240587734210717, 0.8883339356041803, 0.8982776307024136, 0.884967678296104, 0.856037022157689, 0.8991188008846445, 0.8973811410071122, 0.8557215882322184, 0.9999999999999996, 0.8998750872509901, 0.9301082018660597, 0.913027758766259, 0.894596923412281, 0.8778656159254092, 0.9074014717126473, 0.8836634912195142, 0.9328957439396994, 0.8375110632183814, 0.8818012278388804, 0.8676410271317007, 0.8991710398947184, 0.8614245913519577, 0.9332711499232035, 0.9269650498605447, 0.8803889694438738, 0.9277142267967047, 0.9203946857908156, 0.9304186465790942, 0.8955082886038893, 0.9076131712738886, 0.9166403097287892, 0.9332365082377583, 0.8765209517296775, 0.8954818941788028, 0.8869024714120258, 0.9412630094007456, 0.9217792092623112, 0.8988324774260994, 0.8709016961580883, 0.8881763431851766, 0.8720079117217182, 0.8842338117536389, 0.8824750405016604, 0.8809237244046066, 0.913383018420352, 0.9250239591670765, 0.8909488696720111, 0.9172994473545837, 0.8791511373591916, 0.9035701569160652, 0.8912869612701921, 0.9162742536402687, 0.9063028294385678, 0.9353882932948816, 0.9053335581883677, 0.8957176584259073, 0.8970798059929204, 0.9058630713150966, 0.9175458864783944, 0.8771452203940624, 0.9059048150254709, 0.8999663095647243, 0.9123410237713561, 0.9334132069998253, 0.9173635258253618, 0.896806815904481, 0.9206210946679863, 0.8836618263532622, 0.8956146924743281, 0.9377227079883955, 0.868205841430565, 0.926242792429919, 0.8797381176405015, 0.8954247436509758, 0.8813431617384709, 0.898354772920317, 0.9211817142998927, 0.9204672034930992, 0.9002927625078214, 0.8653213711837898, 0.9302841253093608, 0.9110610232700194, 0.8277643548969682, 0.8497010609160123, 0.8946112630755277, 0.8700412812974084, 0.8966913502607038, 0.9166819848533649, 0.8845001793748151, 0.8906351042106411, 0.8532386578366051, 0.9218468111594134, 0.8841130448691263, 0.8874495213621572, 0.9103199514036008, 0.8922700362531166, 0.9179321191462314, 0.8691595741260076, 0.9028600509144833, 0.9155521972156743, 0.9327302903910335, 0.8909392533786158], [0.9548957885299205, 0.9142473481115405, 0.9128669583843921, 0.9608167895357769, 0.9134652245540895, 0.9269466394296922, 0.9387594017676031, 0.8859241196318579, 0.9447330495812182, 0.9309026905596806, 0.9608591373442908, 0.9211386810453019, 0.8877496629457602, 0.8947362121541065, 0.9082021648397195, 0.9299872708775735, 0.924663239140098, 0.9453761601612778, 0.9216073078265719, 0.9558596770155616, 0.9241246619480807, 0.9429198946390327, 0.9269997647667185, 0.9386561726928266, 0.9317163946911853, 0.9695742052805638, 0.9364685966964046, 0.9135986538715822, 0.9536228450793074, 0.9222039408966429, 0.9502069004731228, 0.9218392160591454, 0.9254701427213707, 0.9438247156429486, 0.8722826240100806, 0.9061880987071532, 0.8988970053216037, 0.8922928278369806, 0.9055166282390285, 0.8998750872509901, 1.0000000000000009, 0.9526007050701022, 0.9238678240608884, 0.9063530018027235, 0.871717066627783, 0.9408269643519497, 0.9364317663216426, 0.9244524796934883, 0.8737096023326956, 0.9007918609793866, 0.9171013292209345, 0.9408319924592786, 0.9266564716305483, 0.9381063336751179, 0.9264131067305775, 0.9076328379856375, 0.947262759218314, 0.936447124703538, 0.9383903236790319, 0.9534937160645196, 0.9619862135195429, 0.9449600121657556, 0.9478961896920332, 0.9269217567654623, 0.9024333718641103, 0.9673861241544701, 0.9371516097222974, 0.9151427287444214, 0.9294073110308727, 0.9159401573705521, 0.8747484653651711, 0.9298353050166287, 0.9365718526035526, 0.8712776392517338, 0.8740806317219422, 0.9335853131678514, 0.9355494668847815, 0.9506503080364592, 0.9402549692272761, 0.9325378379886838, 0.9527635687452214, 0.9249031181362767, 0.915886421383252, 0.9234223028074494, 0.9317817658249792, 0.8936837749074782, 0.9087178422707279, 0.8823548186592343, 0.9613097107376678, 0.9583556354947538, 0.9335349335162735, 0.9416360730660628, 0.9034515581507783, 0.9125634876433983, 0.9099523385558763, 0.9137720901377663, 0.9272382896880664, 0.9358673743491512, 0.8872436753052926, 0.887353125117523, 0.9370816440449884, 0.9305698011321087, 0.9264918527190971, 0.941739546773785, 0.9263410173333593, 0.916398348378775, 0.929482354640991, 0.9167521578286895, 0.916628620903282, 0.9252104881469501, 0.9038848164485535, 0.9421197698202695, 0.9223149718154253, 0.790536652632531, 0.9019210085521232, 0.9113753612288908, 0.905050412050717, 0.9274110579260709, 0.9440826682411492, 0.8957287466870957, 0.9272212683520616, 0.8610523774868574, 0.947854383672057, 0.94157122839438, 0.9305732951872089, 0.9024023054344723, 0.8927084597903515, 0.9127870096657593, 0.9328984060206184, 0.9506189157805609, 0.8955023499242946, 0.9038753719906307, 0.86352892609168], [0.9608555459593137, 0.9116000627662706, 0.934487795686194, 0.9468100955550323, 0.9456509829635733, 0.9392919630810501, 0.9301484396937593, 0.9010070262591561, 0.902249629598509, 0.9634863076281258, 0.9346273591571964, 0.9013492228911544, 0.8914641150613296, 0.8953960260635369, 0.8807577071280875, 0.9189670077927033, 0.9432167982838214, 0.9184680836981063, 0.893733510267158, 0.9410605347980057, 0.9540769895190273, 0.9500748652432445, 0.9391874691745274, 0.9217459241009724, 0.9211404646651042, 0.9563159449641776, 0.9518372188597144, 0.9084942437688159, 0.949498201957409, 0.9288199997388528, 0.946774040715879, 0.9359289990344696, 0.9150875971330317, 0.9430669505034395, 0.9079318488269872, 0.8936198482984626, 0.9121606057466936, 0.9081310319347172, 0.8933925042630076, 0.9301082018660597, 0.9526007050701022, 0.9999999999999996, 0.936787849518157, 0.9216111990577349, 0.884796457108993, 0.93704115406495, 0.9127748422078231, 0.9386045826462445, 0.8618606060205686, 0.9224292034769723, 0.9081602726954827, 0.9343552515812235, 0.9178742562127408, 0.9508522192260149, 0.9468130647933369, 0.9159095365372913, 0.9463857382961671, 0.9553946898808425, 0.9498577204308482, 0.9353418684487969, 0.9451515676289755, 0.9512525639501619, 0.9580076421473107, 0.9301387703322981, 0.9163309722584569, 0.9435187085645362, 0.952123649514497, 0.9466656644951436, 0.9320425583996261, 0.906425810589758, 0.8905792230804838, 0.9132820536077554, 0.907753773298522, 0.8822108137148106, 0.8894973763568809, 0.9434495013026468, 0.9514542122059684, 0.9441819540162776, 0.9464987120453108, 0.923263404370975, 0.9372562389958327, 0.9292398605303387, 0.914429333171632, 0.9232992169647007, 0.9417551547624841, 0.906701765050174, 0.9444798313837903, 0.8863326850014437, 0.9417237074071303, 0.9520309948480203, 0.9219137079574861, 0.9490412466409286, 0.9313702395927683, 0.9328322926054434, 0.9363960587827944, 0.9241543533638861, 0.9210385665019539, 0.9499157126738671, 0.9150063727284086, 0.8827963920269799, 0.9329454021174988, 0.922105395818305, 0.9344526446762522, 0.9300671953084836, 0.9176795552763157, 0.9243159619194843, 0.9333770097065426, 0.9287050220446266, 0.930332575130941, 0.9324970104874009, 0.8897774160202963, 0.9358920233906317, 0.925635196815839, 0.8196912426173522, 0.8835083360961689, 0.9212942957644792, 0.9122773193890854, 0.932881182356589, 0.9531685586592424, 0.9068889230246306, 0.924023618905641, 0.8686319982380406, 0.955260942405507, 0.9247327933647395, 0.9224138736756134, 0.9141124832237404, 0.9007332433320334, 0.9386227420889848, 0.921097091637321, 0.9349461045375014, 0.9194859945713384, 0.9207541126983657, 0.9075156912298831], [0.9410219214703548, 0.9026158295036983, 0.94088300483519, 0.945166278383115, 0.9294846735706058, 0.9107872427651504, 0.9241029707204615, 0.8947485928544321, 0.8928313697214397, 0.9356412679048022, 0.9373179936071305, 0.8816651666166999, 0.8837765411697383, 0.8969820598746387, 0.8741883787671808, 0.9062190002637829, 0.967265131917583, 0.9109139365557553, 0.8593362477750488, 0.9120758214769605, 0.9498113144959338, 0.947166840372904, 0.9303788536075233, 0.9328235972527472, 0.9176488902525095, 0.930828248813232, 0.9463540303601261, 0.8776819922220193, 0.9426064133915089, 0.9105181477705209, 0.936785239164071, 0.9243237871163368, 0.9215436929042139, 0.9166257973394009, 0.8953688710825967, 0.8881591982858505, 0.9029680069868193, 0.8893060730332645, 0.8815241518769213, 0.913027758766259, 0.9238678240608884, 0.936787849518157, 0.9999999999999992, 0.9164772930840067, 0.878896522590054, 0.9229449271393869, 0.9133608244671388, 0.9271980154805374, 0.8554018859078049, 0.9588675564430761, 0.8898989360735247, 0.9164904760685134, 0.9115974038367556, 0.9540488589409495, 0.9360409992563088, 0.9019086729146522, 0.9504357478349548, 0.9380220743321205, 0.9304903662613105, 0.9092722067472725, 0.9280460347679791, 0.93071887721336, 0.9559268815598939, 0.9053463318051382, 0.9373319957849426, 0.922890554167192, 0.931091998368934, 0.9396140070630803, 0.9279301308855786, 0.9059630071261305, 0.8912023518514498, 0.9023209898481407, 0.8995098410270164, 0.8803764378985158, 0.8827447727434364, 0.9384629348410443, 0.9392740368875541, 0.9137540888169232, 0.9343771805158531, 0.911545147300039, 0.9217596082869337, 0.9201227154423313, 0.9128691806227123, 0.918600508522428, 0.9418436862757597, 0.897843093088968, 0.9084313024595202, 0.8981954406422116, 0.928708309138998, 0.9325217383480382, 0.9074256345256524, 0.9341359236741618, 0.9307217355075036, 0.9068676071047844, 0.9230831378655326, 0.9415787979813236, 0.9077017514457939, 0.939298499202819, 0.939106756170822, 0.8753256340611018, 0.9262488237195186, 0.8994869092606905, 0.9443907148608868, 0.9080956888158346, 0.9039216043425284, 0.9202112835758015, 0.9336030883204702, 0.9040170053313028, 0.9253657482030749, 0.9231512997982135, 0.9098175791269754, 0.921758685683202, 0.9148095519528796, 0.8349461084362638, 0.889277364615595, 0.8921529092303534, 0.8816820656399795, 0.955330071443037, 0.9409007387074046, 0.9059947587596537, 0.9137483994335459, 0.8574499502945088, 0.9349316232068683, 0.9201912937787199, 0.9234647835173084, 0.9230537507632831, 0.8604416505919743, 0.9156762273970004, 0.902804976640343, 0.9308300631257924, 0.8982914851087618, 0.9246069758844813, 0.8791142439876821], [0.933056600864431, 0.8913900728946713, 0.8997672122509243, 0.90657849114662, 0.9199513944229901, 0.8990012552032195, 0.895835603458217, 0.8778564517392955, 0.8821386590957057, 0.9085018014449435, 0.8987139434266451, 0.8516707650642502, 0.8529368625851901, 0.8773696752597884, 0.8740786742276674, 0.8831582570631828, 0.9065652032375974, 0.8995826738251775, 0.8484925762677518, 0.8916152208267092, 0.9134839799262651, 0.8963280933029879, 0.9399441157400418, 0.8899408838000606, 0.9003691541122273, 0.9043708917878641, 0.8978556404118445, 0.8793537248339147, 0.9252162285282179, 0.8873235202994835, 0.8950247268170768, 0.9110386065230573, 0.890742994606555, 0.9004658929140823, 0.9015433570710046, 0.873611737269816, 0.8910971531890022, 0.8950575320040759, 0.8944066163579244, 0.894596923412281, 0.9063530018027235, 0.9216111990577349, 0.9164772930840067, 1.0, 0.8805026845307877, 0.8928355772499764, 0.8783643705240904, 0.9230748544606654, 0.8530319410931635, 0.9041562486117718, 0.8797822185863554, 0.9053742805010039, 0.8952619716378887, 0.9273956540229413, 0.9102527975092495, 0.897587837736739, 0.9206024730375264, 0.947445057440996, 0.9326945814631589, 0.8931367852747938, 0.9093218476471592, 0.912086197325455, 0.9307258203211037, 0.8803241528098678, 0.892295969197315, 0.9193752232992337, 0.9201847689427786, 0.9413386494685114, 0.8886099279657721, 0.954948600638971, 0.8849305443019846, 0.8887523971687014, 0.9005083174824458, 0.8547492853609944, 0.8696944287123791, 0.9204147817236351, 0.9326493082625174, 0.9053443630401982, 0.9004968549050845, 0.8876343776424421, 0.9153145760219412, 0.9035842864752506, 0.9043565892162969, 0.876440633190725, 0.915485611218096, 0.9296600639671643, 0.8883735020883541, 0.9013106478378394, 0.9057423130806301, 0.9108076308046813, 0.9055790871232803, 0.9067958209345799, 0.8840522145207395, 0.908315768492087, 0.8906194925637402, 0.9043045389882374, 0.8698784764250149, 0.9081849181732893, 0.9030816767727342, 0.8709569534655461, 0.9177078051270589, 0.8691108443356613, 0.9058928986479104, 0.8989003661524075, 0.90531464140211, 0.8915862122334032, 0.9098767402075942, 0.8797598634091393, 0.8985915844096743, 0.87952118877457, 0.9112522566294438, 0.9305891925692988, 0.8970429286156657, 0.815982111260238, 0.8718260581436568, 0.854285150111844, 0.8785880140025599, 0.8999463532376972, 0.9376041879541722, 0.9054250566507924, 0.9617959020626039, 0.8381339213301329, 0.9097860204732862, 0.9052736420655265, 0.8793598840991311, 0.8908726725823192, 0.8702930289828308, 0.919171853624843, 0.8960078631983971, 0.9101916847639884, 0.9091476139446972, 0.9261926142075481, 0.8808622331908571], [0.9021541178874304, 0.873226488497987, 0.8604806591833706, 0.8742748731222807, 0.871810188138287, 0.8624142993349025, 0.8603786366288941, 0.8203500532354984, 0.8390997734526852, 0.8855762997959685, 0.8674539418420524, 0.8046323072194029, 0.8079048622308279, 0.8572919437606873, 0.8240550384210825, 0.8428479458664966, 0.8854755375418857, 0.8617191460599206, 0.8081063007163717, 0.8551891212884335, 0.888725631907229, 0.8697207942356148, 0.8836208208758543, 0.862210312487514, 0.8624664207130491, 0.8791771033158926, 0.8842224231834694, 0.8411737092618522, 0.88354931003007, 0.9269469743237034, 0.8660732209801367, 0.8896609323985144, 0.8521186979798736, 0.881470346449569, 0.8349043227167677, 0.8137048368177897, 0.8675331557183577, 0.8759139312767191, 0.8503762512653318, 0.8778656159254092, 0.871717066627783, 0.884796457108993, 0.878896522590054, 0.8805026845307877, 1.0000000000000007, 0.8632504277535351, 0.8513064494607042, 0.9149631005797766, 0.7838181100281079, 0.8699413621612818, 0.8211535571947864, 0.8610060350186517, 0.8670499154380489, 0.8991123042306256, 0.8819285703843665, 0.8399328162337508, 0.8915222384086505, 0.8899653711087843, 0.8811041553434815, 0.8446914326256106, 0.8704161422268888, 0.8930407246027788, 0.9006910507927104, 0.8485808648444294, 0.8558630819759884, 0.8789467064911536, 0.8823442522440048, 0.8765037010942291, 0.8554465179376357, 0.8628339709282149, 0.8374749135767319, 0.8318674878530183, 0.8501477372275925, 0.8269462329277097, 0.8361111253482637, 0.8991515644568449, 0.9622180143846699, 0.8491386925533091, 0.8967889236725687, 0.8561384575852756, 0.8694791225346984, 0.890392597537167, 0.8716056838581461, 0.8540940470131859, 0.899173460593728, 0.8700613274724605, 0.8564078153718748, 0.8857856168473516, 0.8801091348279839, 0.8706420422071733, 0.847315329286227, 0.8835038998204301, 0.8560160139490085, 0.8723113784631498, 0.8709108800603981, 0.8785854261442649, 0.8398412553045773, 0.8817825628259812, 0.8613051984021799, 0.8335410189825834, 0.8770119080880648, 0.8336739840671191, 0.8847458315865286, 0.8317182073600701, 0.8607676174485451, 0.8626748932680288, 0.8706150499711484, 0.8433032755910503, 0.8878150633959441, 0.864717945390765, 0.8739899747895927, 0.8815311495783069, 0.8561443687645622, 0.7541082371745003, 0.8495353347645611, 0.8358611124065042, 0.9146313138323857, 0.8695154272677017, 0.8797470507950823, 0.9115843877343539, 0.8760705766262373, 0.8042576046579841, 0.886708419515119, 0.8443914242211078, 0.8630278160320491, 0.8746256338537142, 0.8430492378707615, 0.8972095376281054, 0.8453037778790673, 0.8594991576237894, 0.8449787622175127, 0.8754737431383794, 0.8401391263696777], [0.9269792508079, 0.9047173591146384, 0.9156623723189217, 0.9350978408643045, 0.9046673449678437, 0.9454959225479608, 0.9300219746468787, 0.9041211468098573, 0.8913798998574436, 0.9274721029816246, 0.9430069206037585, 0.9023806363697752, 0.8794408770420858, 0.8775861507365783, 0.879928261800118, 0.9021173023282302, 0.9135510062794893, 0.900675793977831, 0.8737226735815864, 0.9250321144027851, 0.9295334898055115, 0.91555837621336, 0.9216739008824664, 0.9080504890632328, 0.9138144480504568, 0.9522721529247394, 0.9341304768894225, 0.887324788956873, 0.9291522584233658, 0.9085917199449925, 0.9217654087908205, 0.9185377115862805, 0.9055627325320765, 0.9300829943277663, 0.876670716175622, 0.8887921995324772, 0.930168433923598, 0.8851490236672321, 0.8878518339157313, 0.9074014717126473, 0.9408269643519497, 0.93704115406495, 0.9229449271393869, 0.8928355772499764, 0.8632504277535351, 0.9999999999999994, 0.9015276344442827, 0.9073639015635636, 0.8528786843006173, 0.8997732686464829, 0.8816191514171939, 0.9379307278865109, 0.8982251961814102, 0.9416731951880282, 0.9226509964666848, 0.8882428055685343, 0.9461039311080944, 0.922172159824891, 0.9384303166462908, 0.9295913790621999, 0.9353815332686602, 0.928740695583299, 0.9355316265928106, 0.9147248590145343, 0.900861743304277, 0.9228587020652907, 0.9244245850271107, 0.9266395901652261, 0.9501284872462779, 0.9021528052401977, 0.8870394255683495, 0.8971561756588637, 0.9040896065632222, 0.9040119163935206, 0.8783711636633631, 0.9300573905962115, 0.9228211118558663, 0.9314218633103243, 0.9341931423491682, 0.9032230319283594, 0.9433016562306336, 0.9159286945611318, 0.9086517041145558, 0.9362371200497674, 0.9347573063030745, 0.8990525770073845, 0.9174423040020722, 0.9067375164439848, 0.9304585819235283, 0.9342724071691108, 0.9021108670597446, 0.9250171314184416, 0.9355990253082438, 0.8988767037932981, 0.914387553234024, 0.9076801949713612, 0.9010721894281416, 0.9440113479819118, 0.9173775027239527, 0.8768333158242643, 0.9378029282456372, 0.9164020520878081, 0.91327397841149, 0.9370302417117229, 0.9047415765881036, 0.9243273823119065, 0.9207081169919215, 0.8859689610579863, 0.9297528610776497, 0.9286998597047998, 0.8868249637009232, 0.9193647242822305, 0.9162660172579938, 0.8177015320456582, 0.8773982925575247, 0.9014990279827397, 0.8798578859557514, 0.9138164469589766, 0.9257516285240328, 0.9007387393104473, 0.9001011200537965, 0.8692724934750536, 0.9402034943958459, 0.9107078741121317, 0.8946003917665145, 0.9259006261802246, 0.8858820846307508, 0.9104649874366386, 0.9243829222807348, 0.9371410525112177, 0.8916241406204675, 0.9100447397348459, 0.873627532709666], [0.9145656812085842, 0.8992135560005144, 0.8940592391939206, 0.9170765666611493, 0.8890183081774335, 0.9048340559628492, 0.9237138420404222, 0.8694671354509, 0.9370829048079427, 0.8895153673196234, 0.9213472557186908, 0.889005338250303, 0.8849370165287039, 0.85972329142962, 0.8628637433955169, 0.9029487109895273, 0.9066580571177936, 0.9071723002562312, 0.8836100253042383, 0.9298200169522253, 0.8957372065891791, 0.9234638168710936, 0.8941298141344605, 0.9074045552611585, 0.8855201447547838, 0.9369038327108995, 0.9110728144411839, 0.9183097672926096, 0.9222942634454587, 0.9059134590734953, 0.9435429556159832, 0.9014624170683857, 0.894895991842148, 0.913167041655125, 0.8391247088281846, 0.922271217534804, 0.8593766284198233, 0.8435541582514166, 0.8657545999227312, 0.8836634912195142, 0.9364317663216426, 0.9127748422078231, 0.9133608244671388, 0.8783643705240904, 0.8513064494607042, 0.9015276344442827, 1.0000000000000002, 0.9116921821667027, 0.8366857115684923, 0.900026022062029, 0.8945792273529694, 0.9149035078288488, 0.9043353544175026, 0.914938281677754, 0.9164984646643068, 0.8743862054731583, 0.9369876038905749, 0.9026789168497905, 0.9060711970218109, 0.9054821885347019, 0.9223314689967025, 0.925066079826064, 0.9175485874849351, 0.9032232370822796, 0.8890877874538061, 0.9241913499117289, 0.9093627673559023, 0.8967211884045867, 0.8945129395184088, 0.8877189072084066, 0.8367961938370705, 0.9003503909680305, 0.9216703300044059, 0.8352381707400882, 0.8427105714536811, 0.9081187984945027, 0.9167272510121898, 0.9045076076068854, 0.9185301869993274, 0.9226342850972369, 0.9076164316634927, 0.9189812342255264, 0.9075741194722494, 0.9007558814175474, 0.9052491471864675, 0.8656627845602533, 0.8690682142236643, 0.8788534908372116, 0.9414721707724948, 0.9246552225637021, 0.8942925018556394, 0.9166394991835197, 0.8672295027728534, 0.8748401471317104, 0.8774234960485893, 0.8817643080785156, 0.903204794977118, 0.9253241865225991, 0.8554042399395075, 0.8434395193301896, 0.9020342470885911, 0.9019342877491829, 0.9001784517463509, 0.8960172713371775, 0.9223975370364719, 0.9044159918598955, 0.9085389034705125, 0.8850833784368762, 0.8790817241709001, 0.9037782637440546, 0.8718743972969977, 0.9087395563629503, 0.9030415931675104, 0.7677581476823722, 0.913760385989856, 0.9015387939761661, 0.8794422106884541, 0.8999184639786416, 0.908501191265412, 0.8719288184926772, 0.8865911986535285, 0.845599854398281, 0.930574446798716, 0.90793042813889, 0.9070046085592223, 0.8833109958984493, 0.8450760771627333, 0.8952375336424906, 0.8954976996694088, 0.9058444439866178, 0.864808447912992, 0.872964113724813, 0.8460493159494393], [0.9636317981469261, 0.9177837426394915, 0.8975635181532251, 0.930247342680681, 0.9310177057210423, 0.9079150279253603, 0.9127321701493378, 0.8950561921914204, 0.8900911791414151, 0.9267769972428722, 0.9207698839032575, 0.8660740453202425, 0.8649221968434502, 0.9015990589335705, 0.8691875350052466, 0.8989377293620018, 0.9255952984975826, 0.8982092130202946, 0.8584741023548854, 0.9086335287944698, 0.9350192869125864, 0.9137920866972293, 0.9497916419360756, 0.8952287369471678, 0.9138508033614496, 0.9330321585354733, 0.939758319897979, 0.9097639833229921, 0.9487110107850688, 0.9269402927345214, 0.9232067158918358, 0.934440323632888, 0.9060088841445312, 0.9142278652746987, 0.8689579504013314, 0.8973183151635181, 0.9026794070886065, 0.9141530979910806, 0.897294578493134, 0.9328957439396994, 0.9244524796934883, 0.9386045826462445, 0.9271980154805374, 0.9230748544606654, 0.9149631005797766, 0.9073639015635636, 0.9116921821667027, 0.9999999999999998, 0.8336532573168538, 0.9001185862569456, 0.8865422004600756, 0.9347296542519453, 0.8949129821012869, 0.9413957173836875, 0.9408654453050024, 0.91419069375146, 0.9307777336379924, 0.9380242797837879, 0.9290997705821683, 0.9073600473209739, 0.9314048703966121, 0.9347982159287901, 0.9452789855018746, 0.8958782487000979, 0.9007463406138414, 0.9200922040182347, 0.9345699156915895, 0.9477247907431146, 0.9097779160399211, 0.8997461571951384, 0.8710599399480904, 0.8854295624216655, 0.8966950850490619, 0.8696971276053208, 0.8884631943195208, 0.9364216221428461, 0.9599666787674054, 0.9202567947930076, 0.9324048626639913, 0.8967695383809581, 0.9376492322172741, 0.915464305463913, 0.926066607297922, 0.9067707672772601, 0.940486218261768, 0.9264846499001778, 0.9111674971019876, 0.9156099106106868, 0.9276092056239282, 0.9293318763166565, 0.9109534005596595, 0.9187427125979651, 0.9165128578284624, 0.9062359920874435, 0.9177880248061798, 0.9125843818160937, 0.8968793429902346, 0.9265667863987465, 0.889074225782924, 0.8802042075056239, 0.9238373092749979, 0.8868909610310071, 0.9324020490380702, 0.8892887695322085, 0.948852944748305, 0.8981267628237732, 0.9103901615110357, 0.9007845608979007, 0.9172079618365929, 0.9075229024373292, 0.9160254676042691, 0.9319726810314286, 0.8971143451193058, 0.8031775678580979, 0.8872432902004671, 0.8996652773653078, 0.9001532870743693, 0.9124126818087093, 0.9424883287489672, 0.9176371063762366, 0.9268227913586493, 0.870742614888749, 0.9287791544042184, 0.9005315401712628, 0.8995600282279081, 0.9034586894168986, 0.8846690006069999, 0.9358252356913975, 0.8927581061291645, 0.9149214003334366, 0.9184290912576036, 0.9208982892325261, 0.9101747656027779], [0.86411744643697, 0.8299444746051128, 0.8495016634589385, 0.8355488065142486, 0.8480774718884476, 0.8471746532549564, 0.876914434675605, 0.8346222424417977, 0.829929904811225, 0.8496688335977046, 0.8466798042215437, 0.8890422172102814, 0.8267479447987913, 0.7943411901312012, 0.8636498647382902, 0.8924371075738682, 0.8590212574581904, 0.865032259035805, 0.8878823452451999, 0.8537816502917817, 0.854812555274066, 0.8762514446111904, 0.8559884852494357, 0.8744710619933638, 0.8653453656666703, 0.8732174321841776, 0.8638968776486009, 0.8362805643857129, 0.9079929665384633, 0.8324232004889633, 0.8547736883732909, 0.8496114198262957, 0.8259283053203698, 0.8497641823392417, 0.7907857117851755, 0.8066202501689196, 0.8136186199596576, 0.7980011838145802, 0.8262151491310771, 0.8375110632183814, 0.8737096023326956, 0.8618606060205686, 0.8554018859078049, 0.8530319410931635, 0.7838181100281079, 0.8528786843006173, 0.8366857115684923, 0.8336532573168538, 0.9999999999999999, 0.8536989994776525, 0.8567860794210459, 0.831951147199762, 0.8561889932049124, 0.8798852898425706, 0.8340103618904449, 0.8158822772291681, 0.8729097342844453, 0.8464216768397954, 0.8650188296444692, 0.9144356460261053, 0.8714984654305109, 0.8649897584454984, 0.8771530634867883, 0.863573759292324, 0.8499053807515796, 0.8811885758508275, 0.8738166280839726, 0.8468798714003148, 0.8444566074474334, 0.8557545625954697, 0.8176894381443135, 0.9170281358597951, 0.8183200635100569, 0.7752387513746106, 0.7856757645387699, 0.8566384178164991, 0.8530981575421923, 0.8899691114851354, 0.8575724015836651, 0.8457058963255861, 0.8551779827868651, 0.8451097265411136, 0.856794173657779, 0.8586805147680807, 0.8499373392840937, 0.8169630706914619, 0.8169468705900156, 0.8099900878680297, 0.8548819063727011, 0.9061957013024629, 0.9026560547221072, 0.8749604895350043, 0.8396988896165696, 0.807539206628356, 0.8236006396258244, 0.8583884897872678, 0.8402097621647089, 0.873030406604966, 0.8484524776381415, 0.8190395885696913, 0.8963666382657817, 0.875974060983125, 0.8526021718696493, 0.8736440385751455, 0.8458241270324511, 0.880823559377754, 0.8604562525961575, 0.8474131098763114, 0.8307702693004522, 0.8504399897021776, 0.8384056079415916, 0.8743714463489193, 0.8803503139423752, 0.7345987637346296, 0.8272589240408701, 0.801723120091224, 0.845008956949794, 0.8555985412334868, 0.8814495756005118, 0.822294207243119, 0.8513388134163375, 0.7996313386970977, 0.8580586267178623, 0.8605026521737075, 0.861276210876482, 0.8321596001382312, 0.781363742442048, 0.8431061352381055, 0.8821263943522166, 0.8868030518971242, 0.8108623593639005, 0.8391535570792883, 0.7760542598147275], [0.9241986385396513, 0.8836907357865861, 0.9298402920477061, 0.9146192674553625, 0.9156116902095255, 0.9050639369168109, 0.918428269986811, 0.8569452161027519, 0.8713292803151939, 0.9232139626565139, 0.9081981710130334, 0.86304930810346, 0.8549204262365204, 0.8768691218044438, 0.8686794225599004, 0.884091665668792, 0.9713937047531201, 0.8947030996823875, 0.8308161561479244, 0.9004237376214903, 0.9495074498866357, 0.9528938924883106, 0.9072674945781778, 0.9097352662470293, 0.8929643140809598, 0.9140567519638405, 0.9233002608410721, 0.8609241633984455, 0.9186242209216446, 0.9062228683472608, 0.9251485501895857, 0.9098648767681757, 0.9000088421295012, 0.8952028414341635, 0.8708993288192446, 0.8488065477545399, 0.8822560209063274, 0.8740569421672372, 0.862110767387796, 0.8818012278388804, 0.9007918609793866, 0.9224292034769723, 0.9588675564430761, 0.9041562486117718, 0.8699413621612818, 0.8997732686464829, 0.900026022062029, 0.9001185862569456, 0.8536989994776525, 1.0000000000000002, 0.8593759457447376, 0.8859544111818853, 0.8971774398002647, 0.9475742462501842, 0.9073161200537648, 0.8609188832827924, 0.9372434070763799, 0.9169684641990171, 0.9135276836838739, 0.8836163920998215, 0.9000578898488554, 0.9152404564624325, 0.9339045324157536, 0.9029444077773593, 0.9322310366189512, 0.9046551124477255, 0.92224421138058, 0.9063526878780349, 0.8836662434772444, 0.8931530665966212, 0.8566170292583175, 0.9114312013738968, 0.877204237866639, 0.8251817161913946, 0.8575373532377429, 0.9290838024111113, 0.920298907455108, 0.8975053979782384, 0.923081205147302, 0.9170261713376092, 0.8963441699431793, 0.9105746482767603, 0.8900298457059854, 0.8829493723676397, 0.9015802060097049, 0.8622620798889156, 0.8943353761276631, 0.8652579365202986, 0.9126718763844722, 0.9133284501980049, 0.8954491443697061, 0.9246377283018343, 0.9054961625348696, 0.8757833776354554, 0.8981716561137771, 0.9362077375005267, 0.8801389603751515, 0.9331223231001385, 0.9238752149253362, 0.8348562433516333, 0.8898382634340075, 0.8892986162921764, 0.9318919704673538, 0.9049863183044753, 0.8676794248710042, 0.9181331642205296, 0.9312764184026818, 0.8921294836208192, 0.8966095866896624, 0.9143341389234566, 0.8929497328160121, 0.8847294885646662, 0.897659965758494, 0.7811974438446488, 0.864751893616651, 0.8757570510260392, 0.8824785433414126, 0.9460816823084212, 0.9275900864081575, 0.8823128268493665, 0.8983854162621482, 0.8147685518294241, 0.9276309964984546, 0.9074404483492379, 0.8900361004262312, 0.8837529780767865, 0.8457514610371051, 0.9064621780600829, 0.9060432008500379, 0.9100015982052357, 0.868129175219986, 0.8860683236332161, 0.8590719927815311], [0.910683962018092, 0.861888638987344, 0.909515979289153, 0.8969984651992032, 0.8805996413546041, 0.8594243203454837, 0.8867194468966392, 0.8792095038429344, 0.8727906765103002, 0.8866050957698647, 0.8880958059752156, 0.8861449330787677, 0.8894710245387858, 0.8501314470896548, 0.847694037792696, 0.9471869967737737, 0.8903084233691572, 0.9077579227977525, 0.9073324369044753, 0.8937788413685624, 0.8905387444982451, 0.9054460645653002, 0.8908346557005808, 0.8979962569361422, 0.8596654288162711, 0.9133917683325044, 0.8914394060409923, 0.8845031482927642, 0.9190431566540384, 0.867186065554676, 0.9038168950145621, 0.8735956729779392, 0.8560375299889738, 0.884455475079079, 0.8655046699826446, 0.8870935652916525, 0.8275460928252361, 0.8380633920881839, 0.8273680004380697, 0.8676410271317007, 0.9171013292209345, 0.9081602726954827, 0.8898989360735247, 0.8797822185863554, 0.8211535571947864, 0.8816191514171939, 0.8945792273529694, 0.8865422004600756, 0.8567860794210459, 0.8593759457447376, 1.0000000000000007, 0.9109011813324637, 0.894320107928026, 0.900669216428401, 0.8994689557256765, 0.8745716786763813, 0.9121841260515846, 0.8982650293587846, 0.875301068958394, 0.8887837060208252, 0.8886239862781027, 0.8844971159783731, 0.9031744329202307, 0.8729422979635353, 0.8543636625703234, 0.9214478600282652, 0.8955850482366048, 0.9001262003648458, 0.9005479568322866, 0.8607036271604716, 0.8663961083122059, 0.8974294591659118, 0.8680787884782938, 0.8449683479671193, 0.8791038993464289, 0.8841226261640398, 0.8905208461219649, 0.8829706970217237, 0.8847704737768348, 0.8845348673361639, 0.8799305085933252, 0.8723218782995147, 0.8655228116734501, 0.8771385823013713, 0.890638611132063, 0.8518620457162069, 0.8694318509062267, 0.8384185291037214, 0.8876689522001635, 0.9281734697747062, 0.8921479727470343, 0.884445219470685, 0.8614845559944808, 0.87726889640442, 0.8672846249278078, 0.8612021066290418, 0.8758782929845454, 0.8830078289360237, 0.8702154665204875, 0.8488214856818922, 0.9030934064443754, 0.8643927558720095, 0.8770745983385297, 0.8788766041037055, 0.9020012131600542, 0.8840526690917712, 0.8862018882604916, 0.8847022965069041, 0.8725898527945637, 0.8806850707404961, 0.8612406974044409, 0.9340367428553359, 0.8818690613972873, 0.805270900099195, 0.8805209509371257, 0.868769239974898, 0.8753653175601732, 0.8679643880598807, 0.8992943719189544, 0.8317145860605822, 0.8848512155358097, 0.8554692392135183, 0.9139533870056163, 0.8902303923308279, 0.9069674829577172, 0.8647724716080116, 0.8718887354188464, 0.8589525213986979, 0.8702537238669835, 0.8900222319361342, 0.866795483297978, 0.8824438531776829, 0.8357370299688652], [0.9343350595240796, 0.9036818564116067, 0.8907420677072526, 0.9262541667685149, 0.9077776876604684, 0.91730329918567, 0.9425153478010817, 0.8871021402531378, 0.9003733070101904, 0.9232810001621662, 0.929620387808284, 0.8999600321081704, 0.8724338296350418, 0.8630175349534165, 0.86291749861442, 0.9215118437092322, 0.9088146963352782, 0.9046942796076465, 0.8680992932890792, 0.9455505392150251, 0.9197158010503601, 0.9209749373152908, 0.9285066584923662, 0.9009772965319055, 0.8986837572170145, 0.9519731933736746, 0.9246927585374458, 0.9239587812793554, 0.9286080427080147, 0.9112350375948824, 0.9402483108150194, 0.9074293681140662, 0.8953514193487819, 0.9264865665192972, 0.8548855236391066, 0.9168510474177759, 0.8820212045339917, 0.8718819801673435, 0.8888856535028371, 0.8991710398947184, 0.9408319924592786, 0.9343552515812235, 0.9164904760685134, 0.9053742805010039, 0.8610060350186517, 0.9379307278865109, 0.9149035078288488, 0.9347296542519453, 0.831951147199762, 0.8859544111818853, 0.9109011813324637, 1.0000000000000002, 0.91277308475614, 0.9294712533925933, 0.9231918903488421, 0.8872847515656241, 0.9329459628079185, 0.9270975321507126, 0.9122435200510386, 0.9141617265414343, 0.9267520362671469, 0.9310102306735618, 0.9332461887846897, 0.9192202237948011, 0.8940599591632826, 0.9238289982639694, 0.9243086050397159, 0.9227130134749925, 0.9215618848998124, 0.9053069735300312, 0.8661863787543775, 0.903368656965191, 0.9197157552764689, 0.8735530843698626, 0.8804044220278838, 0.919780465525933, 0.9219122144474692, 0.9170656308468645, 0.9184012064202478, 0.9179482398971991, 0.9424368398073538, 0.9214462656913713, 0.9003699859493524, 0.9220994491925412, 0.92409572766465, 0.8813471635063055, 0.911700959300515, 0.8798150859030953, 0.9345815527458257, 0.9359986024378604, 0.9086912698469205, 0.9164624843074624, 0.9078340048440762, 0.8984891159404284, 0.8938717506166778, 0.8973303875675087, 0.897403047661215, 0.9299794055332342, 0.8815741483097863, 0.8654834167905489, 0.9167244884693858, 0.9120641481402103, 0.9139055727184251, 0.9153738403536263, 0.9366643293141858, 0.9266163355396726, 0.9126475388232518, 0.9017662917052929, 0.8964251975874205, 0.9176796391308953, 0.8868830267899619, 0.9322642943517053, 0.9055092408345068, 0.7986814656152124, 0.902118181080367, 0.9072326510986557, 0.88614586835391, 0.904119013446128, 0.9233731849140562, 0.8786310963552588, 0.9102572748259206, 0.8597470064171092, 0.9475787714416624, 0.9326644254665533, 0.8904478174722131, 0.8943859292027676, 0.9028966857848066, 0.9174516808897585, 0.9223894985978565, 0.9116601797656992, 0.8994304368678577, 0.9006337414781088, 0.8709805827800501], [0.9236765826853757, 0.8919099775169337, 0.9201282309455685, 0.9050545421296876, 0.8855974104204123, 0.8968794467595667, 0.9278964638490704, 0.872262889990546, 0.9072947046996905, 0.9067742960299591, 0.9042678808738168, 0.9084273283008101, 0.9057414634629055, 0.8708245906124367, 0.8740121297516372, 0.9214088705973464, 0.9215578612183388, 0.9331378079884027, 0.8961866072487357, 0.9300455867553157, 0.8958116543368191, 0.9364720866929643, 0.8977210961492341, 0.9243093261582916, 0.8823858596895514, 0.9275665781207987, 0.9074372366608211, 0.8716494472121574, 0.916941849276331, 0.8945258703657752, 0.9431965412819804, 0.8848314332866083, 0.8950913291577297, 0.9080290761141676, 0.8791398260951819, 0.8882997744158672, 0.858968573453423, 0.8579200171234687, 0.8678481483361162, 0.8614245913519577, 0.9266564716305483, 0.9178742562127408, 0.9115974038367556, 0.8952619716378887, 0.8670499154380489, 0.8982251961814102, 0.9043353544175026, 0.8949129821012869, 0.8561889932049124, 0.8971774398002647, 0.894320107928026, 0.91277308475614, 1.0000000000000002, 0.931638383313405, 0.8975162748153366, 0.8760015418626987, 0.9249909919457839, 0.9444229728070102, 0.9114867483684977, 0.9106358343703608, 0.9225695311821849, 0.9263313245928846, 0.9287210765113839, 0.9086381334913327, 0.8791734324270063, 0.9223333588359047, 0.9075123178079614, 0.9025959300061159, 0.9011228504978264, 0.9022976669829106, 0.881379371868696, 0.9139907568958437, 0.9061417280899886, 0.8483208689860791, 0.8619115376816107, 0.9188013728043984, 0.9264231735180042, 0.8953034571254468, 0.9178962912066234, 0.917162530874434, 0.9010753640821301, 0.9061043064174352, 0.8787344956016987, 0.9030836755221063, 0.9173267525512776, 0.8682079702581609, 0.8801286839505845, 0.8841131438664828, 0.9197692065411707, 0.9204913828485415, 0.8986751637197792, 0.9333705931889638, 0.8755126476788337, 0.8977173513906593, 0.8936403043621622, 0.8884738080988844, 0.9036109758804046, 0.9180698399337328, 0.8853201254619724, 0.8296956274641228, 0.9210326876559571, 0.9091080992285674, 0.898525015527078, 0.8861357001778121, 0.8979358429832915, 0.9171219396351712, 0.9273128295133687, 0.894622788670868, 0.8758192935699745, 0.9184924291404348, 0.8987040314277721, 0.9054293161187399, 0.9000996807883721, 0.7989892385839411, 0.935100843354716, 0.8969154479810153, 0.8945717129633689, 0.9158383474402426, 0.897799614261934, 0.8996300770710541, 0.8940578542555813, 0.8478856249220901, 0.9084930153947616, 0.9166941200432057, 0.9335799721859939, 0.8956017562527753, 0.8384418144919832, 0.8911350976491401, 0.9007913485010852, 0.9104261938684497, 0.8659132290086602, 0.8832180920914254, 0.8207204452871358], [0.9545833494018969, 0.9201795676087849, 0.9457611462513569, 0.9429555176619329, 0.9402507945015186, 0.9298533125819473, 0.9278496638907048, 0.9095515585675646, 0.9144298879609343, 0.9379789420380317, 0.9315481774058125, 0.9055173174562043, 0.8920408516785516, 0.9085677800918548, 0.9113241194796947, 0.9171215500369656, 0.9697189000067654, 0.9341232855514611, 0.8828183554284508, 0.9385459519932696, 0.9537739694721047, 0.9585133957447639, 0.9475151639618594, 0.944199591750135, 0.9152363484265318, 0.9503909913191425, 0.9505701428946485, 0.8956822387341224, 0.948292071478972, 0.929105000312043, 0.9501162143048896, 0.9511895557753507, 0.93462801314567, 0.9287457887581172, 0.8987161963873556, 0.897340035428728, 0.9382506069780543, 0.9058272003189696, 0.8925233399078647, 0.9332711499232035, 0.9381063336751179, 0.9508522192260149, 0.9540488589409495, 0.9273956540229413, 0.8991123042306256, 0.9416731951880282, 0.914938281677754, 0.9413957173836875, 0.8798852898425706, 0.9475742462501842, 0.900669216428401, 0.9294712533925933, 0.931638383313405, 1.0, 0.936648336386493, 0.8936085169469883, 0.9586683438090284, 0.9443740361960813, 0.9528003344463905, 0.9299724106203838, 0.9405151396570143, 0.9425655872707195, 0.9707770597390113, 0.9255659501398512, 0.9246491689813494, 0.9372507786831292, 0.9611766251368133, 0.939717139529813, 0.9304909339679741, 0.9235562417195409, 0.9115733589834649, 0.91988563623084, 0.9184728800982112, 0.881373488934304, 0.8981068006583411, 0.9572909050419042, 0.9485603454066581, 0.9229816383109928, 0.9434235995161062, 0.9449068325331151, 0.9293870426084027, 0.9231650622257084, 0.9261126086793943, 0.9379443438453043, 0.9433574236782712, 0.9061398619914773, 0.9106338225073198, 0.9213541969373391, 0.9405273467005159, 0.9449315875463555, 0.9157617166634069, 0.9508622846816502, 0.9201721691712698, 0.9133900375408008, 0.9471029255491555, 0.9385966892383175, 0.9115449501220976, 0.9563390249794708, 0.9224187304105026, 0.8822941846028425, 0.9432175852956028, 0.923091463482775, 0.9511608091840347, 0.9151708518750313, 0.915149725221468, 0.9257527396259614, 0.9457611640616226, 0.9365659257483772, 0.9223123232591867, 0.9402261724507249, 0.9144200021885158, 0.9342550951182631, 0.9226354508689678, 0.820619116690064, 0.8950300286067673, 0.9108568458596557, 0.9115819927128269, 0.9452821966933659, 0.9458672847172958, 0.9143184364744303, 0.9221699350749268, 0.8647541567061003, 0.9502198930498407, 0.9306626518663723, 0.9291241723769035, 0.9340308207282001, 0.8827149582430742, 0.9351772507450861, 0.9147691649547598, 0.9354718237606272, 0.9152023612209946, 0.928253849403048, 0.8849978748446788], [0.946612570759327, 0.9259285027290189, 0.9259093055435859, 0.9527167695432259, 0.9173093567348238, 0.9302753884795696, 0.9130434467141374, 0.912677777509622, 0.8950279460187002, 0.9266108945671987, 0.9381105060323639, 0.8986503096052316, 0.8966094617682191, 0.8967112429782033, 0.8540936716475441, 0.9107056427704155, 0.933736039033672, 0.9097791050952798, 0.8640040536334174, 0.9251643325206087, 0.9313778498412033, 0.9262942412109745, 0.9421015162879524, 0.9033977490901505, 0.9129520167018057, 0.9477614439119966, 0.9626370358747719, 0.9149176323411381, 0.9284183487080896, 0.9323757060682332, 0.9327221838552112, 0.9206565758975511, 0.9316883432567344, 0.9290641139507247, 0.9144456500379619, 0.9194234521838751, 0.893401715576388, 0.8829026614520975, 0.8803088950686891, 0.9269650498605447, 0.9264131067305775, 0.9468130647933369, 0.9360409992563088, 0.9102527975092495, 0.8819285703843665, 0.9226509964666848, 0.9164984646643068, 0.9408654453050024, 0.8340103618904449, 0.9073161200537648, 0.8994689557256765, 0.9231918903488421, 0.8975162748153366, 0.936648336386493, 1.0000000000000002, 0.9137275025016204, 0.9455286863337284, 0.933417904046284, 0.9411402957891332, 0.9083480584874043, 0.9184876086012647, 0.9300264003005414, 0.9403328041360479, 0.9056285511134121, 0.9077702144965875, 0.9106176544453312, 0.9408511579904941, 0.9515425986816948, 0.9237827636101805, 0.9042315262478929, 0.895090598659249, 0.8923595353439338, 0.9178793092469136, 0.9153075108084254, 0.8564253718945088, 0.9387170732488094, 0.9361393316966955, 0.9071671422614668, 0.9445046235281187, 0.9099554829503304, 0.9235598183306124, 0.9215949312284564, 0.9077599929028254, 0.923582696517364, 0.9392140701598052, 0.9085507513145371, 0.9012887918125121, 0.8919937307556844, 0.9541544695763691, 0.9294330439718504, 0.8965472153671287, 0.9257077094527473, 0.9066639040981599, 0.9174601552727342, 0.9209761324882075, 0.925127346555375, 0.9320539068339023, 0.9414851277730961, 0.912300147732712, 0.8742406742691219, 0.9311901807397591, 0.9049578655207472, 0.9421000256850063, 0.903644424548411, 0.9073276453451852, 0.9125980873297476, 0.9126921597369034, 0.9071989914643627, 0.9387075862273935, 0.927164997015141, 0.8939108974283934, 0.9390279442301813, 0.9152680523587919, 0.8349112615913998, 0.880473495151737, 0.9060294495771648, 0.8930593901635104, 0.9209605097685118, 0.9290952173076639, 0.8986086466266017, 0.9074000031613415, 0.8851510232282276, 0.9451107705115258, 0.9118037906075218, 0.9053938462402735, 0.9189440922155925, 0.8903084622945587, 0.9137638717473325, 0.8987105102444073, 0.9147044484318344, 0.9020512977527609, 0.9400778998986016, 0.9052782059592879], [0.9189732273776972, 0.8669628316340626, 0.8891979655533325, 0.9192873342736194, 0.8924554337429207, 0.8748298640356234, 0.8683286948840367, 0.8909514623930895, 0.8692924356919514, 0.8881281092975457, 0.8993559410278495, 0.8661021162514588, 0.8924747000992561, 0.906497175050935, 0.8190325131401167, 0.8850913685651931, 0.8859154914919752, 0.883978554833563, 0.8598021064977763, 0.880031698522476, 0.9009768546119898, 0.8817439459950372, 0.908219302972398, 0.8809995753131884, 0.8904987146639411, 0.8921680290614894, 0.9013264438498867, 0.8663766806767581, 0.9177142555205143, 0.8676714671605634, 0.8965307929531605, 0.8731663091745356, 0.8938463338856033, 0.8922554306002435, 0.8839101890258568, 0.9229502717828699, 0.8653260193756128, 0.8659978455915116, 0.8813119056287135, 0.8803889694438738, 0.9076328379856375, 0.9159095365372913, 0.9019086729146522, 0.897587837736739, 0.8399328162337508, 0.8882428055685343, 0.8743862054731583, 0.91419069375146, 0.8158822772291681, 0.8609188832827924, 0.8745716786763813, 0.8872847515656241, 0.8760015418626987, 0.8936085169469883, 0.9137275025016204, 1.0000000000000004, 0.8980179725930009, 0.9310869126185483, 0.9037687381308022, 0.9023285397903571, 0.9202469759715826, 0.8887745259406334, 0.9129999336731842, 0.8563833065798919, 0.8663728533168686, 0.904044798168498, 0.875961219131154, 0.9401686255288331, 0.9107662068034359, 0.8754298786660666, 0.8900313853973293, 0.8610926610069305, 0.877681165515856, 0.9073896391589987, 0.8529903397337545, 0.9120835222728974, 0.9136619881371143, 0.8998675909910548, 0.8888381184395768, 0.8579946428130283, 0.940763133911412, 0.8668465959973599, 0.8877934424997552, 0.8880198273811255, 0.9485761718479571, 0.9209788786749514, 0.8816368711371333, 0.8811208742737066, 0.8993276631763742, 0.8973595567571098, 0.8910347870805589, 0.876682055793274, 0.8859637454296226, 0.8939591030524577, 0.8724223681762743, 0.8724186478809133, 0.8899913982492744, 0.8921899039145973, 0.880067991183507, 0.8556286511225728, 0.9133847975806949, 0.8678736456330417, 0.8910388713923821, 0.8825942024226359, 0.9279763439268052, 0.8669413713372157, 0.8665137919838051, 0.8455888606453721, 0.9028770635725891, 0.8743161575717796, 0.8977670516759368, 0.9196351504916886, 0.8674866056482691, 0.8670978230639304, 0.8730220198313643, 0.861532961574728, 0.8419553237564174, 0.8810229424048864, 0.916740989353385, 0.8884844921512288, 0.9062157609832484, 0.9128594088838977, 0.8872965778960796, 0.8849059156958461, 0.8866399679554011, 0.930662932851901, 0.8390607150765454, 0.8725600301392391, 0.8607664425128876, 0.9016580879068308, 0.8922582337369245, 0.9270668850345644, 0.8910726789445779], [0.9537605562306805, 0.9246094351240703, 0.9413930345777615, 0.9365319467100514, 0.915983227674617, 0.9361427845696102, 0.947614349164387, 0.9033242971253725, 0.9229801140310591, 0.9395828617040691, 0.9456431932308655, 0.9154887915449362, 0.9059539883437334, 0.8917801282544853, 0.8909311866255291, 0.9278923347945298, 0.9536604910812426, 0.9252538714981715, 0.8955320514270232, 0.9423309867768931, 0.9482446348392103, 0.9513475400212978, 0.9329953614884607, 0.9395177602428179, 0.9314697887211509, 0.9610083655503439, 0.9620043643759401, 0.9140992026450059, 0.9463473061817379, 0.9318834658926601, 0.9494925476149259, 0.9320976497485355, 0.9273898199702374, 0.9456967441854623, 0.9024246147414692, 0.9079246086733181, 0.9076938832415647, 0.8794674621874903, 0.90146291793215, 0.9277142267967047, 0.947262759218314, 0.9463857382961671, 0.9504357478349548, 0.9206024730375264, 0.8915222384086505, 0.9461039311080944, 0.9369876038905749, 0.9307777336379924, 0.8729097342844453, 0.9372434070763799, 0.9121841260515846, 0.9329459628079185, 0.9249909919457839, 0.9586683438090284, 0.9455286863337284, 0.8980179725930009, 1.0000000000000002, 0.9348131649994875, 0.950993432111089, 0.936386506110143, 0.9476791387481697, 0.947947833349569, 0.9623839316881262, 0.9348284760957994, 0.9275840068965118, 0.94225909738133, 0.9557450453372769, 0.9333320977937833, 0.9398239914443375, 0.9281679119257598, 0.8915357884285015, 0.9290019952831673, 0.9270716815567347, 0.8831013943935302, 0.8806751696802824, 0.9565116250503911, 0.9467549822090449, 0.9351574216560052, 0.951615782666145, 0.9338643809290286, 0.9356775533840499, 0.9381992348421315, 0.9225221688331039, 0.9357122240809725, 0.9446055465300615, 0.9080149153801883, 0.9059175172986009, 0.9093956367797856, 0.9582571685556904, 0.953805165367527, 0.9236463052825181, 0.9500098600368277, 0.9094605983887406, 0.9207556077856842, 0.9252443059787591, 0.9450460968072313, 0.9182854417586275, 0.9505474061526937, 0.9288919573568587, 0.8779673558294779, 0.9499543613706287, 0.9240041732436038, 0.9421835029882238, 0.9256127628273383, 0.9127089839355613, 0.9441234471961271, 0.9503243828906711, 0.92386140306851, 0.9335641629348329, 0.9442089376979841, 0.9079127680074608, 0.9370399188951688, 0.9332360069455452, 0.8050053663743425, 0.9006695334724357, 0.9100368381560064, 0.9141821637355451, 0.9451717219952059, 0.9401443054859854, 0.9111045970595589, 0.9228342335531461, 0.8784993704436013, 0.9580587223845359, 0.9238273364961758, 0.9298512817156601, 0.9308711213992006, 0.8885513540482906, 0.9289595268877494, 0.9306987155918934, 0.9465647972459119, 0.9021433212879115, 0.9238947139096556, 0.8762711177639928], [0.9631363088568979, 0.9012043904352643, 0.930052763179508, 0.9400012222304496, 0.9418416200941009, 0.9359104080634978, 0.926197301926089, 0.9018646152506788, 0.8918507486191283, 0.9370198307263266, 0.9297011317116697, 0.8836376979138482, 0.8917747615174114, 0.9106578474630427, 0.8651508410682024, 0.910906567620873, 0.9369793662196141, 0.9054972200680664, 0.8696107842715612, 0.922836440110339, 0.9389761162533685, 0.9305879712997239, 0.9563007579008783, 0.9130115576847859, 0.9160858973450773, 0.9399978253173465, 0.9309104230735664, 0.8854397291656266, 0.9478802173709355, 0.9012438140606511, 0.9409676860316707, 0.915877922881368, 0.9104320010426309, 0.914403609759903, 0.9291182144179274, 0.8951332454706046, 0.901979832161512, 0.9369132963362045, 0.9043889007790745, 0.9203946857908156, 0.936447124703538, 0.9553946898808425, 0.9380220743321205, 0.947445057440996, 0.8899653711087843, 0.922172159824891, 0.9026789168497905, 0.9380242797837879, 0.8464216768397954, 0.9169684641990171, 0.8982650293587846, 0.9270975321507126, 0.9444229728070102, 0.9443740361960813, 0.933417904046284, 0.9310869126185483, 0.9348131649994875, 1.0, 0.9568232798177652, 0.9165186079584501, 0.9374124397268225, 0.9389413705420353, 0.9455902858201757, 0.9160177250492312, 0.9089238709408838, 0.9314451485806864, 0.9421426832371754, 0.962756998733024, 0.9213323862467099, 0.9248799929408213, 0.9027863244703767, 0.8934847347291166, 0.9060257446202863, 0.8865005597686798, 0.9152706112858042, 0.9385757727148993, 0.957208726047359, 0.9247261401389186, 0.9343763282049864, 0.9068725016658234, 0.941315285849395, 0.9231219943585378, 0.9250449560893573, 0.9136780015837147, 0.9509078458739689, 0.9374610477211229, 0.9222560362818365, 0.9097881719991638, 0.9258054747687671, 0.9294325428819363, 0.9164444690080724, 0.9292481784060231, 0.9204204002714255, 0.9412016518430415, 0.9290439699345263, 0.9202481273716467, 0.9033363117604671, 0.9353650192094756, 0.9083734369911938, 0.8726103194897817, 0.9447284420885795, 0.9002620093113014, 0.9221394597164954, 0.9128482696682095, 0.9317620930281785, 0.911677892716424, 0.93609225395754, 0.9144339440084466, 0.9117052908864965, 0.9216040456266708, 0.9317848196958439, 0.950209359039736, 0.9122801772482163, 0.853101046921035, 0.9028099051065704, 0.9182278356564922, 0.8894024185566582, 0.9286074136336274, 0.9564399957395701, 0.930510522057792, 0.9517102666608077, 0.872740675839218, 0.9328153128711393, 0.9158006719779632, 0.9158680799679346, 0.9262037750360317, 0.8834501852419785, 0.9277807335807635, 0.9177024399526024, 0.9365617366683018, 0.9341113368726711, 0.9407007322582647, 0.8981872854104226], [0.959546618546236, 0.9254899723979749, 0.9234306585588902, 0.9378689545601755, 0.9365102430184788, 0.9648144504922472, 0.9302016408531868, 0.9057946908801072, 0.8936433034077085, 0.9283733359923881, 0.9395699780849099, 0.9028604512403884, 0.8837345380671328, 0.8970833380371979, 0.8788017833521952, 0.9062528991346671, 0.9303492660910555, 0.9120097073558402, 0.8844994884963716, 0.923773325542867, 0.9364744030522453, 0.9216578512304132, 0.9439384618706872, 0.9263144203018222, 0.933683533449034, 0.9455819220785642, 0.9457932315434795, 0.8946640844952625, 0.9412866728011889, 0.9220516846906663, 0.9309263872322335, 0.9292482579828121, 0.9226903360495091, 0.9120274261677641, 0.9215815002065352, 0.8872293408251273, 0.92388542427802, 0.8980797428864054, 0.900900225384589, 0.9304186465790942, 0.9383903236790319, 0.9498577204308482, 0.9304903662613105, 0.9326945814631589, 0.8811041553434815, 0.9384303166462908, 0.9060711970218109, 0.9290997705821683, 0.8650188296444692, 0.9135276836838739, 0.875301068958394, 0.9122435200510386, 0.9114867483684977, 0.9528003344463905, 0.9411402957891332, 0.9037687381308022, 0.950993432111089, 0.9568232798177652, 0.9999999999999994, 0.9336867445900288, 0.9415652083581576, 0.944117608345371, 0.9516053727080971, 0.9216745309157134, 0.9196635040531222, 0.9283671029998812, 0.957023330512803, 0.9521971851978898, 0.9313429914968573, 0.9286331946037882, 0.9050328053881234, 0.8925698104198142, 0.9079539074327002, 0.8863422520068329, 0.8664254756898365, 0.9418298217704836, 0.9426507271284035, 0.9358853295311398, 0.9400207054377766, 0.9081723669239228, 0.9344283924594923, 0.9190012193389461, 0.9237519201125279, 0.9295005617921154, 0.9388626505243423, 0.9269895973794525, 0.8957451977305627, 0.9088546040916745, 0.9375422978067918, 0.9400969134454188, 0.9065846732592009, 0.9558310561253751, 0.9065848818949609, 0.928402629988981, 0.9297540047032775, 0.9285532638437555, 0.907845460053744, 0.9455603787308753, 0.9128969950715746, 0.8770264337793514, 0.9617877526545772, 0.9080478510090593, 0.937714119923604, 0.9261397403780234, 0.9096981178559511, 0.9217335257344466, 0.938811068384093, 0.9160858409889336, 0.923988939713592, 0.9265516748428987, 0.9093976736334756, 0.9396326174065887, 0.9213387373418739, 0.8224679961415043, 0.8848491560050022, 0.9074505272891431, 0.8877753108647392, 0.9293942663296301, 0.9551480380275106, 0.9243404850560363, 0.9255738080017266, 0.8692310202648609, 0.9333531620831615, 0.9021504440812226, 0.9078627383233686, 0.9274476640653587, 0.8822540744127585, 0.9125528726965147, 0.9198040727102659, 0.9395960156849297, 0.9179823351803269, 0.9367045941571741, 0.8836437146835309], [0.933868659201277, 0.9164588044356394, 0.9056667036264939, 0.920421578304668, 0.8964223190023702, 0.9191048828918628, 0.9362126055656834, 0.9074190940173, 0.9133087705173122, 0.9133262782336052, 0.9249203758333934, 0.9452824424333347, 0.8976532277702608, 0.8796404014624283, 0.9203321310058465, 0.9275556141742689, 0.9040010771562108, 0.9213775569549905, 0.9346369673041185, 0.9361593087913679, 0.9088194612459825, 0.9142582238586354, 0.9174130222493965, 0.9269627423430927, 0.9459401341617715, 0.9434084124401325, 0.9350077630126913, 0.8950087537436974, 0.9538556141560338, 0.8976589831007763, 0.9246659305478161, 0.9068346843622144, 0.916201887221806, 0.9192686705212415, 0.8681016985183726, 0.8860940054948031, 0.8832607771378762, 0.8642479140751819, 0.914425498672736, 0.8955082886038893, 0.9534937160645196, 0.9353418684487969, 0.9092722067472725, 0.8931367852747938, 0.8446914326256106, 0.9295913790621999, 0.9054821885347019, 0.9073600473209739, 0.9144356460261053, 0.8836163920998215, 0.8887837060208252, 0.9141617265414343, 0.9106358343703608, 0.9299724106203838, 0.9083480584874043, 0.9023285397903571, 0.936386506110143, 0.9165186079584501, 0.9336867445900288, 0.9999999999999993, 0.9664273487865628, 0.9253030534517954, 0.9427978869989272, 0.926684035743363, 0.8941480577960823, 0.9452638420572304, 0.9269070226143431, 0.9154431818939556, 0.9281643835784213, 0.9278917771515964, 0.8858539901592613, 0.9308824396617338, 0.9115015971205622, 0.872880301948669, 0.8465357854666902, 0.9267418926560482, 0.9192689247083, 0.9557321624208635, 0.9248089064303124, 0.9046943642404361, 0.9457177119062145, 0.9035366401203152, 0.9168073065945992, 0.9196294361043329, 0.9382200952593838, 0.8909847493226681, 0.8873809986871053, 0.8836130622060552, 0.9404759947576559, 0.9503442025519058, 0.943424389556837, 0.928558270073496, 0.8995664066288226, 0.8942548198824234, 0.8976458994938754, 0.9122191435583357, 0.9255725281032826, 0.9270576385466804, 0.8850983762084734, 0.8904388767406937, 0.9446421203948779, 0.9405086583901576, 0.9249589245961932, 0.9231505433560154, 0.9110933567563051, 0.9203125292092011, 0.9120879051173534, 0.898117914786696, 0.9143503449699215, 0.918630032175418, 0.8839017984469781, 0.9247414058296121, 0.9310750242928476, 0.8127894754573799, 0.8930760746764014, 0.8839863385213016, 0.8823015964769474, 0.9177024179537602, 0.9351184466786082, 0.888520661397841, 0.913746881330656, 0.8824646215965536, 0.9267795206217726, 0.9242058161862131, 0.9136077637627221, 0.9087624080919481, 0.8431650194463088, 0.9007878483632467, 0.9281519104115445, 0.946751818649736, 0.8941409306008805, 0.9054460824802165, 0.8452282887036849], [0.9499038678844024, 0.9108404361851593, 0.9222934298948843, 0.9352665661969765, 0.9083985569104159, 0.9221157797621089, 0.9309470994871752, 0.8982189305266757, 0.9330423666552898, 0.9249005319696351, 0.9364773907197577, 0.9088509656300915, 0.8926999201738195, 0.9007625450362614, 0.8930159679944781, 0.9208832838904892, 0.9135156895766976, 0.9224384838192806, 0.9247274947066393, 0.941135055592698, 0.9143305878679021, 0.9234711147478326, 0.930318052436655, 0.9310326673690321, 0.9287312900006591, 0.9489317987199241, 0.9294458828692861, 0.9070827587146003, 0.9587385103523385, 0.9058590597339973, 0.9370180283341287, 0.9147947293052816, 0.9161251843305639, 0.9255852577936912, 0.8779941053282333, 0.9052738125110712, 0.9068369080965801, 0.8868815095570193, 0.9097086493382853, 0.9076131712738886, 0.9619862135195429, 0.9451515676289755, 0.9280460347679791, 0.9093218476471592, 0.8704161422268888, 0.9353815332686602, 0.9223314689967025, 0.9314048703966121, 0.8714984654305109, 0.9000578898488554, 0.8886239862781027, 0.9267520362671469, 0.9225695311821849, 0.9405151396570143, 0.9184876086012647, 0.9202469759715826, 0.9476791387481697, 0.9374124397268225, 0.9415652083581576, 0.9664273487865628, 0.9999999999999994, 0.9401491373575133, 0.9530825377627294, 0.9165307329751949, 0.8905912944808597, 0.9583607631906758, 0.9264953861503158, 0.927154324554181, 0.9458257829675518, 0.9159814210670739, 0.8942425937224345, 0.9118184337935277, 0.9323569867150169, 0.8836944301402079, 0.870472980240806, 0.9393391815895479, 0.9378147046884823, 0.936359056436423, 0.930055531264258, 0.9111756896844703, 0.9561582137753173, 0.9201149733105559, 0.9186539453968849, 0.9189904198955251, 0.9518448384502417, 0.9059541372276371, 0.9076396869242929, 0.9083655079385735, 0.9497638147519596, 0.9450357125919429, 0.9291795798793254, 0.9312376717553335, 0.9158232049587598, 0.9162996018422364, 0.9145231614426605, 0.9138478343505866, 0.9172037683780295, 0.9260220699836155, 0.9033624380277363, 0.8972486978314587, 0.9483740913624954, 0.9217964843639976, 0.9191381582002303, 0.917884919665881, 0.9285243706218717, 0.906882541922466, 0.9274736994123185, 0.8997978173263665, 0.9215938858399891, 0.9100116359839248, 0.8983424967206202, 0.9333628564472598, 0.9255111399684522, 0.8135252837722678, 0.8988191581991094, 0.9035606383989013, 0.8903473549634586, 0.9204420490500005, 0.9355882368877102, 0.9107851301868062, 0.9189485161847962, 0.872982854961371, 0.9262079644080159, 0.9322546572260723, 0.9323835110673885, 0.9209367007759572, 0.8545164994829045, 0.9166998930207999, 0.9173660628140062, 0.9461440498182645, 0.9114626193062835, 0.9195244444775238, 0.8605136858827134], [0.9480027948922807, 0.9177869181810506, 0.9209338584676985, 0.9224908557252458, 0.9068328354332449, 0.9289717290703814, 0.94596218498969, 0.8792069924352629, 0.9150237643647466, 0.9343542893486099, 0.9300265292494589, 0.8985270394615079, 0.8842327983277157, 0.8763138507138882, 0.8877759677563541, 0.9112217167168055, 0.9321219009935522, 0.9168935833709014, 0.8936401390078836, 0.9330285360653086, 0.9335148006536209, 0.9320739143873659, 0.9262937317604251, 0.928146716610359, 0.9185869223512604, 0.9466674060957827, 0.9393317954971225, 0.9156132252821173, 0.941949739745367, 0.9349749265526105, 0.9491170393667221, 0.9241917504330426, 0.9153076089401393, 0.9353207230387409, 0.8810935216102569, 0.8901613214085313, 0.9012231635923447, 0.8882769062622626, 0.8958010753410979, 0.9166403097287892, 0.9449600121657556, 0.9512525639501619, 0.93071887721336, 0.912086197325455, 0.8930407246027788, 0.928740695583299, 0.925066079826064, 0.9347982159287901, 0.8649897584454984, 0.9152404564624325, 0.8844971159783731, 0.9310102306735618, 0.9263313245928846, 0.9425655872707195, 0.9300264003005414, 0.8887745259406334, 0.947947833349569, 0.9389413705420353, 0.944117608345371, 0.9253030534517954, 0.9401491373575133, 1.0000000000000007, 0.9545717473627197, 0.9264887157166506, 0.9061922303454648, 0.9311904371458002, 0.9388020524656823, 0.926040304291972, 0.9224028997094413, 0.9143976188851546, 0.8730873340604413, 0.901273106096539, 0.9203349155172962, 0.8627111678430435, 0.8649287476421051, 0.9356140546171688, 0.9464077076443249, 0.9310962234472282, 0.9503787841251353, 0.9110031618727241, 0.9297273090061036, 0.9550323946586987, 0.9197947273469222, 0.9219369126771078, 0.9383509766923472, 0.903528468731051, 0.9116639574912936, 0.8926032492095648, 0.9424613730963035, 0.9429103763005247, 0.9127734140378454, 0.9493023172035807, 0.9132003222812696, 0.9141425297665807, 0.918059469442329, 0.9115170113336379, 0.8941965374503907, 0.9491631220593033, 0.911548202328523, 0.867371161200045, 0.9399274571756759, 0.9161488032133418, 0.9224320754722592, 0.9106401787554049, 0.9157912290842186, 0.9230576669450514, 0.9366395129734033, 0.9225323143488595, 0.9176132704959465, 0.9267324854565212, 0.896416538884371, 0.928957248250094, 0.9393142941509482, 0.7933509011369202, 0.9112571334057887, 0.9078830622595774, 0.9102849796716201, 0.9369148521403028, 0.9278898736695443, 0.9094015457706619, 0.9127147084277941, 0.852634065052832, 0.9404982872894629, 0.9274660822278911, 0.9197339913176209, 0.9091515342201463, 0.8760391604555602, 0.931034830849806, 0.924742841198674, 0.9352075655566565, 0.8936052099420164, 0.9085076620347416, 0.8660489452466735], [0.958614120585834, 0.9206166596095653, 0.9409690394252312, 0.9431349299981695, 0.9280055875157834, 0.9283658879552724, 0.9301450130147719, 0.9087709377069538, 0.9088563246556597, 0.9468686090385726, 0.9322763563909571, 0.9103416554613928, 0.8902643405544508, 0.9188043670304622, 0.8927724826252332, 0.9262396803543886, 0.9549607346653318, 0.9381716896617176, 0.8975017016741136, 0.930467709364849, 0.9512168549843625, 0.9488863101242239, 0.9520019400540058, 0.9646849589052664, 0.9230157373243091, 0.9446281969234195, 0.9553903366400469, 0.8965828759070454, 0.9557517241226493, 0.9276350949739106, 0.945072716547255, 0.9450502090778743, 0.923120183412013, 0.9334813302053466, 0.8906896070138525, 0.9019478667291234, 0.9247048784066922, 0.8929813181417586, 0.8920190449766245, 0.9332365082377583, 0.9478961896920332, 0.9580076421473107, 0.9559268815598939, 0.9307258203211037, 0.9006910507927104, 0.9355316265928106, 0.9175485874849351, 0.9452789855018746, 0.8771530634867883, 0.9339045324157536, 0.9031744329202307, 0.9332461887846897, 0.9287210765113839, 0.9707770597390113, 0.9403328041360479, 0.9129999336731842, 0.9623839316881262, 0.9455902858201757, 0.9516053727080971, 0.9427978869989272, 0.9530825377627294, 0.9545717473627197, 1.0000000000000004, 0.9164541361848023, 0.9165634962316178, 0.9504509909564411, 0.9555343010995714, 0.9426293272439124, 0.9424054625130888, 0.9220111406583256, 0.9113272491467582, 0.9199681145276701, 0.9199423121617596, 0.8939482728265088, 0.887739436989601, 0.9743354231447487, 0.9569946220272793, 0.9302766740302402, 0.9482725802189813, 0.9288560101515745, 0.9390081746642842, 0.9317144943033104, 0.9226364314299207, 0.9245988742370204, 0.9632373138368984, 0.908181156414597, 0.9125831614949063, 0.9193030789969006, 0.9406888165568987, 0.9564696476231821, 0.9143204790370358, 0.9521833883451597, 0.9214895284525944, 0.9226834802685239, 0.9323426500314378, 0.9310612776421326, 0.9196022426445633, 0.9460125159413371, 0.9220819963920734, 0.8947895815602087, 0.9521964092353077, 0.9111048144648338, 0.9501643775802691, 0.910318938056176, 0.9144378733001945, 0.9236263533074515, 0.9493724140833353, 0.9345579120389572, 0.9341734606333496, 0.9318302545866491, 0.916335096950366, 0.9458895517070187, 0.9296703128319461, 0.8344508554972377, 0.8946076565769643, 0.894828239404382, 0.909628283186466, 0.9441133009658413, 0.9417970452696772, 0.926211843586314, 0.9187579701243942, 0.8790683590915862, 0.944428908295639, 0.9312773197195717, 0.9322350211741388, 0.9394178306726054, 0.884922613614272, 0.9369209175182247, 0.9134267803588951, 0.9419244240462907, 0.908058046322334, 0.9332477060874916, 0.8791240087268584], [0.9251362405076575, 0.8962641265449609, 0.8979372466178023, 0.9049357369509092, 0.9077418239585219, 0.9109384096336854, 0.9583307238570021, 0.8714071961649831, 0.9047572232610358, 0.9226970566547559, 0.927890039709858, 0.9206131742136076, 0.9010865925875282, 0.8460389138809287, 0.8743024933326615, 0.9050528102525129, 0.9269834347196799, 0.8762490089926867, 0.8920278571510988, 0.9552210084851867, 0.9178333364913641, 0.9269753181296684, 0.8953260661592098, 0.8961011384668659, 0.9083473834694905, 0.9556438014539507, 0.9314023504401279, 0.895367969014268, 0.9145577636274338, 0.9051259474251663, 0.9432266816363633, 0.9096901771393577, 0.9127286541873777, 0.9162731366446125, 0.8599825504919927, 0.8819457028903676, 0.883529208333317, 0.868222296902113, 0.8873501363615233, 0.8765209517296775, 0.9269217567654623, 0.9301387703322981, 0.9053463318051382, 0.8803241528098678, 0.8485808648444294, 0.9147248590145343, 0.9032232370822796, 0.8958782487000979, 0.863573759292324, 0.9029444077773593, 0.8729422979635353, 0.9192202237948011, 0.9086381334913327, 0.9255659501398512, 0.9056285511134121, 0.8563833065798919, 0.9348284760957994, 0.9160177250492312, 0.9216745309157134, 0.926684035743363, 0.9165307329751949, 0.9264887157166506, 0.9164541361848023, 0.9999999999999997, 0.9038840165216249, 0.9210484248155764, 0.9260774743878484, 0.8936099083919874, 0.8967989972670983, 0.9025798109405672, 0.8483399430394382, 0.9203944256044573, 0.8945088274705475, 0.8272411112558629, 0.8416770639741057, 0.9120236827912089, 0.9169610339138461, 0.922003750110041, 0.9180618538837806, 0.9341319955596217, 0.9148221218512658, 0.9259144800188939, 0.9048831004965454, 0.9285944420424137, 0.906437298340432, 0.8738917584540347, 0.889771851996368, 0.8599191946621974, 0.9310573500614523, 0.9273245518243015, 0.9085194014687601, 0.9336862779464185, 0.8865221806764989, 0.8897318970599399, 0.8809379770473246, 0.9170878357115614, 0.8932936536182802, 0.9419357526718577, 0.8599918716996066, 0.8485094673491889, 0.9130344152148819, 0.9409476580063968, 0.9159800423475802, 0.9195026388584021, 0.9007696726960859, 0.9363132429846079, 0.9306639212377743, 0.9119845024273882, 0.889717051569972, 0.9596695070223422, 0.8716508996965716, 0.9014836613302424, 0.9265985545128796, 0.7622910748888714, 0.8962534873545306, 0.9057536431601811, 0.899195851327492, 0.9276953349169967, 0.91901028332204, 0.8886451179978105, 0.8946497210577891, 0.8427459838530884, 0.9445805642653997, 0.9149955147120208, 0.9036278070975923, 0.8856244520299487, 0.8796768550479109, 0.9138671017467339, 0.9420431201703277, 0.9249934261060863, 0.8680729561025308, 0.8700517881341194, 0.8418319120574804], [0.923783326144968, 0.8941337730286933, 0.8980285099886314, 0.9209697259775562, 0.8904255189667919, 0.9086253316263038, 0.927855567562627, 0.8389605097583354, 0.8477742455771359, 0.9194239500387542, 0.9382599584502717, 0.8810319902620088, 0.8600044941072342, 0.8362353406422366, 0.8541764883060111, 0.8823362577027468, 0.9475625139139561, 0.8709848731178336, 0.8337425084765332, 0.9013275864144579, 0.9436291116075339, 0.9395609282813987, 0.9114287552328313, 0.89258337266078, 0.9121755499522225, 0.9210976940312204, 0.937810970808197, 0.8674940656609975, 0.9204449567872313, 0.9006489400299631, 0.9218478423585935, 0.8841868018879605, 0.9073109643313906, 0.882025292987711, 0.8555604604874696, 0.8506228457982741, 0.8749837302158733, 0.8822870638917785, 0.889182489981348, 0.8954818941788028, 0.9024333718641103, 0.9163309722584569, 0.9373319957849426, 0.892295969197315, 0.8558630819759884, 0.900861743304277, 0.8890877874538061, 0.9007463406138414, 0.8499053807515796, 0.9322310366189512, 0.8543636625703234, 0.8940599591632826, 0.8791734324270063, 0.9246491689813494, 0.9077702144965875, 0.8663728533168686, 0.9275840068965118, 0.9089238709408838, 0.9196635040531222, 0.8941480577960823, 0.8905912944808597, 0.9061922303454648, 0.9165634962316178, 0.9038840165216249, 0.9999999999999994, 0.8849496660400713, 0.9328322360921184, 0.9126663261195971, 0.8900387037789754, 0.8977382354664758, 0.8485758211818585, 0.8983076894095836, 0.877644468346972, 0.8255412951233927, 0.8464578786916075, 0.8963330268451541, 0.9169969197032757, 0.9105995827511367, 0.9228070517924774, 0.9099869310857551, 0.916313631087403, 0.9020903397254315, 0.9087658745103606, 0.9190081802029946, 0.8999113279885617, 0.8623415115675551, 0.891637368463134, 0.8495995516999884, 0.9107102110336069, 0.9076539350232288, 0.9150805959168666, 0.9190724919670854, 0.9081343582640007, 0.8824480852231003, 0.8907883126487989, 0.9491726437198761, 0.8775971276132122, 0.9331312131110703, 0.8955825254237713, 0.8394375642654551, 0.9051019837062328, 0.8985968921167884, 0.929487194192876, 0.9297339951653452, 0.8740359139032401, 0.9272663920363853, 0.9231460474833479, 0.8952725686910337, 0.9022534517255867, 0.9276953314779727, 0.8724811695364929, 0.8980391246940536, 0.9119276770627331, 0.8024242320666949, 0.8595547095780541, 0.8798610796237554, 0.8614182629469599, 0.9693909992156391, 0.9227428401959411, 0.8760666944617785, 0.9119014836186875, 0.8136847508575469, 0.9244575521840335, 0.9018961839908366, 0.8707292451383729, 0.8829994067336735, 0.8753974865716189, 0.9109873465383362, 0.916561397126302, 0.9203301306771489, 0.8672208402564413, 0.8907761130353743, 0.8778572565793648], [0.9428324095298006, 0.8992758777363963, 0.9239389558093174, 0.9340824812713747, 0.9163378906676373, 0.9036058592065161, 0.9299639315209622, 0.8797373618002136, 0.9324703022900147, 0.9146219494247765, 0.9285565820483727, 0.8999572152502787, 0.8938804099204888, 0.9059203675158528, 0.9068075875182271, 0.9365021486345739, 0.9180968349369624, 0.9374123613210792, 0.9367726139202721, 0.933549231490411, 0.9134760250971741, 0.9335299214387629, 0.9213882220271066, 0.9424688815395528, 0.9196738734536223, 0.9461890872385017, 0.9151905750449589, 0.904357739088954, 0.9551481174825598, 0.9131114166147206, 0.9395636765962392, 0.9141812861050127, 0.8999552293123869, 0.9295342622733382, 0.8665904939939109, 0.898153859479745, 0.8924650087970727, 0.8834333938854516, 0.8991603584577895, 0.8869024714120258, 0.9673861241544701, 0.9435187085645362, 0.922890554167192, 0.9193752232992337, 0.8789467064911536, 0.9228587020652907, 0.9241913499117289, 0.9200922040182347, 0.8811885758508275, 0.9046551124477255, 0.9214478600282652, 0.9238289982639694, 0.9223333588359047, 0.9372507786831292, 0.9106176544453312, 0.904044798168498, 0.94225909738133, 0.9314451485806864, 0.9283671029998812, 0.9452638420572304, 0.9583607631906758, 0.9311904371458002, 0.9504509909564411, 0.9210484248155764, 0.8849496660400713, 1.0, 0.9212055066387058, 0.9133903995932839, 0.9241797178383603, 0.9110885288588633, 0.878409241348133, 0.9171433743568594, 0.9168474965800752, 0.8563155967494749, 0.8804829011040518, 0.9400134452523995, 0.9393066131155039, 0.9355021801547085, 0.9171961858301427, 0.9283641855085412, 0.934816552388739, 0.9263915584916029, 0.9088707876489559, 0.9047100779034516, 0.9308399143179186, 0.8944130237822543, 0.891212791851516, 0.8932752604869326, 0.9428529874054061, 0.9528734036185533, 0.9270006854109101, 0.941740060968855, 0.8962429610348887, 0.9055835403661573, 0.8992100227918403, 0.9121327196869282, 0.9112489930677937, 0.9164214804734739, 0.8888698302834832, 0.8978902497640999, 0.9363647054525974, 0.9145252072787855, 0.914125093128044, 0.9173051987787281, 0.9264563146354295, 0.9143176905046806, 0.9235674603112317, 0.887207280430753, 0.9019740382966426, 0.9143742421155464, 0.9135865503339373, 0.9364625898935415, 0.9173017222802641, 0.7891383868147396, 0.9065653913654711, 0.8930367980308476, 0.909376160147503, 0.9116982232964481, 0.9390268939568046, 0.9009551068772768, 0.9219414359219472, 0.8697844940711829, 0.9364225684836828, 0.9314265310495342, 0.942522453213321, 0.9075030503321382, 0.8672097990074121, 0.9178331547230448, 0.9115674364684193, 0.9408165606729642, 0.890303289876758, 0.9068191455916568, 0.8549200502444041], [0.9553505042089653, 0.9275408610980846, 0.9229535761596672, 0.9322197661824433, 0.9222766579053958, 0.9412448869302958, 0.9357728344987719, 0.8919329658304288, 0.8994878093673689, 0.9451974231815699, 0.9329824867537269, 0.9011045411635938, 0.8708798981122157, 0.8894628545468098, 0.8914265392638699, 0.9015784587012705, 0.9512626856230365, 0.9055806064504378, 0.86637188857623, 0.938595561966532, 0.9455163530671327, 0.9486444512666985, 0.9535112363831836, 0.9184914857662857, 0.9270331193355502, 0.9491159475264435, 0.9587862779786276, 0.9014419398591677, 0.942594457143235, 0.9210521124316352, 0.9403764950216953, 0.9250012240201004, 0.9190865494907163, 0.9227398614225502, 0.8972515423663043, 0.8787906592469765, 0.9012204342510081, 0.9016786555266127, 0.8984262021002349, 0.9412630094007456, 0.9371516097222974, 0.952123649514497, 0.931091998368934, 0.9201847689427786, 0.8823442522440048, 0.9244245850271107, 0.9093627673559023, 0.9345699156915895, 0.8738166280839726, 0.92224421138058, 0.8955850482366048, 0.9243086050397159, 0.9075123178079614, 0.9611766251368133, 0.9408511579904941, 0.875961219131154, 0.9557450453372769, 0.9421426832371754, 0.957023330512803, 0.9269070226143431, 0.9264953861503158, 0.9388020524656823, 0.9555343010995714, 0.9260774743878484, 0.9328322360921184, 0.9212055066387058, 0.9999999999999997, 0.9358751684631461, 0.918063385949821, 0.9181969143423231, 0.8753346878139135, 0.9170660184649082, 0.9085220348909899, 0.8573704730448659, 0.8839477413340805, 0.9466795086355622, 0.9383822554572456, 0.9322337188251143, 0.9459529235486855, 0.9310854721807396, 0.922965657962115, 0.921337620101453, 0.9273435202978466, 0.9284749089651464, 0.9280225002054483, 0.8977187250502519, 0.910781304769804, 0.8741367604560535, 0.937660316104324, 0.9477833239101018, 0.9170465233591637, 0.9522404329248559, 0.9095431599683078, 0.923841321574662, 0.9295414488348892, 0.9403979116964012, 0.9081594856394295, 0.9511466888257033, 0.8992368285784929, 0.8719384004075688, 0.936748393967026, 0.9227970428989689, 0.9546672913560128, 0.9251151114133374, 0.9013368809103177, 0.9264043130110735, 0.9518002564566199, 0.9634610317965049, 0.9210067871366276, 0.9368197050818434, 0.897981157814921, 0.9412375684262011, 0.9266557254064469, 0.7999406504593167, 0.8676511273895872, 0.9109484403612859, 0.908322758208864, 0.943668274252622, 0.9457603294979171, 0.8986984902842537, 0.9217014773776783, 0.8489810934907757, 0.9522358817148291, 0.91382423990067, 0.9042613769955947, 0.9027201264220224, 0.8925413720767308, 0.9346832482886964, 0.9308428322455508, 0.9386647621446924, 0.9074747211506365, 0.9181049542567766, 0.8950955616036553], [0.9477742787554353, 0.9024872965260385, 0.9287784350635546, 0.9410583538507866, 0.9385993337392218, 0.9309915142512679, 0.9047509267231909, 0.918449383876464, 0.8708269921315477, 0.9301066393521781, 0.9263263517460725, 0.8788234561084602, 0.8834680825270596, 0.9079524274421243, 0.8591492629683738, 0.8989976578899567, 0.9224376529233613, 0.8983137467878277, 0.8554025238015277, 0.9079549274877903, 0.9384834207155708, 0.9135981502112117, 0.9534396894513233, 0.8977558138531959, 0.9149244065178211, 0.9309139303550893, 0.937104202121831, 0.8895876815446275, 0.9406451052727035, 0.9040109849141117, 0.9167187913504103, 0.9163733622467669, 0.9141658216418793, 0.9073372315050935, 0.9285522273427889, 0.906790981601876, 0.9032971552678538, 0.9030422706800707, 0.8993406889235058, 0.9217792092623112, 0.9151427287444214, 0.9466656644951436, 0.9396140070630803, 0.9413386494685114, 0.8765037010942291, 0.9266395901652261, 0.8967211884045867, 0.9477247907431146, 0.8468798714003148, 0.9063526878780349, 0.9001262003648458, 0.9227130134749925, 0.9025959300061159, 0.939717139529813, 0.9515425986816948, 0.9401686255288331, 0.9333320977937833, 0.962756998733024, 0.9521971851978898, 0.9154431818939556, 0.927154324554181, 0.926040304291972, 0.9426293272439124, 0.8936099083919874, 0.9126663261195971, 0.9133903995932839, 0.9358751684631461, 1.0000000000000009, 0.9376514106338636, 0.91598663579638, 0.9126162647571227, 0.8771494441598352, 0.8895778350817277, 0.9177602715490787, 0.8828612955419799, 0.933095341157486, 0.9487657930323878, 0.9254387307184473, 0.9303607612301852, 0.8903470366190576, 0.9415453686479062, 0.8975032354383772, 0.9150188605127096, 0.9139944201327447, 0.9540007547543722, 0.9485271044382004, 0.9279390091962545, 0.9086676080026619, 0.9224733750116195, 0.9259237312697377, 0.9080864235551219, 0.914829466119075, 0.9363425871936948, 0.927001949200004, 0.9091443814940878, 0.9143088141647777, 0.8995900662042109, 0.9341338383199324, 0.9282505614579344, 0.8729507438319489, 0.9434587854145859, 0.8954319423558396, 0.9233656614403729, 0.9088579954017092, 0.924164650107747, 0.9060542656045452, 0.9093637563172923, 0.8955585786531242, 0.9304155205966481, 0.9114029575168645, 0.9173702571690059, 0.9440531138390202, 0.901851315630102, 0.8670936743291426, 0.8874604614155085, 0.8929721013085823, 0.8713712994743453, 0.9187968971034517, 0.9514523436836332, 0.9199060881711755, 0.9326006339046773, 0.897813245189296, 0.9300075469310884, 0.9084914224420795, 0.8930153501190496, 0.9309248901965405, 0.8780370854125212, 0.9186718663042048, 0.9003664417709473, 0.9290829967144754, 0.9273385691511746, 0.9488246169281798, 0.9257970457540571], [0.9258416187325023, 0.899406298003143, 0.9416009992934024, 0.9297633179926119, 0.8956928581360889, 0.9112096465505606, 0.908045696595699, 0.8948962689884713, 0.8971758551125927, 0.9148593514558019, 0.930447046636283, 0.8966988518816844, 0.8953917937898253, 0.888097241456703, 0.8500631648533038, 0.919825799735312, 0.9075314174730771, 0.9036875235684737, 0.9009203041245064, 0.917411361838731, 0.910834675059997, 0.9106557636744861, 0.9130234186819141, 0.9206518507556123, 0.8998036387572856, 0.9329772784340414, 0.92957920284393, 0.8746891251023183, 0.9295958241179451, 0.8934344212334173, 0.919202093368805, 0.8979256366779046, 0.9085891969034205, 0.9127406865719963, 0.9078598263934512, 0.9075504885628276, 0.9127132588336981, 0.8592192121757226, 0.8709954289528573, 0.8988324774260994, 0.9294073110308727, 0.9320425583996261, 0.9279301308855786, 0.8886099279657721, 0.8554465179376357, 0.9501284872462779, 0.8945129395184088, 0.9097779160399211, 0.8444566074474334, 0.8836662434772444, 0.9005479568322866, 0.9215618848998124, 0.9011228504978264, 0.9304909339679741, 0.9237827636101805, 0.9107662068034359, 0.9398239914443375, 0.9213323862467099, 0.9313429914968573, 0.9281643835784213, 0.9458257829675518, 0.9224028997094413, 0.9424054625130888, 0.8967989972670983, 0.8900387037789754, 0.9241797178383603, 0.918063385949821, 0.9376514106338636, 1.0000000000000009, 0.882323142562745, 0.9203033748598174, 0.877174615265955, 0.9071657676387959, 0.9172602484802301, 0.858181295119839, 0.921294672688189, 0.9190483616238758, 0.9146023884950585, 0.9200424171996623, 0.8871438419057919, 0.9301489141727524, 0.8976518951892476, 0.8980905378335127, 0.9271434983637372, 0.9463737951124974, 0.8971838719209365, 0.9095371822035371, 0.9162752659498989, 0.9212399135765722, 0.9339666502898476, 0.8866406731169163, 0.9213373182440385, 0.9339159952870221, 0.9135437901049253, 0.8979031938926283, 0.8972844059113557, 0.8967472832935499, 0.9221206700958394, 0.9150936259193274, 0.8759621460513577, 0.9456736675341193, 0.900620235978819, 0.9039502166685982, 0.9068423816907663, 0.9054088651245034, 0.8953342836252693, 0.9118866793115938, 0.8875891820615706, 0.9161177465458269, 0.9163015030864526, 0.8796184202634942, 0.9307156065100388, 0.9047195228005409, 0.8520708770009848, 0.8765139006627545, 0.8874154211603311, 0.8687683696855283, 0.9082801033868124, 0.9127235242755515, 0.9000514524815049, 0.8869414778297129, 0.8925233439916525, 0.9101109112037046, 0.9068632744788931, 0.9223189316810743, 0.9443295676471541, 0.8605066558187155, 0.8877630483108969, 0.8884481639557041, 0.9367086591967206, 0.8942435629227055, 0.9199796053113019, 0.8635670628378098], [0.9233902489293847, 0.9115087145246366, 0.8874370139693374, 0.902534049785337, 0.8940520815967766, 0.9027967467090319, 0.916233690076594, 0.8814922502185174, 0.8998402930742209, 0.8995120300334274, 0.9000180859700159, 0.8890879168216105, 0.8601622821638567, 0.8514695577610722, 0.9010930451704919, 0.8810314307815471, 0.9042856859381448, 0.9052705330199418, 0.858281076868796, 0.9125575198189383, 0.905903516473906, 0.8985003436880658, 0.9182121631502784, 0.8982237326892787, 0.9192447012242434, 0.9169538722149961, 0.9067422045795377, 0.8733895342071469, 0.9161174309618907, 0.8962349268896779, 0.9048460017626663, 0.9072390503321355, 0.9143715393131114, 0.908053591238446, 0.8872237105693104, 0.8665365786773509, 0.8794108796259728, 0.874876623990013, 0.9112319248898586, 0.8709016961580883, 0.9159401573705521, 0.906425810589758, 0.9059630071261305, 0.954948600638971, 0.8628339709282149, 0.9021528052401977, 0.8877189072084066, 0.8997461571951384, 0.8557545625954697, 0.8931530665966212, 0.8607036271604716, 0.9053069735300312, 0.9022976669829106, 0.9235562417195409, 0.9042315262478929, 0.8754298786660666, 0.9281679119257598, 0.9248799929408213, 0.9286331946037882, 0.9278917771515964, 0.9159814210670739, 0.9143976188851546, 0.9220111406583256, 0.9025798109405672, 0.8977382354664758, 0.9110885288588633, 0.9181969143423231, 0.91598663579638, 0.882323142562745, 0.9999999999999996, 0.8732010981059176, 0.90717043327041, 0.9196988167499554, 0.8544382605609698, 0.8639525791842457, 0.9102366007737036, 0.9168802844188145, 0.9156075097679114, 0.9065714742679378, 0.9053465043428022, 0.9159383898679293, 0.9032169614389912, 0.8993629052492074, 0.8940640884957015, 0.9114226646905006, 0.8972164647122919, 0.8653877109814232, 0.8890519611878166, 0.9232562748850992, 0.9075879786813157, 0.9130375086034801, 0.9055395485944099, 0.8719077918064082, 0.8812932229998136, 0.8975925424889121, 0.9099827300579961, 0.8918164304314137, 0.9114211196659596, 0.8866892617086104, 0.8646242042265402, 0.9112643370898219, 0.9021318902822132, 0.9204666519761753, 0.9040766080769683, 0.88816287883007, 0.9020001771909699, 0.9049263892069538, 0.8825729339749058, 0.91215869260164, 0.9005494093833695, 0.8876890913431972, 0.9092059055738149, 0.9305323328503361, 0.8041012701403111, 0.8756141341781042, 0.8586038863220403, 0.8743672528773213, 0.9106151316403138, 0.9217410371531035, 0.8910156620460361, 0.9537347123357429, 0.8290502853310959, 0.9180892047173218, 0.9266536499350182, 0.8725534031598201, 0.8872031960203236, 0.8382869853995564, 0.9161614229290264, 0.9154998618385808, 0.9147946174315853, 0.8982503748438759, 0.9026074332708478, 0.8488866342655259], [0.8988434273071643, 0.8765430510538684, 0.9319642892868566, 0.8888497105744652, 0.8858902817594803, 0.8551400002607102, 0.8426832875736593, 0.8781945732091386, 0.8458157471193086, 0.8770870618615639, 0.86449188096592, 0.8759062622502937, 0.888620751677006, 0.8879075250654773, 0.8088872273625971, 0.9001639098842024, 0.8748512016092018, 0.8827759361093144, 0.8555721074342253, 0.8680901563117067, 0.8661728735560874, 0.8605929085754764, 0.9001877693754124, 0.877431234443751, 0.8577032356285523, 0.8773585906825863, 0.8926544722822338, 0.816137051863945, 0.8881352758392276, 0.8557010161630421, 0.8755305945560827, 0.8848327340639475, 0.8765929363846302, 0.8567439061373834, 0.90933304998827, 0.8535064277072639, 0.8736042478322273, 0.8264776879127192, 0.8118370517107548, 0.8881763431851766, 0.8747484653651711, 0.8905792230804838, 0.8912023518514498, 0.8849305443019846, 0.8374749135767319, 0.8870394255683495, 0.8367961938370705, 0.8710599399480904, 0.8176894381443135, 0.8566170292583175, 0.8663961083122059, 0.8661863787543775, 0.881379371868696, 0.9115733589834649, 0.895090598659249, 0.8900313853973293, 0.8915357884285015, 0.9027863244703767, 0.9050328053881234, 0.8858539901592613, 0.8942425937224345, 0.8730873340604413, 0.9113272491467582, 0.8483399430394382, 0.8485758211818585, 0.878409241348133, 0.8753346878139135, 0.9126162647571227, 0.9203033748598174, 0.8732010981059176, 1.0, 0.8355829229436423, 0.8583621329143394, 0.9220836027188188, 0.8347400223380806, 0.8920027511766835, 0.8896851264739395, 0.8570853352302888, 0.8791085478309237, 0.8581627941777211, 0.8733872023574454, 0.8441373319763777, 0.8554895037435257, 0.8623506053529649, 0.9326596856194239, 0.8799618023596857, 0.8555561175476781, 0.9151473738206489, 0.8689044810896747, 0.8859830113150994, 0.8374160629422175, 0.87451144048987, 0.8742047734511409, 0.8957043199107593, 0.8643987687948718, 0.8583985176014394, 0.8807614813547802, 0.8790284824732095, 0.8781112646857414, 0.881859063054905, 0.9285183891537984, 0.8476010203355527, 0.8789456595152196, 0.8408628741448401, 0.8569143023405734, 0.841017282133077, 0.8641466515472225, 0.8505442100695021, 0.888136692958104, 0.8752314201821927, 0.8675607561313, 0.9075900187479682, 0.8654662339419414, 0.9293038286371601, 0.8437208971462341, 0.8309450199166168, 0.8316217890465498, 0.8636523140527975, 0.8812343100667293, 0.889161971454187, 0.8630423587469428, 0.8792499257975934, 0.8816927535965184, 0.8688110929207804, 0.9106007509305192, 0.9346461765175212, 0.8184396848654059, 0.852182991417451, 0.8210752439723461, 0.8776777102490131, 0.8753439586058982, 0.945255918209218, 0.8076389065166284], [0.9120452514382975, 0.888888516953386, 0.8856931113323357, 0.8950122783521938, 0.881661981695332, 0.8862745340884919, 0.9285133714335054, 0.8764394267081637, 0.9042130404997561, 0.9079329545821825, 0.901408165481218, 0.9273903030054658, 0.8802186725538448, 0.8334938187077803, 0.8940445714253666, 0.9238089985322299, 0.9185684691780158, 0.918792644779081, 0.8868319772621702, 0.9228640161964502, 0.9077325768796284, 0.9429988161952728, 0.8964648116493584, 0.9076628405502287, 0.9074747929376539, 0.9268216547385811, 0.9190598858062414, 0.8847642831147309, 0.9296801589157503, 0.8931545645124114, 0.9193032567959694, 0.8866502725765766, 0.8827137404194161, 0.9132455598166436, 0.8333903775790041, 0.8706487655039755, 0.8563659364408865, 0.8446101867266866, 0.8679527233833431, 0.8720079117217182, 0.9298353050166287, 0.9132820536077554, 0.9023209898481407, 0.8887523971687014, 0.8318674878530183, 0.8971561756588637, 0.9003503909680305, 0.8854295624216655, 0.9170281358597951, 0.9114312013738968, 0.8974294591659118, 0.903368656965191, 0.9139907568958437, 0.91988563623084, 0.8923595353439338, 0.8610926610069305, 0.9290019952831673, 0.8934847347291166, 0.8925698104198142, 0.9308824396617338, 0.9118184337935277, 0.901273106096539, 0.9199681145276701, 0.9203944256044573, 0.8983076894095836, 0.9171433743568594, 0.9170660184649082, 0.8771494441598352, 0.877174615265955, 0.90717043327041, 0.8355829229436423, 1.0, 0.9042066541562046, 0.8307785146596596, 0.8540325273108338, 0.9071948885006467, 0.8997392288083833, 0.9203009800920351, 0.9065277889622441, 0.9330121802690977, 0.9073383572030053, 0.8882064699497482, 0.8835423712620044, 0.890370902226684, 0.8973912186341652, 0.8416911144156016, 0.8707273790472706, 0.8362878334762677, 0.9180685859771902, 0.9483569927996922, 0.939766517988041, 0.9243059013581548, 0.8687622915884257, 0.8614342903643856, 0.8786106459275342, 0.9105845315446136, 0.9224372772603344, 0.9208486580152236, 0.876878120404935, 0.8470133818768444, 0.9057439698432417, 0.9148958314748099, 0.9222971789150792, 0.9138887831602858, 0.8867860680396952, 0.9361786994372983, 0.9234399363523306, 0.8958909077311622, 0.8897839841063724, 0.9134546836338225, 0.8584713293801383, 0.902437506557672, 0.9191689744031826, 0.76450059644187, 0.8839502286315271, 0.8760461440849788, 0.8895699958495793, 0.918591969991845, 0.9142159433353938, 0.8556825178393933, 0.9029083447593541, 0.8316735988948455, 0.9251459974541308, 0.9330761966155697, 0.8923548364622351, 0.8668707265889652, 0.8446017883582033, 0.8945003019138369, 0.9196258447430335, 0.91525700581456, 0.8528290549200794, 0.8669390120259849, 0.8287809256109848], [0.9082415987080087, 0.9011514338511694, 0.8876124303019245, 0.9106172820987518, 0.8636321727318779, 0.8916731915079277, 0.9092665692784757, 0.8745958826071637, 0.9528603923443287, 0.8906752686286185, 0.9052522327177556, 0.8948991817958223, 0.8774671507233969, 0.859552374802343, 0.8707345939516383, 0.8974229404121314, 0.8981607461988815, 0.9112983682230665, 0.87319076288577, 0.9368200658013064, 0.8875913446588525, 0.9081859931929492, 0.9010569430881412, 0.894675097145637, 0.8993736745302372, 0.9234471370655709, 0.9121556032020528, 0.8986338020054341, 0.9167718786463439, 0.8959309130947904, 0.9327516341890448, 0.8907558902021216, 0.9115370709583517, 0.9391676167378009, 0.860082224205966, 0.9046099059756997, 0.8716455585901535, 0.8487180280731216, 0.8790433555636644, 0.8842338117536389, 0.9365718526035526, 0.907753773298522, 0.8995098410270164, 0.9005083174824458, 0.8501477372275925, 0.9040896065632222, 0.9216703300044059, 0.8966950850490619, 0.8183200635100569, 0.877204237866639, 0.8680787884782938, 0.9197157552764689, 0.9061417280899886, 0.9184728800982112, 0.9178793092469136, 0.877681165515856, 0.9270716815567347, 0.9060257446202863, 0.9079539074327002, 0.9115015971205622, 0.9323569867150169, 0.9203349155172962, 0.9199423121617596, 0.8945088274705475, 0.877644468346972, 0.9168474965800752, 0.9085220348909899, 0.8895778350817277, 0.9071657676387959, 0.9196988167499554, 0.8583621329143394, 0.9042066541562046, 1.0000000000000004, 0.8725155219103842, 0.8379346154585053, 0.909516847943743, 0.9033014009316872, 0.8878163361302465, 0.9062674792332688, 0.9196949902304732, 0.9132278675405038, 0.9162378634480062, 0.8936022265872302, 0.902323478757713, 0.9188473279256695, 0.8604427268303694, 0.8682909572845637, 0.8731768090412834, 0.9416894808822227, 0.9079010700913168, 0.896074725925557, 0.9024793805454151, 0.8592289294757475, 0.8895287846071126, 0.8909126642959234, 0.8890889645523828, 0.9148986993229635, 0.91840474741932, 0.8584976841883578, 0.8681390865386442, 0.9074032831838637, 0.9109377680503368, 0.9134304591606016, 0.8879850705792931, 0.9001863451925505, 0.8933209402242337, 0.8959074017691039, 0.8897763183716878, 0.8928284158593812, 0.9014945602630107, 0.8657748555472111, 0.9156044750243595, 0.9165137236959655, 0.7962584992094808, 0.8968502209455611, 0.8839913747196134, 0.8825123705300352, 0.8997645374071558, 0.8896918898270908, 0.8720791177659823, 0.9000170154914289, 0.8463067702306145, 0.9147286538708315, 0.9380135806071086, 0.8923800686328147, 0.8864425577968142, 0.8537586330277822, 0.8927530475375784, 0.8996211813282051, 0.9024074598006715, 0.8736160556052512, 0.8948411733278934, 0.8274451817691619], [0.8716033158575267, 0.8594070187921385, 0.8945695971597426, 0.9023346638923327, 0.8594102448241128, 0.8672162323864103, 0.8302758244008344, 0.9064117158229785, 0.8423956657731629, 0.8593078428326713, 0.8721603556513715, 0.8628473211141384, 0.8733181811857673, 0.8760291121563616, 0.7917457190072055, 0.8678460961964942, 0.8453177943937947, 0.8603642102800406, 0.8203325865513305, 0.8620523857329159, 0.8631153485146814, 0.8472865977772754, 0.8860948523166563, 0.8616281461836292, 0.8570503273869794, 0.8760187719993725, 0.8978191396653981, 0.8343179656496917, 0.8684562572755481, 0.8540728624147444, 0.8659109004845776, 0.8634517884584857, 0.874172377332531, 0.8737304567865614, 0.9035559195321101, 0.8845336147765516, 0.8848276432362138, 0.8179916812742434, 0.8187124240700013, 0.8824750405016604, 0.8712776392517338, 0.8822108137148106, 0.8803764378985158, 0.8547492853609944, 0.8269462329277097, 0.9040119163935206, 0.8352381707400882, 0.8696971276053208, 0.7752387513746106, 0.8251817161913946, 0.8449683479671193, 0.8735530843698626, 0.8483208689860791, 0.881373488934304, 0.9153075108084254, 0.9073896391589987, 0.8831013943935302, 0.8865005597686798, 0.8863422520068329, 0.872880301948669, 0.8836944301402079, 0.8627111678430435, 0.8939482728265088, 0.8272411112558629, 0.8255412951233927, 0.8563155967494749, 0.8573704730448659, 0.9177602715490787, 0.9172602484802301, 0.8544382605609698, 0.9220836027188188, 0.8307785146596596, 0.8725155219103842, 1.0000000000000007, 0.816860337237931, 0.8799993416803772, 0.8827870328823426, 0.8464200930336397, 0.8805070559546525, 0.8434087476287261, 0.8910923780547038, 0.8309629704846514, 0.8391522420778328, 0.8762349848696143, 0.9387865298000314, 0.8818430162283366, 0.8506871239992763, 0.8985277213500883, 0.8833236886785775, 0.8672972260955938, 0.8251096412531417, 0.8525294940789924, 0.8704931251150847, 0.8770485860093509, 0.8669863215944954, 0.8483800674702915, 0.9069031498369591, 0.8810586827478637, 0.8719245360961051, 0.8576296234965972, 0.9036034256531298, 0.8512790249823232, 0.873267296473266, 0.8409267665975397, 0.8636110407938637, 0.8480736357253833, 0.8364183689192606, 0.8259292329921877, 0.9138180811401273, 0.867079874298227, 0.8491093675459341, 0.8870167325361895, 0.8548061544489917, 0.8950271866708609, 0.8433362025964931, 0.8416544899118976, 0.807211681763212, 0.8408730718417108, 0.8614525310392176, 0.883358142272389, 0.8456786435355872, 0.904960610906295, 0.8721886373921917, 0.8694729657048037, 0.8543929478301983, 0.9350077057262373, 0.8220402380293463, 0.8459862782118897, 0.8183092933827963, 0.8671824276928095, 0.8587794454708264, 0.914233241444426, 0.8417115584676486], [0.9000421726396871, 0.8398735345525765, 0.8652578754309498, 0.8672730946753595, 0.8818803987212515, 0.8535381527356741, 0.8551777615533157, 0.8560053068186984, 0.8296399453406935, 0.8846991760189827, 0.8545606177883827, 0.8092396999647105, 0.8214169560497006, 0.8365241243333894, 0.8287357192511684, 0.8697807270330743, 0.8825292599615191, 0.8429044702417021, 0.8123391835517999, 0.8524335699640676, 0.8856794541074293, 0.8818835339245167, 0.899234751151772, 0.843891536666195, 0.8454698795247559, 0.876943173701818, 0.869600472972019, 0.8301030124038145, 0.8981736926861931, 0.8482226124937913, 0.875859956426695, 0.8697344124133726, 0.8283626941766316, 0.8621572994304907, 0.8392646978943139, 0.8194803525790502, 0.8479971855289243, 0.9198291342597629, 0.8234538427300815, 0.8809237244046066, 0.8740806317219422, 0.8894973763568809, 0.8827447727434364, 0.8696944287123791, 0.8361111253482637, 0.8783711636633631, 0.8427105714536811, 0.8884631943195208, 0.7856757645387699, 0.8575373532377429, 0.8791038993464289, 0.8804044220278838, 0.8619115376816107, 0.8981068006583411, 0.8564253718945088, 0.8529903397337545, 0.8806751696802824, 0.9152706112858042, 0.8664254756898365, 0.8465357854666902, 0.870472980240806, 0.8649287476421051, 0.887739436989601, 0.8416770639741057, 0.8464578786916075, 0.8804829011040518, 0.8839477413340805, 0.8828612955419799, 0.858181295119839, 0.8639525791842457, 0.8347400223380806, 0.8540325273108338, 0.8379346154585053, 0.816860337237931, 1.0000000000000004, 0.8768764687161511, 0.890335387782994, 0.8617700373981089, 0.8557690743879571, 0.862644453732148, 0.8705785156414405, 0.8477518628734143, 0.8755594992892909, 0.861575203699193, 0.8825721484883003, 0.8554303092973004, 0.8602778814382401, 0.8598487645164342, 0.8460491522218989, 0.871902379266036, 0.8695580828509006, 0.8581442851332152, 0.8668936413297768, 0.8663028852908164, 0.9300565272767278, 0.8662533052632659, 0.8343746158611008, 0.8637675769078461, 0.8535830062134966, 0.8378253592998071, 0.8700715056005554, 0.8306327994389553, 0.8699863952511361, 0.850280150348276, 0.8779271933401089, 0.8459428181480895, 0.8792270561784427, 0.8558046450768831, 0.8651417604379134, 0.8587140802010298, 0.8534366066970415, 0.8830784357028483, 0.8717663596119077, 0.7969171921020171, 0.8443690205106396, 0.8980470691615539, 0.8448870169594438, 0.8627742173994366, 0.8914111294027508, 0.8546021570987817, 0.9004746266002663, 0.7829240824867569, 0.8815697460094857, 0.8568639300080841, 0.8575618767174829, 0.865047473242872, 0.8172588357352506, 0.8909795260123186, 0.8484360765747002, 0.8614861164483263, 0.8897136367943698, 0.8731775458752288, 0.8421378288061763], [0.9508989229294271, 0.9219099321629716, 0.9273791196841978, 0.9322230932737045, 0.9185837412098937, 0.9234038125325456, 0.9207392254042523, 0.9108180796380511, 0.9004112732050784, 0.9291987377679403, 0.91869125160818, 0.8985154160913433, 0.8831435482328707, 0.9532909334117593, 0.8854661933678, 0.9059563832614056, 0.9482021793235571, 0.9262545158478356, 0.8786967995509637, 0.9222324576140708, 0.9393497025677685, 0.9301519837504095, 0.9447240088780215, 0.9274087288712423, 0.9168502246462157, 0.9361084678996845, 0.9443890787356195, 0.8915622475738233, 0.9350078948234213, 0.9150133272477381, 0.9283485767441484, 0.9345147956426104, 0.9113126227756349, 0.9343434796843675, 0.8801131027976095, 0.8918457050275991, 0.9069239620192779, 0.877070007935409, 0.8888988184030625, 0.913383018420352, 0.9335853131678514, 0.9434495013026468, 0.9384629348410443, 0.9204147817236351, 0.8991515644568449, 0.9300573905962115, 0.9081187984945027, 0.9364216221428461, 0.8566384178164991, 0.9290838024111113, 0.8841226261640398, 0.919780465525933, 0.9188013728043984, 0.9572909050419042, 0.9387170732488094, 0.9120835222728974, 0.9565116250503911, 0.9385757727148993, 0.9418298217704836, 0.9267418926560482, 0.9393391815895479, 0.9356140546171688, 0.9743354231447487, 0.9120236827912089, 0.8963330268451541, 0.9400134452523995, 0.9466795086355622, 0.933095341157486, 0.921294672688189, 0.9102366007737036, 0.8920027511766835, 0.9071948885006467, 0.909516847943743, 0.8799993416803772, 0.8768764687161511, 1.0000000000000013, 0.9440307128146747, 0.918774388831311, 0.9351591669378426, 0.9102566035450393, 0.9250084362571527, 0.9240429867088341, 0.9095590437563974, 0.9062586037960727, 0.9460404905947305, 0.9075557601206499, 0.8970528697204362, 0.9060584194002625, 0.9374400728759134, 0.9418515897759892, 0.9014587151727051, 0.9354144367913018, 0.8966372148759394, 0.9216943512468618, 0.9169242154721668, 0.9241457438374309, 0.9114784059189437, 0.9350297690045009, 0.9106775789351187, 0.8852716012605706, 0.9362983009990753, 0.9059220139819697, 0.9435630550801912, 0.8965716847503019, 0.9003971547880927, 0.9123128852301594, 0.9378381023269482, 0.9118620150550181, 0.9209977747998599, 0.9165679530935464, 0.9256203585285787, 0.9329853617308066, 0.9101228890345786, 0.8182258697140956, 0.877278375532946, 0.8825641394380196, 0.9113019720602653, 0.9251337893223142, 0.9316043944975582, 0.9210812953033113, 0.9025842224084513, 0.8806239138837052, 0.9399888690927614, 0.9053872070654215, 0.9153103185847855, 0.9245651809557791, 0.8797332886549696, 0.9232731162228615, 0.9065815283802484, 0.9198081684220625, 0.8915720233473192, 0.9273221405667911, 0.8730916397960516], [0.9583457991778078, 0.9171071140900481, 0.9205823754871668, 0.9349782864151848, 0.9321955309122553, 0.9235259631838761, 0.9279076823495075, 0.8914696067739978, 0.8965870021493284, 0.9441568181736021, 0.9340894662138461, 0.884005460352726, 0.8785201724166938, 0.903773731125646, 0.8704134291372023, 0.9114863181649269, 0.9406182883211001, 0.9152377052147589, 0.8783665306461064, 0.9198363648963584, 0.9440204204837881, 0.9314378195042458, 0.9435454937112241, 0.9225176344110589, 0.9203628878999549, 0.9435946146819434, 0.9441024424843988, 0.8944760420210451, 0.9542285774119607, 0.9459148822454325, 0.934422506143805, 0.9330273080336979, 0.9166516124479963, 0.9298627501200025, 0.8953475032729197, 0.8821839431354946, 0.9156371785957084, 0.9254254033529438, 0.9040044081416084, 0.9250239591670765, 0.9355494668847815, 0.9514542122059684, 0.9392740368875541, 0.9326493082625174, 0.9622180143846699, 0.9228211118558663, 0.9167272510121898, 0.9599666787674054, 0.8530981575421923, 0.920298907455108, 0.8905208461219649, 0.9219122144474692, 0.9264231735180042, 0.9485603454066581, 0.9361393316966955, 0.9136619881371143, 0.9467549822090449, 0.957208726047359, 0.9426507271284035, 0.9192689247083, 0.9378147046884823, 0.9464077076443249, 0.9569946220272793, 0.9169610339138461, 0.9169969197032757, 0.9393066131155039, 0.9383822554572456, 0.9487657930323878, 0.9190483616238758, 0.9168802844188145, 0.8896851264739395, 0.8997392288083833, 0.9033014009316872, 0.8827870328823426, 0.890335387782994, 0.9440307128146747, 1.0000000000000004, 0.9197732802519772, 0.9479723942722165, 0.9109718826877689, 0.9370791036095201, 0.9343525569226858, 0.9360953659703164, 0.9209959817216322, 0.9601021575605689, 0.9245979852987757, 0.920460169709131, 0.9247859769269559, 0.9345121615924807, 0.9357692125321339, 0.9151999518924385, 0.9371145630629683, 0.9242739745000034, 0.9226554033202206, 0.9218498418114175, 0.9306345215464769, 0.9049123964342801, 0.943507896655401, 0.9050321066600289, 0.8801207055652907, 0.9401170297969731, 0.8986768950610663, 0.9358939026657186, 0.9005614148497143, 0.9281814156746663, 0.926642652290059, 0.9295041045350857, 0.9038460462661659, 0.9340970228112337, 0.9287679043732106, 0.9287491976738315, 0.9391486777965481, 0.9176066346297342, 0.8183761281400579, 0.91338748514906, 0.8993790564068144, 0.9231355617170072, 0.9314950469028622, 0.9438506250732215, 0.9547673340669259, 0.9332116696021653, 0.873005724861535, 0.9392987870032192, 0.9133157424050091, 0.9172777363424053, 0.9303852651416166, 0.8863329707463086, 0.9456083794933314, 0.9078238043975034, 0.9297350973363343, 0.9054381284563155, 0.9271889257659864, 0.897686229834597], [0.9366359204385152, 0.9017710489929114, 0.903299245437467, 0.930432163403856, 0.9098134199679335, 0.9243586772022286, 0.9344335773095267, 0.8702086862484032, 0.8969083113054952, 0.9182443826907368, 0.9384203852618446, 0.8968221375646085, 0.8693142136441094, 0.8729433740645721, 0.9223041982794494, 0.9003778702779763, 0.9104912430145204, 0.9119976828162419, 0.880052132229104, 0.9222571923320748, 0.9187256139196267, 0.9200067128354898, 0.9091404170054534, 0.9074519153096974, 0.967042142843438, 0.9430451826159714, 0.9290873618398253, 0.8933691516314883, 0.9483553323147428, 0.9041148927322677, 0.918700248070289, 0.9220883615724408, 0.9101144152903665, 0.9199635570273669, 0.8702728590190466, 0.8704789271450932, 0.8859119259732465, 0.8892527315556904, 0.9419049838211291, 0.8909488696720111, 0.9506503080364592, 0.9441819540162776, 0.9137540888169232, 0.9053443630401982, 0.8491386925533091, 0.9314218633103243, 0.9045076076068854, 0.9202567947930076, 0.8899691114851354, 0.8975053979782384, 0.8829706970217237, 0.9170656308468645, 0.8953034571254468, 0.9229816383109928, 0.9071671422614668, 0.8998675909910548, 0.9351574216560052, 0.9247261401389186, 0.9358853295311398, 0.9557321624208635, 0.936359056436423, 0.9310962234472282, 0.9302766740302402, 0.922003750110041, 0.9105995827511367, 0.9355021801547085, 0.9322337188251143, 0.9254387307184473, 0.9146023884950585, 0.9156075097679114, 0.8570853352302888, 0.9203009800920351, 0.8878163361302465, 0.8464200930336397, 0.8617700373981089, 0.918774388831311, 0.9197732802519772, 0.999999999999999, 0.9237772502019252, 0.8987316075258637, 0.9539833492544175, 0.904968727354134, 0.9171105447590907, 0.9103548418538447, 0.9171787619692091, 0.9132127349954398, 0.9021873875669741, 0.8689495090981534, 0.9283642265761282, 0.9537685978519215, 0.9609044058727697, 0.936928251918726, 0.9085130683114423, 0.893900325326218, 0.89043555127974, 0.9121387093235879, 0.8867979577036471, 0.934971326877615, 0.9015614621575234, 0.8593979410328827, 0.9244166374754026, 0.9425541145685731, 0.9179799473488073, 0.9585252116636792, 0.9113187073287162, 0.9204582186879916, 0.9190749890005906, 0.892822548548562, 0.9140419361387327, 0.9114576827357487, 0.8967560390003687, 0.9112566099798819, 0.9137397748101028, 0.7755770069906451, 0.8833324895651617, 0.8912854378800641, 0.8860243147126976, 0.926420496518654, 0.9659635624040349, 0.8916688838104271, 0.9451318924604509, 0.8391573957947225, 0.9378754739721835, 0.9106488984143088, 0.8962179605608076, 0.8918639077543382, 0.8600985881757536, 0.9082646220561379, 0.9475999671530289, 0.9688460438619878, 0.8840970873518395, 0.8925508064561398, 0.8631547914314023], [0.94747377133164, 0.9146706189033045, 0.9273409190440766, 0.9421797003262229, 0.9093163479531725, 0.9427238336118475, 0.9347543796725066, 0.8891830980204621, 0.8938198835292083, 0.9432967102618445, 0.9431330194628937, 0.9037756966190524, 0.8828120883261991, 0.8765804245287572, 0.877529852603059, 0.9002684497575827, 0.9421805887552973, 0.9149935869289721, 0.8721003286211342, 0.9284569925525876, 0.9463477621785426, 0.9342623788225974, 0.933594712644277, 0.9270945356641259, 0.9222709494100882, 0.9531415735894296, 0.9548399661565834, 0.8955858746679848, 0.9382590166981416, 0.9338325504853154, 0.9337108130962366, 0.9222061736764174, 0.9213275657474376, 0.9195777400920919, 0.8832814374667801, 0.8826334706596863, 0.90884670265166, 0.901458934710311, 0.8885738787525591, 0.9172994473545837, 0.9402549692272761, 0.9464987120453108, 0.9343771805158531, 0.9004968549050845, 0.8967889236725687, 0.9341931423491682, 0.9185301869993274, 0.9324048626639913, 0.8575724015836651, 0.923081205147302, 0.8847704737768348, 0.9184012064202478, 0.9178962912066234, 0.9434235995161062, 0.9445046235281187, 0.8888381184395768, 0.951615782666145, 0.9343763282049864, 0.9400207054377766, 0.9248089064303124, 0.930055531264258, 0.9503787841251353, 0.9482725802189813, 0.9180618538837806, 0.9228070517924774, 0.9171961858301427, 0.9459529235486855, 0.9303607612301852, 0.9200424171996623, 0.9065714742679378, 0.8791085478309237, 0.9065277889622441, 0.9062674792332688, 0.8805070559546525, 0.8557690743879571, 0.9351591669378426, 0.9479723942722165, 0.9237772502019252, 1.0000000000000004, 0.9129264778871251, 0.9302522087158631, 0.9254730070718251, 0.917739020104621, 0.9241719114835201, 0.9408928517452358, 0.8921694460007485, 0.9178699186368061, 0.8936985424664436, 0.9407270487717175, 0.9354926034154484, 0.9104875409266328, 0.9427786153668862, 0.9289374339077393, 0.9051227312008437, 0.9167710351912965, 0.9305214293955324, 0.9135828537197951, 0.9555699126000138, 0.9208555519483597, 0.8673520239738185, 0.9273088497933792, 0.9052360739559174, 0.9439405954510116, 0.9233329694458474, 0.900967446997923, 0.930903393796441, 0.9340680719638047, 0.9227021997730799, 0.9348317580871146, 0.9410687511131064, 0.8956585212365421, 0.9227124038605994, 0.919124972541458, 0.7998160880587699, 0.8963173619528666, 0.9153994013273431, 0.9081979160310728, 0.9420313139705598, 0.9316723739906184, 0.9223417174833504, 0.914444360829667, 0.8591319371121299, 0.9483403153058028, 0.9124554398264693, 0.906198672495827, 0.9132710466149799, 0.8914449942967736, 0.9326741425157082, 0.921648766781646, 0.9368937060209173, 0.8948965872238587, 0.9018959111889928, 0.8908060954350601], [0.9177196850888995, 0.904023999151873, 0.9013005331622482, 0.9132736755617227, 0.9003855378616272, 0.8918048616397417, 0.9252996660297185, 0.8599264242492227, 0.9306739476837546, 0.9092595420333103, 0.9145120449850036, 0.9024361258905077, 0.893881303307863, 0.8501832205199458, 0.8773681082797206, 0.9059772889252806, 0.9344273313432843, 0.9055133138755237, 0.8703692637115722, 0.9562364835029455, 0.9138764060576224, 0.9704531227024481, 0.89929267736197, 0.9155505574768709, 0.8790402296798958, 0.9416156323065189, 0.9215444344743635, 0.9024322719772333, 0.9114659505131111, 0.9221189607740305, 0.9659569034010974, 0.8996433605358616, 0.9036711282086504, 0.9176093754526087, 0.8533494695171798, 0.9066364109383696, 0.877374702659539, 0.8576326210921295, 0.8705978592912584, 0.8791511373591916, 0.9325378379886838, 0.923263404370975, 0.911545147300039, 0.8876343776424421, 0.8561384575852756, 0.9032230319283594, 0.9226342850972369, 0.8967695383809581, 0.8457058963255861, 0.9170261713376092, 0.8845348673361639, 0.9179482398971991, 0.917162530874434, 0.9449068325331151, 0.9099554829503304, 0.8579946428130283, 0.9338643809290286, 0.9068725016658234, 0.9081723669239228, 0.9046943642404361, 0.9111756896844703, 0.9110031618727241, 0.9288560101515745, 0.9341319955596217, 0.9099869310857551, 0.9283641855085412, 0.9310854721807396, 0.8903470366190576, 0.8871438419057919, 0.9053465043428022, 0.8581627941777211, 0.9330121802690977, 0.9196949902304732, 0.8434087476287261, 0.862644453732148, 0.9102566035450393, 0.9109718826877689, 0.8987316075258637, 0.9129264778871251, 1.000000000000001, 0.9138177985457033, 0.9085438197278952, 0.8921930716709379, 0.914269205808723, 0.9022927249998599, 0.8455949197091069, 0.8737807019237123, 0.8667110672671747, 0.937759951002674, 0.9207027584431451, 0.9012026836077786, 0.9444086923272541, 0.8657225330587979, 0.8857439204880391, 0.8928384482704971, 0.9141032214764665, 0.9151977349942405, 0.9314348697171141, 0.859524984292626, 0.8388837160934984, 0.8970169785292699, 0.9249910681068597, 0.9255174278157106, 0.9153247377338962, 0.8995940694177382, 0.9274491125221694, 0.9331441425555447, 0.9086640954400833, 0.8877089378959149, 0.9542441704059182, 0.8546046859850411, 0.9013757918657946, 0.9106194999330063, 0.771216720405127, 0.8981460685705077, 0.9120367277118631, 0.9028762449243835, 0.9255352950741963, 0.9086324158643697, 0.8661498429533214, 0.8942765450077882, 0.8377833158858065, 0.9480222074695583, 0.9392935508980444, 0.9134963657897456, 0.8905761606376166, 0.862525634284153, 0.9229468468057871, 0.9058044205494977, 0.9077560920393197, 0.8621597201604445, 0.8767616122376406, 0.8420756053335354], [0.9421515791091273, 0.9009896878226257, 0.8996127949347252, 0.9476118474270184, 0.9054705910723325, 0.9280412817003285, 0.9343474680960452, 0.8820720590864218, 0.9097652671658326, 0.9218243328732955, 0.9529611017987414, 0.8978514781434771, 0.8801734455247382, 0.8888383675917215, 0.8792874231923831, 0.9039023748524373, 0.9140027137391215, 0.9019334508747935, 0.8799757893985616, 0.9360139741318918, 0.9278877520123723, 0.9225561233022966, 0.9350511726365934, 0.9120214460483744, 0.9387714068840888, 0.9510020026342161, 0.9300217460882264, 0.9089626776568794, 0.9539745375048535, 0.9057623559563721, 0.9351987746087851, 0.9046151157230496, 0.9266397923825596, 0.9255493756620546, 0.8716522203122051, 0.9166548764986899, 0.9014653231878836, 0.9014632432836364, 0.9542247545858185, 0.9035701569160652, 0.9527635687452214, 0.9372562389958327, 0.9217596082869337, 0.9153145760219412, 0.8694791225346984, 0.9433016562306336, 0.9076164316634927, 0.9376492322172741, 0.8551779827868651, 0.8963441699431793, 0.8799305085933252, 0.9424368398073538, 0.9010753640821301, 0.9293870426084027, 0.9235598183306124, 0.940763133911412, 0.9356775533840499, 0.941315285849395, 0.9344283924594923, 0.9457177119062145, 0.9561582137753173, 0.9297273090061036, 0.9390081746642842, 0.9148221218512658, 0.916313631087403, 0.934816552388739, 0.922965657962115, 0.9415453686479062, 0.9301489141727524, 0.9159383898679293, 0.8733872023574454, 0.9073383572030053, 0.9132278675405038, 0.8910923780547038, 0.8705785156414405, 0.9250084362571527, 0.9370791036095201, 0.9539833492544175, 0.9302522087158631, 0.9138177985457033, 0.9999999999999987, 0.9202118553458994, 0.9360023404944412, 0.9237278472351673, 0.9436661551479975, 0.9293402052640972, 0.9154139889710278, 0.893849250273264, 0.9471704363966111, 0.9304519431201699, 0.9463881960523087, 0.9232860757867236, 0.9259681873730956, 0.9039824765981997, 0.9027201887387836, 0.9128579934403384, 0.9011538267479825, 0.9393099801620057, 0.8978755364033362, 0.8709565823068681, 0.9335792776018559, 0.931753812280678, 0.9232890891305242, 0.952999743628757, 0.9441057828864292, 0.9298576918832271, 0.9165926350148846, 0.8902617381645891, 0.9246813777447669, 0.9247012668606166, 0.9129267428022106, 0.9326913117214755, 0.9113480769120137, 0.8088344848966272, 0.8993440338991849, 0.9041914874110106, 0.8770254547602825, 0.9274271734865269, 0.9488156169646228, 0.9063714873030809, 0.9421757426071125, 0.8795001909082842, 0.9341094123553345, 0.9282189272042172, 0.8948187686705034, 0.921717436527858, 0.8916830229072537, 0.9245164805166325, 0.9385788583390533, 0.95513924959493, 0.9043113272250151, 0.9126670379499089, 0.9023631403844599], [0.9267116772798754, 0.9140352435592892, 0.8973384165763207, 0.9060576184728775, 0.8887710597461097, 0.9120034818939147, 0.9495919659353158, 0.8508056422392649, 0.9066996701637167, 0.9183304480026756, 0.919653531330839, 0.8784903995350744, 0.8753762497646069, 0.8523444506195657, 0.8639435603472834, 0.8970050824164882, 0.9223348354799684, 0.8864735448047999, 0.8771039553399336, 0.926517540112336, 0.9186541606003805, 0.9229070071960916, 0.9003658992192605, 0.9038491461346017, 0.9053142791253244, 0.9376288109091755, 0.92016303065947, 0.9105630380631156, 0.9263611297528369, 0.9224558549822891, 0.9432319835674703, 0.9092298820031073, 0.898637512613059, 0.9269765344086924, 0.8629487802679795, 0.8813320484403202, 0.8755978709748684, 0.8762504432694568, 0.8961975904667674, 0.8912869612701921, 0.9249031181362767, 0.9292398605303387, 0.9201227154423313, 0.9035842864752506, 0.890392597537167, 0.9159286945611318, 0.9189812342255264, 0.915464305463913, 0.8451097265411136, 0.9105746482767603, 0.8723218782995147, 0.9214462656913713, 0.9061043064174352, 0.9231650622257084, 0.9215949312284564, 0.8668465959973599, 0.9381992348421315, 0.9231219943585378, 0.9190012193389461, 0.9035366401203152, 0.9201149733105559, 0.9550323946586987, 0.9317144943033104, 0.9259144800188939, 0.9020903397254315, 0.9263915584916029, 0.921337620101453, 0.8975032354383772, 0.8976518951892476, 0.9032169614389912, 0.8441373319763777, 0.8882064699497482, 0.9162378634480062, 0.8309629704846514, 0.8477518628734143, 0.9240429867088341, 0.9343525569226858, 0.904968727354134, 0.9254730070718251, 0.9085438197278952, 0.9202118553458994, 0.9999999999999999, 0.9210801975168246, 0.9088532130250799, 0.9155017969168033, 0.8881577474344979, 0.8895353488761348, 0.8861666893526567, 0.9376079231030603, 0.9160528725779338, 0.9019567480810895, 0.9294818326698406, 0.8942909814538105, 0.8874104172414032, 0.893584332796181, 0.9081552491033176, 0.8792146842693984, 0.936961082464416, 0.8884767658551173, 0.8501499403209816, 0.9154025807925676, 0.9126698060667158, 0.908909689571578, 0.8984497257710068, 0.913715794786196, 0.9262794544559491, 0.9307332124368757, 0.8947823712423981, 0.8969142120430282, 0.9221684508158043, 0.8898940541745367, 0.9150825805910096, 0.9202160234228554, 0.7679653998712641, 0.8946668139947922, 0.8958187150971736, 0.9068239059105969, 0.9196296803901631, 0.913092837383736, 0.8974261839033126, 0.9039044085881336, 0.8314678398761444, 0.9315760371859827, 0.9080246798621697, 0.9027534115536902, 0.893392779826834, 0.8810057392742403, 0.9224851902732272, 0.9259547327168057, 0.9192244826172778, 0.8709787965690771, 0.8868287652624862, 0.8562049188441305], [0.9281920282512057, 0.907245922590158, 0.8854085548204824, 0.9053452871976226, 0.8992330343071937, 0.9057325650277006, 0.9111748144546408, 0.8647513133160869, 0.8958845796403676, 0.9052274898011088, 0.9151027482883292, 0.8798558904176235, 0.8743069245816124, 0.8665883897754284, 0.8725939562670433, 0.8883358506152079, 0.910183736090413, 0.8681422715492446, 0.8638143748882344, 0.895763740193446, 0.918401267308098, 0.9025865880370706, 0.916302008823098, 0.8933989090257113, 0.9229233115954281, 0.9259100556415379, 0.9307681563879269, 0.8897399562518249, 0.9537368888479509, 0.8957251455945656, 0.9170648721099599, 0.9059449001136518, 0.9283915187457517, 0.891472706460572, 0.8629938625636746, 0.8661219380415051, 0.8900940078470229, 0.9063684271748884, 0.9146807477526506, 0.9162742536402687, 0.915886421383252, 0.914429333171632, 0.9128691806227123, 0.9043565892162969, 0.8716056838581461, 0.9086517041145558, 0.9075741194722494, 0.926066607297922, 0.856794173657779, 0.8900298457059854, 0.8655228116734501, 0.9003699859493524, 0.8787344956016987, 0.9261126086793943, 0.9077599929028254, 0.8877934424997552, 0.9225221688331039, 0.9250449560893573, 0.9237519201125279, 0.9168073065945992, 0.9186539453968849, 0.9197947273469222, 0.9226364314299207, 0.9048831004965454, 0.9087658745103606, 0.9088707876489559, 0.9273435202978466, 0.9150188605127096, 0.8980905378335127, 0.8993629052492074, 0.8554895037435257, 0.8835423712620044, 0.8936022265872302, 0.8391522420778328, 0.8755594992892909, 0.9095590437563974, 0.9360953659703164, 0.9171105447590907, 0.917739020104621, 0.8921930716709379, 0.9360023404944412, 0.9210801975168246, 1.0, 0.9036291652122966, 0.9274690987497869, 0.9119413880638485, 0.8720440336365267, 0.8927691179978003, 0.9111098854477486, 0.9097201516470443, 0.9218448197125867, 0.9144167881073493, 0.901125266949949, 0.8871134545962174, 0.9013151053384809, 0.9076656590926075, 0.8792173163544351, 0.9345802302252992, 0.8664423804641159, 0.8841634921279005, 0.9193793710804914, 0.8946706843976318, 0.9219181060360233, 0.9119254183910946, 0.921725097340812, 0.8994991853065338, 0.9128853733025006, 0.8918259227270884, 0.9013739955934355, 0.9166163194156626, 0.9019311429504498, 0.9091831825045775, 0.8986710078495419, 0.7920923927283638, 0.8863907329126712, 0.8879025816645706, 0.8735555980203864, 0.9127316158708119, 0.9341769862287516, 0.9095958211624349, 0.9232121078630771, 0.8346876177684313, 0.9192283920159546, 0.8792725521274453, 0.8828578380562934, 0.9019894117538749, 0.8654319511703643, 0.9189225421488147, 0.9038673067227819, 0.9254642409895792, 0.8988705450510037, 0.8989636252379618, 0.8742696219766202], [0.920317159964323, 0.9163580772179174, 0.9032613149481326, 0.9247419480235787, 0.8955627852513981, 0.9173644269088008, 0.9312901174717276, 0.8940391260266205, 0.8872116823809004, 0.9129940184050457, 0.9489222130456454, 0.9095974442351558, 0.8887169563033855, 0.8504857369870187, 0.8590736626971687, 0.9076306429622502, 0.9267310754732394, 0.8928689486852366, 0.8825984685596332, 0.9318446076666245, 0.9288123405841591, 0.9280361945258716, 0.9051176082752196, 0.907279503885409, 0.9063615622492783, 0.9392870378994251, 0.9446615982073687, 0.8893941585910223, 0.919302253706393, 0.9161873528985272, 0.9410257433274858, 0.9072069802957524, 0.9235911046299139, 0.9189475345802045, 0.87650676591114, 0.9047579237285278, 0.9011522263203814, 0.884629275338821, 0.8847628241966297, 0.9063028294385678, 0.9234223028074494, 0.9232992169647007, 0.918600508522428, 0.876440633190725, 0.8540940470131859, 0.9362371200497674, 0.9007558814175474, 0.9067707672772601, 0.8586805147680807, 0.8829493723676397, 0.8771385823013713, 0.9220994491925412, 0.9030836755221063, 0.9379443438453043, 0.923582696517364, 0.8880198273811255, 0.9357122240809725, 0.9136780015837147, 0.9295005617921154, 0.9196294361043329, 0.9189904198955251, 0.9219369126771078, 0.9245988742370204, 0.9285944420424137, 0.9190081802029946, 0.9047100779034516, 0.9284749089651464, 0.9139944201327447, 0.9271434983637372, 0.8940640884957015, 0.8623506053529649, 0.890370902226684, 0.902323478757713, 0.8762349848696143, 0.861575203699193, 0.9062586037960727, 0.9209959817216322, 0.9103548418538447, 0.9241719114835201, 0.914269205808723, 0.9237278472351673, 0.9088532130250799, 0.9036291652122966, 1.0000000000000004, 0.9190497584442978, 0.882799912027808, 0.8915193596007029, 0.8828022846325301, 0.9336697052541093, 0.922330146941748, 0.8997771798509389, 0.9323969052008751, 0.8997981557363262, 0.893414367468968, 0.9196110959102246, 0.9192440072243595, 0.8940891217635719, 0.9422764205539756, 0.8809213261110788, 0.8548830254394835, 0.9270351436167059, 0.9281251280234836, 0.9237555914535345, 0.918978407333221, 0.9090489942532534, 0.9278362135988123, 0.9173444782269911, 0.9055628760852951, 0.9130051901815404, 0.9464389012559313, 0.8729047470955839, 0.9128580359216947, 0.9325740343312237, 0.7939502710476815, 0.8893313329794384, 0.9153086688271233, 0.873941237536946, 0.9275985720656289, 0.9092717560532071, 0.8866755635472412, 0.8919570382643064, 0.8639983037573943, 0.927593220646856, 0.9144849607513316, 0.897174814597913, 0.9194904770799063, 0.8725357671350163, 0.9028292369929501, 0.9204425947152729, 0.9251621319866695, 0.8737278191768814, 0.8896821940507942, 0.8700344280060872], [0.9454967247360047, 0.9117088289303552, 0.932103788777272, 0.9330561688897172, 0.9145930444848895, 0.9122276218387873, 0.9138015745231882, 0.9142099340191352, 0.9042004088780933, 0.9370265931336256, 0.924198671144129, 0.9080019224709649, 0.9114124849763905, 0.9167914596410283, 0.8627661573186762, 0.9185995473917125, 0.923633179243162, 0.9106174308312658, 0.8859976005754003, 0.9182652454278821, 0.9341092262220955, 0.917006102827342, 0.9425214627914835, 0.9265307680438899, 0.9252291077729508, 0.93236306098384, 0.9520333499559532, 0.8934423549328399, 0.953400551837604, 0.9117192926568525, 0.9306463461661909, 0.9219862877246806, 0.9244713469631191, 0.9231912362127631, 0.9092379678714608, 0.9089968332228515, 0.9181302874490287, 0.8967846711431935, 0.8909854534454693, 0.9353882932948816, 0.9317817658249792, 0.9417551547624841, 0.9418436862757597, 0.915485611218096, 0.899173460593728, 0.9347573063030745, 0.9052491471864675, 0.940486218261768, 0.8499373392840937, 0.9015802060097049, 0.890638611132063, 0.92409572766465, 0.9173267525512776, 0.9433574236782712, 0.9392140701598052, 0.9485761718479571, 0.9446055465300615, 0.9509078458739689, 0.9388626505243423, 0.9382200952593838, 0.9518448384502417, 0.9383509766923472, 0.9632373138368984, 0.906437298340432, 0.8999113279885617, 0.9308399143179186, 0.9280225002054483, 0.9540007547543722, 0.9463737951124974, 0.9114226646905006, 0.9326596856194239, 0.8973912186341652, 0.9188473279256695, 0.9387865298000314, 0.8825721484883003, 0.9460404905947305, 0.9601021575605689, 0.9171787619692091, 0.9408928517452358, 0.9022927249998599, 0.9436661551479975, 0.9155017969168033, 0.9274690987497869, 0.9190497584442978, 1.0000000000000002, 0.9237180748889878, 0.9162098076292204, 0.9318157591901055, 0.9267048457785219, 0.9328012303153406, 0.9088729829372657, 0.9242392400861814, 0.9325217328170073, 0.9286301602304028, 0.9143851916634969, 0.9210850277104289, 0.928767203715869, 0.9362783718229021, 0.9133627475065911, 0.9058348239847753, 0.9561951901460519, 0.8983127859165236, 0.9387574384841021, 0.8928231270700111, 0.9298615577264221, 0.9084093977742693, 0.9172377670657296, 0.9011976275366236, 0.9493066325116825, 0.9259948605291959, 0.9166084546531917, 0.9431888072979078, 0.9187862811593244, 0.8889172861842403, 0.9130967562505606, 0.8913580567882007, 0.8848853317590867, 0.9228877636382391, 0.9324567594899527, 0.9482379587829044, 0.9185447777931168, 0.9148468094950644, 0.9312169760342195, 0.9202308918300198, 0.9264072453890073, 0.9612930684348349, 0.8729547141524674, 0.9295353294542184, 0.8908997697218188, 0.93420405225401, 0.9192532169045281, 0.9526680543673554, 0.885056468599412], [0.9212877654930772, 0.8693590628425699, 0.8840548272219391, 0.9033730377275023, 0.8997191391738426, 0.8990933925475176, 0.8763489978995729, 0.8832951371277079, 0.8590516538790937, 0.8811266786441148, 0.8959413725335732, 0.8385892193231391, 0.8560223579112091, 0.892440794413757, 0.8634575055292144, 0.8594072930959805, 0.8828611664527185, 0.8708838356036358, 0.8324121294768454, 0.873000625644407, 0.8958873988988961, 0.8645285532152098, 0.9187754823591446, 0.8737204729893115, 0.9176477675846416, 0.9027141300337562, 0.8982370553544485, 0.8551017745505142, 0.9171401976357777, 0.8671168625430336, 0.8766568631715663, 0.9024161539214688, 0.8907689716755545, 0.8855034490688025, 0.911726737448102, 0.8706809600354742, 0.8898508725489516, 0.8994464537763283, 0.9186323138625851, 0.9053335581883677, 0.8936837749074782, 0.906701765050174, 0.897843093088968, 0.9296600639671643, 0.8700613274724605, 0.8990525770073845, 0.8656627845602533, 0.9264846499001778, 0.8169630706914619, 0.8622620798889156, 0.8518620457162069, 0.8813471635063055, 0.8682079702581609, 0.9061398619914773, 0.9085507513145371, 0.9209788786749514, 0.9080149153801883, 0.9374610477211229, 0.9269895973794525, 0.8909847493226681, 0.9059541372276371, 0.903528468731051, 0.908181156414597, 0.8738917584540347, 0.8623415115675551, 0.8944130237822543, 0.8977187250502519, 0.9485271044382004, 0.8971838719209365, 0.8972164647122919, 0.8799618023596857, 0.8416911144156016, 0.8604427268303694, 0.8818430162283366, 0.8554303092973004, 0.9075557601206499, 0.9245979852987757, 0.9132127349954398, 0.8921694460007485, 0.8455949197091069, 0.9293402052640972, 0.8881577474344979, 0.9119413880638485, 0.882799912027808, 0.9237180748889878, 1.0000000000000009, 0.87289724223972, 0.9158990552725049, 0.8940570448015022, 0.8932426493308654, 0.886368134965781, 0.88170310262002, 0.8894373544873512, 0.9002956497678387, 0.89285723984758, 0.8701851963709188, 0.8597051724822159, 0.8996146499081437, 0.8907857333390221, 0.8560317584754754, 0.922591919792369, 0.8752059289517532, 0.8786263039789218, 0.8930752760469498, 0.8992910107145878, 0.8712480627802212, 0.8732859606808654, 0.8568088874175972, 0.9030420610038024, 0.8782268295714077, 0.9158617778393943, 0.9082112810466328, 0.8770556312767545, 0.8185419381473189, 0.8537610968334767, 0.8666566675922738, 0.8519100971140092, 0.875605916448033, 0.9302732782841542, 0.9059706475231465, 0.9306873989552791, 0.8631563904972679, 0.8953079523797189, 0.8627150122324351, 0.8670509324197964, 0.9196373037814272, 0.85648634694714, 0.8862769964026028, 0.889650650344427, 0.9259964751467079, 0.9012097753713795, 0.920540378695784, 0.8759733314368452], [0.9204056457574823, 0.8620377501693044, 0.8957361747425493, 0.908854823917552, 0.9084735364707636, 0.8987509484336765, 0.907910447634674, 0.8643720312496238, 0.8550986858749341, 0.9579450017215068, 0.9086908964238589, 0.8549818436373581, 0.8396721388982621, 0.849783657477243, 0.8229665687097047, 0.8679712207503143, 0.9071834963278838, 0.8599091144335228, 0.8341562307260822, 0.911341793727, 0.9298964758584489, 0.907386155781877, 0.9098122803487878, 0.8618721411138439, 0.8794456758346939, 0.9176521220058012, 0.9087249998399778, 0.8755676491575333, 0.9096000280424784, 0.8802629661325791, 0.9022442393346957, 0.8856737023503394, 0.8804274074376282, 0.9109815103197438, 0.8719211369486572, 0.8633381729693708, 0.8767941759469589, 0.892210149268984, 0.8680004643573993, 0.8957176584259073, 0.9087178422707279, 0.9444798313837903, 0.9084313024595202, 0.8883735020883541, 0.8564078153718748, 0.9174423040020722, 0.8690682142236643, 0.9111674971019876, 0.8169468705900156, 0.8943353761276631, 0.8694318509062267, 0.911700959300515, 0.8801286839505845, 0.9106338225073198, 0.9012887918125121, 0.8816368711371333, 0.9059175172986009, 0.9222560362818365, 0.8957451977305627, 0.8873809986871053, 0.9076396869242929, 0.9116639574912936, 0.9125831614949063, 0.889771851996368, 0.891637368463134, 0.891212791851516, 0.910781304769804, 0.9279390091962545, 0.9095371822035371, 0.8653877109814232, 0.8555561175476781, 0.8707273790472706, 0.8682909572845637, 0.8506871239992763, 0.8602778814382401, 0.8970528697204362, 0.920460169709131, 0.9021873875669741, 0.9178699186368061, 0.8737807019237123, 0.9154139889710278, 0.8895353488761348, 0.8720440336365267, 0.8915193596007029, 0.9162098076292204, 0.87289724223972, 0.9999999999999996, 0.8508345465581473, 0.9020897665510583, 0.900921272926869, 0.8877285732806268, 0.8908278577124166, 0.9520458680900657, 0.9063817967961381, 0.8812535508907826, 0.8908175120652543, 0.8690614887601866, 0.9161096565354707, 0.9012819923324822, 0.8424209610802706, 0.887414722115937, 0.8852977817955472, 0.8977827935186897, 0.8923107708843638, 0.8925454723492439, 0.8950771949643138, 0.8926337788840022, 0.8864101748582254, 0.8933625233532546, 0.8948348776458569, 0.8568723341215533, 0.9049096090531813, 0.8902411671596453, 0.8196340582752375, 0.8456624929557963, 0.8748451409070523, 0.8644463308011816, 0.8992715744676029, 0.9103601624008231, 0.8730362493818413, 0.8951546821649293, 0.837179142770917, 0.9135311189393557, 0.8993321405509795, 0.8697433425430017, 0.876211022195668, 0.8847371264168944, 0.9210680084776995, 0.8963871467985645, 0.9018850676806125, 0.8982047404039841, 0.885583838779357, 0.9214024565476564], [0.9025907900054657, 0.8766747428414559, 0.8992919738041066, 0.8841675776227429, 0.8965129202784833, 0.8692645638532076, 0.8710977483413349, 0.8763271979268791, 0.8725429029899564, 0.8686558506502493, 0.8782817539338676, 0.8508924223746768, 0.8632671160031177, 0.8788107455559294, 0.8362833673561052, 0.8773098550314081, 0.880466319225082, 0.8796515241611457, 0.852919773597527, 0.8760283780238349, 0.8759773437111895, 0.8651870518423531, 0.9008891028767034, 0.8859358890790856, 0.8652074361377862, 0.8937797643794266, 0.8887528564419289, 0.8402960146453118, 0.8987347700156276, 0.8778204769397084, 0.8863448414360028, 0.9176555321777093, 0.8761182296240806, 0.8751878353485311, 0.8707746388371409, 0.8691563322071747, 0.9163553514682659, 0.8763193947190935, 0.8430861445877499, 0.8970798059929204, 0.8823548186592343, 0.8863326850014437, 0.8981954406422116, 0.9013106478378394, 0.8857856168473516, 0.9067375164439848, 0.8788534908372116, 0.9156099106106868, 0.8099900878680297, 0.8652579365202986, 0.8384185291037214, 0.8798150859030953, 0.8841131438664828, 0.9213541969373391, 0.8919937307556844, 0.8811208742737066, 0.9093956367797856, 0.9097881719991638, 0.9088546040916745, 0.8836130622060552, 0.9083655079385735, 0.8926032492095648, 0.9193030789969006, 0.8599191946621974, 0.8495995516999884, 0.8932752604869326, 0.8741367604560535, 0.9086676080026619, 0.9162752659498989, 0.8890519611878166, 0.9151473738206489, 0.8362878334762677, 0.8731768090412834, 0.8985277213500883, 0.8598487645164342, 0.9060584194002625, 0.9247859769269559, 0.8689495090981534, 0.8936985424664436, 0.8667110672671747, 0.893849250273264, 0.8861666893526567, 0.8927691179978003, 0.8828022846325301, 0.9318157591901055, 0.9158990552725049, 0.8508345465581473, 1.0000000000000004, 0.8887257838945901, 0.8867882614418887, 0.8427842690878529, 0.882276240202404, 0.8831389016970728, 0.8783049764251306, 0.8933342074548811, 0.8735180018130215, 0.8673042485313676, 0.8907178345650578, 0.8738292250866331, 0.8694517525192644, 0.916442347324254, 0.8514632245796142, 0.876652617436669, 0.8478786292542385, 0.8916829504598958, 0.858129471054267, 0.872550724750786, 0.8420057534016757, 0.887376322516828, 0.8815363903905769, 0.8855625399586522, 0.8891758525566572, 0.8761566144077235, 0.8261255284516154, 0.8693274090961463, 0.8614743355734189, 0.8569640497125391, 0.8610525356608689, 0.8911305425902357, 0.9273869273732417, 0.8913798574326265, 0.8681392492672139, 0.887622828277067, 0.8675592772791598, 0.8897582251419381, 0.9499544202631057, 0.8236789770223986, 0.8977591138122771, 0.8413490199633111, 0.8906624003711061, 0.8773191171970351, 0.9077750278627159, 0.8300386290901283], [0.9460103987163249, 0.940312042731023, 0.9147307519054462, 0.9531197675179968, 0.9019305774827068, 0.9317468976705366, 0.9480078197021393, 0.8967442564949839, 0.9394823527086794, 0.9214883633628133, 0.9543030298490209, 0.9200313006025195, 0.8887345100865292, 0.8867026787314862, 0.8905434473315297, 0.9139938006182646, 0.9295114065826384, 0.9282710785996873, 0.9041960299303481, 0.9669539945688108, 0.9209041699248594, 0.9411476480240345, 0.9242553738537258, 0.9252038281657644, 0.9188002838467252, 0.9636326166192464, 0.9486375029519817, 0.9232661520711313, 0.9337041283616565, 0.9421659416427002, 0.9559480379405956, 0.9136901526653947, 0.9306374422831054, 0.9548721120036345, 0.8730183236541379, 0.9235723944687211, 0.8871337431148287, 0.8756243909761916, 0.9063489044311768, 0.9058630713150966, 0.9613097107376678, 0.9417237074071303, 0.928708309138998, 0.9057423130806301, 0.8801091348279839, 0.9304585819235283, 0.9414721707724948, 0.9276092056239282, 0.8548819063727011, 0.9126718763844722, 0.8876689522001635, 0.9345815527458257, 0.9197692065411707, 0.9405273467005159, 0.9541544695763691, 0.8993276631763742, 0.9582571685556904, 0.9258054747687671, 0.9375422978067918, 0.9404759947576559, 0.9497638147519596, 0.9424613730963035, 0.9406888165568987, 0.9310573500614523, 0.9107102110336069, 0.9428529874054061, 0.937660316104324, 0.9224733750116195, 0.9212399135765722, 0.9232562748850992, 0.8689044810896747, 0.9180685859771902, 0.9416894808822227, 0.8833236886785775, 0.8460491522218989, 0.9374400728759134, 0.9345121615924807, 0.9283642265761282, 0.9407270487717175, 0.937759951002674, 0.9471704363966111, 0.9376079231030603, 0.9111098854477486, 0.9336697052541093, 0.9267048457785219, 0.8940570448015022, 0.9020897665510583, 0.8887257838945901, 0.9999999999999997, 0.9358992134790376, 0.914049099714882, 0.9450736721393855, 0.8966806039204529, 0.9052301316315394, 0.9110098584404579, 0.9194932003771106, 0.9421334035504039, 0.942489701400081, 0.8956257041954113, 0.8771691799975609, 0.9304205239164794, 0.9369694762456562, 0.9329225248648936, 0.927808216226643, 0.914403978534461, 0.9293286626617349, 0.9193453137950492, 0.9085633588939923, 0.9230292601294888, 0.9368594061785537, 0.8963771443215787, 0.9316995430690941, 0.9378995785704667, 0.7928283139394716, 0.8993651044242068, 0.9099747850394536, 0.9128648179120332, 0.9249683259931234, 0.9240624710396063, 0.890450081996061, 0.9132080271398517, 0.8775096281295672, 0.9520906620322694, 0.9465414735568322, 0.9170902332344137, 0.9023984647380767, 0.8775262296428854, 0.9235448521670617, 0.929073545310138, 0.9330778495633533, 0.8918461648960669, 0.9056907828425793, 0.8838010415775432], [0.9514438185250375, 0.924153954012289, 0.9315883541887706, 0.9376438790364579, 0.9227968214444432, 0.9186825746215008, 0.9378050866332189, 0.8972861833787151, 0.9081719851951372, 0.9278758715088651, 0.9431546962407819, 0.9309616219827265, 0.8888979280891136, 0.8899477682387851, 0.9028002663740098, 0.9534074052406749, 0.9345275020235605, 0.9490610805555629, 0.9129746395631326, 0.9317519770572534, 0.9310601036559696, 0.9380338435248441, 0.9355769011855577, 0.9384904194397669, 0.9371754763610691, 0.9531952161076678, 0.9484117140470589, 0.8987436549922161, 0.9564923778482278, 0.9251851550769632, 0.9358484703584797, 0.9265559341977461, 0.9059609248727511, 0.931055287873369, 0.8783293476001528, 0.8944236953322755, 0.8987307017205047, 0.8771834729295049, 0.8861075174173709, 0.9175458864783944, 0.9583556354947538, 0.9520309948480203, 0.9325217383480382, 0.9108076308046813, 0.8706420422071733, 0.9342724071691108, 0.9246552225637021, 0.9293318763166565, 0.9061957013024629, 0.9133284501980049, 0.9281734697747062, 0.9359986024378604, 0.9204913828485415, 0.9449315875463555, 0.9294330439718504, 0.8973595567571098, 0.953805165367527, 0.9294325428819363, 0.9400969134454188, 0.9503442025519058, 0.9450357125919429, 0.9429103763005247, 0.9564696476231821, 0.9273245518243015, 0.9076539350232288, 0.9528734036185533, 0.9477833239101018, 0.9259237312697377, 0.9339666502898476, 0.9075879786813157, 0.8859830113150994, 0.9483569927996922, 0.9079010700913168, 0.8672972260955938, 0.871902379266036, 0.9418515897759892, 0.9357692125321339, 0.9537685978519215, 0.9354926034154484, 0.9207027584431451, 0.9304519431201699, 0.9160528725779338, 0.9097201516470443, 0.922330146941748, 0.9328012303153406, 0.8932426493308654, 0.900921272926869, 0.8867882614418887, 0.9358992134790376, 1.0000000000000007, 0.9327101711232791, 0.9512093207701618, 0.9041721016312394, 0.9236416330225263, 0.9097283095763038, 0.9280138544535949, 0.9183919558523188, 0.940487507644037, 0.9103332718351682, 0.891062977326435, 0.9487411578580649, 0.9211132563882735, 0.9376841901911807, 0.9292573296257542, 0.9148294117781427, 0.9301280632586505, 0.9385205852330769, 0.924958508734381, 0.9236431291714341, 0.926107989119694, 0.8996621420392439, 0.9456893336163958, 0.927882099594289, 0.7987642856536867, 0.888623064342382, 0.9002074373214475, 0.9006801600433463, 0.9343075582619084, 0.948292485515685, 0.8991180661770772, 0.9178728033639809, 0.8723258487818668, 0.9528905741729996, 0.9301608774665109, 0.9311806122475402, 0.9129349559783062, 0.8783576857243195, 0.9112760262767647, 0.9222783927876765, 0.9469349645779035, 0.8910211743386748, 0.9144634231646225, 0.8616514418283254], [0.9227613421052279, 0.8831700125466702, 0.8809573914345226, 0.9107915330937737, 0.8931670790693299, 0.8948866662691356, 0.927037938582071, 0.8555486550247088, 0.8977454685002736, 0.9095386891036762, 0.9213267155316588, 0.8866092088056914, 0.8737093062808453, 0.8471635457305119, 0.902726277187554, 0.9048972765853251, 0.9056316672177298, 0.8955986306595871, 0.8829343281097862, 0.9088764653933548, 0.9137096187467987, 0.9186390458709385, 0.9033564881753782, 0.8920531566761467, 0.9459916892931819, 0.927198008215132, 0.9169971565248742, 0.8988519416468375, 0.9618078208009944, 0.8920966811404147, 0.9086456823397416, 0.8973409154495611, 0.9029142905889427, 0.9057033032949111, 0.842251723787413, 0.86266662165426, 0.8600679834571452, 0.8877351577852628, 0.9384304082932162, 0.8771452203940624, 0.9335349335162735, 0.9219137079574861, 0.9074256345256524, 0.9055790871232803, 0.847315329286227, 0.9021108670597446, 0.8942925018556394, 0.9109534005596595, 0.9026560547221072, 0.8954491443697061, 0.8921479727470343, 0.9086912698469205, 0.8986751637197792, 0.9157617166634069, 0.8965472153671287, 0.8910347870805589, 0.9236463052825181, 0.9164444690080724, 0.9065846732592009, 0.943424389556837, 0.9291795798793254, 0.9127734140378454, 0.9143204790370358, 0.9085194014687601, 0.9150805959168666, 0.9270006854109101, 0.9170465233591637, 0.9080864235551219, 0.8866406731169163, 0.9130375086034801, 0.8374160629422175, 0.939766517988041, 0.896074725925557, 0.8251096412531417, 0.8695580828509006, 0.9014587151727051, 0.9151999518924385, 0.9609044058727697, 0.9104875409266328, 0.9012026836077786, 0.9463881960523087, 0.9019567480810895, 0.9218448197125867, 0.8997771798509389, 0.9088729829372657, 0.886368134965781, 0.8877285732806268, 0.8427842690878529, 0.914049099714882, 0.9327101711232791, 1.0000000000000004, 0.9132738232758674, 0.8922767581042106, 0.8766286749617694, 0.8860638267099272, 0.9160567250411619, 0.8735144855841028, 0.9212704911415686, 0.8928467364219046, 0.8573215341304321, 0.9126424675041463, 0.9300137021241133, 0.9176347690335405, 0.9376559375853691, 0.917783903491494, 0.9215332896121644, 0.9101395297242747, 0.8750540311829779, 0.8998168370171395, 0.9002265686986675, 0.8899238824166669, 0.9084111362057194, 0.9073285291841382, 0.7691982634928628, 0.8983712775061772, 0.8873689959672386, 0.8760766595358536, 0.9257299327695089, 0.9571429687944997, 0.872009830308572, 0.9535022888912656, 0.8239519422588522, 0.9225313158615922, 0.9086273787218047, 0.8895863488834723, 0.8718367143670223, 0.8527405777400202, 0.9033196182841384, 0.9318094449432264, 0.9496128189829276, 0.8892330289083654, 0.8836098185809297, 0.8546137900153864], [0.9405306222810663, 0.9323823912367899, 0.9253205877263176, 0.9281055676028958, 0.9156176889882577, 0.9296540481790125, 0.9430811659092282, 0.8707709883526146, 0.9099702133690755, 0.9268872266941071, 0.9398679577386169, 0.9152185455243325, 0.8936021564257209, 0.8760745293498194, 0.8863976023147672, 0.9209707211483251, 0.9401466203904478, 0.9271755590871236, 0.8979741610193119, 0.936458073667026, 0.9287547867061923, 0.9547628728783025, 0.9131409625035514, 0.9490034276069972, 0.9231287108709503, 0.9421756928541366, 0.9458296572533447, 0.9007005573783091, 0.9342977232321737, 0.9456349942360761, 0.9530331992202826, 0.9172871079644236, 0.9159852101976823, 0.9266623641011037, 0.883811812799995, 0.8906512608254222, 0.9030741034906605, 0.8798072430510293, 0.8867286040341622, 0.9059048150254709, 0.9416360730660628, 0.9490412466409286, 0.9341359236741618, 0.9067958209345799, 0.8835038998204301, 0.9250171314184416, 0.9166394991835197, 0.9187427125979651, 0.8749604895350043, 0.9246377283018343, 0.884445219470685, 0.9164624843074624, 0.9333705931889638, 0.9508622846816502, 0.9257077094527473, 0.876682055793274, 0.9500098600368277, 0.9292481784060231, 0.9558310561253751, 0.928558270073496, 0.9312376717553335, 0.9493023172035807, 0.9521833883451597, 0.9336862779464185, 0.9190724919670854, 0.941740060968855, 0.9522404329248559, 0.914829466119075, 0.9213373182440385, 0.9055395485944099, 0.87451144048987, 0.9243059013581548, 0.9024793805454151, 0.8525294940789924, 0.8581442851332152, 0.9354144367913018, 0.9371145630629683, 0.936928251918726, 0.9427786153668862, 0.9444086923272541, 0.9232860757867236, 0.9294818326698406, 0.9144167881073493, 0.9323969052008751, 0.9242392400861814, 0.88170310262002, 0.8908278577124166, 0.882276240202404, 0.9450736721393855, 0.9512093207701618, 0.9132738232758674, 1.000000000000001, 0.9007085402354178, 0.9076780531874388, 0.9181293333272825, 0.9271806432755122, 0.9107262425363585, 0.9457508686638346, 0.9066137059628617, 0.8670441132940419, 0.9355165523527966, 0.9196547862242161, 0.9386075955199127, 0.9329414415855012, 0.9017388485805331, 0.9442767632761901, 0.9584506869645953, 0.9222289023287248, 0.9130015005672776, 0.9455608037957097, 0.8910402847607938, 0.9166726917507331, 0.9232739704107217, 0.7762896342632193, 0.9013641802637802, 0.9207420972438032, 0.9158989746391293, 0.9474157403504403, 0.9345444905612699, 0.9123713782961396, 0.9067113945594031, 0.8554417179541449, 0.9412280551029237, 0.9196577143732348, 0.9301717856193935, 0.9136344550469933, 0.8668190404989395, 0.9195044274661246, 0.9186871092565845, 0.9382169752038271, 0.8759661392245328, 0.8984832911069457, 0.8606335462830099], [0.918651583535533, 0.8704213898078706, 0.9143351133459849, 0.9173525512704938, 0.9093874364049868, 0.9100380425149873, 0.9085454535842185, 0.8684564496975503, 0.8422960467982512, 0.9455956592938716, 0.9169913283068357, 0.8595148516402544, 0.8477324156137651, 0.858514714327701, 0.8394476460615996, 0.8771048371663178, 0.9147428277704511, 0.864143319597724, 0.8446998267001655, 0.8904707602576455, 0.9352498174405068, 0.9054296747942523, 0.9184508899085122, 0.8886636244361796, 0.8924013521845773, 0.9221541183722877, 0.919742885579518, 0.8527172599981309, 0.9303050722016912, 0.8764417796172984, 0.8986638292130086, 0.8826212126311695, 0.895192722771971, 0.8836707689482723, 0.8746123321209183, 0.8531840118848533, 0.901040498601911, 0.906338455913285, 0.8758136768078627, 0.8999663095647243, 0.9034515581507783, 0.9313702395927683, 0.9307217355075036, 0.8840522145207395, 0.8560160139490085, 0.9355990253082438, 0.8672295027728534, 0.9165128578284624, 0.8396988896165696, 0.9054961625348696, 0.8614845559944808, 0.9078340048440762, 0.8755126476788337, 0.9201721691712698, 0.9066639040981599, 0.8859637454296226, 0.9094605983887406, 0.9204204002714255, 0.9065848818949609, 0.8995664066288226, 0.9158232049587598, 0.9132003222812696, 0.9214895284525944, 0.8865221806764989, 0.9081343582640007, 0.8962429610348887, 0.9095431599683078, 0.9363425871936948, 0.9339159952870221, 0.8719077918064082, 0.8742047734511409, 0.8687622915884257, 0.8592289294757475, 0.8704931251150847, 0.8668936413297768, 0.8966372148759394, 0.9242739745000034, 0.9085130683114423, 0.9289374339077393, 0.8657225330587979, 0.9259681873730956, 0.8942909814538105, 0.901125266949949, 0.8997981557363262, 0.9325217328170073, 0.8894373544873512, 0.9520458680900657, 0.8831389016970728, 0.8966806039204529, 0.9041721016312394, 0.8922767581042106, 0.9007085402354178, 1.0000000000000002, 0.8836795936299711, 0.8931463323212415, 0.9026208104118316, 0.8717988191140961, 0.9184534580187609, 0.9328632128960792, 0.8563515403375362, 0.9040996382169229, 0.8834125884263357, 0.9093013429610998, 0.9079471952138252, 0.8893140239577676, 0.8945490314783545, 0.8971894208031262, 0.8786784215306788, 0.9116255359350087, 0.9079021573104136, 0.8739855786389235, 0.9005148803279264, 0.8873522361930786, 0.8231629013241524, 0.8479322708582413, 0.8817965500614559, 0.8508725179644219, 0.91569023342377, 0.920790479781181, 0.8927555651585176, 0.9002442307709285, 0.84798705479147, 0.9057989670243074, 0.8948141697019425, 0.8746428345919404, 0.9073049535519697, 0.869948960435702, 0.9126852815482583, 0.897090499470415, 0.9280838194716351, 0.8957451910128631, 0.8937049822466461, 0.913920269617863], [0.9330467075505937, 0.9026044971871761, 0.910703316171732, 0.9133387330041449, 0.9020997187348051, 0.8984683188017911, 0.8852113617047547, 0.8695414014706719, 0.8696884637395066, 0.9134931755397306, 0.9097241995183447, 0.8732100145231161, 0.8749131949667412, 0.9008739039299762, 0.8449155603218604, 0.8946765867258932, 0.9064727797476579, 0.884282554791896, 0.8579549757882704, 0.9028732630502687, 0.9018885943215359, 0.8980965146125338, 0.9243421834694894, 0.880162122438437, 0.8954121048502421, 0.91476483006955, 0.9204922020207715, 0.8668351968781663, 0.9083895116871153, 0.8910660460530779, 0.9054030277571412, 0.889541767781602, 0.8930337196682969, 0.8999942472716534, 0.9149257386282811, 0.8678390717781933, 0.8855258803838443, 0.8806479074658523, 0.863858143951407, 0.9123410237713561, 0.9125634876433983, 0.9328322926054434, 0.9068676071047844, 0.908315768492087, 0.8723113784631498, 0.8988767037932981, 0.8748401471317104, 0.9062359920874435, 0.807539206628356, 0.8757833776354554, 0.87726889640442, 0.8984891159404284, 0.8977173513906593, 0.9133900375408008, 0.9174601552727342, 0.8939591030524577, 0.9207556077856842, 0.9412016518430415, 0.928402629988981, 0.8942548198824234, 0.9162996018422364, 0.9141425297665807, 0.9226834802685239, 0.8897318970599399, 0.8824480852231003, 0.9055835403661573, 0.923841321574662, 0.927001949200004, 0.9135437901049253, 0.8812932229998136, 0.8957043199107593, 0.8614342903643856, 0.8895287846071126, 0.8770485860093509, 0.8663028852908164, 0.9216943512468618, 0.9226554033202206, 0.893900325326218, 0.9051227312008437, 0.8857439204880391, 0.9039824765981997, 0.8874104172414032, 0.8871134545962174, 0.893414367468968, 0.9286301602304028, 0.9002956497678387, 0.9063817967961381, 0.8783049764251306, 0.9052301316315394, 0.9236416330225263, 0.8766286749617694, 0.9076780531874388, 0.8836795936299711, 0.9999999999999998, 0.8987914381410478, 0.8952555297682969, 0.8920208857381212, 0.906131569455198, 0.8848972177294848, 0.871182095392818, 0.9242883664161018, 0.872352029467457, 0.9076446873904234, 0.878755806073532, 0.8776455098841618, 0.8752730817477771, 0.9042812917885028, 0.8979432240846927, 0.905794290067661, 0.907602572443206, 0.882052177855911, 0.9273609023098844, 0.8888354885272242, 0.8485323862848658, 0.8687784831396497, 0.8818481520092655, 0.8684916591140857, 0.9049481657455116, 0.9107768633155646, 0.9002236485867929, 0.8977565184826757, 0.8561643626827103, 0.916723948560777, 0.8763310430265789, 0.9022888984173192, 0.9060908198568447, 0.8706500906649128, 0.8979440214442499, 0.8723599561588244, 0.8989267771311911, 0.8904120192701235, 0.9296432634322418, 0.8645545324051367], [0.9334341400633859, 0.9012519979312498, 0.9008699991263218, 0.9203170402237193, 0.8978590868509031, 0.9150602280854887, 0.8920277544896578, 0.8955881010255764, 0.8736173729463507, 0.9140798282200177, 0.9064838045585382, 0.8643846784151509, 0.8588569799366179, 0.8708109318131113, 0.8795155398516855, 0.8886869325881923, 0.9320109872130447, 0.8914176335859112, 0.8472695426654919, 0.8925689262779286, 0.9281017427767022, 0.9165723446777702, 0.9271088809512901, 0.9030624692003814, 0.8970601382207071, 0.9158854555473572, 0.9344251688957027, 0.8611148988396586, 0.9303394985982967, 0.9086748604696026, 0.911983276926555, 0.9090349261134909, 0.9003062961222678, 0.9077937400324879, 0.8921863045900954, 0.8528524339332252, 0.8991366171274331, 0.929217632672126, 0.8718648087917049, 0.9334132069998253, 0.9099523385558763, 0.9363960587827944, 0.9230831378655326, 0.8906194925637402, 0.8709108800603981, 0.914387553234024, 0.8774234960485893, 0.9177880248061798, 0.8236006396258244, 0.8981716561137771, 0.8672846249278078, 0.8938717506166778, 0.8936403043621622, 0.9471029255491555, 0.9209761324882075, 0.8724223681762743, 0.9252443059787591, 0.9290439699345263, 0.9297540047032775, 0.8976458994938754, 0.9145231614426605, 0.918059469442329, 0.9323426500314378, 0.8809379770473246, 0.8907883126487989, 0.8992100227918403, 0.9295414488348892, 0.9091443814940878, 0.8979031938926283, 0.8975925424889121, 0.8643987687948718, 0.8786106459275342, 0.8909126642959234, 0.8669863215944954, 0.9300565272767278, 0.9169242154721668, 0.9218498418114175, 0.89043555127974, 0.9167710351912965, 0.8928384482704971, 0.9027201887387836, 0.893584332796181, 0.9013151053384809, 0.9196110959102246, 0.9143851916634969, 0.89285723984758, 0.8812535508907826, 0.8933342074548811, 0.9110098584404579, 0.9097283095763038, 0.8860638267099272, 0.9181293333272825, 0.8931463323212415, 0.8987914381410478, 1.0000000000000004, 0.9199130847489496, 0.8891857082887356, 0.9202754531272155, 0.8981973661149226, 0.8795335254333373, 0.9166395450843743, 0.8844035899221636, 0.9243353344684139, 0.8818654150928584, 0.882330208415256, 0.8899274409295872, 0.9085867940209132, 0.9113763239442476, 0.9195461622252766, 0.9111967247818352, 0.8793379050180455, 0.9056561889309767, 0.9189288756021288, 0.8012000485977812, 0.8603298987398692, 0.9427175696825709, 0.8742045404470867, 0.9151690007632826, 0.9092533504670777, 0.8887126069788591, 0.9092601149557704, 0.8263751554060164, 0.916936942480991, 0.8957287372386412, 0.8904487371983171, 0.9053142633161761, 0.853276402960581, 0.9192741969840352, 0.8838583769642205, 0.8988086851311671, 0.9205602047320106, 0.9039223869871367, 0.870760335476445], [0.9324633604448811, 0.9149282176203741, 0.9118572086656149, 0.9290476865265334, 0.9098423584532074, 0.9065839834591876, 0.9276829237113944, 0.864993860603499, 0.8693867511979934, 0.9335732302626377, 0.93787501803832, 0.8815133251397654, 0.8679724811012326, 0.8595033815827766, 0.8790761851094907, 0.8919977805791651, 0.9508634221740804, 0.8949579037876333, 0.8461451639302215, 0.9010375662680881, 0.9509175869305448, 0.9352698177246241, 0.9206668130418018, 0.8992883775138223, 0.9299836653421993, 0.9247104881807745, 0.9512539880976538, 0.8697864923213966, 0.9297688462068006, 0.9163338873960906, 0.917268869027271, 0.9092696891054511, 0.9194202436665834, 0.9007422845733796, 0.8790801444592105, 0.8540993944265156, 0.8949013929015576, 0.8990967295129909, 0.8915919951695246, 0.9173635258253618, 0.9137720901377663, 0.9241543533638861, 0.9415787979813236, 0.9043045389882374, 0.8785854261442649, 0.9076801949713612, 0.8817643080785156, 0.9125843818160937, 0.8583884897872678, 0.9362077375005267, 0.8612021066290418, 0.8973303875675087, 0.8884738080988844, 0.9385966892383175, 0.925127346555375, 0.8724186478809133, 0.9450460968072313, 0.9202481273716467, 0.9285532638437555, 0.9122191435583357, 0.9138478343505866, 0.9115170113336379, 0.9310612776421326, 0.9170878357115614, 0.9491726437198761, 0.9121327196869282, 0.9403979116964012, 0.9143088141647777, 0.8972844059113557, 0.9099827300579961, 0.8583985176014394, 0.9105845315446136, 0.8890889645523828, 0.8483800674702915, 0.8662533052632659, 0.9241457438374309, 0.9306345215464769, 0.9121387093235879, 0.9305214293955324, 0.9141032214764665, 0.9128579934403384, 0.9081552491033176, 0.9076656590926075, 0.9192440072243595, 0.9210850277104289, 0.8701851963709188, 0.8908175120652543, 0.8735180018130215, 0.9194932003771106, 0.9280138544535949, 0.9160567250411619, 0.9271806432755122, 0.9026208104118316, 0.8952555297682969, 0.9199130847489496, 1.0, 0.8917826946944165, 0.9315951287940374, 0.9099351784136636, 0.8735067677632944, 0.9177235409075957, 0.8991930674875765, 0.9576711213697707, 0.9031312915496754, 0.8799069021611909, 0.9229461171272791, 0.9348860642377507, 0.8941982623085443, 0.92613766268672, 0.9310486765070678, 0.883059129012266, 0.9078008901459242, 0.917986759072909, 0.7856074598493606, 0.8703167482315098, 0.8980740058159509, 0.876616123943133, 0.9547838019946359, 0.9311533770617153, 0.898891780498481, 0.9191096947287807, 0.8290806491964038, 0.935332955566447, 0.9093317121348585, 0.8822246266568735, 0.8982555719587908, 0.8691478429269248, 0.9343316806358037, 0.9130731190008613, 0.9211592815634115, 0.883231095926718, 0.907036178810074, 0.8910874640304953], [0.9163462228489039, 0.9157925026068455, 0.8972738329430787, 0.9231671181276262, 0.8825178325370806, 0.8971647233672567, 0.8921535564281552, 0.9129827583364214, 0.9004320342451394, 0.9038151929860585, 0.9029712301514163, 0.9331762942310527, 0.9049677338226736, 0.8820722172016896, 0.867276364113698, 0.9057884318786558, 0.8996145759727294, 0.9106693405919162, 0.8871705350166416, 0.9228875951245084, 0.8963099958890091, 0.9170584824825305, 0.9080207752677023, 0.9044974819535229, 0.8942862262629071, 0.9234932274820871, 0.94042425987753, 0.8761228708892184, 0.9111711112118597, 0.894884694644549, 0.9255046261620495, 0.8791013111429686, 0.8991776176669619, 0.9107688180796492, 0.8710403237318542, 0.8938881112078909, 0.8636905813385489, 0.8388448184469809, 0.8490514283538344, 0.896806815904481, 0.9272382896880664, 0.9210385665019539, 0.9077017514457939, 0.8698784764250149, 0.8398412553045773, 0.9010721894281416, 0.903204794977118, 0.8968793429902346, 0.8402097621647089, 0.8801389603751515, 0.8758782929845454, 0.897403047661215, 0.9036109758804046, 0.9115449501220976, 0.9320539068339023, 0.8899913982492744, 0.9182854417586275, 0.9033363117604671, 0.907845460053744, 0.9255725281032826, 0.9172037683780295, 0.8941965374503907, 0.9196022426445633, 0.8932936536182802, 0.8775971276132122, 0.9112489930677937, 0.9081594856394295, 0.8995900662042109, 0.8967472832935499, 0.8918164304314137, 0.8807614813547802, 0.9224372772603344, 0.9148986993229635, 0.9069031498369591, 0.8343746158611008, 0.9114784059189437, 0.9049123964342801, 0.8867979577036471, 0.9135828537197951, 0.9151977349942405, 0.9011538267479825, 0.8792146842693984, 0.8792173163544351, 0.8940891217635719, 0.928767203715869, 0.8597051724822159, 0.8690614887601866, 0.8673042485313676, 0.9421334035504039, 0.9183919558523188, 0.8735144855841028, 0.9107262425363585, 0.8717988191140961, 0.8920208857381212, 0.8891857082887356, 0.8917826946944165, 1.0, 0.9085419325659745, 0.8568202132052922, 0.8842109357016541, 0.9179074982146849, 0.8935750839503485, 0.9283993576287497, 0.8768600551746624, 0.8808877620566214, 0.8886876931102725, 0.8936144613243466, 0.8903156250154, 0.9182174739980341, 0.9151801207328146, 0.8582435918177638, 0.9073655214732683, 0.9043786577054379, 0.8393498604293501, 0.8686429451607006, 0.8793963561766466, 0.8809687563677169, 0.8959215313156891, 0.8940681496759846, 0.8708946142198977, 0.870978493879141, 0.885919665302794, 0.9183357844018192, 0.9167142144754417, 0.9024939009630224, 0.8863129100164974, 0.839774882091997, 0.8900091083796211, 0.8743672839162876, 0.889455685168719, 0.8698025229842377, 0.9030385913321273, 0.8530589251873035], [0.9404766611689402, 0.9214374688757848, 0.9298361735089178, 0.9325055169727812, 0.9106776009910724, 0.9434372461771012, 0.9485072008201927, 0.9003110473299727, 0.9111922356837336, 0.9407678569937868, 0.9427502430337262, 0.9105329048560831, 0.892251861118666, 0.8782664156169042, 0.8863763170383374, 0.9038772420762538, 0.950694008222332, 0.9069933289031983, 0.865083759557691, 0.9436080141186747, 0.9488528266825358, 0.9464567819472538, 0.925383687935889, 0.9187968878370533, 0.92654376576953, 0.9593209173567985, 0.9544413396182032, 0.9006670518764816, 0.9362926756124303, 0.9346964856489283, 0.9490645123980188, 0.9308587222903706, 0.9285697848858718, 0.93232249804104, 0.8891313498233242, 0.891641785004373, 0.9142521666549837, 0.892770266370208, 0.9065161796939697, 0.9206210946679863, 0.9358673743491512, 0.9499157126738671, 0.939298499202819, 0.9081849181732893, 0.8817825628259812, 0.9440113479819118, 0.9253241865225991, 0.9265667863987465, 0.873030406604966, 0.9331223231001385, 0.8830078289360237, 0.9299794055332342, 0.9180698399337328, 0.9563390249794708, 0.9414851277730961, 0.8921899039145973, 0.9505474061526937, 0.9353650192094756, 0.9455603787308753, 0.9270576385466804, 0.9260220699836155, 0.9491631220593033, 0.9460125159413371, 0.9419357526718577, 0.9331312131110703, 0.9164214804734739, 0.9511466888257033, 0.9341338383199324, 0.9221206700958394, 0.9114211196659596, 0.8790284824732095, 0.9208486580152236, 0.91840474741932, 0.8810586827478637, 0.8637675769078461, 0.9350297690045009, 0.943507896655401, 0.934971326877615, 0.9555699126000138, 0.9314348697171141, 0.9393099801620057, 0.936961082464416, 0.9345802302252992, 0.9422764205539756, 0.9362783718229021, 0.8996146499081437, 0.9161096565354707, 0.8907178345650578, 0.942489701400081, 0.940487507644037, 0.9212704911415686, 0.9457508686638346, 0.9184534580187609, 0.906131569455198, 0.9202754531272155, 0.9315951287940374, 0.9085419325659745, 1.0000000000000004, 0.9103673215682603, 0.8620592538579166, 0.9278046410020165, 0.946296060088908, 0.9409814815681716, 0.9338101193997762, 0.9151037351658715, 0.9464398537635301, 0.9376858251078598, 0.9262799634623728, 0.9209998056300897, 0.95740173261712, 0.9064410751867271, 0.920412407405057, 0.9305402270899283, 0.8101163986943152, 0.9085777976791674, 0.9170535846957742, 0.9005795879179793, 0.9455459938216385, 0.9350032007807402, 0.9196598939558743, 0.9126113261704647, 0.8654275839543197, 0.9558912587715453, 0.9267300697857457, 0.8985903895169477, 0.9239340318792867, 0.8883398863170009, 0.9298981167578688, 0.9385472026627113, 0.9392244332801158, 0.8891687634947346, 0.9009181157685955, 0.8856295072896108], [0.9136054446086744, 0.8765495806956394, 0.9305014544049597, 0.9085068540054146, 0.8932746645288996, 0.9005486381142326, 0.8931386790275493, 0.8673156500564545, 0.8372549798485698, 0.9134905101511572, 0.8979638776578114, 0.8524772923620492, 0.8562795775422747, 0.8545835000757278, 0.8633141473734713, 0.8737590750604975, 0.920421766606963, 0.8949988719841577, 0.8316240501896212, 0.8628537832775611, 0.9243693697214276, 0.9047736357816722, 0.9037459293677859, 0.9001020405172466, 0.8969778826030731, 0.8977201923573597, 0.913363228074018, 0.8403392778422137, 0.9104442312051724, 0.8874799628612173, 0.875709948757103, 0.8893969105191384, 0.8815812938800762, 0.8829924378107573, 0.8902655356248224, 0.8508512509439854, 0.8883164268421758, 0.8684282196561361, 0.8643584787924062, 0.8836618263532622, 0.8872436753052926, 0.9150063727284086, 0.939106756170822, 0.9030816767727342, 0.8613051984021799, 0.9173775027239527, 0.8554042399395075, 0.889074225782924, 0.8484524776381415, 0.9238752149253362, 0.8702154665204875, 0.8815741483097863, 0.8853201254619724, 0.9224187304105026, 0.912300147732712, 0.880067991183507, 0.9288919573568587, 0.9083734369911938, 0.9128969950715746, 0.8850983762084734, 0.9033624380277363, 0.911548202328523, 0.9220819963920734, 0.8599918716996066, 0.8955825254237713, 0.8888698302834832, 0.8992368285784929, 0.9282505614579344, 0.9150936259193274, 0.8866892617086104, 0.8781112646857414, 0.876878120404935, 0.8584976841883578, 0.8719245360961051, 0.8535830062134966, 0.9106775789351187, 0.9050321066600289, 0.9015614621575234, 0.9208555519483597, 0.859524984292626, 0.8978755364033362, 0.8884767658551173, 0.8664423804641159, 0.8809213261110788, 0.9133627475065911, 0.8907857333390221, 0.9012819923324822, 0.8738292250866331, 0.8956257041954113, 0.9103332718351682, 0.8928467364219046, 0.9066137059628617, 0.9328632128960792, 0.8848972177294848, 0.8981973661149226, 0.9099351784136636, 0.8568202132052922, 0.9103673215682603, 0.9999999999999998, 0.8502280685983239, 0.905981576271413, 0.867209245327912, 0.9036783175748806, 0.8940754799286502, 0.8600252529365717, 0.8967482949014882, 0.9029096226949802, 0.8635594666290252, 0.922896028901803, 0.8863334546952966, 0.8761599408578169, 0.8925888266937524, 0.8871390391578375, 0.8088133462407782, 0.8483140170913631, 0.870184231253589, 0.8581585269280323, 0.9139036985040468, 0.9194742199081085, 0.8844109327459089, 0.9045399699505898, 0.8307130081230816, 0.9025565589184334, 0.8849277314334948, 0.8805361424738242, 0.9023090726979194, 0.8442746735092593, 0.8873207412906265, 0.8876857407086216, 0.9214140175573169, 0.877943125850913, 0.9027084448641327, 0.871428506525743], [0.8939746898371853, 0.8743508560641947, 0.8631457333859607, 0.87465683308074, 0.8601154594862511, 0.8476930667089358, 0.8408948957336471, 0.8542534463648108, 0.8560299969876867, 0.8600508689116132, 0.8587888120835028, 0.8592739761706354, 0.8486188215027588, 0.8664312793657728, 0.8392893807177435, 0.8722967793528283, 0.8531375434131141, 0.8623858976351024, 0.8523813419336465, 0.8408465823854274, 0.8681629578352711, 0.8325797616922385, 0.8941042602737675, 0.864695645659703, 0.8806983323328057, 0.8647186324775946, 0.9003524574067756, 0.8282453772988807, 0.9082449946386242, 0.8498633523521253, 0.8426850120042564, 0.868402914275521, 0.8628428483857411, 0.8621012022607765, 0.8290242001251371, 0.8224905962814599, 0.8524112332934719, 0.85328256796754, 0.834570112315032, 0.8956146924743281, 0.887353125117523, 0.8827963920269799, 0.8753256340611018, 0.8709569534655461, 0.8335410189825834, 0.8768333158242643, 0.8434395193301896, 0.8802042075056239, 0.8190395885696913, 0.8348562433516333, 0.8488214856818922, 0.8654834167905489, 0.8296956274641228, 0.8822941846028425, 0.8742406742691219, 0.8556286511225728, 0.8779673558294779, 0.8726103194897817, 0.8770264337793514, 0.8904388767406937, 0.8972486978314587, 0.867371161200045, 0.8947895815602087, 0.8485094673491889, 0.8394375642654551, 0.8978902497640999, 0.8719384004075688, 0.8729507438319489, 0.8759621460513577, 0.8646242042265402, 0.881859063054905, 0.8470133818768444, 0.8681390865386442, 0.8576296234965972, 0.8378253592998071, 0.8852716012605706, 0.8801207055652907, 0.8593979410328827, 0.8673520239738185, 0.8388837160934984, 0.8709565823068681, 0.8501499403209816, 0.8841634921279005, 0.8548830254394835, 0.9058348239847753, 0.8560317584754754, 0.8424209610802706, 0.8694517525192644, 0.8771691799975609, 0.891062977326435, 0.8573215341304321, 0.8670441132940419, 0.8563515403375362, 0.871182095392818, 0.8795335254333373, 0.8735067677632944, 0.8842109357016541, 0.8620592538579166, 0.8502280685983239, 0.9999999999999994, 0.9113225103535391, 0.8284759055570518, 0.8870016044141402, 0.8332305834248414, 0.8602645565994431, 0.8356106113387077, 0.8492021362339243, 0.8569132817155556, 0.896586572260848, 0.8512952683071735, 0.8495481400936111, 0.8924036090427833, 0.8856832735343891, 0.8403930101190932, 0.8157684349785942, 0.8318964297564697, 0.8318058809207742, 0.8542192126150201, 0.8778598969264351, 0.860273056555596, 0.8716837812452337, 0.8324088375345264, 0.8951333640617201, 0.8801004342220582, 0.8748662572189977, 0.8675728167685017, 0.8185560861598363, 0.8830532410114945, 0.8422298981432415, 0.8598075807961183, 0.8811810499238595, 0.9068855706967923, 0.8154206762877367], [0.9486987527177749, 0.9152501976179137, 0.9261235912341822, 0.9268802185765679, 0.9064539593302692, 0.9291452419976141, 0.9246281557982426, 0.9152619087880672, 0.896931774314194, 0.9147950397964986, 0.9327726449662881, 0.9293410201679151, 0.9130883312226367, 0.8976924947074033, 0.8710435554756172, 0.941336938680405, 0.9172323800629781, 0.9154972595127396, 0.9202901675220623, 0.9169016627180329, 0.9196263687874707, 0.9125906470198708, 0.9450086211228961, 0.9307604110310268, 0.924668218116771, 0.9404253357246701, 0.9472403635128814, 0.8909939071160948, 0.9539950830387383, 0.9075455724720957, 0.9261665893641039, 0.9159127912638524, 0.9119108478081203, 0.9144390691371478, 0.9034373617224568, 0.894948929317725, 0.9082096525428704, 0.8822536369617884, 0.8851538291090771, 0.9377227079883955, 0.9370816440449884, 0.9329454021174988, 0.9262488237195186, 0.9177078051270589, 0.8770119080880648, 0.9378029282456372, 0.9020342470885911, 0.9238373092749979, 0.8963666382657817, 0.8898382634340075, 0.9030934064443754, 0.9167244884693858, 0.9210326876559571, 0.9432175852956028, 0.9311901807397591, 0.9133847975806949, 0.9499543613706287, 0.9447284420885795, 0.9617877526545772, 0.9446421203948779, 0.9483740913624954, 0.9399274571756759, 0.9521964092353077, 0.9130344152148819, 0.9051019837062328, 0.9363647054525974, 0.936748393967026, 0.9434587854145859, 0.9456736675341193, 0.9112643370898219, 0.9285183891537984, 0.9057439698432417, 0.9074032831838637, 0.9036034256531298, 0.8700715056005554, 0.9362983009990753, 0.9401170297969731, 0.9244166374754026, 0.9273088497933792, 0.8970169785292699, 0.9335792776018559, 0.9154025807925676, 0.9193793710804914, 0.9270351436167059, 0.9561951901460519, 0.922591919792369, 0.887414722115937, 0.916442347324254, 0.9304205239164794, 0.9487411578580649, 0.9126424675041463, 0.9355165523527966, 0.9040996382169229, 0.9242883664161018, 0.9166395450843743, 0.9177235409075957, 0.9179074982146849, 0.9278046410020165, 0.905981576271413, 0.9113225103535391, 1.0, 0.9078056169910695, 0.9207140649537924, 0.9043209477168712, 0.9139978193849668, 0.9201649541211375, 0.9262642145726154, 0.9081919642189908, 0.9312457281085249, 0.9240791780638499, 0.9113825278442681, 0.9637206320572049, 0.9331416789615768, 0.8620306532839388, 0.8979703750331367, 0.8937344255355049, 0.8851882437001829, 0.9195316230683952, 0.932203668846715, 0.9214514979451132, 0.9116576492053565, 0.8985504699528459, 0.9273501518992541, 0.9135864737680722, 0.9367699342887985, 0.936537708588171, 0.8732341122511348, 0.9085293708891232, 0.9080106201257768, 0.939982279977946, 0.9119905100269606, 0.9571817619796055, 0.8577333739334316], [0.9059184877903231, 0.8926968954652126, 0.8913070153680862, 0.9158737295590648, 0.8772887886259408, 0.9053952954774129, 0.9476774335600577, 0.8792658533717831, 0.9171962048326961, 0.9039649505283623, 0.9255944803962004, 0.9145823656828742, 0.882011058522111, 0.8529608146461001, 0.8960941374270076, 0.8939196838775219, 0.9123971133275895, 0.8857853622736752, 0.883424993894091, 0.9559249722656227, 0.9014014993518911, 0.9281222976536746, 0.8911504352877087, 0.8901835008428343, 0.9260336713650006, 0.9458104860726966, 0.918717025070845, 0.8831535456458833, 0.9180234385139808, 0.891094637282817, 0.9426442615862117, 0.8994895446842064, 0.9229852411112585, 0.9235770083524415, 0.8589415124216077, 0.8832317676719645, 0.8588223293839653, 0.8460117594909577, 0.9190926676465985, 0.868205841430565, 0.9305698011321087, 0.922105395818305, 0.8994869092606905, 0.8691108443356613, 0.8336739840671191, 0.9164020520878081, 0.9019342877491829, 0.8868909610310071, 0.875974060983125, 0.8892986162921764, 0.8643927558720095, 0.9120641481402103, 0.9091080992285674, 0.923091463482775, 0.9049578655207472, 0.8678736456330417, 0.9240041732436038, 0.9002620093113014, 0.9080478510090593, 0.9405086583901576, 0.9217964843639976, 0.9161488032133418, 0.9111048144648338, 0.9409476580063968, 0.8985968921167884, 0.9145252072787855, 0.9227970428989689, 0.8954319423558396, 0.900620235978819, 0.9021318902822132, 0.8476010203355527, 0.9148958314748099, 0.9109377680503368, 0.8512790249823232, 0.8306327994389553, 0.9059220139819697, 0.8986768950610663, 0.9425541145685731, 0.9052360739559174, 0.9249910681068597, 0.931753812280678, 0.9126698060667158, 0.8946706843976318, 0.9281251280234836, 0.8983127859165236, 0.8752059289517532, 0.8852977817955472, 0.8514632245796142, 0.9369694762456562, 0.9211132563882735, 0.9300137021241133, 0.9196547862242161, 0.8834125884263357, 0.872352029467457, 0.8844035899221636, 0.8991930674875765, 0.8935750839503485, 0.946296060088908, 0.867209245327912, 0.8284759055570518, 0.9078056169910695, 1.0000000000000004, 0.9042821440644786, 0.9348311768033368, 0.8880731769772208, 0.9344076797944725, 0.9060270798201843, 0.8923019466590301, 0.8875900753226077, 0.938789853227579, 0.8756470420333387, 0.8942767829115739, 0.9225124779867151, 0.7758261613127917, 0.8967085235293388, 0.8905726607572433, 0.87697372057132, 0.9115757950777106, 0.9157298812389021, 0.8644624602736606, 0.8936825608380325, 0.8446206913023385, 0.9252946607879025, 0.9141493871824677, 0.8922780051838828, 0.8859712166839018, 0.8531467789353131, 0.8941871638655169, 0.9475782877007423, 0.9367407781548212, 0.850908823557256, 0.8704625234837082, 0.8397642064219649], [0.9413151001290947, 0.9431824640791113, 0.9122213386067508, 0.9384013136767729, 0.9177208875098295, 0.9117835733517691, 0.9204450327619462, 0.8900794915601075, 0.8903195735592218, 0.9436941862628396, 0.9321158229389248, 0.9110777858426516, 0.8851440829645655, 0.8873986158974085, 0.8861124118820408, 0.8961146563957033, 0.9558693694647966, 0.913705234747413, 0.8612077902331274, 0.9144283657518166, 0.9569132835190534, 0.9357621272773674, 0.9332908669841324, 0.9143035822771391, 0.9335639138604905, 0.930524156226501, 0.968145469930009, 0.8828716281261672, 0.9375325953645459, 0.9279050206137147, 0.9296493374711008, 0.9270765354642543, 0.9448854871156673, 0.916829212095738, 0.8801564188693333, 0.8755665135381778, 0.9104680678817176, 0.8979368887872317, 0.8895044619446246, 0.926242792429919, 0.9264918527190971, 0.9344526446762522, 0.9443907148608868, 0.9058928986479104, 0.8847458315865286, 0.91327397841149, 0.9001784517463509, 0.9324020490380702, 0.8526021718696493, 0.9318919704673538, 0.8770745983385297, 0.9139055727184251, 0.898525015527078, 0.9511608091840347, 0.9421000256850063, 0.8910388713923821, 0.9421835029882238, 0.9221394597164954, 0.937714119923604, 0.9249589245961932, 0.9191381582002303, 0.9224320754722592, 0.9501643775802691, 0.9159800423475802, 0.929487194192876, 0.914125093128044, 0.9546672913560128, 0.9233656614403729, 0.9039502166685982, 0.9204666519761753, 0.8789456595152196, 0.9222971789150792, 0.9134304591606016, 0.873267296473266, 0.8699863952511361, 0.9435630550801912, 0.9358939026657186, 0.9179799473488073, 0.9439405954510116, 0.9255174278157106, 0.9232890891305242, 0.908909689571578, 0.9219181060360233, 0.9237555914535345, 0.9387574384841021, 0.8786263039789218, 0.8977827935186897, 0.876652617436669, 0.9329225248648936, 0.9376841901911807, 0.9176347690335405, 0.9386075955199127, 0.9093013429610998, 0.9076446873904234, 0.9243353344684139, 0.9576711213697707, 0.9283993576287497, 0.9409814815681716, 0.9036783175748806, 0.8870016044141402, 0.9207140649537924, 0.9042821440644786, 1.0000000000000002, 0.9074206005555606, 0.8927839775218687, 0.9166040498575203, 0.9335626477668308, 0.9177254307072168, 0.9453356816017358, 0.9388944140084339, 0.8885869982065536, 0.9190070209196508, 0.9210885351669935, 0.8064863597721377, 0.8771170611375488, 0.8975352061342567, 0.8927460781290906, 0.9490594957608391, 0.933268260894246, 0.9005757619115493, 0.9170092279102918, 0.8508095974297332, 0.9460777961995404, 0.91775437403297, 0.8981745119116098, 0.9045435540058029, 0.878720161000043, 0.9355088298686374, 0.9043012979823966, 0.9229168816938439, 0.8926758249065474, 0.9160091531315048, 0.898309944858857], [0.919733183250204, 0.8841162268907963, 0.8910188690467973, 0.9293704639052432, 0.8971329298945896, 0.9253345643152274, 0.9306485877828865, 0.8513801551238788, 0.8815083150855967, 0.9135331174806428, 0.946751764435148, 0.8922780124239652, 0.8526810480788103, 0.8413720720574511, 0.8875845192013105, 0.8941663502689149, 0.9108139989302123, 0.8928040092555806, 0.8674363989823664, 0.9308942702002831, 0.9181046700374094, 0.9323207187089454, 0.902148285419947, 0.9032673505245113, 0.9307267071822631, 0.9470194633229974, 0.9172159326672579, 0.8888788330548658, 0.9259516380647936, 0.8965763256679299, 0.9262360540058707, 0.8916140442275674, 0.9099966729220886, 0.9067124591826398, 0.8582821697814746, 0.8737233027218506, 0.8814083279911802, 0.8749792983577873, 0.9222718628463898, 0.8797381176405015, 0.941739546773785, 0.9300671953084836, 0.9080956888158346, 0.8989003661524075, 0.8317182073600701, 0.9370302417117229, 0.8960172713371775, 0.8892887695322085, 0.8736440385751455, 0.9049863183044753, 0.8788766041037055, 0.9153738403536263, 0.8861357001778121, 0.9151708518750313, 0.903644424548411, 0.8825942024226359, 0.9256127628273383, 0.9128482696682095, 0.9261397403780234, 0.9231505433560154, 0.917884919665881, 0.9106401787554049, 0.910318938056176, 0.9195026388584021, 0.9297339951653452, 0.9173051987787281, 0.9251151114133374, 0.9088579954017092, 0.9068423816907663, 0.9040766080769683, 0.8408628741448401, 0.9138887831602858, 0.8879850705792931, 0.8409267665975397, 0.850280150348276, 0.8965716847503019, 0.9005614148497143, 0.9585252116636792, 0.9233329694458474, 0.9153247377338962, 0.952999743628757, 0.8984497257710068, 0.9119254183910946, 0.918978407333221, 0.8928231270700111, 0.8930752760469498, 0.8923107708843638, 0.8478786292542385, 0.927808216226643, 0.9292573296257542, 0.9376559375853691, 0.9329414415855012, 0.9079471952138252, 0.878755806073532, 0.8818654150928584, 0.9031312915496754, 0.8768600551746624, 0.9338101193997762, 0.8940754799286502, 0.8332305834248414, 0.9043209477168712, 0.9348311768033368, 0.9074206005555606, 1.0, 0.8920852534418472, 0.9261942352606523, 0.9135123834831617, 0.8890293290557112, 0.899470868626163, 0.9192614288268373, 0.873761083735207, 0.9030771540686828, 0.9073148766015463, 0.7621998793964753, 0.8701438841214613, 0.8935572108644985, 0.868609067222907, 0.926387453375618, 0.9432356503660618, 0.8618471914580297, 0.9262991269345635, 0.824777744711367, 0.929884958233814, 0.9112782336413177, 0.8742868298955182, 0.8822355936407115, 0.8900992117882209, 0.8929071353207362, 0.9453033542599384, 0.956161534522745, 0.8694517361778358, 0.8716105393587837, 0.8660828539363821], [0.9338279546295947, 0.8879984640191988, 0.8828071685445609, 0.9090396150176587, 0.9145103097485994, 0.894565211699358, 0.9173116402682907, 0.8917863810605138, 0.9065765037135349, 0.8990643397436415, 0.9058599891673461, 0.8753406261507426, 0.8905712636221983, 0.8641216351431312, 0.8488133552238207, 0.9102308552897245, 0.8895401979746749, 0.8782825177708542, 0.8772795057144906, 0.916751552427092, 0.9075161386439964, 0.9031915674847646, 0.914177302673829, 0.8839824113613535, 0.8924503710376177, 0.9263988383383714, 0.906348720452729, 0.9361332259942954, 0.9423455554526682, 0.8967958535093575, 0.9328806009514812, 0.899344195421215, 0.8808785549485016, 0.9084406932691295, 0.8532982742980967, 0.9376796833461913, 0.8692844475743735, 0.8840995770377968, 0.8950289057459326, 0.8954247436509758, 0.9263410173333593, 0.9176795552763157, 0.9039216043425284, 0.90531464140211, 0.8607676174485451, 0.9047415765881036, 0.9223975370364719, 0.948852944748305, 0.8458241270324511, 0.8676794248710042, 0.9020012131600542, 0.9366643293141858, 0.8979358429832915, 0.915149725221468, 0.9073276453451852, 0.9279763439268052, 0.9127089839355613, 0.9317620930281785, 0.9096981178559511, 0.9110933567563051, 0.9285243706218717, 0.9157912290842186, 0.9144378733001945, 0.9007696726960859, 0.8740359139032401, 0.9264563146354295, 0.9013368809103177, 0.924164650107747, 0.9054088651245034, 0.88816287883007, 0.8569143023405734, 0.8867860680396952, 0.9001863451925505, 0.8636110407938637, 0.8779271933401089, 0.9003971547880927, 0.9281814156746663, 0.9113187073287162, 0.900967446997923, 0.8995940694177382, 0.9441057828864292, 0.913715794786196, 0.921725097340812, 0.9090489942532534, 0.9298615577264221, 0.8992910107145878, 0.8925454723492439, 0.8916829504598958, 0.914403978534461, 0.9148294117781427, 0.917783903491494, 0.9017388485805331, 0.8893140239577676, 0.8776455098841618, 0.882330208415256, 0.8799069021611909, 0.8808877620566214, 0.9151037351658715, 0.8600252529365717, 0.8602645565994431, 0.9139978193849668, 0.8880731769772208, 0.8927839775218687, 0.8920852534418472, 0.9999999999999993, 0.9038440447604964, 0.8963234667286772, 0.8766570562934519, 0.8796904864926106, 0.8960322810110852, 0.8956898286499149, 0.928524847712111, 0.8836527819031258, 0.7998488381703435, 0.9134289756832361, 0.9009525056826211, 0.8750587917301379, 0.8849109992410737, 0.9311292735312513, 0.8924012776282797, 0.9163806179749892, 0.892338576723552, 0.9124877027101421, 0.9080157297992116, 0.8926715362606807, 0.9019677751979565, 0.8676678757238323, 0.9120902778129578, 0.894142375082154, 0.9058491350993881, 0.9137442620739293, 0.8960143222286827, 0.875798828660937], [0.9197210163070888, 0.8916247180400656, 0.8953577761608407, 0.9131075484050348, 0.8910769165320491, 0.9300218958193164, 0.9655767378601264, 0.8841591430213588, 0.883328463855328, 0.9167731508507896, 0.928306681230589, 0.9182441814563164, 0.8896660029322797, 0.8368831858551214, 0.8614168246946574, 0.9170657694800486, 0.9294124022892793, 0.8905970627318064, 0.8703304795304581, 0.9345774092508186, 0.9293456357004073, 0.9377484308989313, 0.9017534326503408, 0.9106637698771123, 0.9186934937962917, 0.9434834562566772, 0.9297472315004438, 0.8934805455132968, 0.9289278555843871, 0.9143693961412713, 0.9357912950947085, 0.8944263604305251, 0.8940517186962436, 0.9242404634738549, 0.8598985133074295, 0.8880709265745155, 0.870600328568578, 0.8624154336363142, 0.8969042473726592, 0.8813431617384709, 0.916398348378775, 0.9243159619194843, 0.9202112835758015, 0.8915862122334032, 0.8626748932680288, 0.9243273823119065, 0.9044159918598955, 0.8981267628237732, 0.880823559377754, 0.9181331642205296, 0.8840526690917712, 0.9266163355396726, 0.9171219396351712, 0.9257527396259614, 0.9125980873297476, 0.8669413713372157, 0.9441234471961271, 0.911677892716424, 0.9217335257344466, 0.9203125292092011, 0.906882541922466, 0.9230576669450514, 0.9236263533074515, 0.9363132429846079, 0.9272663920363853, 0.9143176905046806, 0.9264043130110735, 0.9060542656045452, 0.8953342836252693, 0.9020001771909699, 0.841017282133077, 0.9361786994372983, 0.8933209402242337, 0.8480736357253833, 0.8459428181480895, 0.9123128852301594, 0.926642652290059, 0.9204582186879916, 0.930903393796441, 0.9274491125221694, 0.9298576918832271, 0.9262794544559491, 0.8994991853065338, 0.9278362135988123, 0.9084093977742693, 0.8712480627802212, 0.8950771949643138, 0.858129471054267, 0.9293286626617349, 0.9301280632586505, 0.9215332896121644, 0.9442767632761901, 0.8945490314783545, 0.8752730817477771, 0.8899274409295872, 0.9229461171272791, 0.8886876931102725, 0.9464398537635301, 0.8967482949014882, 0.8356106113387077, 0.9201649541211375, 0.9344076797944725, 0.9166040498575203, 0.9261942352606523, 0.9038440447604964, 0.9999999999999998, 0.9319275569231753, 0.8924346956552969, 0.902423903334709, 0.9451321590078311, 0.8869165434450322, 0.9069485143356896, 0.9268052855692891, 0.7671446849151106, 0.9117728677183915, 0.8943530666130031, 0.8931193331475773, 0.9302310379773318, 0.9213833287838, 0.8892164625219215, 0.8998770724154511, 0.8517617861391364, 0.9387112342025805, 0.913717504682583, 0.8961608959203458, 0.8982483812433094, 0.8780112726008292, 0.911178971987405, 0.9447187484008933, 0.9218875526285817, 0.8513299003095905, 0.8766018028018451, 0.8564835658174651], [0.9410042142986494, 0.9120461607852182, 0.9248827158398001, 0.9189138946644402, 0.9174249742291252, 0.9268063977950076, 0.9408229076111037, 0.8699015861748032, 0.8925682854008552, 0.9354714522238583, 0.9358626477107418, 0.8966381745509735, 0.8961561420900556, 0.8648558750732525, 0.8819763904035136, 0.9029495287673914, 0.9462998807206058, 0.9000871385193961, 0.8768137454262646, 0.9215300356415758, 0.9414284275700691, 0.9490940386218778, 0.9193800752277295, 0.9181024923536143, 0.9115745464129622, 0.9365827381689684, 0.9377079420997037, 0.8780342525909897, 0.9285580892320755, 0.9073979316584336, 0.9446584834039851, 0.9120462265555298, 0.9078415148960135, 0.9045659403792052, 0.880938550727663, 0.8760533812882686, 0.9006730620738946, 0.8906221937097105, 0.8820597326992707, 0.898354772920317, 0.929482354640991, 0.9333770097065426, 0.9336030883204702, 0.9098767402075942, 0.8706150499711484, 0.9207081169919215, 0.9085389034705125, 0.9103901615110357, 0.8604562525961575, 0.9312764184026818, 0.8862018882604916, 0.9126475388232518, 0.9273128295133687, 0.9457611640616226, 0.9126921597369034, 0.8665137919838051, 0.9503243828906711, 0.93609225395754, 0.938811068384093, 0.9120879051173534, 0.9274736994123185, 0.9366395129734033, 0.9493724140833353, 0.9306639212377743, 0.9231460474833479, 0.9235674603112317, 0.9518002564566199, 0.9093637563172923, 0.9118866793115938, 0.9049263892069538, 0.8641466515472225, 0.9234399363523306, 0.8959074017691039, 0.8364183689192606, 0.8792270561784427, 0.9378381023269482, 0.9295041045350857, 0.9190749890005906, 0.9340680719638047, 0.9331441425555447, 0.9165926350148846, 0.9307332124368757, 0.9128853733025006, 0.9173444782269911, 0.9172377670657296, 0.8732859606808654, 0.8926337788840022, 0.872550724750786, 0.9193453137950492, 0.9385205852330769, 0.9101395297242747, 0.9584506869645953, 0.8971894208031262, 0.9042812917885028, 0.9085867940209132, 0.9348860642377507, 0.8936144613243466, 0.9376858251078598, 0.9029096226949802, 0.8492021362339243, 0.9262642145726154, 0.9060270798201843, 0.9335626477668308, 0.9135123834831617, 0.8963234667286772, 0.9319275569231753, 1.0000000000000002, 0.9281441343667648, 0.9053359359673097, 0.9378857835349778, 0.8795877074510717, 0.9177110041633771, 0.9164787139815875, 0.7730759299940178, 0.8904076612588788, 0.907239929573034, 0.9004298093298924, 0.9567867035226997, 0.932488086564152, 0.9029719639215383, 0.9083390593074642, 0.8239799934273544, 0.9309931624062013, 0.9049730895075901, 0.9169233172957226, 0.8960401657187392, 0.8600671778722163, 0.923721428156852, 0.927488433144906, 0.9324210191824197, 0.8702655901561308, 0.8951975710801972, 0.8566266949042224], [0.9265866927116064, 0.8931951715926609, 0.9063533497757137, 0.8983949474400513, 0.8875143923829804, 0.9067273343518779, 0.9021454407039319, 0.8640996166522167, 0.8785350245127026, 0.9168933022032585, 0.9021460319565842, 0.8917279640757216, 0.8596628107425913, 0.8588673157791793, 0.8643019338411532, 0.8907824707103991, 0.9332799799122431, 0.8831517593938523, 0.8519123995729705, 0.9243074344706762, 0.9183690243364966, 0.9295540969427255, 0.9297482690638226, 0.9111753744629735, 0.8800922319840312, 0.928565674450725, 0.9304853271514085, 0.8729274965976344, 0.9133199590715713, 0.888451698276231, 0.9290588426950601, 0.892658397157414, 0.8909652350143726, 0.900433816791809, 0.8688400783696907, 0.86027868397929, 0.864921920488227, 0.8721545270286868, 0.8524273263219306, 0.9211817142998927, 0.9167521578286895, 0.9287050220446266, 0.9040170053313028, 0.8797598634091393, 0.8433032755910503, 0.8859689610579863, 0.8850833784368762, 0.9007845608979007, 0.8474131098763114, 0.8921294836208192, 0.8847022965069041, 0.9017662917052929, 0.894622788670868, 0.9365659257483772, 0.9071989914643627, 0.8455888606453721, 0.92386140306851, 0.9144339440084466, 0.9160858409889336, 0.898117914786696, 0.8997978173263665, 0.9225323143488595, 0.9345579120389572, 0.9119845024273882, 0.8952725686910337, 0.887207280430753, 0.9634610317965049, 0.8955585786531242, 0.8875891820615706, 0.8825729339749058, 0.8505442100695021, 0.8958909077311622, 0.8897763183716878, 0.8259292329921877, 0.8558046450768831, 0.9118620150550181, 0.9038460462661659, 0.892822548548562, 0.9227021997730799, 0.9086640954400833, 0.8902617381645891, 0.8947823712423981, 0.8918259227270884, 0.9055628760852951, 0.9011976275366236, 0.8568088874175972, 0.8864101748582254, 0.8420057534016757, 0.9085633588939923, 0.924958508734381, 0.8750540311829779, 0.9222289023287248, 0.8786784215306788, 0.8979432240846927, 0.9113763239442476, 0.8941982623085443, 0.8903156250154, 0.9262799634623728, 0.8635594666290252, 0.8569132817155556, 0.9081919642189908, 0.8923019466590301, 0.9177254307072168, 0.8890293290557112, 0.8766570562934519, 0.8924346956552969, 0.9281441343667648, 1.0000000000000004, 0.8865712597827303, 0.9199456380367033, 0.8630992495863117, 0.9176250492454021, 0.902181562514702, 0.7775820124688874, 0.8424989974025752, 0.8928463165819285, 0.8860389774264839, 0.9228039237857026, 0.9005214790810702, 0.8692517801592261, 0.8807006813374114, 0.8265295286407301, 0.9281859543608727, 0.9028952209320222, 0.8933545673850973, 0.8718802456258948, 0.88058619406273, 0.9041569402463567, 0.90434065559492, 0.9059504446772705, 0.8814689679897117, 0.8814189600633989, 0.8558564143952672], [0.9281534419724249, 0.9223229871161054, 0.9080841078235399, 0.9349513781979227, 0.8955087210404167, 0.9072883591291561, 0.8977961438008242, 0.9017785676430634, 0.8759655338232032, 0.9283741227804364, 0.9255666200039515, 0.8927017862455345, 0.8772754164902616, 0.8771300576231005, 0.8657114857883147, 0.8868589869021752, 0.917848287317107, 0.8959551628217497, 0.8590082529648551, 0.8945097497391528, 0.9373117605108389, 0.9036774910029706, 0.9219559473793408, 0.898470177787373, 0.9246384185693893, 0.9198474878309415, 0.9553541686112028, 0.8690697496924908, 0.927850087501453, 0.9230071269909388, 0.9005277555490367, 0.9217871648882155, 0.9249116327662893, 0.9179427991992744, 0.8902873955036488, 0.8686788931615619, 0.9162497996153607, 0.8867777503597852, 0.8883358699016438, 0.9204672034930992, 0.916628620903282, 0.930332575130941, 0.9253657482030749, 0.8985915844096743, 0.8878150633959441, 0.9297528610776497, 0.8790817241709001, 0.9172079618365929, 0.8307702693004522, 0.8966095866896624, 0.8725898527945637, 0.8964251975874205, 0.8758192935699745, 0.9223123232591867, 0.9387075862273935, 0.9028770635725891, 0.9335641629348329, 0.9117052908864965, 0.923988939713592, 0.9143503449699215, 0.9215938858399891, 0.9176132704959465, 0.9341734606333496, 0.889717051569972, 0.9022534517255867, 0.9019740382966426, 0.9210067871366276, 0.9304155205966481, 0.9161177465458269, 0.91215869260164, 0.888136692958104, 0.8897839841063724, 0.8928284158593812, 0.9138180811401273, 0.8651417604379134, 0.9209977747998599, 0.9340970228112337, 0.9140419361387327, 0.9348317580871146, 0.8877089378959149, 0.9246813777447669, 0.8969142120430282, 0.9013739955934355, 0.9130051901815404, 0.9493066325116825, 0.9030420610038024, 0.8933625233532546, 0.887376322516828, 0.9230292601294888, 0.9236431291714341, 0.8998168370171395, 0.9130015005672776, 0.9116255359350087, 0.905794290067661, 0.9195461622252766, 0.92613766268672, 0.9182174739980341, 0.9209998056300897, 0.922896028901803, 0.896586572260848, 0.9312457281085249, 0.8875900753226077, 0.9453356816017358, 0.899470868626163, 0.8796904864926106, 0.902423903334709, 0.9053359359673097, 0.8865712597827303, 0.9999999999999999, 0.9191195990058832, 0.8721576730368159, 0.9131177433838926, 0.925838192422604, 0.8256547335069362, 0.8596119958452063, 0.8839460983058575, 0.8832631395807657, 0.9199877552753679, 0.9212291686398792, 0.9067606528807426, 0.9124496066240316, 0.8528507149146571, 0.9278740505629586, 0.9067948773914862, 0.8961151036620932, 0.9135298429264794, 0.8679608415823963, 0.9152608615251864, 0.8897891796672328, 0.9222733539511786, 0.8900514295631018, 0.9275324500525693, 0.8776877259465318], [0.9301558455369912, 0.9211267955514699, 0.9199139305653554, 0.9254228252599332, 0.8958799669821034, 0.9186975445663705, 0.9469933517026756, 0.8839801996818936, 0.8983993939642896, 0.928516437964468, 0.9416532645120503, 0.9258608612333209, 0.9172779068916468, 0.8551787378960066, 0.8699524053853047, 0.9117969169975669, 0.9480012659162227, 0.885645307187384, 0.8790426413175282, 0.9495039782750906, 0.9380322708375612, 0.9483371261212595, 0.9119386210617942, 0.9159070604752843, 0.9088917084849829, 0.956026471640289, 0.9539610887079709, 0.8781850287472741, 0.9241439931267599, 0.9271012950334476, 0.9565875818497356, 0.9049147949673195, 0.9297707703794347, 0.9192620735907399, 0.8851510050449123, 0.893311808907668, 0.8922550683248506, 0.8841395952436126, 0.8896895553213121, 0.9002927625078214, 0.9252104881469501, 0.9324970104874009, 0.9231512997982135, 0.87952118877457, 0.864717945390765, 0.9286998597047998, 0.9037782637440546, 0.9075229024373292, 0.8504399897021776, 0.9143341389234566, 0.8806850707404961, 0.9176796391308953, 0.9184924291404348, 0.9402261724507249, 0.927164997015141, 0.8743161575717796, 0.9442089376979841, 0.9216040456266708, 0.9265516748428987, 0.918630032175418, 0.9100116359839248, 0.9267324854565212, 0.9318302545866491, 0.9596695070223422, 0.9276953314779727, 0.9143742421155464, 0.9368197050818434, 0.9114029575168645, 0.9163015030864526, 0.9005494093833695, 0.8752314201821927, 0.9134546836338225, 0.9014945602630107, 0.867079874298227, 0.8587140802010298, 0.9165679530935464, 0.9287679043732106, 0.9114576827357487, 0.9410687511131064, 0.9542441704059182, 0.9247012668606166, 0.9221684508158043, 0.9166163194156626, 0.9464389012559313, 0.9259948605291959, 0.8782268295714077, 0.8948348776458569, 0.8815363903905769, 0.9368594061785537, 0.926107989119694, 0.9002265686986675, 0.9455608037957097, 0.9079021573104136, 0.907602572443206, 0.9111967247818352, 0.9310486765070678, 0.9151801207328146, 0.95740173261712, 0.8863334546952966, 0.8512952683071735, 0.9240791780638499, 0.938789853227579, 0.9388944140084339, 0.9192614288268373, 0.8960322810110852, 0.9451321590078311, 0.9378857835349778, 0.9199456380367033, 0.9191195990058832, 0.9999999999999997, 0.8810818010802117, 0.9100699149377777, 0.9264644445909015, 0.798779420786863, 0.8991046014092747, 0.9281773011199415, 0.8953412876564076, 0.947403968208934, 0.9109686764796399, 0.9037101588226222, 0.8943389242452904, 0.862365210763829, 0.945657955112122, 0.9181535073135099, 0.9168256068500777, 0.9181357933128383, 0.8833779611921554, 0.921632871490293, 0.9261484780472606, 0.9294147535042019, 0.8762425655114521, 0.8904545430822425, 0.8639464743655746], [0.9216074550290796, 0.8576186504126748, 0.8943597831367506, 0.9071593774038824, 0.8844062018370323, 0.8882675183029565, 0.8903808172699359, 0.8683277634733244, 0.8649741531372859, 0.8713643546110192, 0.8982975581153586, 0.8497176413049056, 0.8531945120669268, 0.928546935622086, 0.8546118433565146, 0.8811481139482527, 0.9064123386968603, 0.8933303615388274, 0.8325179960516137, 0.8778929952473745, 0.8946325186788154, 0.8819476993102815, 0.921664238190411, 0.9025738866875166, 0.8980364298603178, 0.9061769388116157, 0.8953802467860158, 0.8443996663660881, 0.9224438314841507, 0.8671418897971347, 0.8859351165699079, 0.8848057715516446, 0.8849056585654679, 0.8878714048128922, 0.8685137912346007, 0.8548885240021135, 0.8710165394540323, 0.877752084388244, 0.8901380904521533, 0.8653213711837898, 0.9038848164485535, 0.8897774160202963, 0.9098175791269754, 0.9112522566294438, 0.8739899747895927, 0.8868249637009232, 0.8718743972969977, 0.9160254676042691, 0.8384056079415916, 0.8929497328160121, 0.8612406974044409, 0.8868830267899619, 0.8987040314277721, 0.9144200021885158, 0.8939108974283934, 0.8977670516759368, 0.9079127680074608, 0.9317848196958439, 0.9093976736334756, 0.8839017984469781, 0.8983424967206202, 0.896416538884371, 0.916335096950366, 0.8716508996965716, 0.8724811695364929, 0.9135865503339373, 0.897981157814921, 0.9173702571690059, 0.8796184202634942, 0.8876890913431972, 0.8675607561313, 0.8584713293801383, 0.8657748555472111, 0.8491093675459341, 0.8534366066970415, 0.9256203585285787, 0.9287491976738315, 0.8967560390003687, 0.8956585212365421, 0.8546046859850411, 0.9129267428022106, 0.8898940541745367, 0.9019311429504498, 0.8729047470955839, 0.9166084546531917, 0.9158617778393943, 0.8568723341215533, 0.8855625399586522, 0.8963771443215787, 0.8996621420392439, 0.8899238824166669, 0.8910402847607938, 0.8739855786389235, 0.882052177855911, 0.8793379050180455, 0.883059129012266, 0.8582435918177638, 0.9064410751867271, 0.8761599408578169, 0.8495481400936111, 0.9113825278442681, 0.8756470420333387, 0.8885869982065536, 0.873761083735207, 0.8956898286499149, 0.8869165434450322, 0.8795877074510717, 0.8630992495863117, 0.8721576730368159, 0.8810818010802117, 1.0000000000000002, 0.9100625169330093, 0.8665268719176986, 0.808900846378924, 0.8730917191133912, 0.8480090510199425, 0.8483174267185443, 0.8882095442379387, 0.9188122147382346, 0.9369230641786975, 0.9103164864191908, 0.8581475642657448, 0.8931397660286645, 0.8680508380788103, 0.877705210585934, 0.8914449045250004, 0.8382581759949782, 0.8839781925881813, 0.88329282962747, 0.9028504323859062, 0.8717032946114613, 0.9037850416354215, 0.8487690275049047], [0.9500150703917882, 0.9019018379913689, 0.9116563245681033, 0.9349775735793592, 0.9195942153441499, 0.915992286462995, 0.9142434595796, 0.9064415032629188, 0.8946297001557317, 0.9237717708059582, 0.930456097573398, 0.8987911152475137, 0.8864295610433561, 0.896221272269148, 0.8543531779338547, 0.9435196873697702, 0.9158983695682741, 0.9147471245886903, 0.9052162899679915, 0.9239267918563162, 0.9248390827530042, 0.911129761442933, 0.9647358222177489, 0.9158277864228854, 0.9021638637240208, 0.9412225912881997, 0.9287953479867527, 0.9051185880840553, 0.9504087749308396, 0.90747459299093, 0.9255107293952721, 0.9115216476357386, 0.8958917542162744, 0.9230356941807236, 0.8891058594049773, 0.9094232061556126, 0.8908609227123392, 0.8835477719038194, 0.8764886986138349, 0.9302841253093608, 0.9421197698202695, 0.9358920233906317, 0.921758685683202, 0.9305891925692988, 0.8815311495783069, 0.9193647242822305, 0.9087395563629503, 0.9319726810314286, 0.8743714463489193, 0.8847294885646662, 0.9340367428553359, 0.9322642943517053, 0.9054293161187399, 0.9342550951182631, 0.9390279442301813, 0.9196351504916886, 0.9370399188951688, 0.950209359039736, 0.9396326174065887, 0.9247414058296121, 0.9333628564472598, 0.928957248250094, 0.9458895517070187, 0.9014836613302424, 0.8980391246940536, 0.9364625898935415, 0.9412375684262011, 0.9440531138390202, 0.9307156065100388, 0.9092059055738149, 0.9075900187479682, 0.902437506557672, 0.9156044750243595, 0.8870167325361895, 0.8830784357028483, 0.9329853617308066, 0.9391486777965481, 0.9112566099798819, 0.9227124038605994, 0.9013757918657946, 0.9326913117214755, 0.9150825805910096, 0.9091831825045775, 0.9128580359216947, 0.9431888072979078, 0.9082112810466328, 0.9049096090531813, 0.8891758525566572, 0.9316995430690941, 0.9456893336163958, 0.9084111362057194, 0.9166726917507331, 0.9005148803279264, 0.9273609023098844, 0.9056561889309767, 0.9078008901459242, 0.9073655214732683, 0.920412407405057, 0.8925888266937524, 0.8924036090427833, 0.9637206320572049, 0.8942767829115739, 0.9190070209196508, 0.9030771540686828, 0.928524847712111, 0.9069485143356896, 0.9177110041633771, 0.9176250492454021, 0.9131177433838926, 0.9100699149377777, 0.9100625169330093, 0.9999999999999994, 0.9211011173224002, 0.8563695772231209, 0.8853245456583252, 0.891024737084374, 0.8911784260739465, 0.9064221522855064, 0.9343948393441771, 0.8973376369351239, 0.9200171589720695, 0.8901477597810377, 0.9378896741830693, 0.9213384813150656, 0.922396505493629, 0.9120883545508637, 0.8967792281651286, 0.912107171682201, 0.9050927631991734, 0.9193955753779779, 0.923442163845219, 0.9543726275706086, 0.8846819590725525], [0.9313981601769936, 0.9189780653189628, 0.9030988173301862, 0.9026215798896493, 0.885810806052408, 0.9035130835149446, 0.9437883356106307, 0.8936971217367852, 0.9011968895349192, 0.9188167973068155, 0.9147978780164493, 0.9208579888458104, 0.876759060756713, 0.8410410020184577, 0.8902724880310162, 0.915314176715104, 0.9207960316359656, 0.8951342903232864, 0.9034364912974704, 0.9278095098112213, 0.9228720121174413, 0.9193499717906634, 0.9092894272763371, 0.8994119243688649, 0.9211280864190925, 0.9289480945531043, 0.9354881839826531, 0.8851559236197981, 0.926121297192039, 0.911571659504628, 0.9266741155257987, 0.9157850899031761, 0.9002034213465646, 0.9285244677862594, 0.8597714037975952, 0.8693916304744294, 0.8837173182270209, 0.8810989447832204, 0.8843896753135287, 0.9110610232700194, 0.9223149718154253, 0.925635196815839, 0.9148095519528796, 0.8970429286156657, 0.8561443687645622, 0.9162660172579938, 0.9030415931675104, 0.8971143451193058, 0.8803503139423752, 0.897659965758494, 0.8818690613972873, 0.9055092408345068, 0.9000996807883721, 0.9226354508689678, 0.9152680523587919, 0.8674866056482691, 0.9332360069455452, 0.9122801772482163, 0.9213387373418739, 0.9310750242928476, 0.9255111399684522, 0.9393142941509482, 0.9296703128319461, 0.9265985545128796, 0.9119276770627331, 0.9173017222802641, 0.9266557254064469, 0.901851315630102, 0.9047195228005409, 0.9305323328503361, 0.8654662339419414, 0.9191689744031826, 0.9165137236959655, 0.8548061544489917, 0.8717663596119077, 0.9101228890345786, 0.9176066346297342, 0.9137397748101028, 0.919124972541458, 0.9106194999330063, 0.9113480769120137, 0.9202160234228554, 0.8986710078495419, 0.9325740343312237, 0.9187862811593244, 0.8770556312767545, 0.8902411671596453, 0.8761566144077235, 0.9378995785704667, 0.927882099594289, 0.9073285291841382, 0.9232739704107217, 0.8873522361930786, 0.8888354885272242, 0.9189288756021288, 0.917986759072909, 0.9043786577054379, 0.9305402270899283, 0.8871390391578375, 0.8856832735343891, 0.9331416789615768, 0.9225124779867151, 0.9210885351669935, 0.9073148766015463, 0.8836527819031258, 0.9268052855692891, 0.9164787139815875, 0.902181562514702, 0.925838192422604, 0.9264644445909015, 0.8665268719176986, 0.9211011173224002, 1.0000000000000002, 0.8043208409875086, 0.8839481446090012, 0.8870588553138593, 0.896440870045416, 0.9209905226254319, 0.9080078384129868, 0.8799870643572879, 0.9080910783082613, 0.8344092632569714, 0.9387163444035136, 0.9407856413319248, 0.9002845390657301, 0.8914633764034025, 0.8497229760724702, 0.9248525242396531, 0.9250853049039018, 0.9202788437908791, 0.8779004576187497, 0.8992919202029196, 0.8428173347591408], [0.8277540514511157, 0.8012650648264935, 0.8524973184544244, 0.8284027313332636, 0.7977962741603565, 0.7876672195440836, 0.7705646107082287, 0.8402475514503542, 0.7555441023953119, 0.8071828678302472, 0.7909248586799333, 0.8142720016678154, 0.8291801540583299, 0.8424946911487727, 0.7140501359892968, 0.8262318084940017, 0.7991463730108741, 0.7850686777196134, 0.769231556815827, 0.7876968062288746, 0.7978852694008343, 0.7829254634623519, 0.8510675886671497, 0.7936407403206939, 0.790654185045009, 0.7949148417189984, 0.8300065862687374, 0.7537216880280805, 0.819723787562731, 0.7648355792366754, 0.7999666313243335, 0.7826814433734361, 0.7998066494482131, 0.7789756218514566, 0.8676478703463386, 0.8011588977517496, 0.783167247161372, 0.7659371012784012, 0.7394333561929037, 0.8277643548969682, 0.790536652632531, 0.8196912426173522, 0.8349461084362638, 0.815982111260238, 0.7541082371745003, 0.8177015320456582, 0.7677581476823722, 0.8031775678580979, 0.7345987637346296, 0.7811974438446488, 0.805270900099195, 0.7986814656152124, 0.7989892385839411, 0.820619116690064, 0.8349112615913998, 0.8670978230639304, 0.8050053663743425, 0.853101046921035, 0.8224679961415043, 0.8127894754573799, 0.8135252837722678, 0.7933509011369202, 0.8344508554972377, 0.7622910748888714, 0.8024242320666949, 0.7891383868147396, 0.7999406504593167, 0.8670936743291426, 0.8520708770009848, 0.8041012701403111, 0.9293038286371601, 0.76450059644187, 0.7962584992094808, 0.8950271866708609, 0.7969171921020171, 0.8182258697140956, 0.8183761281400579, 0.7755770069906451, 0.7998160880587699, 0.771216720405127, 0.8088344848966272, 0.7679653998712641, 0.7920923927283638, 0.7939502710476815, 0.8889172861842403, 0.8185419381473189, 0.8196340582752375, 0.8261255284516154, 0.7928283139394716, 0.7987642856536867, 0.7691982634928628, 0.7762896342632193, 0.8231629013241524, 0.8485323862848658, 0.8012000485977812, 0.7856074598493606, 0.8393498604293501, 0.8101163986943152, 0.8088133462407782, 0.8403930101190932, 0.8620306532839388, 0.7758261613127917, 0.8064863597721377, 0.7621998793964753, 0.7998488381703435, 0.7671446849151106, 0.7730759299940178, 0.7775820124688874, 0.8256547335069362, 0.798779420786863, 0.808900846378924, 0.8563695772231209, 0.8043208409875086, 0.9999999999999994, 0.7776445786370924, 0.7632790064302699, 0.7408016927087565, 0.7958195350030164, 0.8018102164233123, 0.8127400182517824, 0.8004383548060275, 0.848828993772196, 0.8032753786262687, 0.8008206266904347, 0.8206895961736274, 0.8717092937964686, 0.7646914036476842, 0.7856828745700393, 0.7489757990398014, 0.7946220586891326, 0.8356057898808643, 0.9074345539039179, 0.7741621338439879], [0.8885805309407172, 0.8673003606353693, 0.8781557055767466, 0.8809539137211182, 0.8620233541439722, 0.8742091837306608, 0.9142180563419005, 0.8420392131462968, 0.9119748284862066, 0.8757179681107579, 0.8903803087345452, 0.8705349650568696, 0.8957128519159775, 0.8309765395150668, 0.864155187510165, 0.9039428047972604, 0.8758843976154106, 0.8961426730172299, 0.8818084124329109, 0.9069241334246615, 0.8737960283012284, 0.8949731147364307, 0.8622780698726186, 0.8844378145140528, 0.874779096091237, 0.9061805761692449, 0.8833515220509474, 0.8931060565934625, 0.9049715314295615, 0.890784804955788, 0.9223842991261565, 0.86247247925617, 0.8795262747547729, 0.8868851282251149, 0.8406546351888762, 0.8868513858545646, 0.8380471518721484, 0.8339254342065371, 0.8628463684113278, 0.8497010609160123, 0.9019210085521232, 0.8835083360961689, 0.889277364615595, 0.8718260581436568, 0.8495353347645611, 0.8773982925575247, 0.913760385989856, 0.8872432902004671, 0.8272589240408701, 0.864751893616651, 0.8805209509371257, 0.902118181080367, 0.935100843354716, 0.8950300286067673, 0.880473495151737, 0.8730220198313643, 0.9006695334724357, 0.9028099051065704, 0.8848491560050022, 0.8930760746764014, 0.8988191581991094, 0.9112571334057887, 0.8946076565769643, 0.8962534873545306, 0.8595547095780541, 0.9065653913654711, 0.8676511273895872, 0.8874604614155085, 0.8765139006627545, 0.8756141341781042, 0.8437208971462341, 0.8839502286315271, 0.8968502209455611, 0.8433362025964931, 0.8443690205106396, 0.877278375532946, 0.91338748514906, 0.8833324895651617, 0.8963173619528666, 0.8981460685705077, 0.8993440338991849, 0.8946668139947922, 0.8863907329126712, 0.8893313329794384, 0.9130967562505606, 0.8537610968334767, 0.8456624929557963, 0.8693274090961463, 0.8993651044242068, 0.888623064342382, 0.8983712775061772, 0.9013641802637802, 0.8479322708582413, 0.8687784831396497, 0.8603298987398692, 0.8703167482315098, 0.8686429451607006, 0.9085777976791674, 0.8483140170913631, 0.8157684349785942, 0.8979703750331367, 0.8967085235293388, 0.8771170611375488, 0.8701438841214613, 0.9134289756832361, 0.9117728677183915, 0.8904076612588788, 0.8424989974025752, 0.8596119958452063, 0.8991046014092747, 0.8730917191133912, 0.8853245456583252, 0.8839481446090012, 0.7776445786370924, 0.9999999999999998, 0.8837648385806192, 0.8669108237442908, 0.8864854008272842, 0.8841567829676931, 0.8838659029597269, 0.8762359712050617, 0.8462932844058111, 0.8970801333144568, 0.891175574227819, 0.8916542623327572, 0.88591523364327, 0.8250088538992324, 0.8824514025860428, 0.8829655684527413, 0.8865651992512018, 0.8296374747224717, 0.8605681769959244, 0.8108688168254867], [0.907790153187011, 0.8850518405570467, 0.8855076203665827, 0.9080466701565388, 0.8806550861054324, 0.9093822087728507, 0.9102719318916812, 0.8593612431701505, 0.8755687854651679, 0.8986305932033862, 0.9097673017882002, 0.8676547801944237, 0.8795369993008522, 0.832563677337816, 0.8438690728455931, 0.8853107005774982, 0.9008831579889877, 0.868655204654934, 0.8467120046433319, 0.9123894793814823, 0.8994589577658754, 0.9166265537805508, 0.8981963326226573, 0.8790034590563983, 0.8738693383327276, 0.9242965751424349, 0.9139960186805526, 0.890387430071749, 0.9087883906582751, 0.9088154430613469, 0.9272346824526853, 0.8722138747369736, 0.8773828450315662, 0.8881239770904611, 0.8670551047629829, 0.8830630407339627, 0.860714068449485, 0.9081000090586573, 0.85889748309619, 0.8946112630755277, 0.9113753612288908, 0.9212942957644792, 0.8921529092303534, 0.854285150111844, 0.8358611124065042, 0.9014990279827397, 0.9015387939761661, 0.8996652773653078, 0.801723120091224, 0.8757570510260392, 0.868769239974898, 0.9072326510986557, 0.8969154479810153, 0.9108568458596557, 0.9060294495771648, 0.861532961574728, 0.9100368381560064, 0.9182278356564922, 0.9074505272891431, 0.8839863385213016, 0.9035606383989013, 0.9078830622595774, 0.894828239404382, 0.9057536431601811, 0.8798610796237554, 0.8930367980308476, 0.9109484403612859, 0.8929721013085823, 0.8874154211603311, 0.8586038863220403, 0.8309450199166168, 0.8760461440849788, 0.8839913747196134, 0.8416544899118976, 0.8980470691615539, 0.8825641394380196, 0.8993790564068144, 0.8912854378800641, 0.9153994013273431, 0.9120367277118631, 0.9041914874110106, 0.8958187150971736, 0.8879025816645706, 0.9153086688271233, 0.8913580567882007, 0.8666566675922738, 0.8748451409070523, 0.8614743355734189, 0.9099747850394536, 0.9002074373214475, 0.8873689959672386, 0.9207420972438032, 0.8817965500614559, 0.8818481520092655, 0.9427175696825709, 0.8980740058159509, 0.8793963561766466, 0.9170535846957742, 0.870184231253589, 0.8318964297564697, 0.8937344255355049, 0.8905726607572433, 0.8975352061342567, 0.8935572108644985, 0.9009525056826211, 0.8943530666130031, 0.907239929573034, 0.8928463165819285, 0.8839460983058575, 0.9281773011199415, 0.8480090510199425, 0.891024737084374, 0.8870588553138593, 0.7632790064302699, 0.8837648385806192, 1.0000000000000002, 0.8729939512606384, 0.9071606496024078, 0.8959773866393935, 0.8703702182744577, 0.8898336982400519, 0.8208657961198322, 0.9186691361076121, 0.8947221503363694, 0.881587828989005, 0.8818677079357787, 0.852404895873192, 0.9024546107324178, 0.8970051414416486, 0.8962840855002896, 0.8902524749601154, 0.8688102221315286, 0.8549039023014472], [0.9109653783548588, 0.8956473195365633, 0.8837993849205023, 0.8825859909007614, 0.8672576732440027, 0.8725889533026536, 0.905737299819116, 0.8449392470996804, 0.8822321314543331, 0.9018295969450283, 0.8770540252715684, 0.8649931086822737, 0.8584428382556167, 0.8549536388845685, 0.8645477934255364, 0.8863351960668189, 0.8995646890650834, 0.8891679744594109, 0.8812640638680562, 0.9036392217881926, 0.8876652390819362, 0.9073187782625152, 0.8789038969364471, 0.8768599448709424, 0.8716451945653672, 0.9076949504115982, 0.9012295017646355, 0.8872113221454222, 0.8995970301942863, 0.9311648493263569, 0.9066863325871023, 0.898131929788728, 0.8578215237161911, 0.9063620711180808, 0.8287878102075452, 0.850248440069753, 0.8479879247298212, 0.8571354742882695, 0.849822317147155, 0.8700412812974084, 0.905050412050717, 0.9122773193890854, 0.8816820656399795, 0.8785880140025599, 0.9146313138323857, 0.8798578859557514, 0.8794422106884541, 0.9001532870743693, 0.845008956949794, 0.8824785433414126, 0.8753653175601732, 0.88614586835391, 0.8945717129633689, 0.9115819927128269, 0.8930593901635104, 0.8419553237564174, 0.9141821637355451, 0.8894024185566582, 0.8877753108647392, 0.8823015964769474, 0.8903473549634586, 0.9102849796716201, 0.909628283186466, 0.899195851327492, 0.8614182629469599, 0.909376160147503, 0.908322758208864, 0.8713712994743453, 0.8687683696855283, 0.8743672528773213, 0.8316217890465498, 0.8895699958495793, 0.8825123705300352, 0.807211681763212, 0.8448870169594438, 0.9113019720602653, 0.9231355617170072, 0.8860243147126976, 0.9081979160310728, 0.9028762449243835, 0.8770254547602825, 0.9068239059105969, 0.8735555980203864, 0.873941237536946, 0.8848853317590867, 0.8519100971140092, 0.8644463308011816, 0.8569640497125391, 0.9128648179120332, 0.9006801600433463, 0.8760766595358536, 0.9158989746391293, 0.8508725179644219, 0.8684916591140857, 0.8742045404470867, 0.876616123943133, 0.8809687563677169, 0.9005795879179793, 0.8581585269280323, 0.8318058809207742, 0.8851882437001829, 0.87697372057132, 0.8927460781290906, 0.868609067222907, 0.8750587917301379, 0.8931193331475773, 0.9004298093298924, 0.8860389774264839, 0.8832631395807657, 0.8953412876564076, 0.8483174267185443, 0.8911784260739465, 0.896440870045416, 0.7408016927087565, 0.8669108237442908, 0.8729939512606384, 0.9999999999999996, 0.8866596693016234, 0.886031447513082, 0.8653932718352667, 0.8787982046854363, 0.8174927902855655, 0.9169623894845877, 0.8855013772489555, 0.903922273962308, 0.8582282272533446, 0.8495905635186433, 0.9046499931736262, 0.8863927093966084, 0.8866204268895064, 0.8374645243388965, 0.8624813164384391, 0.8287640727860333], [0.9380951167880164, 0.9098455896094302, 0.9285091012664201, 0.9388878930465087, 0.8966630819982144, 0.9166738381450006, 0.9372719793327774, 0.8522733771159152, 0.8810161333863025, 0.9364489008602624, 0.9541190923278625, 0.9010306932978159, 0.8853899635496507, 0.8658583147318447, 0.8866746039585472, 0.8996114935650372, 0.963073962400522, 0.9032608011003052, 0.8634940130698265, 0.9161419732231559, 0.9525761113045211, 0.9527858392316966, 0.919522081239124, 0.9229975381445501, 0.9315396926614427, 0.9331471824902363, 0.953849933985702, 0.8709966858253011, 0.9337994027428129, 0.9170065586952578, 0.93906858041369, 0.9004915316085566, 0.9285027738581724, 0.9030979143445118, 0.8784487165146455, 0.8677665998101874, 0.8944385564387775, 0.8989541471679636, 0.904505047128119, 0.8966913502607038, 0.9274110579260709, 0.932881182356589, 0.955330071443037, 0.8999463532376972, 0.8695154272677017, 0.9138164469589766, 0.8999184639786416, 0.9124126818087093, 0.8555985412334868, 0.9460816823084212, 0.8679643880598807, 0.904119013446128, 0.9158383474402426, 0.9452821966933659, 0.9209605097685118, 0.8810229424048864, 0.9451717219952059, 0.9286074136336274, 0.9293942663296301, 0.9177024179537602, 0.9204420490500005, 0.9369148521403028, 0.9441133009658413, 0.9276953349169967, 0.9693909992156391, 0.9116982232964481, 0.943668274252622, 0.9187968971034517, 0.9082801033868124, 0.9106151316403138, 0.8636523140527975, 0.918591969991845, 0.8997645374071558, 0.8408730718417108, 0.8627742173994366, 0.9251337893223142, 0.9314950469028622, 0.926420496518654, 0.9420313139705598, 0.9255352950741963, 0.9274271734865269, 0.9196296803901631, 0.9127316158708119, 0.9275985720656289, 0.9228877636382391, 0.875605916448033, 0.8992715744676029, 0.8610525356608689, 0.9249683259931234, 0.9343075582619084, 0.9257299327695089, 0.9474157403504403, 0.91569023342377, 0.9049481657455116, 0.9151690007632826, 0.9547838019946359, 0.8959215313156891, 0.9455459938216385, 0.9139036985040468, 0.8542192126150201, 0.9195316230683952, 0.9115757950777106, 0.9490594957608391, 0.926387453375618, 0.8849109992410737, 0.9302310379773318, 0.9567867035226997, 0.9228039237857026, 0.9199877552753679, 0.947403968208934, 0.8882095442379387, 0.9064221522855064, 0.9209905226254319, 0.7958195350030164, 0.8864854008272842, 0.9071606496024078, 0.8866596693016234, 1.0, 0.9276315283386077, 0.8996154566117365, 0.917604275230807, 0.8328966041173731, 0.9337167238389656, 0.9235742818499527, 0.9083221963998194, 0.9026954728860602, 0.8667737306098815, 0.9197023745693171, 0.9288354344323639, 0.9426036980987955, 0.8791434146807415, 0.8980813900907703, 0.8692535331521176], [0.9615450929846505, 0.8984707525747679, 0.9147562850762978, 0.9452406721643598, 0.9677669475123142, 0.9329326260343911, 0.9247140407402846, 0.8890165159770371, 0.8932150860866197, 0.9324870874724872, 0.9359832661187615, 0.8841456645958531, 0.8770847127927411, 0.895610023831775, 0.9013909857504263, 0.9080927278179844, 0.9352055359192789, 0.9101087002274546, 0.871005841159101, 0.9160695413272066, 0.9471821873988054, 0.9306863411591064, 0.9401118070576219, 0.9115669362399701, 0.9511102830805114, 0.9431137481390437, 0.9381196886330829, 0.8902750978686007, 0.9638621505947668, 0.9088534095828819, 0.9260306592118468, 0.9406834270574599, 0.9184355389464529, 0.9115378793670252, 0.8953151183472181, 0.8806872549040394, 0.9103547425727884, 0.917836823422462, 0.925955161001197, 0.9166819848533649, 0.9440826682411492, 0.9531685586592424, 0.9409007387074046, 0.9376041879541722, 0.8797470507950823, 0.9257516285240328, 0.908501191265412, 0.9424883287489672, 0.8814495756005118, 0.9275900864081575, 0.8992943719189544, 0.9233731849140562, 0.897799614261934, 0.9458672847172958, 0.9290952173076639, 0.916740989353385, 0.9401443054859854, 0.9564399957395701, 0.9551480380275106, 0.9351184466786082, 0.9355882368877102, 0.9278898736695443, 0.9417970452696772, 0.91901028332204, 0.9227428401959411, 0.9390268939568046, 0.9457603294979171, 0.9514523436836332, 0.9127235242755515, 0.9217410371531035, 0.8812343100667293, 0.9142159433353938, 0.8896918898270908, 0.8614525310392176, 0.8914111294027508, 0.9316043944975582, 0.9438506250732215, 0.9659635624040349, 0.9316723739906184, 0.9086324158643697, 0.9488156169646228, 0.913092837383736, 0.9341769862287516, 0.9092717560532071, 0.9324567594899527, 0.9302732782841542, 0.9103601624008231, 0.8911305425902357, 0.9240624710396063, 0.948292485515685, 0.9571429687944997, 0.9345444905612699, 0.920790479781181, 0.9107768633155646, 0.9092533504670777, 0.9311533770617153, 0.8940681496759846, 0.9350032007807402, 0.9194742199081085, 0.8778598969264351, 0.932203668846715, 0.9157298812389021, 0.933268260894246, 0.9432356503660618, 0.9311292735312513, 0.9213833287838, 0.932488086564152, 0.9005214790810702, 0.9212291686398792, 0.9109686764796399, 0.9188122147382346, 0.9343948393441771, 0.9080078384129868, 0.8018102164233123, 0.8841567829676931, 0.8959773866393935, 0.886031447513082, 0.9276315283386077, 1.0000000000000002, 0.9068386332736019, 0.9627283088204621, 0.8497315652127229, 0.9438529991184073, 0.906857008738757, 0.9020837455915542, 0.9063295136417141, 0.8756846846907472, 0.9202801085844997, 0.931810014745852, 0.9541876307401654, 0.9212296605717973, 0.9223248340896661, 0.8944775360259395], [0.9144170244971022, 0.8783674745212566, 0.9032153334225896, 0.897718377972744, 0.8926166658707695, 0.899089189739807, 0.8916483603555936, 0.868539029578588, 0.8656663276352515, 0.8969202882453694, 0.9024473763870096, 0.8566984008877052, 0.8643930296075378, 0.8979172932001126, 0.8308276420208979, 0.871269621882126, 0.8953545029300327, 0.8812870477033635, 0.833516701168775, 0.8823414726725824, 0.9006023791217347, 0.8793083506137549, 0.9142260005839169, 0.8971920514273763, 0.8906791990396532, 0.9061187078438331, 0.9075773970206171, 0.8450559150923493, 0.9135547709554876, 0.8936017401015764, 0.8878661240091794, 0.9067781981077997, 0.8897260380842507, 0.892594076923761, 0.873748788188706, 0.8486718293348373, 0.915483452171477, 0.8982418880519935, 0.8679264276349026, 0.8845001793748151, 0.8957287466870957, 0.9068889230246306, 0.9059947587596537, 0.9054250566507924, 0.9115843877343539, 0.9007387393104473, 0.8719288184926772, 0.9176371063762366, 0.822294207243119, 0.8823128268493665, 0.8317145860605822, 0.8786310963552588, 0.8996300770710541, 0.9143184364744303, 0.8986086466266017, 0.8884844921512288, 0.9111045970595589, 0.930510522057792, 0.9243404850560363, 0.888520661397841, 0.9107851301868062, 0.9094015457706619, 0.926211843586314, 0.8886451179978105, 0.8760666944617785, 0.9009551068772768, 0.8986984902842537, 0.9199060881711755, 0.9000514524815049, 0.8910156620460361, 0.889161971454187, 0.8556825178393933, 0.8720791177659823, 0.883358142272389, 0.8546021570987817, 0.9210812953033113, 0.9547673340669259, 0.8916688838104271, 0.9223417174833504, 0.8661498429533214, 0.9063714873030809, 0.8974261839033126, 0.9095958211624349, 0.8866755635472412, 0.9482379587829044, 0.9059706475231465, 0.8730362493818413, 0.9273869273732417, 0.890450081996061, 0.8991180661770772, 0.872009830308572, 0.9123713782961396, 0.8927555651585176, 0.9002236485867929, 0.8887126069788591, 0.898891780498481, 0.8708946142198977, 0.9196598939558743, 0.8844109327459089, 0.860273056555596, 0.9214514979451132, 0.8644624602736606, 0.9005757619115493, 0.8618471914580297, 0.8924012776282797, 0.8892164625219215, 0.9029719639215383, 0.8692517801592261, 0.9067606528807426, 0.9037101588226222, 0.9369230641786975, 0.8973376369351239, 0.8799870643572879, 0.8127400182517824, 0.8838659029597269, 0.8703702182744577, 0.8653932718352667, 0.8996154566117365, 0.9068386332736019, 0.9999999999999993, 0.9039125995265078, 0.856360728659304, 0.8949789210399753, 0.8691242805845872, 0.8843778605048933, 0.9296303190983698, 0.8441677970576178, 0.91789303717277, 0.8754543520074447, 0.9040088023952169, 0.8691697712770126, 0.9056357638728275, 0.855003569531344], [0.939653249177625, 0.8927336155443026, 0.8913977921120764, 0.923105198856215, 0.9110726504304282, 0.9016313448514508, 0.9127803601297397, 0.8664629826905049, 0.8871517920000712, 0.9096865448340798, 0.9206844750537986, 0.8635408909945359, 0.8572556268849415, 0.8605696622067501, 0.892732790380663, 0.8851156095395851, 0.9098551423873322, 0.8969611844135987, 0.8503536555539841, 0.8996073268741503, 0.9185267368069607, 0.9050926110930697, 0.9289468194062627, 0.8902418834314105, 0.9394169178200662, 0.919674644396321, 0.911329925874475, 0.8797147823640553, 0.9471350613914136, 0.8936641252198805, 0.9021765047875806, 0.9096836956091119, 0.9069737355939997, 0.899285947110654, 0.888517288964294, 0.8681712744177875, 0.8866581187432487, 0.939755411693745, 0.9372187334264903, 0.8906351042106411, 0.9272212683520616, 0.924023618905641, 0.9137483994335459, 0.9617959020626039, 0.8760705766262373, 0.9001011200537965, 0.8865911986535285, 0.9268227913586493, 0.8513388134163375, 0.8983854162621482, 0.8848512155358097, 0.9102572748259206, 0.8940578542555813, 0.9221699350749268, 0.9074000031613415, 0.9062157609832484, 0.9228342335531461, 0.9517102666608077, 0.9255738080017266, 0.913746881330656, 0.9189485161847962, 0.9127147084277941, 0.9187579701243942, 0.8946497210577891, 0.9119014836186875, 0.9219414359219472, 0.9217014773776783, 0.9326006339046773, 0.8869414778297129, 0.9537347123357429, 0.8630423587469428, 0.9029083447593541, 0.9000170154914289, 0.8456786435355872, 0.9004746266002663, 0.9025842224084513, 0.9332116696021653, 0.9451318924604509, 0.914444360829667, 0.8942765450077882, 0.9421757426071125, 0.9039044085881336, 0.9232121078630771, 0.8919570382643064, 0.9185447777931168, 0.9306873989552791, 0.8951546821649293, 0.8913798574326265, 0.9132080271398517, 0.9178728033639809, 0.9535022888912656, 0.9067113945594031, 0.9002442307709285, 0.8977565184826757, 0.9092601149557704, 0.9191096947287807, 0.870978493879141, 0.9126113261704647, 0.9045399699505898, 0.8716837812452337, 0.9116576492053565, 0.8936825608380325, 0.9170092279102918, 0.9262991269345635, 0.9163806179749892, 0.8998770724154511, 0.9083390593074642, 0.8807006813374114, 0.9124496066240316, 0.8943389242452904, 0.9103164864191908, 0.9200171589720695, 0.9080910783082613, 0.8004383548060275, 0.8762359712050617, 0.8898336982400519, 0.8787982046854363, 0.917604275230807, 0.9627283088204621, 0.9039125995265078, 1.0000000000000002, 0.8233167960967668, 0.9224749250938133, 0.9142505779942482, 0.8787494109339424, 0.8910812916150798, 0.8667836565780955, 0.9246846290276307, 0.9233642971154554, 0.945266028640174, 0.9211691925563763, 0.9061660883999291, 0.8885812992978182], [0.8669308947130476, 0.8478842695452049, 0.8658486318039511, 0.8632304635222269, 0.8496646761303875, 0.8426090968086588, 0.8453520942038706, 0.8998948819551229, 0.8421360828731757, 0.8474932949300172, 0.856025262805458, 0.8823983833186972, 0.8845312295927948, 0.8762940693343317, 0.7845050852766287, 0.8772242715632218, 0.8415446016824122, 0.8486955744316893, 0.8548135935661171, 0.8667131078913872, 0.8492066443211382, 0.8464577580690654, 0.8722786802330112, 0.8546766349334671, 0.8322054100234346, 0.8692434561710058, 0.8788363204472486, 0.8361456289975974, 0.8689485300107797, 0.8419474505646727, 0.8739453719010404, 0.8331398374444521, 0.8456808000890693, 0.8644171997660817, 0.8466347360405488, 0.8969081904429924, 0.8316126928263478, 0.7863911951398628, 0.8140700090394332, 0.8532386578366051, 0.8610523774868574, 0.8686319982380406, 0.8574499502945088, 0.8381339213301329, 0.8042576046579841, 0.8692724934750536, 0.845599854398281, 0.870742614888749, 0.7996313386970977, 0.8147685518294241, 0.8554692392135183, 0.8597470064171092, 0.8478856249220901, 0.8647541567061003, 0.8851510232282276, 0.9128594088838977, 0.8784993704436013, 0.872740675839218, 0.8692310202648609, 0.8824646215965536, 0.872982854961371, 0.852634065052832, 0.8790683590915862, 0.8427459838530884, 0.8136847508575469, 0.8697844940711829, 0.8489810934907757, 0.897813245189296, 0.8925233439916525, 0.8290502853310959, 0.8792499257975934, 0.8316735988948455, 0.8463067702306145, 0.904960610906295, 0.7829240824867569, 0.8806239138837052, 0.873005724861535, 0.8391573957947225, 0.8591319371121299, 0.8377833158858065, 0.8795001909082842, 0.8314678398761444, 0.8346876177684313, 0.8639983037573943, 0.9148468094950644, 0.8631563904972679, 0.837179142770917, 0.8681392492672139, 0.8775096281295672, 0.8723258487818668, 0.8239519422588522, 0.8554417179541449, 0.84798705479147, 0.8561643626827103, 0.8263751554060164, 0.8290806491964038, 0.885919665302794, 0.8654275839543197, 0.8307130081230816, 0.8324088375345264, 0.8985504699528459, 0.8446206913023385, 0.8508095974297332, 0.824777744711367, 0.892338576723552, 0.8517617861391364, 0.8239799934273544, 0.8265295286407301, 0.8528507149146571, 0.862365210763829, 0.8581475642657448, 0.8901477597810377, 0.8344092632569714, 0.848828993772196, 0.8462932844058111, 0.8208657961198322, 0.8174927902855655, 0.8328966041173731, 0.8497315652127229, 0.856360728659304, 0.8233167960967668, 0.9999999999999998, 0.8606405404789841, 0.8532080831434209, 0.8530050332053994, 0.9131997475083986, 0.8135952091096776, 0.8357087874485148, 0.8087452825143134, 0.8503692221762129, 0.8442199909825152, 0.8868224839887979, 0.8331637430060015], [0.9500337992544176, 0.9256132639217991, 0.9232671935337848, 0.937922445981782, 0.9271635196512201, 0.929478739587309, 0.9402479548789039, 0.8922971019163061, 0.9123341086486092, 0.9369057427205936, 0.9375300736620674, 0.9064571841248985, 0.8955892352171247, 0.8845091188326335, 0.8984071676543809, 0.9202524299198749, 0.9456384474138873, 0.9214652605059651, 0.8765360735428293, 0.9480433454336435, 0.9477662398612757, 0.9453584464879483, 0.931676688951395, 0.9156588379904052, 0.9263959268983196, 0.9622125481002215, 0.9541844998667044, 0.91907598399423, 0.9384927580597601, 0.9432577557760548, 0.944660285247537, 0.9350158171674038, 0.9162618138602547, 0.9424788060625898, 0.8778828595196038, 0.8997282509996709, 0.8980493762806662, 0.8959654598052711, 0.896767172515674, 0.9218468111594134, 0.947854383672057, 0.955260942405507, 0.9349316232068683, 0.9097860204732862, 0.886708419515119, 0.9402034943958459, 0.930574446798716, 0.9287791544042184, 0.8580586267178623, 0.9276309964984546, 0.9139533870056163, 0.9475787714416624, 0.9084930153947616, 0.9502198930498407, 0.9451107705115258, 0.8872965778960796, 0.9580587223845359, 0.9328153128711393, 0.9333531620831615, 0.9267795206217726, 0.9262079644080159, 0.9404982872894629, 0.944428908295639, 0.9445805642653997, 0.9244575521840335, 0.9364225684836828, 0.9522358817148291, 0.9300075469310884, 0.9101109112037046, 0.9180892047173218, 0.8816927535965184, 0.9251459974541308, 0.9147286538708315, 0.8721886373921917, 0.8815697460094857, 0.9399888690927614, 0.9392987870032192, 0.9378754739721835, 0.9483403153058028, 0.9480222074695583, 0.9341094123553345, 0.9315760371859827, 0.9192283920159546, 0.927593220646856, 0.9312169760342195, 0.8953079523797189, 0.9135311189393557, 0.887622828277067, 0.9520906620322694, 0.9528905741729996, 0.9225313158615922, 0.9412280551029237, 0.9057989670243074, 0.916723948560777, 0.916936942480991, 0.935332955566447, 0.9183357844018192, 0.9558912587715453, 0.9025565589184334, 0.8951333640617201, 0.9273501518992541, 0.9252946607879025, 0.9460777961995404, 0.929884958233814, 0.9124877027101421, 0.9387112342025805, 0.9309931624062013, 0.9281859543608727, 0.9278740505629586, 0.945657955112122, 0.8931397660286645, 0.9378896741830693, 0.9387163444035136, 0.8032753786262687, 0.8970801333144568, 0.9186691361076121, 0.9169623894845877, 0.9337167238389656, 0.9438529991184073, 0.8949789210399753, 0.9224749250938133, 0.8606405404789841, 0.9999999999999996, 0.9418650477280444, 0.9093136052506139, 0.9053284709926103, 0.8956628822040732, 0.9405205740740582, 0.9366025278115785, 0.9285113103792754, 0.900215444391625, 0.9149313348309535, 0.8823623782485451], [0.9215918762475691, 0.9056017634604401, 0.9078054449126076, 0.9216322884172543, 0.8863117519125746, 0.8920253805930739, 0.9265321163386088, 0.8766460088639431, 0.9221448409972041, 0.9163075935589999, 0.9186984681739466, 0.9079843297413563, 0.8682605891353825, 0.8491554587553315, 0.8850570599239703, 0.9136335824895077, 0.9187637355257927, 0.9255312389926449, 0.8814569827081503, 0.945384545630732, 0.911404156083204, 0.9393245985764501, 0.9124658602572342, 0.9158671697819598, 0.8968861725453253, 0.930165309015667, 0.9175818864092007, 0.8970298199961482, 0.9216737628124123, 0.916882698743986, 0.9403025040718878, 0.8913355737128874, 0.9022249329213176, 0.9295205212081515, 0.8531735680586106, 0.9025619794358395, 0.8792399552410988, 0.8662322420403255, 0.8883229217903228, 0.8841130448691263, 0.94157122839438, 0.9247327933647395, 0.9201912937787199, 0.9052736420655265, 0.8443914242211078, 0.9107078741121317, 0.90793042813889, 0.9005315401712628, 0.8605026521737075, 0.9074404483492379, 0.8902303923308279, 0.9326644254665533, 0.9166941200432057, 0.9306626518663723, 0.9118037906075218, 0.8849059156958461, 0.9238273364961758, 0.9158006719779632, 0.9021504440812226, 0.9242058161862131, 0.9322546572260723, 0.9274660822278911, 0.9312773197195717, 0.9149955147120208, 0.9018961839908366, 0.9314265310495342, 0.91382423990067, 0.9084914224420795, 0.9068632744788931, 0.9266536499350182, 0.8688110929207804, 0.9330761966155697, 0.9380135806071086, 0.8694729657048037, 0.8568639300080841, 0.9053872070654215, 0.9133157424050091, 0.9106488984143088, 0.9124554398264693, 0.9392935508980444, 0.9282189272042172, 0.9080246798621697, 0.8792725521274453, 0.9144849607513316, 0.9202308918300198, 0.8627150122324351, 0.8993321405509795, 0.8675592772791598, 0.9465414735568322, 0.9301608774665109, 0.9086273787218047, 0.9196577143732348, 0.8948141697019425, 0.8763310430265789, 0.8957287372386412, 0.9093317121348585, 0.9167142144754417, 0.9267300697857457, 0.8849277314334948, 0.8801004342220582, 0.9135864737680722, 0.9141493871824677, 0.91775437403297, 0.9112782336413177, 0.9080157297992116, 0.913717504682583, 0.9049730895075901, 0.9028952209320222, 0.9067948773914862, 0.9181535073135099, 0.8680508380788103, 0.9213384813150656, 0.9407856413319248, 0.8008206266904347, 0.891175574227819, 0.8947221503363694, 0.8855013772489555, 0.9235742818499527, 0.906857008738757, 0.8691242805845872, 0.9142505779942482, 0.8532080831434209, 0.9418650477280444, 1.0000000000000002, 0.8973372041259364, 0.8901273037231646, 0.8461377858260283, 0.9185159154984327, 0.9189337876235313, 0.9207340208140953, 0.8859812012322726, 0.8913093527168778, 0.8526325522181148], [0.9279829124778807, 0.8863251355615854, 0.9323863676566486, 0.9153054531709506, 0.8875605559816373, 0.869647334526901, 0.9053868220156329, 0.8648148290933896, 0.9133143496769965, 0.9017712339221204, 0.9114805556444008, 0.9015930773237233, 0.919299713280909, 0.8833870221983057, 0.850765517269354, 0.9367630258212715, 0.9204835364327534, 0.9080782276931747, 0.9268050719986906, 0.9130193656108618, 0.8904638204124072, 0.9256892276651048, 0.8981422787801517, 0.9247480242986112, 0.8854315442990915, 0.9203815777597364, 0.9136721490526682, 0.8692021024406427, 0.9367640396923462, 0.8935013750163067, 0.933794544006504, 0.9044325008648489, 0.889803113292892, 0.9021669027223215, 0.8737111921808745, 0.8910167707338669, 0.8661056223549783, 0.8469347258238223, 0.8450050636168509, 0.8874495213621572, 0.9305732951872089, 0.9224138736756134, 0.9234647835173084, 0.8793598840991311, 0.8630278160320491, 0.8946003917665145, 0.9070046085592223, 0.8995600282279081, 0.861276210876482, 0.8900361004262312, 0.9069674829577172, 0.8904478174722131, 0.9335799721859939, 0.9291241723769035, 0.9053938462402735, 0.8866399679554011, 0.9298512817156601, 0.9158680799679346, 0.9078627383233686, 0.9136077637627221, 0.9323835110673885, 0.9197339913176209, 0.9322350211741388, 0.9036278070975923, 0.8707292451383729, 0.942522453213321, 0.9042613769955947, 0.8930153501190496, 0.9223189316810743, 0.8725534031598201, 0.9106007509305192, 0.8923548364622351, 0.8923800686328147, 0.8543929478301983, 0.8575618767174829, 0.9153103185847855, 0.9172777363424053, 0.8962179605608076, 0.906198672495827, 0.9134963657897456, 0.8948187686705034, 0.9027534115536902, 0.8828578380562934, 0.897174814597913, 0.9264072453890073, 0.8670509324197964, 0.8697433425430017, 0.8897582251419381, 0.9170902332344137, 0.9311806122475402, 0.8895863488834723, 0.9301717856193935, 0.8746428345919404, 0.9022888984173192, 0.8904487371983171, 0.8822246266568735, 0.9024939009630224, 0.8985903895169477, 0.8805361424738242, 0.8748662572189977, 0.9367699342887985, 0.8922780051838828, 0.8981745119116098, 0.8742868298955182, 0.8926715362606807, 0.8961608959203458, 0.9169233172957226, 0.8933545673850973, 0.8961151036620932, 0.9168256068500777, 0.877705210585934, 0.922396505493629, 0.9002845390657301, 0.8206895961736274, 0.8916542623327572, 0.881587828989005, 0.903922273962308, 0.9083221963998194, 0.9020837455915542, 0.8843778605048933, 0.8787494109339424, 0.8530050332053994, 0.9093136052506139, 0.8973372041259364, 1.0, 0.9117020780960262, 0.8343264776809564, 0.8797237753179212, 0.8693894836515602, 0.918515005790101, 0.8701695261594455, 0.9109360807754239, 0.8100049869530626], [0.9123211711021413, 0.8881727268337349, 0.9313320584879771, 0.9124222200782921, 0.8980400457461888, 0.8892772721985251, 0.8920278595656993, 0.888244084430614, 0.8836824374948954, 0.8971323855765702, 0.9087658737381026, 0.8844069985918073, 0.9018251438123495, 0.8978457629657752, 0.8318500486865543, 0.9024248471605933, 0.909012262746544, 0.8915510983679625, 0.8661638056204786, 0.8957455474312068, 0.906387493312617, 0.8989639471601972, 0.9085229818039711, 0.9186558243074775, 0.8918854786671506, 0.9118327228709211, 0.9188725687980023, 0.8552927848328937, 0.9140689810701677, 0.8930464025324578, 0.9140478649204143, 0.9078243462515774, 0.9085029727202161, 0.8978331005228539, 0.913524165805632, 0.9004649743475497, 0.9207269680320723, 0.8719099465029161, 0.8664311460009704, 0.9103199514036008, 0.9024023054344723, 0.9141124832237404, 0.9230537507632831, 0.8908726725823192, 0.8746256338537142, 0.9259006261802246, 0.8833109958984493, 0.9034586894168986, 0.8321596001382312, 0.8837529780767865, 0.8647724716080116, 0.8943859292027676, 0.8956017562527753, 0.9340308207282001, 0.9189440922155925, 0.930662932851901, 0.9308711213992006, 0.9262037750360317, 0.9274476640653587, 0.9087624080919481, 0.9209367007759572, 0.9091515342201463, 0.9394178306726054, 0.8856244520299487, 0.8829994067336735, 0.9075030503321382, 0.9027201264220224, 0.9309248901965405, 0.9443295676471541, 0.8872031960203236, 0.9346461765175212, 0.8668707265889652, 0.8864425577968142, 0.9350077057262373, 0.865047473242872, 0.9245651809557791, 0.9303852651416166, 0.8918639077543382, 0.9132710466149799, 0.8905761606376166, 0.921717436527858, 0.893392779826834, 0.9019894117538749, 0.9194904770799063, 0.9612930684348349, 0.9196373037814272, 0.876211022195668, 0.9499544202631057, 0.9023984647380767, 0.9129349559783062, 0.8718367143670223, 0.9136344550469933, 0.9073049535519697, 0.9060908198568447, 0.9053142633161761, 0.8982555719587908, 0.8863129100164974, 0.9239340318792867, 0.9023090726979194, 0.8675728167685017, 0.936537708588171, 0.8859712166839018, 0.9045435540058029, 0.8822355936407115, 0.9019677751979565, 0.8982483812433094, 0.8960401657187392, 0.8718802456258948, 0.9135298429264794, 0.9181357933128383, 0.8914449045250004, 0.9120883545508637, 0.8914633764034025, 0.8717092937964686, 0.88591523364327, 0.8818677079357787, 0.8582282272533446, 0.9026954728860602, 0.9063295136417141, 0.9296303190983698, 0.8910812916150798, 0.9131997475083986, 0.9053284709926103, 0.8901273037231646, 0.9117020780960262, 1.0000000000000004, 0.848631865379055, 0.890560397074778, 0.8638850171326075, 0.9205072935024735, 0.8846417889302688, 0.9280705736497432, 0.8534163642244537], [0.8953021522553767, 0.8505491546172083, 0.8501461731937687, 0.8941847103118884, 0.8613525937104185, 0.8670523489467846, 0.8787574173034254, 0.8256063653090686, 0.8280417526552757, 0.8981304397545377, 0.901465582780481, 0.850068097320368, 0.8147730625757992, 0.829713067524742, 0.7974254146144296, 0.8667138219444408, 0.8825904058739477, 0.8403732305568032, 0.8099516588510223, 0.885230662078011, 0.9041647226444266, 0.8758794010503297, 0.9033466971550385, 0.8476962652780831, 0.8489259559036386, 0.9142429449685958, 0.8902185821674199, 0.8731269357713536, 0.8772504728882021, 0.8612098043444766, 0.8817404301932749, 0.8698087266494126, 0.8590308119763478, 0.876704507567091, 0.833721619876443, 0.8427599542801802, 0.8529390544745763, 0.8456877525994763, 0.8374445365348276, 0.8922700362531166, 0.8927084597903515, 0.9007332433320334, 0.8604416505919743, 0.8702930289828308, 0.8430492378707615, 0.8858820846307508, 0.8450760771627333, 0.8846690006069999, 0.781363742442048, 0.8457514610371051, 0.8718887354188464, 0.9028966857848066, 0.8384418144919832, 0.8827149582430742, 0.8903084622945587, 0.8390607150765454, 0.8885513540482906, 0.8834501852419785, 0.8822540744127585, 0.8431650194463088, 0.8545164994829045, 0.8760391604555602, 0.884922613614272, 0.8796768550479109, 0.8753974865716189, 0.8672097990074121, 0.8925413720767308, 0.8780370854125212, 0.8605066558187155, 0.8382869853995564, 0.8184396848654059, 0.8446017883582033, 0.8537586330277822, 0.8220402380293463, 0.8172588357352506, 0.8797332886549696, 0.8863329707463086, 0.8600985881757536, 0.8914449942967736, 0.862525634284153, 0.8916830229072537, 0.8810057392742403, 0.8654319511703643, 0.8725357671350163, 0.8729547141524674, 0.85648634694714, 0.8847371264168944, 0.8236789770223986, 0.8775262296428854, 0.8783576857243195, 0.8527405777400202, 0.8668190404989395, 0.869948960435702, 0.8706500906649128, 0.853276402960581, 0.8691478429269248, 0.839774882091997, 0.8883398863170009, 0.8442746735092593, 0.8185560861598363, 0.8732341122511348, 0.8531467789353131, 0.878720161000043, 0.8900992117882209, 0.8676678757238323, 0.8780112726008292, 0.8600671778722163, 0.88058619406273, 0.8679608415823963, 0.8833779611921554, 0.8382581759949782, 0.8967792281651286, 0.8497229760724702, 0.7646914036476842, 0.8250088538992324, 0.852404895873192, 0.8495905635186433, 0.8667737306098815, 0.8756846846907472, 0.8441677970576178, 0.8667836565780955, 0.8135952091096776, 0.8956628822040732, 0.8461377858260283, 0.8343264776809564, 0.848631865379055, 0.9999999999999999, 0.8764827310469859, 0.8716195393684442, 0.8769167017426798, 0.8567494152710261, 0.8601778737670307, 0.8709441892582128], [0.9326375688771151, 0.8984039741379624, 0.8899852706597399, 0.9063592291970006, 0.9111322771938916, 0.9040614235094472, 0.9243771775562817, 0.8587476994010819, 0.8884825634876925, 0.9415919335544572, 0.9097784030156626, 0.8657817353084435, 0.8600792880518623, 0.8606488785688169, 0.872854403936957, 0.8729159014691068, 0.9196994737963761, 0.8761522464234289, 0.8436048732277963, 0.9156213534279803, 0.9407948945891901, 0.9232976983916162, 0.9340566775473623, 0.8843534716150719, 0.895720885124996, 0.9271068699797254, 0.9314413621091854, 0.901788111456075, 0.9306025581414137, 0.9135366916234655, 0.9256182404740825, 0.9140143077553323, 0.8986361529021138, 0.9200464157478042, 0.8510545512545893, 0.8693881650212106, 0.906230085750208, 0.9178372066295564, 0.8944819101011621, 0.9179321191462314, 0.9127870096657593, 0.9386227420889848, 0.9156762273970004, 0.919171853624843, 0.8972095376281054, 0.9104649874366386, 0.8952375336424906, 0.9358252356913975, 0.8431061352381055, 0.9064621780600829, 0.8589525213986979, 0.9174516808897585, 0.8911350976491401, 0.9351772507450861, 0.9137638717473325, 0.8725600301392391, 0.9289595268877494, 0.9277807335807635, 0.9125528726965147, 0.9007878483632467, 0.9166998930207999, 0.931034830849806, 0.9369209175182247, 0.9138671017467339, 0.9109873465383362, 0.9178331547230448, 0.9346832482886964, 0.9186718663042048, 0.8877630483108969, 0.9161614229290264, 0.852182991417451, 0.8945003019138369, 0.8927530475375784, 0.8459862782118897, 0.8909795260123186, 0.9232731162228615, 0.9456083794933314, 0.9082646220561379, 0.9326741425157082, 0.9229468468057871, 0.9245164805166325, 0.9224851902732272, 0.9189225421488147, 0.9028292369929501, 0.9295353294542184, 0.8862769964026028, 0.9210680084776995, 0.8977591138122771, 0.9235448521670617, 0.9112760262767647, 0.9033196182841384, 0.9195044274661246, 0.9126852815482583, 0.8979440214442499, 0.9192741969840352, 0.9343316806358037, 0.8900091083796211, 0.9298981167578688, 0.8873207412906265, 0.8830532410114945, 0.9085293708891232, 0.8941871638655169, 0.9355088298686374, 0.8929071353207362, 0.9120902778129578, 0.911178971987405, 0.923721428156852, 0.9041569402463567, 0.9152608615251864, 0.921632871490293, 0.8839781925881813, 0.912107171682201, 0.9248525242396531, 0.7856828745700393, 0.8824514025860428, 0.9024546107324178, 0.9046499931736262, 0.9197023745693171, 0.9202801085844997, 0.91789303717277, 0.9246846290276307, 0.8357087874485148, 0.9405205740740582, 0.9185159154984327, 0.8797237753179212, 0.890560397074778, 0.8764827310469859, 1.0, 0.9110453992799138, 0.9084927053291889, 0.8983213151956038, 0.9009700778050047, 0.9104777669809739], [0.9185295348878981, 0.8822362694632937, 0.8849727601702779, 0.9168208784207392, 0.8846547701026126, 0.93856491358165, 0.9597513643274908, 0.8569953023702056, 0.8875816747653351, 0.915305301743671, 0.9303457477147581, 0.8930122908300918, 0.858586918109345, 0.8340696344146903, 0.8964974928948601, 0.890224394173935, 0.9120527673743042, 0.8869339139041172, 0.8653366059668675, 0.9361305250224269, 0.9223436484898777, 0.9209152784439147, 0.9032962201205776, 0.8951809354115223, 0.9369961691878583, 0.9450051363561423, 0.9148707979788935, 0.889631008284122, 0.9257926547822631, 0.8889264894747546, 0.9236931895007566, 0.886093976135064, 0.8954792661385528, 0.9105976277229075, 0.8510365701921838, 0.87033082018913, 0.8590350563399844, 0.8840034537772989, 0.9334930632163445, 0.8691595741260076, 0.9328984060206184, 0.921097091637321, 0.902804976640343, 0.8960078631983971, 0.8453037778790673, 0.9243829222807348, 0.8954976996694088, 0.8927581061291645, 0.8821263943522166, 0.9060432008500379, 0.8702537238669835, 0.9223894985978565, 0.9007913485010852, 0.9147691649547598, 0.8987105102444073, 0.8607664425128876, 0.9306987155918934, 0.9177024399526024, 0.9198040727102659, 0.9281519104115445, 0.9173660628140062, 0.924742841198674, 0.9134267803588951, 0.9420431201703277, 0.916561397126302, 0.9115674364684193, 0.9308428322455508, 0.9003664417709473, 0.8884481639557041, 0.9154998618385808, 0.8210752439723461, 0.9196258447430335, 0.8996211813282051, 0.8183092933827963, 0.8484360765747002, 0.9065815283802484, 0.9078238043975034, 0.9475999671530289, 0.921648766781646, 0.9058044205494977, 0.9385788583390533, 0.9259547327168057, 0.9038673067227819, 0.9204425947152729, 0.8908997697218188, 0.889650650344427, 0.8963871467985645, 0.8413490199633111, 0.929073545310138, 0.9222783927876765, 0.9318094449432264, 0.9186871092565845, 0.897090499470415, 0.8723599561588244, 0.8838583769642205, 0.9130731190008613, 0.8743672839162876, 0.9385472026627113, 0.8876857407086216, 0.8422298981432415, 0.9080106201257768, 0.9475782877007423, 0.9043012979823966, 0.9453033542599384, 0.894142375082154, 0.9447187484008933, 0.927488433144906, 0.90434065559492, 0.8897891796672328, 0.9261484780472606, 0.88329282962747, 0.9050927631991734, 0.9250853049039018, 0.7489757990398014, 0.8829655684527413, 0.8970051414416486, 0.8863927093966084, 0.9288354344323639, 0.931810014745852, 0.8754543520074447, 0.9233642971154554, 0.8087452825143134, 0.9366025278115785, 0.9189337876235313, 0.8693894836515602, 0.8638850171326075, 0.8716195393684442, 0.9110453992799138, 1.0000000000000004, 0.9440963247233519, 0.860706919478207, 0.8683792736193441, 0.8588227440738758], [0.9393349005814209, 0.9024213071991092, 0.9364938253530395, 0.9407360903714092, 0.8965665856824976, 0.9213500564340107, 0.9410643580179673, 0.8706753218464538, 0.9019842593923938, 0.9220709020491228, 0.9547996614904805, 0.9052256900045457, 0.8797491103885415, 0.8732630130163115, 0.9060833220303228, 0.9099773136678697, 0.926798916037994, 0.9132677143362938, 0.8946393554188331, 0.9257189757734253, 0.9253322810793441, 0.9332222399853765, 0.9207484220682728, 0.9296506763945986, 0.9553620174311468, 0.9463917611486562, 0.9354919415630447, 0.8779483577154066, 0.9554953068903081, 0.8996142299362869, 0.9308113761542316, 0.9144541578474598, 0.9245327470468314, 0.9123445438140434, 0.8909707062580421, 0.878204113405959, 0.908303817941404, 0.8990035491049093, 0.938314051283952, 0.9028600509144833, 0.9506189157805609, 0.9349461045375014, 0.9308300631257924, 0.9101916847639884, 0.8594991576237894, 0.9371410525112177, 0.9058444439866178, 0.9149214003334366, 0.8868030518971242, 0.9100015982052357, 0.8900222319361342, 0.9116601797656992, 0.9104261938684497, 0.9354718237606272, 0.9147044484318344, 0.9016580879068308, 0.9465647972459119, 0.9365617366683018, 0.9395960156849297, 0.946751818649736, 0.9461440498182645, 0.9352075655566565, 0.9419244240462907, 0.9249934261060863, 0.9203301306771489, 0.9408165606729642, 0.9386647621446924, 0.9290829967144754, 0.9367086591967206, 0.9147946174315853, 0.8776777102490131, 0.91525700581456, 0.9024074598006715, 0.8671824276928095, 0.8614861164483263, 0.9198081684220625, 0.9297350973363343, 0.9688460438619878, 0.9368937060209173, 0.9077560920393197, 0.95513924959493, 0.9192244826172778, 0.9254642409895792, 0.9251621319866695, 0.93420405225401, 0.9259964751467079, 0.9018850676806125, 0.8906624003711061, 0.9330778495633533, 0.9469349645779035, 0.9496128189829276, 0.9382169752038271, 0.9280838194716351, 0.8989267771311911, 0.8988086851311671, 0.9211592815634115, 0.889455685168719, 0.9392244332801158, 0.9214140175573169, 0.8598075807961183, 0.939982279977946, 0.9367407781548212, 0.9229168816938439, 0.956161534522745, 0.9058491350993881, 0.9218875526285817, 0.9324210191824197, 0.9059504446772705, 0.9222733539511786, 0.9294147535042019, 0.9028504323859062, 0.9193955753779779, 0.9202788437908791, 0.7946220586891326, 0.8865651992512018, 0.8962840855002896, 0.8866204268895064, 0.9426036980987955, 0.9541876307401654, 0.9040088023952169, 0.945266028640174, 0.8503692221762129, 0.9285113103792754, 0.9207340208140953, 0.918515005790101, 0.9205072935024735, 0.8769167017426798, 0.9084927053291889, 0.9440963247233519, 1.0, 0.8861201761740186, 0.9007659967053097, 0.8677961635870894], [0.9355196836100225, 0.8655465861988658, 0.876013155888869, 0.8987328822761373, 0.9079472383145256, 0.8949460995127961, 0.8652827580784449, 0.8886936637553451, 0.8572032330553748, 0.9057981428528468, 0.8804286598052318, 0.8405078297343278, 0.8404250873517163, 0.857480881369486, 0.8403844021898736, 0.8712423782018396, 0.8872736646187765, 0.8532827612668361, 0.8304748978557217, 0.8836359784403537, 0.9123096235572207, 0.8740312895491215, 0.930263792212579, 0.8746535910624593, 0.880469950176404, 0.899345026164091, 0.9112060470276189, 0.8764229270829872, 0.926557028956535, 0.8726045467333952, 0.8830521472538503, 0.8919945679973755, 0.8754945880961134, 0.877035982580338, 0.8812583607689745, 0.8674718089191202, 0.8723945659505355, 0.8991909983196769, 0.8687236972026143, 0.9155521972156743, 0.8955023499242946, 0.9194859945713384, 0.8982914851087618, 0.9091476139446972, 0.8449787622175127, 0.8916241406204675, 0.864808447912992, 0.9184290912576036, 0.8108623593639005, 0.868129175219986, 0.866795483297978, 0.8994304368678577, 0.8659132290086602, 0.9152023612209946, 0.9020512977527609, 0.8922582337369245, 0.9021433212879115, 0.9341113368726711, 0.9179823351803269, 0.8941409306008805, 0.9114626193062835, 0.8936052099420164, 0.908058046322334, 0.8680729561025308, 0.8672208402564413, 0.890303289876758, 0.9074747211506365, 0.9273385691511746, 0.8942435629227055, 0.8982503748438759, 0.8753439586058982, 0.8528290549200794, 0.8736160556052512, 0.8587794454708264, 0.8897136367943698, 0.8915720233473192, 0.9054381284563155, 0.8840970873518395, 0.8948965872238587, 0.8621597201604445, 0.9043113272250151, 0.8709787965690771, 0.8988705450510037, 0.8737278191768814, 0.9192532169045281, 0.9012097753713795, 0.8982047404039841, 0.8773191171970351, 0.8918461648960669, 0.8910211743386748, 0.8892330289083654, 0.8759661392245328, 0.8957451910128631, 0.8904120192701235, 0.9205602047320106, 0.883231095926718, 0.8698025229842377, 0.8891687634947346, 0.877943125850913, 0.8811810499238595, 0.9119905100269606, 0.850908823557256, 0.8926758249065474, 0.8694517361778358, 0.9137442620739293, 0.8513299003095905, 0.8702655901561308, 0.8814689679897117, 0.8900514295631018, 0.8762425655114521, 0.8717032946114613, 0.923442163845219, 0.8779004576187497, 0.8356057898808643, 0.8296374747224717, 0.8902524749601154, 0.8374645243388965, 0.8791434146807415, 0.9212296605717973, 0.8691697712770126, 0.9211691925563763, 0.8442199909825152, 0.900215444391625, 0.8859812012322726, 0.8701695261594455, 0.8846417889302688, 0.8567494152710261, 0.8983213151956038, 0.860706919478207, 0.8861201761740186, 0.9999999999999993, 0.911026900248551, 0.8775725235605868], [0.9313855477711477, 0.8968003008714606, 0.91691689822446, 0.9180932288880201, 0.9129050544371353, 0.9027893628149317, 0.8808284589985761, 0.9026564935888235, 0.8680115134795984, 0.9021216962672429, 0.9018629414734194, 0.8799667546502075, 0.8907540835391202, 0.9077537561932915, 0.8371369606829023, 0.9093985417632454, 0.9070022006141791, 0.891527551875551, 0.8585494536920384, 0.8869675273186852, 0.9080627408212611, 0.8910193658883052, 0.9564581554968921, 0.8896653340406975, 0.8967284034074108, 0.9098415996329655, 0.9269071015350967, 0.87379691261808, 0.9278022751547623, 0.8925198509275373, 0.9000379667764064, 0.906718058324276, 0.9066366213730073, 0.8975366702386154, 0.9160169550314559, 0.8805329901266541, 0.8938627109249007, 0.8724759679891856, 0.8593147662952442, 0.9327302903910335, 0.9038753719906307, 0.9207541126983657, 0.9246069758844813, 0.9261926142075481, 0.8754737431383794, 0.9100447397348459, 0.872964113724813, 0.9208982892325261, 0.8391535570792883, 0.8860683236332161, 0.8824438531776829, 0.9006337414781088, 0.8832180920914254, 0.928253849403048, 0.9400778998986016, 0.9270668850345644, 0.9238947139096556, 0.9407007322582647, 0.9367045941571741, 0.9054460824802165, 0.9195244444775238, 0.9085076620347416, 0.9332477060874916, 0.8700517881341194, 0.8907761130353743, 0.9068191455916568, 0.9181049542567766, 0.9488246169281798, 0.9199796053113019, 0.9026074332708478, 0.945255918209218, 0.8669390120259849, 0.8948411733278934, 0.914233241444426, 0.8731775458752288, 0.9273221405667911, 0.9271889257659864, 0.8925508064561398, 0.9018959111889928, 0.8767616122376406, 0.9126670379499089, 0.8868287652624862, 0.8989636252379618, 0.8896821940507942, 0.9526680543673554, 0.920540378695784, 0.885583838779357, 0.9077750278627159, 0.9056907828425793, 0.9144634231646225, 0.8836098185809297, 0.8984832911069457, 0.8937049822466461, 0.9296432634322418, 0.9039223869871367, 0.907036178810074, 0.9030385913321273, 0.9009181157685955, 0.9027084448641327, 0.9068855706967923, 0.9571817619796055, 0.8704625234837082, 0.9160091531315048, 0.8716105393587837, 0.8960143222286827, 0.8766018028018451, 0.8951975710801972, 0.8814189600633989, 0.9275324500525693, 0.8904545430822425, 0.9037850416354215, 0.9543726275706086, 0.8992919202029196, 0.9074345539039179, 0.8605681769959244, 0.8688102221315286, 0.8624813164384391, 0.8980813900907703, 0.9223248340896661, 0.9056357638728275, 0.9061660883999291, 0.8868224839887979, 0.9149313348309535, 0.8913093527168778, 0.9109360807754239, 0.9280705736497432, 0.8601778737670307, 0.9009700778050047, 0.8683792736193441, 0.9007659967053097, 0.911026900248551, 1.0000000000000002, 0.8679046275427194], [0.8951145621211425, 0.8531838847095721, 0.850551953645073, 0.9013339229460682, 0.8902680485035999, 0.8822285192331997, 0.8554545067139392, 0.8430153401770181, 0.8135935139442736, 0.9096171779092703, 0.8930881097354735, 0.8140472299188409, 0.8093283037815828, 0.8359755345459801, 0.7918311858749606, 0.8253126386534722, 0.8787039679192016, 0.8303144313482962, 0.7908595686127715, 0.8603395502341515, 0.9183048291837383, 0.8725604722434871, 0.907193874826425, 0.8299027825825585, 0.8501731565661532, 0.8814807683092376, 0.8916300678726136, 0.8511510219267399, 0.8844533788604105, 0.857808252959061, 0.8676027918688743, 0.8504739982165173, 0.8740065644884085, 0.866961817753173, 0.8477254056687287, 0.860281722296231, 0.8648553615345576, 0.8846361520777299, 0.8557757637586065, 0.8909392533786158, 0.86352892609168, 0.9075156912298831, 0.8791142439876821, 0.8808622331908571, 0.8401391263696777, 0.873627532709666, 0.8460493159494393, 0.9101747656027779, 0.7760542598147275, 0.8590719927815311, 0.8357370299688652, 0.8709805827800501, 0.8207204452871358, 0.8849978748446788, 0.9052782059592879, 0.8910726789445779, 0.8762711177639928, 0.8981872854104226, 0.8836437146835309, 0.8452282887036849, 0.8605136858827134, 0.8660489452466735, 0.8791240087268584, 0.8418319120574804, 0.8778572565793648, 0.8549200502444041, 0.8950955616036553, 0.9257970457540571, 0.8635670628378098, 0.8488866342655259, 0.8076389065166284, 0.8287809256109848, 0.8274451817691619, 0.8417115584676486, 0.8421378288061763, 0.8730916397960516, 0.897686229834597, 0.8631547914314023, 0.8908060954350601, 0.8420756053335354, 0.9023631403844599, 0.8562049188441305, 0.8742696219766202, 0.8700344280060872, 0.885056468599412, 0.8759733314368452, 0.9214024565476564, 0.8300386290901283, 0.8838010415775432, 0.8616514418283254, 0.8546137900153864, 0.8606335462830099, 0.913920269617863, 0.8645545324051367, 0.870760335476445, 0.8910874640304953, 0.8530589251873035, 0.8856295072896108, 0.871428506525743, 0.8154206762877367, 0.8577333739334316, 0.8397642064219649, 0.898309944858857, 0.8660828539363821, 0.875798828660937, 0.8564835658174651, 0.8566266949042224, 0.8558564143952672, 0.8776877259465318, 0.8639464743655746, 0.8487690275049047, 0.8846819590725525, 0.8428173347591408, 0.7741621338439879, 0.8108688168254867, 0.8549039023014472, 0.8287640727860333, 0.8692535331521176, 0.8944775360259395, 0.855003569531344, 0.8885812992978182, 0.8331637430060015, 0.8823623782485451, 0.8526325522181148, 0.8100049869530626, 0.8534163642244537, 0.8709441892582128, 0.9104777669809739, 0.8588227440738758, 0.8677961635870894, 0.8775725235605868, 0.8679046275427194, 1.0]]}],                        {\"coloraxis\": {\"colorbar\": {\"title\": {\"text\": \"Similarity Score\"}}, \"colorscale\": [[0.0, \"rgb(247,252,240)\"], [0.125, \"rgb(224,243,219)\"], [0.25, \"rgb(204,235,197)\"], [0.375, \"rgb(168,221,181)\"], [0.5, \"rgb(123,204,196)\"], [0.625, \"rgb(78,179,211)\"], [0.75, \"rgb(43,140,190)\"], [0.875, \"rgb(8,104,172)\"], [1.0, \"rgb(8,64,129)\"]]}, \"height\": 800, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"legend\": {\"title\": {\"text\": \"Trend\"}}, \"margin\": {\"t\": 60}, \"showlegend\": true, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Similarity Matrix\", \"x\": 0.55, \"xanchor\": \"center\", \"y\": 0.95, \"yanchor\": \"top\"}, \"width\": 800, \"xaxis\": {\"anchor\": \"y\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0], \"scaleanchor\": \"y\"}, \"yaxis\": {\"anchor\": \"x\", \"autorange\": \"reversed\", \"constrain\": \"domain\", \"domain\": [0.0, 1.0]}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('e52a9ceb-7893-48a9-8ef6-88fe3d989cd3');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "DLF1W5ULKaQZ",
        "outputId": "ba5e6158-1b55-410d-db10-64407d42c654"
      },
      "source": [
        "reduce_model2.visualize_term_rank()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"49d6fc95-e890-415d-9885-8036c839370b\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"49d6fc95-e890-415d-9885-8036c839370b\")) {                    Plotly.newPlot(                        \"49d6fc95-e890-415d-9885-8036c839370b\",                        [{\"hovertext\": \"<b>Topic -1</b>:design_system_users_user_use_using\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0031229056188063846, 0.0029501672655586103, 0.0028734830263659273, 0.0028649308976772306, 0.0027746531022974506, 0.002750421824528132, 0.0027456743369184454, 0.002697664186334901, 0.0026204233472174065, 0.002604343699381143]}, {\"hovertext\": \"<b>Topic 0</b>:flow_fluid_vortex_jet_vortices_flow\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.034877479358464046, 0.016846857033500133, 0.014872184683317384, 0.010757307349596313, 0.00812219339029751, 0.007219998801742158, 0.006711711880192743, 0.005812130745426178, 0.005789263873593459, 0.005675618812752145]}, {\"hovertext\": \"<b>Topic 1</b>:language_word_linguistic_lexical_ve\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.021627367635129947, 0.021373397790192518, 0.010154506356954465, 0.008421185838041228, 0.0074024438852824835, 0.0065449939179222155, 0.005969466006070861, 0.005527666895010051, 0.005384142021561197, 0.005379133391717828]}, {\"hovertext\": \"<b>Topic 2</b>:visualization_topic_visual_visualiz\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.019846943765942895, 0.015188194813632296, 0.01272565310886845, 0.011416331963999198, 0.010962033556569904, 0.00869117407398828, 0.006580068923659234, 0.005190813123486162, 0.0037705482098249307, 0.0035814213857678513]}, {\"hovertext\": \"<b>Topic 3</b>:recommendation_recommender_recommen\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02044677424151193, 0.015366766851646662, 0.008692096250854674, 0.008046855120247479, 0.007301099773862471, 0.006091401872784688, 0.005925418319888323, 0.005833333992257505, 0.005494971176764654, 0.005387655705145038]}, {\"hovertext\": \"<b>Topic 4</b>:graph_graphs_network_networks_commu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03881946393643109, 0.025442927585748527, 0.016693807953635526, 0.016343718068530123, 0.008521848129229452, 0.007926477523115176, 0.004930556265649621, 0.004874915934990105, 0.004798483501222645, 0.004435799165587439]}, {\"hovertext\": \"<b>Topic 5</b>:shape_mesh_meshes_subdivision_shape\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.018586282277007614, 0.016514287308550275, 0.01318636091873257, 0.01269372104559105, 0.010466097372276651, 0.008094449438205505, 0.007972798808057768, 0.00584350126851022, 0.005641821976075533, 0.005223904865324701]}, {\"hovertext\": \"<b>Topic 6</b>:game_games_sports_play_gaming_exerc\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02997067945651865, 0.02542006947332145, 0.009478118442114585, 0.008833010948069106, 0.00662368412869977, 0.005425931137704594, 0.004766554128745294, 0.004713130345727731, 0.004278639499144143, 0.004037287505304801]}, {\"hovertext\": \"<b>Topic 7</b>:light_illumination_rendering_lighti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02963906286728744, 0.02307655767613874, 0.01733204265393536, 0.010710771833506725, 0.010147644407867725, 0.010137529962307957, 0.009735750287453953, 0.0074193883756126225, 0.0072811745390324485, 0.00602780905491577]}, {\"hovertext\": \"<b>Topic 8</b>:database_query_queries_join_sql_dat\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.024441692160561454, 0.023753907472631647, 0.017898298502220456, 0.012828118419441894, 0.009571909103592135, 0.009106608318609603, 0.006882506495649922, 0.006395593307787928, 0.005719168607661133, 0.005169852791646396]}, {\"hovertext\": \"<b>Topic 9</b>:dimensional_visualization_multidime\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.01436157201840766, 0.012977601751080878, 0.011700736965615808, 0.00870121680395305, 0.007938646256967117, 0.007645402937480186, 0.006507068210597304, 0.005414432832275612, 0.0053895596621500235, 0.005291743184316917]}, {\"hovertext\": \"<b>Topic 10</b>:motion_animation_motions_animation\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04233699307956505, 0.03737070746951127, 0.016974041875681505, 0.008179684610135535, 0.007513867049223989, 0.006122388308835543, 0.005725670896723697, 0.005568171863239592, 0.005109000217805348, 0.00453598698439722]}, {\"hovertext\": \"<b>Topic 11</b>:music_musical_voice_sound_audio_mu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0398467018551373, 0.02162633794356384, 0.019701292964868708, 0.013528800913670619, 0.009385814182093435, 0.005649914648181555, 0.00483994902101234, 0.004616763189626524, 0.0039959961200618024, 0.0037103917092535586]}, {\"hovertext\": \"<b>Topic 12</b>:education_educational_teaching_cla\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.015404742462420058, 0.013362391752532503, 0.012038193048005961, 0.011549449140522396, 0.009797971868232067, 0.008843649369920176, 0.008497253085253313, 0.008359934715581968, 0.006273913070657548, 0.005500704655703679]}, {\"hovertext\": \"<b>Topic 13</b>:driving_vehicle_vehicles_driver_ro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03294319560649562, 0.028407989495974548, 0.019863972452261854, 0.018115634632030173, 0.0146028825367296, 0.011092962092620305, 0.007681993687620818, 0.004575508035482198, 0.004493834253023191, 0.004388154012951838]}, {\"hovertext\": \"<b>Topic 14</b>:gesture_gestures_touch_finger_hand\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04627666591751272, 0.04204177311188392, 0.02040763544931806, 0.013088283924672648, 0.011961903725547864, 0.011525829306714414, 0.007121545221217835, 0.005587310464143957, 0.004977984453931944, 0.004838304284915396]}, {\"hovertext\": \"<b>Topic 15</b>:classification_class_feature_kerne\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.023370393546890352, 0.014594248494393338, 0.014570876382752288, 0.013547381477553322, 0.012537800021319568, 0.011081910843468955, 0.009642304653542747, 0.009225230767214938, 0.006249880298129222, 0.005840967611438698]}, {\"hovertext\": \"<b>Topic 16</b>:gaze_eye_attention_head_movements_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05120184867413094, 0.05118929126346684, 0.008626970745721382, 0.007466252919225465, 0.0074421279110178954, 0.00643540462384047, 0.006229463887829542, 0.005306261349592143, 0.005012845923218154, 0.004659280346590598]}, {\"hovertext\": \"<b>Topic 17</b>:haptic_tactile_force_virtual_vibro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06037574873578524, 0.028094792718655302, 0.019545860507267514, 0.01629061373252367, 0.015351584743784773, 0.01119278643114964, 0.010461409965075236, 0.009562078135832859, 0.009071355126859646, 0.005760820665650056]}, {\"hovertext\": \"<b>Topic 18</b>:rendering_graphics_gpu_splatting_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.028532469861654933, 0.020762651204030484, 0.016778748305214176, 0.008180404861598127, 0.007626053157199993, 0.0072921061547260935, 0.0067195356839508886, 0.006135107795982142, 0.005950240758874894, 0.005750252071121254]}, {\"hovertext\": \"<b>Topic 19</b>:mining_frequent_itemsets_rules_ass\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03820373912684161, 0.0313305581803579, 0.02500446181924009, 0.022813762030451653, 0.01947365423099974, 0.011077059697302301, 0.008041671388553011, 0.007739036212871121, 0.007603961282399162, 0.007037248033578494]}, {\"hovertext\": \"<b>Topic 20</b>:image_images_retrieval_recognition\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.022747820142596843, 0.015644336968650627, 0.011226971312791392, 0.008211271084266898, 0.007809943182477438, 0.006882895445036077, 0.005821735081378492, 0.005232804024555053, 0.00518119180849189, 0.004754729946859051]}, {\"hovertext\": \"<b>Topic 21</b>:software_programmers_collaboration\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.01655464831610718, 0.012961197059507162, 0.012239237779747916, 0.010556556796118263, 0.009837336318109569, 0.0073399721840017515, 0.006799037649360384, 0.005280486824119474, 0.0049818795097878385, 0.004902493162180108]}, {\"hovertext\": \"<b>Topic 22</b>:brain_cognitive_attention_visual_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0191780802925019, 0.012319711225550346, 0.011419365250466896, 0.01047550775624897, 0.00738257486097931, 0.006886682806751083, 0.005471975461231645, 0.005369515162134108, 0.004941239386426757, 0.004173414164812375]}, {\"hovertext\": \"<b>Topic 23</b>:trajectory_trajectories_mobility_u\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.019457949493871425, 0.01933731198310893, 0.01527275534592362, 0.010201265192428846, 0.009073075005027758, 0.00884220794109104, 0.008390876312052235, 0.0056819032849258775, 0.0050362582123349145, 0.004870673326932939]}, {\"hovertext\": \"<b>Topic 24</b>:graphics_graphic_standards_phigs_d\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05679682604945275, 0.011952979957402451, 0.01134693979180988, 0.0107224350948761, 0.007478499268936361, 0.007230938564234911, 0.006633862526675, 0.006447269294910574, 0.0061341159503478584, 0.005452360799761176]}, {\"hovertext\": \"<b>Topic 25</b>:series_time_patterns_mining_cluste\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05509326654670257, 0.02726616762444783, 0.010200086948080273, 0.007667598629390057, 0.00747780760731165, 0.007278061165873465, 0.006487175287627851, 0.006136883273291302, 0.00473244763523349, 0.004446000871372103]}, {\"hovertext\": \"<b>Topic 26</b>:fabrication_printing_print_manufac\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.031564244106165686, 0.02121741597974587, 0.006822534577814497, 0.0066450714974712255, 0.006062028622026706, 0.0057655128450918615, 0.005446042834280585, 0.005165863649504413, 0.005135797857719605, 0.004844545231284493]}, {\"hovertext\": \"<b>Topic 27</b>:smart_activities_context_interface\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.013530822707059643, 0.013266143896514494, 0.010119173035361898, 0.008646788752762686, 0.007272318246571794, 0.006911496084708739, 0.0064309174243725176, 0.006332620960795668, 0.006257261236481799, 0.006062414048853252]}, {\"hovertext\": \"<b>Topic 28</b>:vessel_imaging_ultrasound_clinical\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.014447306421615392, 0.012683248347310579, 0.010858427567411821, 0.009231234262608785, 0.00918524740957234, 0.008290213337740387, 0.00812151989442924, 0.007525779189589348, 0.006615395498384264, 0.006222015778251911]}, {\"hovertext\": \"<b>Topic 29</b>:texture_textures_synthesis_image_s\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06933376192013903, 0.0315314864188173, 0.030600802227659558, 0.013227484571838357, 0.010210960667647751, 0.010028216951298326, 0.009061101030493084, 0.007045189945984113, 0.005701501239965253, 0.00487450728815208]}, {\"hovertext\": \"<b>Topic 30</b>:decision_choice_risk_risky_decisio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.024291036775087392, 0.023476205939258026, 0.013331494892869604, 0.013007690134126707, 0.01279557905128225, 0.011791696082975903, 0.010942558801540605, 0.0077474701403217675, 0.00650528753440441, 0.005935451504236171]}, {\"hovertext\": \"<b>Topic 31</b>:weather_visualization_climate_ocea\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.01959130911834254, 0.014104794525339916, 0.013550317932574408, 0.012368603846394169, 0.009029487362863142, 0.008065427693724097, 0.006179097322643769, 0.005901810225651685, 0.005370931369708365, 0.004933138442702137]}, {\"hovertext\": \"<b>Topic 32</b>:ray_rays_traversal_rendering_casti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.09369069134676371, 0.02232881379840685, 0.014258025184840602, 0.012823511117267764, 0.011483256707427537, 0.010673528896199375, 0.010673337929684314, 0.008403592335725966, 0.007449725679480491, 0.006504588985054944]}, {\"hovertext\": \"<b>Topic 33</b>:twitter_tweets_media_sentiment_twe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0445932537708723, 0.026937917019757507, 0.025518952831753896, 0.011517576455297864, 0.007777162152909612, 0.007007427644077733, 0.0068288008493925766, 0.006673740613407366, 0.005396138411775461, 0.004891722806653154]}, {\"hovertext\": \"<b>Topic 34</b>:creativity_painting_art_creative_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0270420063407136, 0.024415988177901502, 0.023576677017357175, 0.019679370842807374, 0.014159330549686218, 0.013030642284942945, 0.012270101898438895, 0.010792187214100888, 0.007528080615665579, 0.006171507112766211]}, {\"hovertext\": \"<b>Topic 35</b>:causal_beliefs_evidence_belief_exp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06116253621435824, 0.013756431476636254, 0.013201799516061222, 0.012867086775772715, 0.012356782544540656, 0.010063928264809136, 0.009202350033515733, 0.007203385976665072, 0.007197887355764095, 0.006051260427005341]}, {\"hovertext\": \"<b>Topic 36</b>:privacy_security_private_protectio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06784808506599006, 0.016984748067566804, 0.01265099922538283, 0.009248876838680878, 0.008576581981115734, 0.0082597340402229, 0.00745132622705759, 0.005473990049444494, 0.004827764211555336, 0.004490058644839569]}, {\"hovertext\": \"<b>Topic 37</b>:urban_city_building_buildings_citi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0365074567737416, 0.017088811972298425, 0.012447927664223684, 0.011858483528540865, 0.00905068630294655, 0.007631616596291661, 0.007187878745066957, 0.006733437638626997, 0.0057042497629096875, 0.004810828279804614]}, {\"hovertext\": \"<b>Topic 38</b>:transaction_transactions_concurren\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.035288566672743625, 0.03059467343945518, 0.025281750556184316, 0.011901550754853557, 0.010383534557552738, 0.010359647890008435, 0.009490946920966081, 0.007663835443361047, 0.007400489255489619, 0.0070728478659106185]}, {\"hovertext\": \"<b>Topic 39</b>:displays_display_navigation_lenses\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0235841230676991, 0.02096350629252988, 0.010949786586899343, 0.006832754046292347, 0.00672159129220642, 0.006463587113200161, 0.0062534137283611745, 0.005866534603558363, 0.00554730382853299, 0.005532153581676377]}, {\"hovertext\": \"<b>Topic 40</b>:search_web_information_pages_brows\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.033714124664078554, 0.027897734405168743, 0.016066974127103808, 0.011967743984882165, 0.008042406030902218, 0.007097084951853963, 0.006548715266925652, 0.0056984557256439415, 0.005122620255410034, 0.004620593887963536]}, {\"hovertext\": \"<b>Topic 41</b>:category_categories_categorization\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.07286827511719236, 0.031068186412628995, 0.02965180734244502, 0.013064501600133654, 0.010578841808468421, 0.010209765959343562, 0.00988508055579221, 0.009518625788911696, 0.006163378169299697, 0.0056945403470787205]}, {\"hovertext\": \"<b>Topic 42</b>:crowdsourcing_workers_crowd_worker\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04734069545543566, 0.045163636943618066, 0.038290179217579025, 0.020587653325307813, 0.015361655121385959, 0.01134840276648396, 0.011324787048588782, 0.008284833224670789, 0.006733550351392744, 0.005644480416482131]}, {\"hovertext\": \"<b>Topic 43</b>:patient_patients_care_clinical_hos\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.036170624520332324, 0.025916009631389514, 0.021488898772234682, 0.020862186689210017, 0.014645555462036516, 0.014289239355016319, 0.007502967009685667, 0.006231405298218057, 0.006093723073755886, 0.005459577894900898]}, {\"hovertext\": \"<b>Topic 44</b>:diagrams_diagrammatic_diagram_logi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06678516933974207, 0.050804631048571, 0.02654488709591892, 0.024536600958138907, 0.023820162827395363, 0.01539674840252908, 0.008089494547457261, 0.007285389203574726, 0.006939658593754759, 0.005605555588453424]}, {\"hovertext\": \"<b>Topic 45</b>:color_colors_palette_palettes_colo\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.11026337449407156, 0.03406950014479555, 0.01147956355188269, 0.01088223774744095, 0.010171635828294346, 0.008097781458859402, 0.006335702703672804, 0.006236841743794351, 0.005716414444734469, 0.004599439232062896]}, {\"hovertext\": \"<b>Topic 46</b>:hci_design_research_practice_desig\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.030548707816374827, 0.030053276688728946, 0.023554194141620955, 0.015542155412416058, 0.010808737869274603, 0.008585458263678696, 0.007298095451915627, 0.006730480348486982, 0.005715605493362276, 0.005054289183288596]}, {\"hovertext\": \"<b>Topic 47</b>:robot_robots_robotic_robotics_inte\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.08257485504228922, 0.05344463321735456, 0.019845884844311962, 0.015151224421746691, 0.011162690727578415, 0.00937543771311893, 0.006162383321921854, 0.005523329802715914, 0.004419923419078357, 0.0040746756693450055]}, {\"hovertext\": \"<b>Topic 48</b>:label_labels_unlabeled_classificat\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04620634070179869, 0.022496901719794044, 0.016054989634922714, 0.0128634184897051, 0.011595514287947688, 0.011140286959206281, 0.01064710965166793, 0.010480403671417787, 0.009632827111408011, 0.007569000789989103]}, {\"hovertext\": \"<b>Topic 49</b>:keyboard_keyboards_touch_finger_ha\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04996151500167049, 0.019052633514852212, 0.01628352505981684, 0.010265093986404782, 0.00884333256173951, 0.008386313008735519, 0.007798078898539255, 0.0072670619918878965, 0.007181758617483575, 0.006468329077296019]}, {\"hovertext\": \"<b>Topic 50</b>:sketching_sketches_drawing_design_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04422164752291879, 0.025645521401292132, 0.013819790093132481, 0.010060077940859512, 0.007813554607509897, 0.007647769373200818, 0.0075497685455594085, 0.0068930018976303626, 0.005084357254858749, 0.004997360357531425]}, {\"hovertext\": \"<b>Topic 51</b>:facial_face_animation_faces_blends\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.07393769176859484, 0.04630296111783682, 0.018710476529083735, 0.01483190500049286, 0.01042086601250377, 0.00958182250969139, 0.007349226764124408, 0.006004955223589447, 0.00576738716623988, 0.005361129165417817]}, {\"hovertext\": \"<b>Topic 52</b>:machine_fairness_deep_explanations\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.028119626226046225, 0.01952413266961167, 0.01734232473206249, 0.008374118000568694, 0.00803489413215593, 0.007713420052104174, 0.00615762265403367, 0.005971990299753429, 0.005337908004111631, 0.004911973279660784]}, {\"hovertext\": \"<b>Topic 53</b>:papers_conference_issue_editorial_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.029921087033253243, 0.022214183503612282, 0.018373245626717674, 0.017548430225433388, 0.01600419738028212, 0.015049925158820199, 0.01433586256004883, 0.010790823662349232, 0.009341884350377253, 0.008914781437953743]}, {\"hovertext\": \"<b>Topic 54</b>:heritage_museum_visitors_museums_e\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03922274868595047, 0.031565209528611714, 0.018575024807629913, 0.016091211975048907, 0.009943337915953377, 0.008076827092029568, 0.007742327304856693, 0.0072824020308279456, 0.006306863005866344, 0.0058616920033231655]}, {\"hovertext\": \"<b>Topic 55</b>:number_symbolic_magnitude_numbers_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.030117497277327293, 0.027348980291695878, 0.025730441173794694, 0.023767988035798826, 0.014904065845202288, 0.010682701840916936, 0.010354510240207022, 0.009594778052278303, 0.008657332755968125, 0.008125303891458085]}, {\"hovertext\": \"<b>Topic 56</b>:facebook_social_privacy_friends_si\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05169828748035435, 0.03232603564109951, 0.015766830750847016, 0.012709564149046889, 0.011586645420185343, 0.011143059814837158, 0.010029094349945953, 0.009121300225749602, 0.006973168046129575, 0.006948238902736903]}, {\"hovertext\": \"<b>Topic 57</b>:influence_social_networks_network_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04110556522863373, 0.025930485181739123, 0.025836799649633584, 0.02481636744464002, 0.021617729709755385, 0.014766325216749924, 0.01209816201695859, 0.009213734303640442, 0.006226605736729892, 0.005648359650922183]}, {\"hovertext\": \"<b>Topic 58</b>:walking_virtual_locomotion_reality\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.038812776308944225, 0.03543297143455156, 0.018560773461259228, 0.014152303602637174, 0.010529755384177657, 0.010504657260958025, 0.010311212634523899, 0.00668400357581888, 0.006270623647566111, 0.00599059357741458]}, {\"hovertext\": \"<b>Topic 59</b>:reality_augmented_virtual_interact\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05538599049608295, 0.04026592652418644, 0.022714158975612908, 0.007903432301967982, 0.0073272019548678655, 0.006729230169423124, 0.006514786660411222, 0.005347732430880131, 0.005229414307864175, 0.0051599379226490065]}, {\"hovertext\": \"<b>Topic 60</b>:molecules_atoms_molecule_halos_str\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.016755460509471083, 0.010716584187088391, 0.009648638330470416, 0.009182810564220632, 0.0084892029940098, 0.006761881279376637, 0.006458348795827807, 0.0061368201865992745, 0.005967790173259087, 0.0059086109038313]}, {\"hovertext\": \"<b>Topic 61</b>:memory_insight_solving_task_cognit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.024208494646364247, 0.019456483400025464, 0.015753179595980858, 0.015723384510339444, 0.010594483196727933, 0.009630814834132377, 0.006886560387918933, 0.006355437470352167, 0.005817402645264043, 0.005810046000289774]}, {\"hovertext\": \"<b>Topic 62</b>:spline_splines_curves_cubic_surfac\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06980073829066251, 0.046700074210670864, 0.03552132697707075, 0.02822318538286937, 0.021605991654822066, 0.018293871827980607, 0.011213280157096467, 0.009745269288384895, 0.00942933222880207, 0.00916141454114782]}, {\"hovertext\": \"<b>Topic 63</b>:clustering_clusters_cluster_cluste\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.08768888387699181, 0.023434292939752143, 0.022372182262561734, 0.01883863975012778, 0.006878442935578781, 0.006673326639428309, 0.006602885774018317, 0.005549996702623682, 0.005401071692960322, 0.005249755605131278]}, {\"hovertext\": \"<b>Topic 64</b>:impaired_visually_tactile_impairme\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03335357132212422, 0.02730111242820497, 0.01910830079096087, 0.01589964827104872, 0.01519683920734133, 0.014671533340100093, 0.00837637086745085, 0.007810129665256997, 0.006774569406320298, 0.0056568050731460855]}, {\"hovertext\": \"<b>Topic 65</b>:distributed_parallel_scientific_co\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0227916173574646, 0.01995361810717596, 0.010387285106350834, 0.008091885990298397, 0.007431806695942089, 0.007210097786445842, 0.006009307851175268, 0.005937487223521019, 0.005258631019920309, 0.004986450792570415]}, {\"hovertext\": \"<b>Topic 66</b>:wikipedia_communities_community_ne\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04124013578216363, 0.03499516268877575, 0.025315348016943733, 0.013351563540113544, 0.01284287232649116, 0.009998362986611827, 0.00732920361462633, 0.007102374409975515, 0.006665745013099153, 0.006017703650549274]}, {\"hovertext\": \"<b>Topic 67</b>:metaphors_metaphor_analogical_anal\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.040355762562711534, 0.03984001293088589, 0.03583528938534941, 0.0307309821320463, 0.016447062667585218, 0.01472732264735642, 0.008115523527488929, 0.006872421670389908, 0.006676639879539692, 0.0063489417111059245]}, {\"hovertext\": \"<b>Topic 68</b>:crowd_crowds_simulation_pedestrian\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06481856785634393, 0.028046832082892804, 0.021938591776584415, 0.015186982878172913, 0.014801618079328414, 0.010083809847222337, 0.010042572310665797, 0.009769070464993956, 0.006855965095343317, 0.00668359241682785]}, {\"hovertext\": \"<b>Topic 69</b>:conversational_dialogue_agent_conv\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.041649255347529404, 0.031210454173926188, 0.01740422696093891, 0.01637261519721684, 0.01292255186621501, 0.009942589454733915, 0.008610949052767753, 0.006714583441824864, 0.005555152999410982, 0.005505245890919457]}, {\"hovertext\": \"<b>Topic 70</b>:tracking_camera_tracker_pose_calib\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.038121781248529996, 0.02068226779429756, 0.011376150089677524, 0.01038242958384638, 0.009701724194556713, 0.007315757919555765, 0.006668270429794488, 0.006571838805223754, 0.00638467334498547, 0.006248490989451448]}, {\"hovertext\": \"<b>Topic 71</b>:shadow_shadows_light_rendering_sce\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.13473290926325915, 0.06929581792786618, 0.026792152439711184, 0.012711718026595263, 0.009769486351401475, 0.009382421309853103, 0.009031554875961662, 0.008636603535897203, 0.007857437970825266, 0.007320818669170545]}, {\"hovertext\": \"<b>Topic 72</b>:narrative_story_stories_storytelli\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04547399547278778, 0.04328852184061042, 0.029723140295046798, 0.023362449435839684, 0.012528563772058321, 0.011386994104169256, 0.0109147641124941, 0.007161597082409525, 0.0049933847614094355, 0.004788547538658667]}, {\"hovertext\": \"<b>Topic 73</b>:authentication_passwords_password_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.07415093891044366, 0.07376022343569219, 0.06856029166587987, 0.026631216796782608, 0.018027630217992287, 0.014611307150232958, 0.011205888983046773, 0.009423725173213696, 0.00805657134646044, 0.006525685592089412]}, {\"hovertext\": \"<b>Topic 74</b>:students_math_solving_achievement_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03267402982507641, 0.02592811409218996, 0.020232367725277728, 0.01705977043234123, 0.015602889139028072, 0.012765386007263756, 0.010109504622115116, 0.008338075324072571, 0.007955497296123699, 0.007927670578837262]}, {\"hovertext\": \"<b>Topic 75</b>:health_patients_self_online_commun\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.035169768673619976, 0.02374233968932964, 0.021923683974692583, 0.018773548745480782, 0.013665170698234056, 0.011031795701038027, 0.010872612469860949, 0.009029933560796606, 0.008337633181520905, 0.007820580141638972]}, {\"hovertext\": \"<b>Topic 76</b>:route_map_navigation_wayfinding_sp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.030456751039830962, 0.023214376313935598, 0.02032924055222869, 0.01897370241271569, 0.017837297665102232, 0.01411490792687118, 0.013345855982424985, 0.009669557761233969, 0.009120446476481492, 0.008252720998737629]}, {\"hovertext\": \"<b>Topic 77</b>:gene_genome_genomic_visualization_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02546430634804702, 0.019770249064874085, 0.018873073955396415, 0.014846449393304189, 0.012797433135204959, 0.009231347687647183, 0.007955382225758836, 0.007163259194245788, 0.006683785186422773, 0.006248583930605972]}, {\"hovertext\": \"<b>Topic 78</b>:image_smoothing_denoising_inpainti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04395855130277612, 0.015917710189658804, 0.015683677504868425, 0.015401506230355291, 0.015201376070810277, 0.014865110454109563, 0.014216636526966824, 0.0131837536069751, 0.0079564415105136, 0.007011238102537073]}, {\"hovertext\": \"<b>Topic 79</b>:construction_visualisation_buildin\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.024765913000647365, 0.022383436107891005, 0.01587466798020058, 0.011048992178616882, 0.00971034932484415, 0.009440788436195644, 0.007754871860088028, 0.007681108310522366, 0.007002181006034549, 0.006901822632394694]}, {\"hovertext\": \"<b>Topic 80</b>:solid_solids_boundary_polyhedral_s\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.07508778618204255, 0.026219604057422574, 0.024286335874540838, 0.012102574313637954, 0.010706491775676305, 0.010115355936032116, 0.009841281511885958, 0.009633603512831664, 0.00947681389342684, 0.009073483996568743]}, {\"hovertext\": \"<b>Topic 81</b>:electricity_households_heating_sma\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03373595690183237, 0.012677825793921335, 0.012315921083248145, 0.011019030466065498, 0.010618582208026155, 0.00984028079853703, 0.00951195945692969, 0.008359139835494307, 0.00811082938744468, 0.007496119759473253]}, {\"hovertext\": \"<b>Topic 82</b>:fractal_fractals_compression_chaos\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.12655834848072972, 0.04351507643452271, 0.014971971395433041, 0.011421094082516884, 0.01067654080226436, 0.008515668378854313, 0.00797448625533805, 0.00702151217192513, 0.006654410850475889, 0.00618761009623204]}, {\"hovertext\": \"<b>Topic 83</b>:memories_diary_life_everyday_coupl\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.015436745233328126, 0.011191783137888987, 0.010413885342155408, 0.010328170448833895, 0.010281018208374031, 0.009392708582286583, 0.008803004636576421, 0.008129840712146291, 0.007504259901961611, 0.007403907171731872]}, {\"hovertext\": \"<b>Topic 84</b>:civic_civics_infrastructure_citize\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.026589024597048934, 0.016064059109191363, 0.012970131826074406, 0.012561462883074994, 0.011129424354099596, 0.010487000878881592, 0.009905117929751584, 0.00874541124013107, 0.008032029554595681, 0.0077459026341320835]}, {\"hovertext\": \"<b>Topic 85</b>:xml_query_xquery_queries_twig_sche\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.13937626580198959, 0.03227878058517086, 0.031398716350848385, 0.019906867459683505, 0.018782145886092567, 0.011892702271169207, 0.009627648563448775, 0.00913882625337008, 0.008172815207638295, 0.006686170240342868]}, {\"hovertext\": \"<b>Topic 86</b>:moral_dilemmas_judgment_harm_moral\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.11287546328465438, 0.03329793611459189, 0.020982520359585675, 0.020840118806776817, 0.01730773669756049, 0.01469197077473407, 0.012681088113267947, 0.010632629679405666, 0.0103202841284068, 0.009867535315498872]}, {\"hovertext\": \"<b>Topic 87</b>:volume_volumetric_rendering_opacit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04403096722360565, 0.025607688200322505, 0.020413166178569947, 0.01723615062300506, 0.01163184038558087, 0.008812209911468551, 0.008542685770499837, 0.008056730519338732, 0.008038839811100274, 0.007437067384850615]}, {\"hovertext\": \"<b>Topic 88</b>:pointing_target_movement_targets_e\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.07738116838171445, 0.03525554664275376, 0.02166180787471902, 0.019149425100397747, 0.016027874511754636, 0.012621041416398776, 0.009922578384208194, 0.007687944306955905, 0.007685156124658822, 0.006909520001866122]}, {\"hovertext\": \"<b>Topic 89</b>:indoor_location_positioning_rfid_f\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.05212246587659888, 0.031585078985939874, 0.026067011764847572, 0.020249791615016718, 0.011152426787690888, 0.010689774051273583, 0.009235669133322182, 0.00838938487986674, 0.008347913387644654, 0.008190732722445181]}, {\"hovertext\": \"<b>Topic 90</b>:diffusion_tensor_tracts_brain_fibe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.052385400945977746, 0.04802839899587551, 0.02817532325633104, 0.027149804470241658, 0.023522001450993636, 0.02253773602006219, 0.021674209745502417, 0.016704110830980775, 0.00867240038242591, 0.0064596310686407775]}, {\"hovertext\": \"<b>Topic 91</b>:ontology_schema_ontologies_schemas\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.052461320831746074, 0.04327868656864604, 0.04040995588506726, 0.02193461834163326, 0.020622038518590024, 0.013153583155090711, 0.008722416415983706, 0.006155237349144541, 0.005931433875791278, 0.0053444962999335596]}, {\"hovertext\": \"<b>Topic 92</b>:email_emails_mail_inbox_folders_wo\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.150959361685423, 0.025307819974994712, 0.019588966256334862, 0.012295087780282028, 0.011133645575943209, 0.008567881568864327, 0.00737644376239957, 0.006481057304224413, 0.006194203321922694, 0.006103512521071467]}, {\"hovertext\": \"<b>Topic 93</b>:security_traffic_cyber_intrusion_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03810055987120316, 0.020878532213994522, 0.017753328658939287, 0.016911030253526627, 0.015001926502952973, 0.013055680453142057, 0.009725981834424248, 0.007232505012450057, 0.006500186213001105, 0.006401612630838084]}, {\"hovertext\": \"<b>Topic 94</b>:outlier_outliers_datasets_distance\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.10416380971809384, 0.05252998645905821, 0.01164265886337953, 0.008923559723841146, 0.008497407376987755, 0.007743245907866348, 0.0071631905351977184, 0.007067606775379495, 0.006196395582902468, 0.005529633014366049]}, {\"hovertext\": \"<b>Topic 95</b>:video_videos_frames_temporal_brows\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0832642176928587, 0.028690275374794082, 0.018377908546280998, 0.014436633074128782, 0.010978148156970981, 0.009497176214017605, 0.007633792821942891, 0.006242114201452679, 0.006065334196187995, 0.00594655945160334]}, {\"hovertext\": \"<b>Topic 96</b>:tree_trees_plant_plants_branches_l\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0390366936480265, 0.03452011048978827, 0.02500675203295956, 0.023381073102836443, 0.0192172044494626, 0.01547797866331794, 0.012605474188950472, 0.009999660130094033, 0.009323652715978981, 0.007303626987222453]}, {\"hovertext\": \"<b>Topic 97</b>:entity_entities_name_disambiguatio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0906135948629179, 0.035025709604258846, 0.014407238854613771, 0.013970287727241022, 0.013214970324490108, 0.011322163350078782, 0.010425601602266547, 0.007744127280017505, 0.007647386827418489, 0.007329106690770216]}, {\"hovertext\": \"<b>Topic 98</b>:interruptions_interruption_interru\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06265920757115619, 0.0496232214625934, 0.03364329776276457, 0.021440558526265658, 0.017186310245363396, 0.011748064122235936, 0.009652306042235988, 0.008487949671953666, 0.008219566219706662, 0.007597814912035043]}, {\"hovertext\": \"<b>Topic 99</b>:coordination_interpersonal_synchro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04740040652690541, 0.02444547465235753, 0.015834275154850617, 0.014758492581044027, 0.013777946168338008, 0.013777356751162744, 0.010773001589431905, 0.008691476712670787, 0.008243216755327826, 0.007467344334519626]}, {\"hovertext\": \"<b>Topic 100</b>:terrain_rendering_terrains_resolu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.08602351519317641, 0.0250178195986488, 0.020681165040253843, 0.011669029450800032, 0.01134341529919005, 0.010675392744860426, 0.01053428020843727, 0.010388252535779232, 0.007036514316401606, 0.006548021947646204]}, {\"hovertext\": \"<b>Topic 101</b>:stream_drift_ensemble_drifting_mi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04057046762194803, 0.03354910535391271, 0.02274061715556815, 0.017956409078730605, 0.015452530060318758, 0.015173852897883654, 0.010963126856578024, 0.008036596151650782, 0.007552222282657238, 0.007483035273591486]}, {\"hovertext\": \"<b>Topic 102</b>:cartograms_map_maps_cartographic_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03745312247590661, 0.031017465262735997, 0.026279134317250766, 0.020964042032276, 0.013793958872013958, 0.01138770377807058, 0.009985800331548111, 0.009138263489155486, 0.007841937441281609, 0.00718298426264366]}, {\"hovertext\": \"<b>Topic 103</b>:design_clothing_clothes_designers\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.015722603979131215, 0.015666547115924325, 0.01115785987584229, 0.010879920221047374, 0.01068258540135768, 0.009831928749699624, 0.008637171485376557, 0.008616600913758378, 0.007500120282576143, 0.006757986591305892]}, {\"hovertext\": \"<b>Topic 104</b>:skeleton_skeletons_segmentation_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.061836093242665674, 0.03248266860938197, 0.024349297991762154, 0.02140755733584761, 0.019462421065963686, 0.011720608961431856, 0.011538953592649151, 0.010780588491572126, 0.00693867752228935, 0.006923238739216028]}, {\"hovertext\": \"<b>Topic 105</b>:matrix_factorization_nonnegative_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06818269370669565, 0.03713531973496861, 0.02060107545358826, 0.01860694770648524, 0.017738435860238367, 0.011807883543379315, 0.011663438646380624, 0.011472243137826065, 0.010927608276909574, 0.010109544510959025]}, {\"hovertext\": \"<b>Topic 106</b>:parallel_compiler_cache_paralleli\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.03165536084097607, 0.02442673695764265, 0.022070534540636847, 0.01711170130805615, 0.016690414409852326, 0.016187856658461224, 0.014697765661945124, 0.009741786910378981, 0.008679423286473144, 0.008232667116304946]}, {\"hovertext\": \"<b>Topic 107</b>:event_events_sentinel_ranking_vis\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06891397507328073, 0.03005006331451403, 0.010934243034850627, 0.01033102581741782, 0.010001031655969427, 0.00945671783119469, 0.007571576620005682, 0.006540071399546936, 0.006402415705099931, 0.006230844964441518]}, {\"hovertext\": \"<b>Topic 108</b>:wavelet_wavelets_multiresolution_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.08754392405475771, 0.058428116087646566, 0.045465323775726686, 0.04390614159469028, 0.030375775509842336, 0.018750732916663064, 0.018660367505639753, 0.017062357217586487, 0.008554947517339633, 0.008118741313058194]}, {\"hovertext\": \"<b>Topic 109</b>:children_participatory_child_tech\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06888617811925014, 0.026828315136803456, 0.025603459140807517, 0.00956707538780653, 0.008705663065142682, 0.008484941075769413, 0.007905345618830752, 0.0074272452907996386, 0.0072191406664980275, 0.0069849165514100624]}, {\"hovertext\": \"<b>Topic 110</b>:tabletop_collaboration_touch_grou\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06691865826882738, 0.02941798051945446, 0.02503749439902041, 0.01903420260063149, 0.0172957870547844, 0.016181355434408316, 0.01407086047732199, 0.011618543620254137, 0.01077863432696881, 0.009374288625659756]}, {\"hovertext\": \"<b>Topic 111</b>:collision_collisions_deformable_r\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.1168439406934478, 0.029972954331604153, 0.029082756494662743, 0.01911450814445708, 0.010849769622439628, 0.010524394092198746, 0.010286157380056482, 0.010067005939485537, 0.009347113538806937, 0.009055367862810566]}, {\"hovertext\": \"<b>Topic 112</b>:chatbot_chatbots_chat_conversatio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06429342281323018, 0.05590465442208556, 0.051494284041973475, 0.020743268343266244, 0.01945665185005037, 0.013825425222202248, 0.01161616430783062, 0.010125130998453845, 0.007331783190969391, 0.006603235065161431]}, {\"hovertext\": \"<b>Topic 113</b>:hair_hairs_cloth_hairstyles_furry\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.19688873217812514, 0.03589118172536017, 0.023382827305717734, 0.022779564999640612, 0.01771743944416492, 0.016219761873136174, 0.01570828694576941, 0.012007156835904245, 0.010991383748366237, 0.008122650036478631]}, {\"hovertext\": \"<b>Topic 114</b>:watermarking_watermark_watermarks\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.10021344419098462, 0.0652881628402527, 0.033033208535027204, 0.024339738514773585, 0.017295867329555306, 0.013791830825155987, 0.013667790473226462, 0.012734301887097278, 0.012278155485155453, 0.011234637889728376]}, {\"hovertext\": \"<b>Topic 115</b>:surgical_surgery_laparoscopic_min\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0459428146867929, 0.04257630870328129, 0.02211366420371084, 0.02196354114377139, 0.020575981446929202, 0.015234593361821256, 0.014282675322557111, 0.013933517200114268, 0.013094922421260397, 0.011413569442073645]}, {\"hovertext\": \"<b>Topic 116</b>:subspace_clustering_clusters_subs\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.10067830247536627, 0.061155918190940836, 0.05812016758976392, 0.03837336598600522, 0.010158562680153787, 0.00897949601302916, 0.00893352108050026, 0.007211909505611267, 0.0062916088230335, 0.006288396819208413]}, {\"hovertext\": \"<b>Topic 117</b>:location_recommendation_friends_l\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.037233509124400814, 0.0343954279496239, 0.015223315332315255, 0.0142002732499046, 0.012510698672268344, 0.010420213861777251, 0.010237408128455265, 0.00977210236103568, 0.009727829669506433, 0.0079967624408636]}, {\"hovertext\": \"<b>Topic 118</b>:parents_parenting_child_life_bere\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0424315689492212, 0.02482275557307068, 0.0127078638648597, 0.012660629864895965, 0.010485429043644266, 0.009165515963784687, 0.008699758990576555, 0.008573325177569412, 0.008295449977115486, 0.007383215718242563]}, {\"hovertext\": \"<b>Topic 119</b>:location_privacy_crowdsensing_obf\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.06146658897833811, 0.03556014471514466, 0.03074463867600615, 0.015158855979230647, 0.013591659473277291, 0.01326859106948967, 0.010779655363515732, 0.008996863532189927, 0.007644253972002926, 0.006863358081997179]}, {\"hovertext\": \"<b>Topic 120</b>:dance_dancers_dancer_choreographe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.11438292769257383, 0.06215463365756462, 0.020324222134926788, 0.018478600703491405, 0.01567769282969399, 0.014088375896351533, 0.012434133333275914, 0.010935384482666552, 0.007777954300026943, 0.007640919810289097]}, {\"hovertext\": \"<b>Topic 121</b>:line_clipping_algorithms_polygon_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.1125540197392056, 0.10381617796905901, 0.024709507920902943, 0.016729186543945215, 0.01543424174383362, 0.014558730685028677, 0.011206678020392618, 0.011160732958162238, 0.010397202595502824, 0.010043522080776104]}, {\"hovertext\": \"<b>Topic 122</b>:occlusion_culling_rendering_occlu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.12967322439653906, 0.05177618612434655, 0.029107028300413094, 0.015569666493554148, 0.015440478019211966, 0.013425685533939916, 0.013402786562108518, 0.012802504323246679, 0.010751454199514806, 0.010422552021677318]}, {\"hovertext\": \"<b>Topic 123</b>:multimodal_modality_modalities_sp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.09618565974203652, 0.03342511933765746, 0.02455544807265985, 0.021508997422812415, 0.01999879783808497, 0.01436764226887578, 0.012867033538342043, 0.010434015473712165, 0.007989147136597872, 0.007959224293917011]}, {\"hovertext\": \"<b>Topic 124</b>:religious_dreaming_religion_cultu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.02659544047817145, 0.023048751579874766, 0.022880363373367296, 0.02003698166912996, 0.015414916671446044, 0.013035047931234804, 0.013017418226241882, 0.011674218051132992, 0.011488343292765272, 0.010076149673980883]}, {\"hovertext\": \"<b>Topic 125</b>:spreadsheet_spreadsheets_web_prog\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.14674547412146258, 0.055932258262063606, 0.01755236975651935, 0.01583346177051873, 0.009202510541036494, 0.008256489165243623, 0.0073373438540011065, 0.006765761411973832, 0.006714459107557381, 0.00640812436682676]}, {\"hovertext\": \"<b>Topic 126</b>:cleaning_repairing_repair_tuples_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.04848327407323683, 0.033422991363376356, 0.016428461150386407, 0.013252523692686083, 0.012533857128260677, 0.012357771513450602, 0.009236553385718176, 0.007934264536425739, 0.007696126685828714, 0.007536720172879049]}, {\"hovertext\": \"<b>Topic 127</b>:polygons_polygon_hull_algorithm_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0793132197823459, 0.06830389771783835, 0.026656081631424453, 0.026176684866602202, 0.024303285851908503, 0.02115916829805646, 0.016518147203848615, 0.012670410637075335, 0.011829904255371344, 0.011199843798320503]}, {\"hovertext\": \"<b>Topic 128</b>:spatial_languages_across_meaning_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.0826133326444654, 0.03100380474927502, 0.015703124700319836, 0.014725276463881326, 0.012938950797960027, 0.012190207859505812, 0.00974196653643872, 0.009103532695375616, 0.008874679333340922, 0.008237113094891705]}, {\"hovertext\": \"<b>Topic 129</b>:ubicomp_ubiquitous_design_activit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.12238610115387533, 0.021930117893463413, 0.011705440962476539, 0.009115645642570289, 0.007488503487476784, 0.007454106980653211, 0.00720309828293088, 0.0070910107038473155, 0.0070392321712415004, 0.007021719456678557]}, {\"hovertext\": \"<b>Topic 130</b>:meetings_communication_informal_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.045166391400986945, 0.024918677131630367, 0.013365982848825012, 0.013293475597682448, 0.011420176829627674, 0.01058318761335728, 0.010340045634262527, 0.009784070934592545, 0.0092353182404457, 0.008320286261430096]}, {\"hovertext\": \"<b>Topic 131</b>:provenance_lakes_workflows_lake_d\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [0.12215547382290122, 0.02284141383765096, 0.01937843022415908, 0.0168079528823799, 0.014344601064552497, 0.011718920820999918, 0.009282098715908856, 0.009234022128851943, 0.008490082742802973, 0.008126885520587546]}],                        {\"height\": 500, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Term score decline per Topic</b>\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.9, \"yanchor\": \"top\"}, \"width\": 800, \"xaxis\": {\"dtick\": 2, \"range\": [0, 10], \"tick0\": 1, \"title\": {\"text\": \"Term Rank\"}}, \"yaxis\": {\"title\": {\"text\": \"c-TF-IDF score\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('49d6fc95-e890-415d-9885-8036c839370b');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 517
        },
        "id": "zZ1x60ylOZx7",
        "outputId": "25b582cf-c2ef-4c67-c455-0e2d6e44a8b8"
      },
      "source": [
        "reduce_model2.visualize_term_rank(log_scale=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<html>\n",
              "<head><meta charset=\"utf-8\" /></head>\n",
              "<body>\n",
              "    <div>            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
              "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>                <div id=\"9a157421-cd89-4011-8a32-01ee3cf25bb7\" class=\"plotly-graph-div\" style=\"height:500px; width:800px;\"></div>            <script type=\"text/javascript\">                                    window.PLOTLYENV=window.PLOTLYENV || {};                                    if (document.getElementById(\"9a157421-cd89-4011-8a32-01ee3cf25bb7\")) {                    Plotly.newPlot(                        \"9a157421-cd89-4011-8a32-01ee3cf25bb7\",                        [{\"hovertext\": \"<b>Topic -1</b>:design_system_users_user_use_using\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-2.5054411409222093, -2.530153360140558, -2.5415913638956527, -2.542885848781894, -2.5567913062982015, -2.5606006945275386, -2.5613509754993498, -2.5690121136332618, -2.5816285397840923, -2.584301701787891]}, {\"hovertext\": \"<b>Topic 0</b>:flow_fluid_vortex_jet_vortices_flow\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.457454909641612, -1.7734811096487344, -1.8276252301183773, -1.9682964228662705, -2.090326674124587, -2.1414628745074817, -2.173166695136469, -2.2356646246943095, -2.2373766549186307, -2.2459867804234186]}, {\"hovertext\": \"<b>Topic 1</b>:language_word_linguistic_lexical_ve\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6649963372926668, -1.6701264313112894, -1.9933411841904032, -2.0746267485649943, -2.130624876124349, -2.18409075269062, -2.2240645166075117, -2.2574581360422914, -2.268883492920994, -2.269287685952643]}, {\"hovertext\": \"<b>Topic 2</b>:visualization_topic_visual_visualiz\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.7023063608291866, -1.818493840953962, -1.8953199194588684, -1.9424734112987236, -1.960108872815649, -2.0609215515821027, -2.181769557296666, -2.2847646060469198, -2.423595501997605, -2.4459445774111064]}, {\"hovertext\": \"<b>Topic 3</b>:recommendation_recommender_recommen\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6893751981511813, -1.8134174978999396, -2.0608754732185606, -2.0943738178657236, -2.13661171662676, -2.215282747506385, -2.2272809841185084, -2.234083156976148, -2.2600345812759577, -2.2686001653865464]}, {\"hovertext\": \"<b>Topic 4</b>:graph_graphs_network_networks_commu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4109504661413028, -1.5944329181342998, -1.7774445869505129, -1.7866491379528053, -2.06946620977712, -2.100919767554832, -2.307104080829488, -2.3120328690494865, -2.3188959941060765, -2.3530281251134157]}, {\"hovertext\": \"<b>Topic 5</b>:shape_mesh_meshes_subdivision_shape\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.7308074713388595, -1.7821401640036059, -1.8798750415250594, -1.8964110498767703, -1.9802152290798503, -2.0918126854011287, -2.0983891951005185, -2.233326857347039, -2.248580621836774, -2.282004740776002]}, {\"hovertext\": \"<b>Topic 6</b>:game_games_sports_play_gaming_exerc\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5233034111794193, -1.5948232668489297, -2.0232778684963573, -2.053891231276775, -2.1789003864335608, -2.265525722315057, -2.3217954707878623, -2.3266905492818437, -2.368694303870809, -2.3939103222960463]}, {\"hovertext\": \"<b>Topic 7</b>:light_illumination_rendering_lighti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5281355320692267, -1.6368289742752045, -1.7611502508431807, -1.9701792321602056, -1.993634759661443, -1.9940678491856427, -2.0116305738671043, -2.1296318947269923, -2.13779855823145, -2.219840513442651]}, {\"hovertext\": \"<b>Topic 8</b>:database_query_queries_join_sql_dat\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6118687300761942, -1.6242649395457112, -1.7471882531664544, -1.8918370396484314, -2.0190014341701543, -2.0406433423222166, -2.1622533700510744, -2.1941191605917085, -2.2426670997643186, -2.286521822996166]}, {\"hovertext\": \"<b>Topic 9</b>:dimensional_visualization_multidime\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.842798019595577, -1.886805557343375, -1.9317867835512172, -2.0604200101066055, -2.1002535496200374, -2.116599620923636, -2.1866146407333718, -2.266447029475151, -2.2684467160953394, -2.2764012408905128]}, {\"hovertext\": \"<b>Topic 10</b>:motion_animation_motions_animation\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3732799903252442, -1.427468680389684, -1.7702147307351304, -2.087263441404278, -2.124136493635052, -2.213079128996038, -2.2421736182152996, -2.254287368565471, -2.2916640788030254, -2.3433282002819436]}, {\"hovertext\": \"<b>Topic 11</b>:music_musical_voice_sound_audio_mu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3996076196980276, -1.6650170147980654, -1.705505270839357, -1.8687406941380291, -2.027528048087544, -2.24795811290689, -2.315159212737743, -2.3356624014020904, -2.398374942126878, -2.430580239121529]}, {\"hovertext\": \"<b>Topic 12</b>:education_educational_teaching_cla\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.8123455578523817, -1.8741157999472988, -1.919438696481283, -1.93743872927284, -2.0088638118167284, -2.0533684845157034, -2.0707214463706727, -2.077797114041033, -2.2024615030426866, -2.2595816726000497]}, {\"hovertext\": \"<b>Topic 13</b>:driving_vehicle_vehicles_driver_ro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4822342750219781, -1.5465595012894153, -1.701933895740995, -1.7419464470359618, -1.835561408172346, -1.954952471099559, -2.1145260540352755, -2.33956067760693, -2.3473829497906964, -2.357718138207324]}, {\"hovertext\": \"<b>Topic 14</b>:gesture_gestures_touch_finger_hand\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3346379380907736, -1.3763189758867005, -1.6902073123247474, -1.883117292402799, -1.9221996972952182, -1.9383278164483078, -2.147425763633098, -2.2527971959893214, -2.3029464640114985, -2.3153068219799042]}, {\"hovertext\": \"<b>Topic 15</b>:classification_class_feature_kerne\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6313339742229305, -1.8358182633440723, -1.8365143262844328, -1.868144639826163, -1.9017786614654788, -1.9553853481614258, -2.015819150880154, -2.035022761247543, -2.20412830047349, -2.233515201945967]}, {\"hovertext\": \"<b>Topic 16</b>:gaze_eye_attention_head_movements_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2907143582726128, -1.2908208833916626, -2.064141674663327, -2.126897302440316, -2.1283028698463506, -2.1914241417857494, -2.205549327430045, -2.275211363496077, -2.2999156438259036, -2.331681157481735]}, {\"hovertext\": \"<b>Topic 17</b>:haptic_tactile_force_virtual_vibro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2191374704051743, -1.5513741677504762, -1.708945204979423, -1.7880625537745167, -1.813846785661977, -1.951061782906006, -1.9804097782999972, -2.019447711819647, -2.0423278308939494, -2.2395156441504644]}, {\"hovertext\": \"<b>Topic 18</b>:rendering_graphics_gpu_splatting_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5446606327992651, -1.6827171917789852, -1.7752404406714688, -2.0872252018535065, -2.1177001718137025, -2.1371470177356295, -2.172660735408195, -2.212177802164535, -2.225465461475577, -2.2403131169281933]}, {\"hovertext\": \"<b>Topic 19</b>:mining_frequent_itemsets_rules_ass\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4178941291646137, -1.504031867726341, -1.6019824885048195, -1.6418030928755731, -1.7105525454780142, -1.9555755037501852, -2.0946536776959257, -2.111313121163882, -2.1189601031273737, -2.152597141637645]}, {\"hovertext\": \"<b>Topic 20</b>:image_images_retrieval_recognition\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.643060214189279, -1.8056428382038332, -1.949737387064039, -2.0855896099749676, -2.1073521256139007, -2.1622288275679824, -2.234947561060241, -2.281265529859622, -2.285570329768915, -2.322874144535086]}, {\"hovertext\": \"<b>Topic 21</b>:software_programmers_collaboration\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.781080040885718, -1.8873548864028808, -1.9122456278078548, -1.9764777113750196, -2.007122480730281, -2.1343055859091935, -2.1675525539333766, -2.2773260366929895, -2.3026067803858346, -2.309583003397969]}, {\"hovertext\": \"<b>Topic 22</b>:brain_cognitive_attention_visual_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.7171948674520656, -1.9093994719296965, -1.9423580358345696, -1.9798249172501916, -2.1317921404962554, -2.1619899196936525, -2.2618558588529227, -2.270064926947708, -2.3061641054941524, -2.3795085142656944]}, {\"hovertext\": \"<b>Topic 23</b>:trajectory_trajectories_mobility_u\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.7109029282206685, -1.7136038959219366, -1.8160826051451382, -1.991345962354186, -2.0422454988951193, -2.0534392760613915, -2.0761926806951414, -2.2455061629362936, -2.2978920114241013, -2.312410997315512]}, {\"hovertext\": \"<b>Topic 24</b>:graphics_graphic_standards_phigs_d\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2456759330869185, -1.9225238087142484, -1.9451212495484476, -1.969706573955522, -2.1261855444631514, -2.1408053283191326, -2.178233532594208, -2.190624189436617, -2.212248019008846, -2.2634154132627504]}, {\"hovertext\": \"<b>Topic 25</b>:series_time_patterns_mining_cluste\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.258901477015852, -1.5643758997010988, -1.9913961261880302, -2.1153406289190846, -2.12622571277872, -2.1379842988611184, -2.1879443669963927, -2.212052137144223, -2.324914182827443, -2.352030456519606]}, {\"hovertext\": \"<b>Topic 26</b>:fabrication_printing_print_manufac\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5008046066043894, -1.673307508939455, -2.1660542545710775, -2.177500341916106, -2.217382017430799, -2.2391620559516947, -2.2639189471645196, -2.2868570610061636, -2.2893920782033352, -2.3147469849317823]}, {\"hovertext\": \"<b>Topic 27</b>:smart_activities_context_interface\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.8686757964346212, -1.8772552962639897, -1.994854977699167, -2.063145151019769, -2.1383271240509703, -2.1604279336669245, -2.1917270669013864, -2.1984165059030896, -2.2036157131391194, -2.217354405647141]}, {\"hovertext\": \"<b>Topic 28</b>:vessel_imaging_ultrasound_clinical\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.840213115902069, -1.8967695036591452, -1.9642330613254275, -2.034740227727779, -2.0369091412454967, -2.081434293308437, -2.0903626875082533, -2.1234485282629936, -2.1794441866040075, -2.2060688919095637]}, {\"hovertext\": \"<b>Topic 29</b>:texture_textures_synthesis_image_s\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.159055235156284, -1.5012555557895455, -1.5142671879472145, -1.8785227363443369, -1.9909333966954947, -1.9987762790484334, -2.0428190272222326, -2.152107293345156, -2.2440107768906303, -2.3120692759348667]}, {\"hovertext\": \"<b>Topic 30</b>:decision_choice_risk_risky_decisio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6145539485093894, -1.6293720893999415, -1.8751211493615774, -1.8857998172790484, -1.8929400557645781, -1.928423722767541, -1.9608811109596738, -2.1108400889084247, -2.1867335028156285, -2.22654623907837]}, {\"hovertext\": \"<b>Topic 31</b>:weather_visualization_climate_ocea\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.707936542878337, -1.8506332361417968, -1.8680505147716553, -1.9076793202599005, -2.0443369054782496, -2.0933725978845192, -2.209074964462668, -2.2290147594713274, -2.269950397046838, -2.306876696405298]}, {\"hovertext\": \"<b>Topic 32</b>:ray_rays_traversal_rendering_casti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.0283035563647211, -1.6511343478864597, -1.8459406225008772, -1.891993047353855, -1.939934926442847, -1.9716919698195003, -1.9716997401123866, -2.075535023690994, -2.127859718940477, -2.18678014063385]}, {\"hovertext\": \"<b>Topic 33</b>:twitter_tweets_media_sentiment_twe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3507308379625624, -1.569635989229201, -1.59313715082555, -1.938638896157656, -2.109178845961975, -2.1544413778973244, -2.1656555525724177, -2.175630676967262, -2.2679169191373885, -2.310538160579273]}, {\"hovertext\": \"<b>Topic 34</b>:creativity_painting_art_creative_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5679610897135392, -1.6123256940083635, -1.627517405972146, -1.7059887902473982, -1.84895727951702, -1.8850341772320145, -1.9111518306107325, -1.9668905294827672, -2.123315738843385, -2.209608766139914]}, {\"hovertext\": \"<b>Topic 35</b>:causal_beliefs_evidence_belief_exp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2135145140860206, -1.8614942107953998, -1.8793668667767862, -1.8905197701446936, -1.908094595999086, -1.9972324675177036, -2.0361012513219126, -2.1424633139412417, -2.142794954175587, -2.2181541560119538]}, {\"hovertext\": \"<b>Topic 36</b>:privacy_security_private_protectio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.168462405292523, -1.769940890576526, -1.897875170857204, -2.033911003734434, -2.066685756731124, -2.0830339365444104, -2.127766422307757, -2.2616959963806407, -2.316253949038861, -2.3477479866216457]}, {\"hovertext\": \"<b>Topic 37</b>:urban_city_building_buildings_citi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4376184203398146, -1.767288128725108, -1.9049029440625944, -1.9259708453137196, -2.043318487504008, -2.1173834562150518, -2.14339925777237, -2.171763157719185, -2.2438014669782964, -2.3177801447528648]}, {\"hovertext\": \"<b>Topic 38</b>:transaction_transactions_concurren\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4523659811628389, -1.5143541780025347, -1.597192857977877, -1.924396446977489, -1.9836547873789205, -1.9846550054040184, -2.022690455429962, -2.1155538289304916, -2.130739567575032, -2.150405683315277]}, {\"hovertext\": \"<b>Topic 39</b>:displays_display_navigation_lenses\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6273802675607318, -1.6785360768341049, -1.9605943452106382, -2.165404211980446, -2.172527898432415, -2.1895263935988636, -2.2038828372716286, -2.231618363313141, -2.255918046949406, -2.2571057716667187]}, {\"hovertext\": \"<b>Topic 40</b>:search_web_information_pages_brows\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.472188111636029, -1.554431064657779, -1.7940659056658563, -1.921987709849116, -2.0946140047808637, -2.148919996250528, -2.1838438919488503, -2.2442428216430375, -2.290507837583092, -2.3353022007016095]}, {\"hovertext\": \"<b>Topic 41</b>:category_categories_categorization\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1374615106447057, -1.5076840976937214, -1.5279488302953665, -1.8839071535937868, -1.9755618770763181, -1.990984213224609, -2.0050197871703905, -2.021425746507507, -2.2101811842405397, -2.244541325629439]}, {\"hovertext\": \"<b>Topic 42</b>:crowdsourcing_workers_crowd_worker\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3247653663849754, -1.345211092412585, -1.4169126009277504, -1.6863931534281558, -1.8135619892941042, -1.9450652590449014, -1.9459699557162193, -2.0817162295903535, -2.171755888011625, -2.2483760294060118]}, {\"hovertext\": \"<b>Topic 43</b>:patient_patients_care_clinical_hos\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4416439926651796, -1.586431867326088, -1.6677858399481125, -1.680640172549675, -1.834294152181586, -1.8449908889635, -2.1247669631250674, -2.2054140007825898, -2.215117285963759, -2.262840933302903]}, {\"hovertext\": \"<b>Topic 44</b>:diagrams_diagrammatic_diagram_logi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1753199684976123, -1.2940966982048459, -1.5760191175152776, -1.6101856000184223, -1.6230552741379762, -1.8125709869520203, -2.0920786133825326, -2.1375472421850295, -2.1586618947462304, -2.251381336317609]}, {\"hovertext\": \"<b>Topic 45</b>:color_colors_palette_palettes_colo\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9575687205296243, -1.4676342381946563, -1.9400746233154136, -1.963281790167498, -1.9926091971193558, -2.091633948053175, -2.198205209761937, -2.2050352757771225, -2.2428762920335643, -2.3372951146806704]}, {\"hovertext\": \"<b>Topic 46</b>:hci_design_research_practice_desig\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5150071553096998, -1.5221081702418042, -1.6279317496653598, -1.8084887526646616, -1.9662250154279142, -2.0662365186655265, -2.136790460789245, -2.1719539394531617, -2.2429377550330276, -2.296339913363163]}, {\"hovertext\": \"<b>Topic 47</b>:robot_robots_robotic_robotics_inte\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.083152180026971, -1.272095899082134, -1.7023295329656805, -1.8195522689358752, -1.9522311076127177, -2.0280084471250857, -2.21025129053422, -2.2577990239095267, -2.354585255302449, -2.389906953947176]}, {\"hovertext\": \"<b>Topic 48</b>:label_labels_unlabeled_classificat\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3352984239492338, -1.6478772889396804, -1.794389970477256, -1.8906436010910015, -1.93570998463146, -1.9531036221609686, -1.972768273229721, -1.9796219894044895, -2.016246234298625, -2.120961449434729]}, {\"hovertext\": \"<b>Topic 49</b>:keyboard_keyboards_touch_finger_ha\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3013644008245289, -1.7200449862917566, -1.7882515731379336, -1.988637069908576, -2.0533840426301664, -2.076428932126854, -2.1080123750691815, -2.138641135028977, -2.143769195820445, -2.1892078934010306]}, {\"hovertext\": \"<b>Topic 50</b>:sketching_sketches_drawing_design_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3543650813687083, -1.5909884668301593, -1.8594985533501411, -1.997398654553046, -2.107151348295989, -2.116465217156703, -2.1220663624008997, -2.1615916019453487, -2.2937639411308774, -2.3012593326377306]}, {\"hovertext\": \"<b>Topic 51</b>:facial_face_animation_faces_blends\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1311341116180598, -1.3343912345540652, -1.727915151499664, -1.828803064880664, -1.9820961880592027, -2.018551878121533, -2.1337583520367978, -2.221490226599214, -2.2390208933060003, -2.2707437292133337]}, {\"hovertext\": \"<b>Topic 52</b>:machine_fairness_deep_explanations\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5509904563778343, -1.7094282499048574, -1.7608926859466516, -2.0770609237129065, -2.0950198411313012, -2.112753017484405, -2.2105869286663697, -2.2238809063668015, -2.2726289153089008, -2.308744004352117]}, {\"hovertext\": \"<b>Topic 53</b>:papers_conference_issue_editorial_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5240226326000943, -1.6533696448985715, -1.7358141189654188, -1.7557617267721475, -1.7957661010921684, -1.8224656597506843, -1.843576171304893, -1.9669454044032044, -2.029565513445569, -2.0498892998755256]}, {\"hovertext\": \"<b>Topic 54</b>:heritage_museum_visitors_museums_e\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4064619747347353, -1.5007913234974748, -1.7310705975507203, -1.793411244014507, -2.002467801202775, -2.0927592143554206, -2.1111284729436313, -2.137725349166071, -2.2001866024048824, -2.2319770048623235]}, {\"hovertext\": \"<b>Topic 55</b>:number_symbolic_magnitude_numbers_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5211811202470995, -1.5630588617234367, -1.58955276731853, -1.624007579817143, -1.8266952394225462, -1.9713188927940961, -1.9848704380554862, -2.0179650669718296, -2.062615889482428, -2.0901603871595156]}, {\"hovertext\": \"<b>Topic 56</b>:facebook_social_privacy_friends_si\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2865238427890435, -1.4904475525725522, -1.8022555942894647, -1.8958693425151867, -1.9360422833099546, -1.9529955382256396, -1.9987382829894789, -2.039943249322985, -2.1565698686216437, -2.1581252575311236]}, {\"hovertext\": \"<b>Topic 57</b>:influence_social_networks_network_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.386099375582202, -1.5861893571303511, -1.587761282495158, -1.6052617890824468, -1.6651899175194882, -1.8307275708123378, -1.9172806037764327, -2.0355643156481924, -2.2057486325576208, -2.2480776580189143]}, {\"hovertext\": \"<b>Topic 58</b>:walking_virtual_locomotion_reality\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4110252907170866, -1.4505924258910008, -1.7314039298974497, -1.8491728632854647, -1.9775817177542847, -1.9786181129013338, -1.9866902571690825, -2.1749633264390305, -2.2026892640771654, -2.2225301434497715]}, {\"hovertext\": \"<b>Topic 59</b>:reality_augmented_virtual_interact\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2566000731716616, -1.3950623032842817, -1.6437033389291424, -2.102184262369969, -2.1350618381217044, -2.172034616651927, -2.186099801551274, -2.2718303304114214, -2.2815469492027862, -2.2873555231815406]}, {\"hovertext\": \"<b>Topic 60</b>:molecules_atoms_molecule_halos_str\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.7758436314530748, -1.9699436199692404, -2.01553397238567, -2.0370243748207844, -2.0711330814346667, -2.169932458557567, -2.189878503757884, -2.2120566016813235, -2.224186455005514, -2.228514608409709]}, {\"hovertext\": \"<b>Topic 61</b>:memory_insight_solving_task_cognit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6160322153952538, -1.7109356521444266, -1.8026317757396244, -1.8034539649152252, -1.9749202235009407, -2.0163369669775775, -2.1619976398540435, -2.196854549843117, -2.235270875936101, -2.235820429125516]}, {\"hovertext\": \"<b>Topic 62</b>:spline_splines_curves_cubic_surfac\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.156139983768457, -1.330682429299857, -1.449510818567568, -1.5493939715833631, -1.6654257959885417, -1.737694368029797, -1.950267327124198, -2.0112061556388423, -2.025519062258982, -2.038037465198331]}, {\"hovertext\": \"<b>Topic 63</b>:clustering_clusters_cluster_cluste\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.0570554576814644, -1.630148145493311, -1.650291651202256, -1.724950458779904, -2.1625098613311122, -2.17565761720985, -2.1802662156972494, -2.2557072749012455, -2.2675200579251733, -2.2798609140823167]}, {\"hovertext\": \"<b>Topic 64</b>:impaired_visually_tactile_impairme\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.476857657326083, -1.5638196565640785, -1.7187779309418372, -1.7986124829520171, -1.8182467316312652, -1.8335244951311538, -2.076944102327096, -2.107341755823321, -2.1691183034649133, -2.2474287862791384]}, {\"hovertext\": \"<b>Topic 65</b>:distributed_parallel_scientific_co\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.6422248549644654, -1.6999783440117193, -1.9834979478616381, -2.091950244800528, -2.1289055950286055, -2.1420588451521594, -2.221175546920029, -2.2263973118951257, -2.27912730106986, -2.3022084623191894]}, {\"hovertext\": \"<b>Topic 66</b>:wikipedia_communities_community_ne\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3846799134819419, -1.455991983157186, -1.5966160978722668, -1.8744678730947202, -1.8913378348310614, -2.0000711004079035, -2.134943212884564, -2.1485964370892714, -2.176151303565084, -2.220569203452067]}, {\"hovertext\": \"<b>Topic 67</b>:metaphors_metaphor_analogical_anal\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3940944418465693, -1.3996805292892154, -1.4456890840658532, -1.5124235598961657, -1.783911652800036, -1.831876198518177, -2.0906834588610623, -2.1628902014024707, -2.175442047841179, -2.1972986601143796]}, {\"hovertext\": \"<b>Topic 68</b>:crowd_crowds_simulation_pedestrian\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1883005687829542, -1.5521161856240528, -1.6587912529366415, -1.8185284966776618, -1.8296908059217876, -1.9963753525117252, -1.9981550324855042, -2.010146757788807, -2.1639314021318796, -2.174990042399199]}, {\"hovertext\": \"<b>Topic 69</b>:conversational_dialogue_agent_conv\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3803927589954874, -1.5056999114437732, -1.7593452618973233, -1.7858819452057968, -1.8886517160636747, -2.0025004929220622, -2.0649489802924847, -2.172980924846098, -2.2553039752676898, -2.2592232785660573]}, {\"hovertext\": \"<b>Topic 70</b>:tracking_camera_tracker_pose_calib\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4188268150553744, -1.684401842920875, -1.944004686771768, -1.9837010056985234, -2.0131510758741147, -2.135740673881863, -2.1759867957987478, -2.1823130975285743, -2.194861317366783, -2.2042248521090624]}, {\"hovertext\": \"<b>Topic 71</b>:shadow_shadows_light_rendering_sce\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.870526312474442, -1.159292974705016, -1.5719923944493388, -1.8957957492849373, -2.010128269507036, -2.027685069317213, -2.0442374749446186, -2.063657016273979, -2.104719038758952, -2.135440350140686]}, {\"hovertext\": \"<b>Topic 72</b>:narrative_story_stories_storytelli\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3422368857871547, -1.3636272436492247, -1.5269053086139057, -1.6314816255707176, -1.9020987120561623, -1.9435909042141746, -1.9619856457312195, -2.14499011641662, -2.3016049684293827, -2.319796196732097]}, {\"hovertext\": \"<b>Topic 73</b>:authentication_passwords_password_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1298833454981334, -1.1321777763803869, -1.163927343526329, -1.574608989923975, -1.7440613587402045, -1.8353109296687624, -1.9505536844107503, -2.0257773878261967, -2.0938497425765306, -2.1853738543774375]}, {\"hovertext\": \"<b>Topic 74</b>:students_math_solving_achievement_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.485797298862065, -1.5862290709337488, -1.6939532902469023, -1.7680268172856257, -1.8067949772248806, -1.893966048208733, -1.9952701248395461, -2.078934185885026, -2.099332667530656, -2.100854404532568]}, {\"hovertext\": \"<b>Topic 75</b>:health_patients_self_online_commun\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4538304882113702, -1.624476485714322, -1.659086466818609, -1.7264536253592084, -1.8643849389557259, -1.9573537895020219, -1.9636660911551667, -2.0443154450669554, -2.078957215799513, -2.106761029169409]}, {\"hovertext\": \"<b>Topic 76</b>:route_map_navigation_wayfinding_sp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5163164266969509, -1.63424297975808, -1.6918788451758808, -1.7218479152620811, -1.7486709402082277, -1.8503219504594774, -1.8746535660112178, -2.0145933879901827, -2.039983900977938, -2.083402836916203]}, {\"hovertext\": \"<b>Topic 77</b>:gene_genome_genomic_visualization_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5940681495808147, -1.7039878594258773, -1.7241573582801646, -1.8283773977454545, -1.8928771308996066, -2.0347348915436614, -2.0993389493234913, -2.144889334113734, -2.1749775165659586, -2.2042183923845573]}, {\"hovertext\": \"<b>Topic 78</b>:image_smoothing_denoising_inpainti\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3569566286138217, -1.7981194066686894, -1.8045520964468145, -1.8124368041282313, -1.8181170967322218, -1.8278318594538587, -1.8472031399325943, -1.879960922161752, -2.0992811254646977, -2.154205283941868]}, {\"hovertext\": \"<b>Topic 79</b>:construction_visualisation_buildin\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.60614565702801, -1.6500732436276249, -1.799295349240691, -1.9566773338545793, -2.0127651462893863, -2.0249917346012345, -2.1104253739840266, -2.114576110903834, -2.1547666669348886, -2.1610362056881174]}, {\"hovertext\": \"<b>Topic 80</b>:solid_solids_boundary_polyhedral_s\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1244306998150888, -1.5813738708829626, -1.6146380030830463, -1.9171222419732692, -1.9703528122735798, -1.9950188308037102, -2.006948344932241, -2.016211231774204, -2.023337648007814, -2.04222592242672]}, {\"hovertext\": \"<b>Topic 81</b>:electricity_households_heating_sma\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.471906966810253, -1.8969552201660682, -1.9095331025895335, -1.9578566161703792, -1.9739334663369994, -2.0069925085284965, -2.0217300094899997, -2.0778384096324904, -2.0909347339548625, -2.1251634836913933]}, {\"hovertext\": \"<b>Topic 82</b>:fractal_fractals_compression_chaos\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.8977092011218858, -1.3613602492998234, -1.8247210112942878, -1.9422922909027418, -1.971569435868915, -2.0697812594035, -2.098297286159009, -2.153569346958465, -2.1768903888314552, -2.208477060581903]}, {\"hovertext\": \"<b>Topic 83</b>:memories_diary_life_everyday_coupl\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.8114442633404937, -1.9511007137173206, -1.9823872082565754, -1.9859766033929551, -1.9879638716850816, -2.0272091518535835, -2.0553690693990863, -2.0899179634481944, -2.124692133046755, -2.1305390349565916]}, {\"hovertext\": \"<b>Topic 84</b>:civic_civics_infrastructure_citize\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5752975942174803, -1.7941447065054177, -1.88705560980291, -1.9009597805787963, -1.9535272980465423, -1.9793486955988422, -2.0041403494100907, -2.0582197636443773, -2.095174702169399, -2.110927966390076]}, {\"hovertext\": \"<b>Topic 85</b>:xml_query_xquery_queries_twig_sche\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.8558111753686757, -1.491082880242859, -1.5030881064853403, -1.7009970750809702, -1.726254790491171, -1.9247194533614478, -2.016479771091291, -2.039109579366622, -2.0876283206346415, -2.1748225697864876]}, {\"hovertext\": \"<b>Topic 86</b>:moral_dilemmas_judgment_harm_moral\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9474004541618837, -1.4775826842661097, -1.6781423468136214, -1.6810998095097247, -1.7617597203410251, -1.832919944224399, -1.8968434797892175, -1.9733593117687143, -1.9863083459548727, -2.005791310607761]}, {\"hovertext\": \"<b>Topic 87</b>:volume_volumetric_rendering_opacit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3562417743346835, -1.5916296268092454, -1.6900896289322658, -1.7635597193612214, -1.9343515659191044, -2.05491516627539, -2.068405568194901, -2.093841162348432, -2.094806625380268, -2.1285982834935293]}, {\"hovertext\": \"<b>Topic 88</b>:pointing_target_movement_targets_e\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1113647171335057, -1.4527725471310027, -1.6643053003769228, -1.7178442597879289, -1.7951240664805315, -1.8989048081081288, -2.0033754616629627, -2.114189771446345, -2.1143473053419735, -2.160552121624569]}, {\"hovertext\": \"<b>Topic 89</b>:indoor_location_positioning_rfid_f\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2829750463119587, -1.5005180327124676, -1.5839087520468889, -1.6935794416302512, -1.9526306190889209, -1.97103147433492, -2.0345316340210258, -2.076269881015517, -2.0784220655317305, -2.0866772456045606]}, {\"hovertext\": \"<b>Topic 90</b>:diffusion_tensor_tracts_brain_fibe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2807897277489873, -1.3185018901223435, -1.550131092579621, -1.5662332938026067, -1.6285257275728964, -1.647089712219673, -1.6640567281965835, -1.7771766371450437, -2.0618606800833317, -2.1897922853220857]}, {\"hovertext\": \"<b>Topic 91</b>:ontology_schema_ontologies_schemas\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.280160779267633, -1.3637259277685123, -1.3935116236697578, -1.6588699178382322, -1.6856684062874194, -1.8809559253103048, -2.059363183559528, -2.2107551957893126, -2.226840306792811, -2.2720932192610914]}, {\"hovertext\": \"<b>Topic 92</b>:email_emails_mail_inbox_folders_wo\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.8211399492043108, -1.5967452635184236, -1.7079884818722966, -1.9102683662863038, -1.9533626079672946, -2.067126545250919, -2.132152964274895, -2.1883541385841228, -2.208014543225304, -2.2144201601552314]}, {\"hovertext\": \"<b>Topic 93</b>:security_traffic_cyber_intrusion_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.419068642508433, -1.6803000360227003, -1.750720206965058, -1.7718299335144976, -1.8238529665524368, -1.8842004881195829, -2.01206654591494, -2.1407112566943387, -2.1870742018001517, -2.1937106090702594]}, {\"hovertext\": \"<b>Topic 94</b>:outlier_outliers_datasets_distance\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9822831444701173, -1.27959271114734, -1.9339478274327317, -2.0494618653518075, -2.070713560593958, -2.1110769483131717, -2.144893496798317, -2.150727621592199, -2.2078608643170194, -2.2573036905984543]}, {\"hovertext\": \"<b>Topic 95</b>:video_videos_frames_temporal_brows\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.079541593997622, -1.5422652832918342, -1.7357039139777202, -1.8405340815465605, -1.9594709124393763, -2.0224055038656337, -2.1172596308039915, -2.204668290043159, -2.217145264778992, -2.225734234835971]}, {\"hovertext\": \"<b>Topic 96</b>:tree_trees_plant_plants_branches_l\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.408526973567493, -1.4619278228922696, -1.601942712338443, -1.6311355602423814, -1.7163097894289583, -1.8102857563589447, -1.8994408125205722, -2.0000147606133085, -2.0304139112929085, -2.136461415310516]}, {\"hovertext\": \"<b>Topic 97</b>:entity_entities_name_disambiguatio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.042806639729144, -1.4556130573529038, -1.8414192436902521, -1.8547946492139311, -1.8789338077819617, -1.9460705836391945, -1.981898874962719, -2.1110275177147715, -2.116486941357515, -2.134948956178982]}, {\"hovertext\": \"<b>Topic 98</b>:interruptions_interruption_interru\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2030151017883437, -1.3043150454242596, -1.473101440639409, -1.6687639054664065, -1.7648173526370357, -1.9300336917153562, -2.015368916524214, -2.0711972041841906, -2.0851511013600326, -2.1193112903628895]}, {\"hovertext\": \"<b>Topic 99</b>:coordination_interpersonal_synchro\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.324217933607884, -1.6118015257186808, -1.8004018125228056, -1.8309579986895854, -1.8608155164077516, -1.8608340958171337, -1.967663276079127, -2.0609064291118364, -2.0839032802357416, -2.126833822003217]}, {\"hovertext\": \"<b>Topic 100</b>:terrain_rendering_terrains_resolu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.0653828147718425, -1.6017505434650836, -1.6844249996060616, -1.932965264065202, -1.9452561674642292, -1.9716161384305184, -1.9773951337325175, -1.9834575013259166, -2.1526424243862894, -2.1838898735903247]}, {\"hovertext\": \"<b>Topic 101</b>:stream_drift_ensemble_drifting_mi\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.391789986516496, -1.474319056569191, -1.6431977532093787, -1.7457805091619174, -1.8110004028878688, -1.8189041304964852, -1.9600655605522914, -2.0949278549290993, -2.121925236041716, -2.1259222075913398]}, {\"hovertext\": \"<b>Topic 102</b>:cartograms_map_maps_cartographic_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4265119692188155, -1.508393695477444, -1.5803889453311848, -1.6785249782211504, -1.860311073235001, -1.9435638384360914, -2.000617122015518, -2.039136323820639, -2.1055766265875286, -2.1436950850708785]}, {\"hovertext\": \"<b>Topic 103</b>:design_clothing_clothes_designers\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.8034755244471743, -1.8050267108536773, -1.9524190969075992, -1.9633742891677954, -1.9713236265528784, -2.007361277367779, -2.0636284576844792, -2.0646640213594334, -2.124931771589606, -2.170182674255061]}, {\"hovertext\": \"<b>Topic 104</b>:skeleton_skeletons_segmentation_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2087579566180122, -1.4883482985589276, -1.6135135552994018, -1.6694328841339794, -1.710803135794969, -1.9310498233248392, -1.9378335732897738, -1.9673575312024785, -2.158723296044041, -2.159690692029121]}, {\"hovertext\": \"<b>Topic 105</b>:matrix_factorization_nonnegative_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1663258450131924, -1.4302128324583676, -1.6861101072343672, -1.7303248629224437, -1.7510846780339462, -1.9278279387796, -1.9331733908304551, -1.9403516573267943, -1.9614748815821785, -1.9952684112570047]}, {\"hovertext\": \"<b>Topic 106</b>:parallel_compiler_cache_paralleli\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.499552731570671, -1.6121345443216422, -1.6561871482503232, -1.7667068091632205, -1.7775328799967411, -1.7908106498892513, -1.8327486812001763, -2.011361374318621, -2.061509131024352, -2.0844594447092906]}, {\"hovertext\": \"<b>Topic 107</b>:event_events_sentinel_ranking_vis\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.161692698531102, -1.522154608615814, -1.9612112772963441, -1.98585655314398, -1.9999551980614951, -2.0242595692150953, -2.1208136784821394, -2.184417510351577, -2.1936561307901767, -2.205453054703384]}, {\"hovertext\": \"<b>Topic 108</b>:wavelet_wavelets_multiresolution_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.057773990540667, -1.2333781165295343, -1.3423197117908, -1.357474726360907, -1.517472625481012, -1.726981752179377, -1.7290798073151497, -1.7679609698934842, -2.0677826504127355, -2.0905112962717847]}, {\"hovertext\": \"<b>Topic 109</b>:children_participatory_child_tech\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1618679097138656, -1.5714066008936731, -1.5917013556148094, -2.019220803817311, -2.0601981453317264, -2.071351169322387, -2.1020791381201565, -2.129172232920052, -2.14151449578346, -2.1558387780220425]}, {\"hovertext\": \"<b>Topic 110</b>:tabletop_collaboration_touch_grou\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1744527753050722, -1.5313871439592812, -1.6014091348516295, -1.7204653123562814, -1.7620596703785882, -1.790985102437658, -1.8516793432812437, -1.9348483071717804, -1.9674362615828282, -2.028061679085313]}, {\"hovertext\": \"<b>Topic 111</b>:collision_collisions_deformable_r\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9323938043811383, -1.5232704480227104, -1.536364432968193, -1.7186368727899426, -1.9645794832684873, -1.9778028978665712, -1.987746835180473, -1.997099675156862, -2.029322481930174, -2.043093902330194]}, {\"hovertext\": \"<b>Topic 112</b>:chatbot_chatbots_chat_conversatio\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1918334529237036, -1.252552032799104, -1.2882409757510525, -1.6831228144071377, -1.7109318921330154, -1.8593215024235492, -1.934937253610278, -1.9945993491959992, -2.1347903860935906, -2.1802432422263998]}, {\"hovertext\": \"<b>Topic 113</b>:hair_hairs_cloth_hairstyles_furry\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.7057791375586221, -1.4450122421862903, -1.6311029778176827, -1.6424545734992142, -1.751599042924282, -1.7899555260769033, -1.8038711740029667, -1.9205598166317734, -1.9589476291006251, -2.090302257894589]}, {\"hovertext\": \"<b>Topic 114</b>:watermarking_watermark_watermarks\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9990740115397195, -1.1851655519433424, -1.481049240980646, -1.6136840917674549, -1.762057654696444, -1.8603780786765436, -1.8643016875422125, -1.8950248587012934, -1.910866871206783, -1.949440921022083]}, {\"hovertext\": \"<b>Topic 115</b>:surgical_surgery_laparoscopic_min\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3377824012721113, -1.3708319938908269, -1.6553392894609424, -1.6582976380281176, -1.6866394403528735, -1.8171691333726518, -1.845190436187296, -1.8559392419540892, -1.882897070138201, -1.942578514515152]}, {\"hovertext\": \"<b>Topic 116</b>:subspace_clustering_clusters_subs\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9970641156484705, -1.2135615089743728, -1.235673142082124, -1.4159701042410133, -1.9931677353823989, -2.0467480380434653, -2.0489773334481365, -2.1419497314033578, -2.2012382872056433, -2.2014600606463035]}, {\"hovertext\": \"<b>Topic 117</b>:location_recommendation_friends_l\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.4290660311588337, -1.4634992826672373, -1.8174907566498268, -1.8477032985899031, -1.902718436026965, -1.9821233675972783, -1.9898099826170148, -2.0100119925172533, -2.0119840423313193, -2.097085805340057]}, {\"hovertext\": \"<b>Topic 118</b>:parents_parenting_child_life_bere\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3723109094685588, -1.6051500091486453, -1.8959274462730382, -1.8975446876801103, -1.979413794337885, -2.037843081829179, -2.060492778474772, -2.0668507036095796, -2.081160051197438, -2.1317544424438823]}, {\"hovertext\": \"<b>Topic 119</b>:location_privacy_crowdsensing_obf\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.2113608869114942, -1.4490364802985367, -1.5122306066017301, -1.8193335731534952, -1.8667275148577578, -1.8771751904160316, -1.9673951237611507, -2.045908867012904, -2.1166648924167197, -2.1634633420712137]}, {\"hovertext\": \"<b>Topic 120</b>:dance_dancers_dancer_choreographe\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9416387916461635, -1.2065264889547929, -1.6919860670856082, -1.733330918925491, -1.8047178488618436, -1.8511390693396608, -1.9053844799310675, -1.961165942780437, -2.1091346129119364, -2.116854358114353]}, {\"hovertext\": \"<b>Topic 121</b>:line_clipping_algorithms_polygon_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9486389900514527, -0.9837349638746385, -1.6071359032974124, -1.7765251760767462, -1.8115147017541509, -1.8368764876959227, -1.9505231056229295, -1.9523072830657695, -1.9830834934664459, -1.9981139612936385]}, {\"hovertext\": \"<b>Topic 122</b>:occlusion_culling_rendering_occlu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.8871496900478122, -1.2858699432049963, -1.5360021318546329, -1.8077206900369123, -1.811339258540929, -1.872063529389595, -1.8728048984460992, -1.8927050688376899, -1.9685327908076877, -1.9820259285191497]}, {\"hovertext\": \"<b>Topic 123</b>:multimodal_modality_modalities_sp\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.0168896718201492, -1.4759270335022205, -1.6098521367224312, -1.6673798324711075, -1.698996109734902, -1.8426144937744429, -1.8905215670370754, -1.981548523551652, -2.097499580340444, -2.0991292565446535]}, {\"hovertext\": \"<b>Topic 124</b>:religious_dreaming_religion_cultu\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.5751928124253674, -1.6373525929057726, -1.640537082597757, -1.698167699130538, -1.8120588186007218, -1.884887367546476, -1.8854751418261484, -1.9327721991944868, -1.9397425953923328, -1.9967053899927816]}, {\"hovertext\": \"<b>Topic 125</b>:spreadsheet_spreadsheets_web_prog\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.8334352842499214, -1.2523376457002915, -1.7556642408675538, -1.8004241221894492, -2.036093676417415, -2.0832045846760763, -2.134461127865931, -2.1696833212524687, -2.172988966772554, -2.193269068193721]}, {\"hovertext\": \"<b>Topic 126</b>:cleaning_repairing_repair_tuples_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.3144080599653634, -1.4759546832735764, -1.7844031149091304, -1.8777014106749275, -1.9019152600717943, -1.9080598388483332, -2.0344900552736833, -2.1004933238020347, -2.1137277919962947, -2.1228176091318924]}, {\"hovertext\": \"<b>Topic 127</b>:polygons_polygon_hull_algorithm_a\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.1006544192394543, -1.165554512877029, -1.5742036902904544, -1.5820853553141183, -1.6143350049663208, -1.674501407084086, -1.7820386679279354, -1.8972093097790708, -1.9270187702944843, -1.950788034294151]}, {\"hovertext\": \"<b>Topic 128</b>:spatial_languages_across_meaning_\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.0829498579258787, -1.508585006803731, -1.8040139205155032, -1.8319365426793337, -1.8881009385923877, -1.913988889011089, -2.0113533665590517, -2.040790043680609, -2.0518473302476883, -2.0842249711475267]}, {\"hovertext\": \"<b>Topic 129</b>:ubicomp_ubiquitous_design_activit\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.912267900286173, -1.6589590336055144, -1.9316122210990916, -2.0402125657281185, -2.1256049636179912, -2.1276043785832583, -2.142480659436368, -2.1492918590594896, -2.1524747104571866, -2.153556526173765]}, {\"hovertext\": \"<b>Topic 130</b>:meetings_communication_informal_m\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-1.345184606300309, -1.6034750169760579, -1.873999100496886, -1.8763614573149099, -1.9423271714371955, -1.9753835048539221, -1.9854775445433657, -2.009480407321889, -2.0345481345834404, -2.079861731447162]}, {\"hovertext\": \"<b>Topic 131</b>:provenance_lakes_workflows_lake_d\", \"line\": {\"color\": \"black\", \"width\": 1.5}, \"mode\": \"lines+lines\", \"name\": \"\", \"opacity\": 0.1, \"type\": \"scatter\", \"x\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"y\": [-0.9130870673903606, -1.6412770176378197, -1.7126814064698574, -1.7744851780551674, -1.8433115253456687, -1.931112380046953, -2.032353817133697, -2.0346090890195785, -2.0710880771803533, -2.0900758578954153]}],                        {\"height\": 500, \"hoverlabel\": {\"bgcolor\": \"white\", \"font\": {\"family\": \"Rockwell\", \"size\": 16}}, \"showlegend\": false, \"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"white\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"#C8D4E3\", \"linecolor\": \"#C8D4E3\", \"minorgridcolor\": \"#C8D4E3\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"autotypenumbers\": \"strict\", \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"white\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"#C8D4E3\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"white\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"radialaxis\": {\"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"yaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}, \"zaxis\": {\"backgroundcolor\": \"white\", \"gridcolor\": \"#DFE8F3\", \"gridwidth\": 2, \"linecolor\": \"#EBF0F8\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"#EBF0F8\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}, \"bgcolor\": \"white\", \"caxis\": {\"gridcolor\": \"#DFE8F3\", \"linecolor\": \"#A2B1C6\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"#EBF0F8\", \"linecolor\": \"#EBF0F8\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"#EBF0F8\", \"zerolinewidth\": 2}}}, \"title\": {\"font\": {\"color\": \"Black\", \"size\": 22}, \"text\": \"<b>Term score decline per Topic</b>\", \"x\": 0.5, \"xanchor\": \"center\", \"y\": 0.9, \"yanchor\": \"top\"}, \"width\": 800, \"xaxis\": {\"dtick\": 2, \"range\": [0, 10], \"tick0\": 1, \"title\": {\"text\": \"Term Rank\"}}, \"yaxis\": {\"title\": {\"text\": \"c-TF-IDF score (log scale)\"}}},                        {\"responsive\": true}                    ).then(function(){\n",
              "                            \n",
              "var gd = document.getElementById('9a157421-cd89-4011-8a32-01ee3cf25bb7');\n",
              "var x = new MutationObserver(function (mutations, observer) {{\n",
              "        var display = window.getComputedStyle(gd).display;\n",
              "        if (!display || display === 'none') {{\n",
              "            console.log([gd, 'removed!']);\n",
              "            Plotly.purge(gd);\n",
              "            observer.disconnect();\n",
              "        }}\n",
              "}});\n",
              "\n",
              "// Listen for the removal of the full notebook cells\n",
              "var notebookContainer = gd.closest('#notebook-container');\n",
              "if (notebookContainer) {{\n",
              "    x.observe(notebookContainer, {childList: true});\n",
              "}}\n",
              "\n",
              "// Listen for the clearing of the current output cell\n",
              "var outputEl = gd.closest('.output');\n",
              "if (outputEl) {{\n",
              "    x.observe(outputEl, {childList: true});\n",
              "}}\n",
              "\n",
              "                        })                };                            </script>        </div>\n",
              "</body>\n",
              "</html>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2SXHbOz_-Ly"
      },
      "source": [
        "reduce_model2.save(\"final_model\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mK-lXj4e_9-h"
      },
      "source": [
        "repre_docs = reduce_model2.get_representative_docs()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M7xHrctS_-OI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4790dde3-22c3-4349-cfe9-cf6818472d6f"
      },
      "source": [
        "repre_docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: ['Target Temperature Driven Dynamic Flame Animation.[SEP]Fire/flame plays an important role in virtual environment. Controlling the flame behavior in an intuitive yet precise manner remains a challenging open problem. In this paper, a target temperature driven simulation method is proposed to control flame animation. The diverse descriptions of target flame are unified by temperature field. An adaptive control force is presented to control the degree of target-driven changing over the temperature field. A bidirectional iterative method is proposed to subdivide the final goal into a plurality of intermediate targets. We take geometric model, image, and temperature field as target flames to test our method. Experimental results show that this method allows complex flame animations to be controllably generated with very little additional cost compared to ordinary flow simulations.',\n",
              "  'Simulation and interaction of fluid dynamics.[SEP]In the fluid simulation, the fluids and their surroundings may greatly change properties such as shape and temperature simultaneously, and different surroundings would characterize different interactions, which would change the shape and motion of the fluids in different ways. On the other hand, interactions among fluid mixtures of different kinds would generate more comprehensive behavior. To investigate the interaction behavior in physically based simulation of fluids, it is of importance to build physically correct models to represent the varying interactions between fluids and the environments, as well as interactions among the mixtures. In this paper, we will make a simple review of the interactions, and focus on those most interesting to us, and model them with various physical solutions. In particular, more detail will be given on the simulation of miscible and immiscible binary mixtures. In some of the methods, it is advantageous to be taken with the graphics processing unit (GPU) to achieve real-time computation for middle-scale simulation.',\n",
              "  'Visual simulation of smoke.[SEP]In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.',\n",
              "  'Construction of Vector Field Hierarchies.[SEP]Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.',\n",
              "  'Segmentation of Discrete Vector Fields.[SEP]In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement',\n",
              "  'PLIC: Briding the Gap Between Streamlines and LIC.[SEP]This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.',\n",
              "  'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow.[SEP]Numerical simulation of scramjet asymmetric nozzle flow is carried out to visualize and investigate the effects of interaction between engine exhaust and hypersonic external flow. The Single Expansion Ramp Nozzle (SERN) configuration studied here consists of flat ramp and a cowl with different combinations of ramp angle and cowl geometry. UsingPARAS 3D, simulations are performed for a free stream Mach number of 6.5 that constitutes the external flow around the vehicle. Appropriate specific heats ratio has been simulated for the jet and free stream flow. External shock wave due to jet plume interaction with free stream flow, the internal barrel shock wave and the shear layer emanating from the cowl trailing edge and sidewalls are well captured. Wall static pressure distribution on the nozzle ramp for different nozzle expansion angles has been computed for both with and without side fence. Axial thrust and normal force have been evaluated by integrating the wall static pressure. Effect of cowl length variation and side fence on the SERN performance has also been studied and found to be quite significant. Based on this study, an optimum ramp angle at which the SERN generates maximum axial thrust is obtained. SERN angle of 20° was found to be optimum when the flight axis coincides with nozzle axis.',\n",
              "  'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump.[SEP]Comparison between numerical simulation and experimental results for unsteady flow field in a radial diffuser pump is presented for the design operating point. The numerical result is obtained by solving three-dimensional, unsteady Reynolds-averaged Navier-Stokes equations by the commercial CFD code CFX-10 withk-ω based shear stress transport turbulence model. Two-dimensional PIV measurements are conducted to acquire the experiment result. The phase-averaged velocity and turbulent kinetic energy fields are compared in detail between the results by the two methods in the impeller, diffuser and return channel regions. The qualitative comparison between CFD and PIV results is quite good in the phase-averaged velocity field. Although the turbulence level by PIV is higher than that by CFD generally, the main turbulence features are nearly the same. Furthermore, the blade orientation effect and other associated unsteady phenomena are also examined, in order to enhance the understanding on impeller-diffuser interaction in a radial diffuser pump.',\n",
              "  'Characteristic flow phenomena on a tee-branch pipe.[SEP]Osao, A. et al., Advanced Materials Research, 33-37 (2008), 1037–1042.'],\n",
              " 1: ['The role of word-word co-occurrence in word learning.[SEP]A growing body of research on early word learning suggests that learners gather word-object co-occurrence statistics across learning situations. Here we test a new mechanism whereby learners are also sensitive to word-word co-occurrence statistics. Indeed, we find that participants can infer the likely referent of a novel word based on its co-occurrence with other words, in a way that mimics a machine learning algorithm dubbed ‘zero-shot learning’. We suggest that the interaction between referential and distributional regularities can bring robustness to the process of word acquisition',\n",
              "  'Interlocutors preserve complexity in language.[SEP]Why do languages change? One possibility is they evolve in response to two competing pressures: (1) to be easily learned, and (2) to be effective for communication. In a number of domains, variation in the world’s natural languages appears to be accounted for by different but near-optimal tradeoffs between these pressures. Models of these evolutionary processes have used transmission chain paradigms in which errors of learning by one agent become the input for the subsequent generation. However, a critical feature of human language is that children do not learn in isolation. Rather, they learn in communicative interactions with caregivers who draw inferences from their errorful productions to their intended interests. In a set of iterated reproduction experiments, we show that this supportive context can have a powerful stabilizing role in the development of artificial patterned systems, allowing them to achieve higher levels of complexity than they would by vertical transmission alone while retaining equivalent transmission accuracies.',\n",
              "  'Linguistic Structure Evolves to Match Meaning Structure.[SEP]Quantitative analysis has usually highlighted the random nature of linguistic forms (Zipf, 1949). We zoom in on three structured samples of language (numerals; playing cards; and a corpus of artificial languages from Kirby, Cornish & Smith 2008) to quantitative explore and illustrate the idea that linguistic forms are nonrandom in that their structure reflects the structure of the meanings they convey. A novel methodology returns frequency spectra showing the distribution of character n-gram frequencies in our language samples. These spectra, purely derived from linguistic form, clearly reflect the quantitative structure of the underlying meaning spaces, as verified with a new information theoretical metric of compositionality. Moreover, analyses of a diachronic corpus of languages show that linguistic structure gradually adapts to match the structure of meanings over cultural transmission.',\n",
              "  'Eye-tracking situated language comprehension: Immediate actor gaze versus recent action events.[SEP]Visual-world eye-tracking findings suggest visual cues rapidly affect spoken sentence comprehension. When participants saw an actor perform an action and then listened to a related sentence (NP1-VERB-ADV-NP2), they preferentially inspected the “recent” over another “future” event target, and this even when future events were much more frequent. The current studies assessed to which extent this recent-event preference is modulated by another situation-immediate cue to the future event target (an actor’s gaze). Half of the sentences referenced a future event, and the experimenter performed one “recent” action before and one “future” action after the sentence. On 50% of the trials, he gazed at the future target object during the verb (Experiment 1) or at verb onset (Experiment 2). Results showed that gaze and future tense together cued attention to the future target; however gaze did not completely override the recent event preference.',\n",
              "  'Response direction and sentence-tense compatibility effects: An eye tracking study.[SEP]Recent evidence shows tense-response compatibility effects only when the task relates to sentence tense (Ulrich & Maienborn, 2010). In two eye-tracking experiments, we investigated tense-response compatibility effects. In our first experiment (E1, where sentence tense was relevant to the task) we found compatibility effects at the beginning of the sentence (e.g., Yesterday versus Tomorrow), which shifted to interference effects by sentence end. Overall, we also found compatibility effects in response times, replicating Ulrich and Maienborn. Both compatibility effects in Experiment 1 (E1) were stronger for low- compared to high-WM readers. In Experiment 2 (E2, where tense was irrelevant), we found compatibility effects for high-WM readers, but only in early reading measures. These results suggest that compatibility effects are weaker depending on the task, but not eliminated; an implication which may help refine a strict view of embodied cognition.',\n",
              "  \"Visual attention during spatial language comprehension: Reference alone isn't enough.[SEP]When people listen to sentences referring to objects and events in visual context, their visual attention to objects is closely time-locked to words in the unfolding utterance. How precisely people deploy attention during situated language understanding and in verifying (spatial) utterances is, however, unclear. A ‘visual world’ hypothesis suggests that we look at what is mentioned (Tanenhaus et al., 1995) and anticipate likely referents based on linguistic cues (Altmann & Kamide, 1999). In spatial language research, in contrast, the Attention Vector Sum model (Regier & Carlson, 2001) predicts that in order to process a sentence such as “The plant is above the clock”, attention must shift from the clock to the plant. An eye-tracking study examined whether gaze pattern during comprehension of spatial descriptions support the visual world or the Attention Vector Sum account. Analyses of eye movements indicate that we need both accounts to accommodate the findings.\",\n",
              "  \"Monsieur, azonnal k[SEP]Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems. This paper proposes a new way to compensate for such resource-scarce languages, based on the fact that most languages share a common vocabulary. Concretely, our approach leverages a family of languages closely related to the speaker's native language to construct translations in a coherent mix of these languages. Experimental results indicate that these translations can be easily understood, being also a useful aid for users who are not proficient in foreign languages. Therefore this work significantly contributes to HCI in two ways: it establishes a language that can improve how applications communicate to their users, and it reports insights on the user acceptance towards the method.\",\n",
              "  'Effects of machine translation on collaborative work.[SEP]Even though multilingual communities that use machine translation to overcome language barriers are increasing, we still lack a complete understanding of how machine translation affects communication. In this study, eight pairs from three different language communities--China, Korea, and Japan--worked on referential tasks in their shared second language (English) and in their native languages using a machine translation embedded chat system. Drawing upon prior research, we predicted differences in conversational efficiency and content, and in the shortening of referring expressions over trials. Quantitative results combined with interview data show that lexical entrainment was disrupted in machine translation-mediated communication because echoing is disrupted by asymmetries in machine translations. In addition, the process of shortening referring expressions is also disrupted because the translations do not translate the same terms consistently throughout the conversation. To support natural referring behavior in machine translation-mediated communication, we need to resolve asymmetries and inconsistencies caused by machine translations.',\n",
              "  \"Machine translation vs. common language: effects on idea exchange in cross-lingual groups.[SEP]Diversity among members of international teams can be a valuable source of novel ideas. However, to reap these benefits, groups need to overcome communication barriers that stem from differences in members' native languages. We compare two strategies for overcoming these barriers: the use of English as a common language, and the use of machine translation (MT) tools that allow each person to communicate in his or her own native language. Dyads consisting of one English-speaking American and one native Mandarin-speaking Chinese participant exchanged ideas to perform brainstorming tasks, either through English or using MT. We found that MT helped the non-native English speakers produce ideas but that both native and non-native English speakers viewed MT-mediated messages as less comprehensible than English messages. The findings suggest it can be effective to support cross-lingual communication with asymmetric design, using MT technology to help people produce messages in their native languages, while leaving incoming messages untranslated and leveraging people's second language proficiency for comprehension.\"],\n",
              " 2: ['Patterns for visualization evaluation.[SEP]We propose a patterns-based approach to evaluating data visualization: a set of general and reusable solutions to commonly occurring problems in evaluating tools, techniques, and systems for visual sensemaking. Patterns have had significant impact in a wide array of disciplines, particularly software engineering, and we believe that they provide a powerful lens for looking at visualization evaluation by offering practical, tried-and-tested tips and tricks that can be adopted immediately. The 12 patterns presented here have also been added to a freely editable Wiki repository. The motivation for creating this evaluation pattern language is to (a) disseminate hard-won experience on visualization evaluation to researchers and practitioners alike; to (b) provide a standardized vocabulary for designing visualization evaluation; and to (c) invite the community to add new evaluation patterns to a growing repository of patterns.',\n",
              "  \"Metrics for measuring human interaction with interactive visualizations for information analysis.[SEP]There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.\",\n",
              "  'Learning-based evaluation of visual analytic systems.[SEP]Evaluation in visualization remains a difficult problem because of the unique constraints and opportunities inherent to visualization use. While many potentially useful methodologies have been proposed, there remain significant gaps in assessing the value of the open-ended exploration and complex task-solving that the visualization community holds up as an ideal. In this paper, we propose a methodology to quantitatively evaluate a visual analytics (VA) system based on measuring what is learned by its users as the users reapply the knowledge to a different problem or domain. The motivation for this methodology is based on the observation that the ultimate goal of a user of a VA system is to gain knowledge of and expertise with the dataset, task, or tool itself. We propose a framework for describing and measuring knowledge gain in the analytical process based on these three types of knowledge and discuss considerations for evaluating each. We propose that through careful design of tests that examine how well participants can reapply knowledge learned from using a VA system, the utility of the visualization can be more directly assessed.',\n",
              "  'Text visualization techniques: Taxonomy, visual survey, and community insights.[SEP]Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.',\n",
              "  'Visualizing the Performance of Computational Linguistics Algorithms.[SEP]We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components',\n",
              "  'Quantity estimation in visualizations of tagged text.[SEP]A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.',\n",
              "  'MetaLDA: A Topic Model that Efficiently Incorporates Meta Information.[SEP]Besides the text content, documents and their associated words usually come with rich sets of meta information, such as categories of documents and semantic/syntactic features of words, like those encoded in word embeddings. Incorporating such meta information directly into the generative process of topic models can improve modelling accuracy and topic quality, especially in the case where the word-occurrence information in the training data is insufficient. In this paper, we present a topic model, called MetaLDA, which is able to leverage either document or word meta information, or both of them jointly. With two data argumentation techniques, we can derive an efficient Gibbs sampling algorithm, which benefits from the fully local conjugacy of the model. Moreover, the algorithm is favoured by the sparsity of the meta information. Extensive experiments on several real world datasets demonstrate that our model achieves comparable or improved performance in terms of both perplexity and topic quality, particularly in handling sparse texts. In addition, compared with other models using meta information, our model runs significantly faster.',\n",
              "  'Discriminatively Enhanced Topic Models.[SEP]This paper proposes a space-efficient, discriminatively enhanced topic model: a V structured topic model with an embedded log-linear component. The discriminative log-linear component reduces the number of parameters to be learnt while outperforming baseline generative models. At the same time, the explanatory power of the generative component is not compromised. We establish its superiority over a purely generative model by applying it to two different ranking tasks: (a) In the first task, we look at the problem of proposing alternative citations given textual and bibliographic evidence. We solve it as a ranking problem in itself and as a platform for further qualitative analysis of convergence of scientific phenomenon. (b) In the second task we address the problem of ranking potential email recipients based on email content and sender information.',\n",
              "  'Stochastic collapsed variational Bayesian inference for latent Dirichlet allocation.[SEP]There has been an explosion in the amount of digital text information available in recent years, leading to challenges of scale for traditional inference algorithms for topic models. Recent advances in stochastic variational inference algorithms for latent Dirichlet allocation (LDA) have made it feasible to learn topic models on very large-scale corpora, but these methods do not currently take full advantage of the collapsed representation of the model. We propose a stochastic algorithm for collapsed variational Bayesian inference for LDA, which is simpler and more efficient than the state of the art method. In experiments on large-scale text corpora, the algorithm was found to converge faster and often to a better solution than previous methods. Human-subject experiments also demonstrated that the method can learn coherent topics in seconds on small corpora, facilitating the use of topic models in interactive document analysis software.'],\n",
              " 3: ['Smart Pacing for Effective Online Ad Campaign Optimization.[SEP]In targeted online advertising, advertisers look for maximizing campaign performance under delivery constraint within budget schedule. Most of the advertisers typically prefer to impose the delivery constraint to spend budget smoothly over the time in order to reach a wider range of audiences and have a sustainable impact. Since lots of impressions are traded through public auctions for online advertising today, the liquidity makes price elasticity and bid landscape between demand and supply change quite dynamically. Therefore, it is challenging to perform smooth pacing control and maximize campaign performance simultaneously. In this paper, we propose a smart pacing approach in which the delivery pace of each campaign is learned from both offline and online data to achieve smooth delivery and optimal performance goals. The implementation of the proposed approach in a real DSP system is also presented. Experimental evaluations on both real online ad campaigns and offline simulations show that our approach can effectively improve campaign performance and achieve delivery goals.',\n",
              "  'From 0.5 Million to 2.5 Million: Efficiently Scaling up Real-Time Bidding.[SEP]Real-Time Bidding allows an advertiser to purchase media inventory through an auction system that unfolds in the order of milliseconds. Media providers are increasingly being integrated into such programmatic buying platforms. It is typical for a contemporary Real-Time Bidding system to receive millions of bid requests per second at peak time, and have a large portion of these to be irrelevant to any advertiser. Meanwhile, given a valuable bid request, tens of thousands of advertisements might be qualified for scoring. We present our efforts in building selection models for both bid requests and advertisements to handle this scalability challenge. Our bid request model treats the system load as a hierarchical resource allocation problem and directs traffic based on the estimated quality of bid requests. Next, our exploration/exploitation advertisement model selects a limited number of qualified advertisements for thorough scoring based on the expected value of a bid request to the advertiser given its features. Our combined bid request and advertisement model is able to win more auctions and bring more value to clients by stabilizing the bidding pipeline. We empirically show that our deployed system is capable of handling 5x more bid requests.',\n",
              "  \"An Engagement-Based Customer Lifetime Value System for E-commerce.[SEP]A comprehensive understanding of individual customer value is crucial to any successful customer relationship management strategy. It is also the key to building products for long-term value returns. Modeling customer lifetime value (CLTV) can be fraught with technical difficulties, however, due to both the noisy nature of user-level behavior and the potentially large customer base. Here we describe a new CLTV system that solves these problems. This was built at Groupon, a large global e-commerce company, where confronting the unique challenges of local commerce means quickly iterating on new products and the optimal inventory to appeal to a wide and diverse audience. Given current purchaser frequency we need a faster way to determine the health of individual customers, and given finite resources we need to know where to focus our energy. Our CLTV system predicts future value on an individual user basis with a random forest model which includes features that account for nearly all aspects of each customer's relationship with our platform. This feature set includes those quantifying engagement via email and our mobile app, which give us the ability to predict changes in value far more quickly than models based solely on purchase behavior. We further model different customer types, such as one-time buyers and power users, separately so as to allow for different feature weights and to enhance the interpretability of our results. Additionally, we developed an economical scoring framework wherein we re-score a user when any trigger events occur and apply a decay function otherwise, to enable frequent scoring of a large customer base with a complex model. This system is deployed, predicting the value of hundreds of millions of users on a daily cadence, and is actively being used across our products and business initiatives.\"],\n",
              " 4: [\"Discrete Overlapping Community Detection with Pseudo Supervision.[SEP]Community detection is of significant importance in understanding the structures and functions of networks. Recently, overlapping community detection has drawn much attention due to the ubiquity of overlapping community structures in real-world networks. Nonnegative matrix factorization (NMF), as an emerging standard framework, has been widely employed for overlapping community detection, which obtains nodes' soft community memberships by factorizing the adjacency matrix into low-rank factor matrices. However, in order to determine the ultimate community memberships, we have to post-process the real-valued factor matrix by manually specifying a threshold on it, which is undoubtedly a difficult task. Even worse, a unified threshold may not be suitable for all nodes. To circumvent the cumbersome post-processing step, we propose a novel discrete overlapping community detection approach, i.e., Discrete Nonnegative Matrix Factorization (DNMF), which seeks for a discrete (binary) community membership matrix directly. Thus DNMF is able to assign explicit community memberships to nodes without post-processing. Moreover, DNMF incorporates a pseudo supervision module into it to exploit the discriminative information in an unsupervised manner, which further enhances its robustness. We thoroughly evaluate DNMF using both synthetic and real-world networks. Experiments show that DNMF has the ability to outperform state-of-the-art baseline approaches.\",\n",
              "  'Communities in Preference Networks: Refined Axioms and Beyond.[SEP]Borgs et al. [2016] investigated essential requirements for communities in preference networks. They defined six axioms on community functions, i.e., community detection rules. Though having elegant properties, the practicality of this axiomsystem is compromised by the intractability of checking twocritical axioms, so no nontrivial consistent community functionwas reported in [Borgs et al., 2016]. By adapting the two axioms in a natural way, we propose two new axioms that are efficiently-checkable. We show that most of the desirable properties of the original axiom system are preserved. More importantly, the new axioms provide a general approach to constructing consistent community functions. We further find a natural consistent community function that is also enumerable and samplable, answering an open problem in the literature.',\n",
              "  'Joint Community and Structural Hole Spanner Detection via Harmonic Modularity.[SEP]Detecting communities (or modular structures) and structural hole spanners, the nodes bridging different communities in a network, are two essential tasks in the realm of network analytics. Due to the topological nature of communities and structural hole spanners, these two tasks are naturally tangled with each other, while there has been little synergy between them. In this paper, we propose a novel harmonic modularity method to tackle both tasks simultaneously. Specifically, we apply a harmonic function to measure the smoothness of community structure and to obtain the community indicator. We then investigate the sparsity level of the interactions between communities, with particular emphasis on the nodes connecting to multiple communities, to discriminate the indicator of SH spanners and assist the community guidance. Extensive experiments on real-world networks demonstrate that our proposed method outperforms several state-of-the-art methods in the community detection task and also in the SH spanner identification task (even the methods that require the supervised community information). Furthermore, by removing the SH spanners spotted by our method, we show that the quality of other community detection methods can be further improved.',\n",
              "  \"Gragnostics: Fast, Interpretable Features for Comparing Graphs.[SEP]Many analytical tasks, such as social network analysis, depend on comparing graphs. Existing methods are slow, or can be difficult to understand. To address these challenges, this paper proposes gragnostics, a set of 10 fast, layperson-understandable graph-level features. Each can be computed in linear time. To evaluate the ability of these features to discriminate different topologies and types of graphs, this paper compares a machine learning classifier using gragnostics to alternative classifiers, and the evaluation finds that the gragnostics classifier achieves higher performance. To evaluate gragnostics' utility in interactive visualization tools, this paper presents Chiron, a graph visualization tool that enables users to explore the subgraphs of a larger graph. Example usage scenarios of Chiron demonstrate that using gragnostics in a rank-by-feature framework can be effective for finding interesting subgraphs.\",\n",
              "  'Interactively Uncluttering Node Overlaps for Network Visualization.[SEP]Visual interaction with networks have been promising in the sense that we can successfully elucidate underlying relationships hidden behind complicated mutual relationships such as co-authorship networks, product co purchasing networks, and scale-free social networks. However, it is still burdensome to alleviate visual clutter arising from overlaps among node labels especially in such interactive environments as the networks become dense in terms of the topological connectivity. This paper presents a novel approach for dynamically rearranging the network layouts by incorporating centroidal Voronoi tessellation for better readability of node labels. Our idea is to smoothly transform the network layouts obtained through the conventional force-directed algorithm to that produced by the centroidal Voronoi tessellation to seek a plausible compromise between them. We also incorporated the Chebyshev distance metric into the centroidal Voronoi tessellation while adaptively adjusting the aspect ratios of the Voronoi cells so that we can place rectangular labels compactly over the network nodes. Finally, we applied the proposed approach to relatively large networks to demonstrate the feasibility of our formulation especially in interactive environments.',\n",
              "  'Multilayer graph edge bundling.[SEP]Many real world information can be represented by a graph with a set of nodes interconnected with each other by multiple type of relations called edge layers (e.g., social network, biological data). Edge bundling techniques have been proposed to solve cluttering issue for standard graphs while few efforts were done to deal with the similar issue for multilayer graphs. In multilayer graphs scenario, not only the clutter induced by large amount of edges is a problem but also the fact that different type of edges can overlap each other making useless the final visualization. In this paper we introduce a new multilayer graph edge bundling technique that firstly produces a preliminary edge bundling independently of the different edge layers and then deals with the specificity of multilayer graphs where more than one type of edges can be routed on the same bundle. The proposed visualization is tested on a real world case study and the outcomes point out the ability of our proposal to discover patterns present in the data.',\n",
              "  \"Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks.[SEP]We introduce MultiPiles, a visualization to explore time‐series of dense, weighted networks. MultiPiles is based on the physical analogy of piling adjacency matrices, each one representing a single temporal snapshot. Common interfaces for visualizing dynamic networks use techniques such as: flipping/animation; small multiples; or summary views in isolation. Our proposed ‘piling’ metaphor presents a hybrid of these techniques, leveraging each one's advantages, as well as offering the ability to scale to networks with hundreds of temporal snapshots. While the MultiPiles technique is applicable to many domains, our prototype was initially designed to help neuroscientists investigate changes in brain connectivity networks over several hundred snapshots. The piling metaphor and associated interaction and visual encodings allowed neuroscientists to explore their data, prior to a statistical analysis. They detected high‐level temporal patterns in individual networks and this helped them to formulate and reject several hypotheses.\",\n",
              "  'Edge-stacked Timelines for Visualizing Dynamic Weighted Digraphs.[SEP]We investigate the problem of visually encoding time-varying weighted digraphs to provide an overview about dynamic graphs. Starting from a rough overview of dynamic relational data an analyst can subsequently explore the data in more detail to gain further insights. To reach this goal we first map the graph vertices in the graph sequence to a common horizontal axis. Edges between vertices are represented as stacked horizontal and color-coded links starting and ending at their corresponding start and end vertex positions. The direction of each edge is indicated by placing it either above or below the horizontal vertex line. We attach a vertically aligned timeline to each link to show the weight evolution for those links. The order of the vertices and stacked edges is important for the readability of the visualization. We support interactive reordering and sorting in the vertex, edge, and timeline representations. The usefulness of our edge-stacked timelines is illustrated in a case st',\n",
              "  'Interactive Time-Series of Measures for Exploring Dynamic Networks.[SEP]We present MeasureFlow, an interface to visually and interactively explore dynamic networks through time-series of network measures such as link number, graph density, or node activation. When networks contain many time steps, become large and more dense, or contain high frequencies of change, traditional visualizations that focus on network topology, such as animations or small multiples, fail to provide adequate overviews and thus fail to guide the analyst towards interesting time points and periods. MeasureFlow presents a complementary approach that relies on visualizing time-series of common network measures to provide a detailed yet comprehensive overview of when changes are happening and which network measures they involve. As dynamic networks undergo changes of varying rates and characteristics, network measures provide important hints on the pace and nature of their evolution and can guide an analysts in their exploration; based on a set of interactive and signal-processing methods, MeasureFlow allows an analyst to select and navigate periods of interest in the network. We demonstrate MeasureFlow through case studies with real-world data.',\n",
              "  'Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees.[SEP]Finding dense subgraphs is an important graph-mining task with many applications. Given that the direct optimization of edge density is not meaningful, as even a single edge achieves maximum density, research has focused on optimizing alternative density functions. A very popular among such functions is the average degree, whose maximization leads to the well-known densest-subgraph notion. Surprisingly enough, however, densest subgraphs are typically large graphs, with small edge density and large diameter.',\n",
              "  'Graph-Structured Sparse Optimization for Connected Subgraph Detection.[SEP]Structured sparse optimization is an important and challenging problem for analyzing high-dimensional data in a variety of applications such as bioinformatics, medical imaging, social networks, and astronomy. Although a number of structured sparsity models have been explored, such as trees, groups, clusters, and paths, connected subgraphs have been rarely explored in the current literature. One of the main technical challenges is that there is no structured sparsity-inducing norm that can directly model the space of connected subgraphs, and there is no exact implementation of a projection oracle for connected subgraphs due to its NP-hardness. In this paper, we explore efficient approximate projection oracles for connected subgraphs, and propose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to optimize a generic nonlinear objective function subject to connectivity constraint on the support of the variables. Our proposed algorithms enjoy strong guarantees analogous to several current methods for sparsity-constrained optimization, such as Projected Gradient Descent (PGD), Approximate Model Iterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit (GHTP) with respect to convergence rate and approximation accuracy. We apply our proposed algorithms to optimize several well-known graph scan statistics in several applications of connected subgraph detection as a case study, and the experimental results demonstrate that our proposed algorithms outperform state-of-the-art methods.',\n",
              "  'Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling.[SEP]This paper studies the problem of efficiently computing a maximum independent set from a large graph, a fundamental problem in graph analysis. Due to the hardness results of computing an exact maximum independent set or an approximate maximum independent set with accuracy guarantee, the existing algorithms resort to heuristic techniques for approximately computing a maximum independent set with good performance in practice but no accuracy guarantee theoretically. Observing that the existing techniques have various limits, in this paper, we aim to develop efficient algorithms (with linear or near-linear time complexity) that can generate a high-quality (large-size) independent set from a graph in practice. In particular, firstly we develop a Reducing-Peeling framework which iteratively reduces the graph size by applying reduction rules on vertices with very low degrees (Reducing) and temporarily removing the vertex with the highest degree (Peeling) if the reduction rules cannot be applied. Secondly, based on our framework we design two baseline algorithms, BDOne and BDTwo, by utilizing the existing reduction rules for handling degree-one and degree-two vertices, respectively. Both algorithms can generate higher-quality (larger-size) independent sets than the existing algorithms. Thirdly, we propose a linear-time algorithm, LinearTime, and a near-linear time algorithm, NearLinear, by designing new reduction rules and developing techniques for efficiently and incrementally applying reduction rules. In practice, LinearTime takes similar time and space to BDOne but computes a higher quality independent set, similar in size to that of an independent set generated by BDTwo. Moreover, in practice NearLinear has a good chance to generate a maximum independent set and it often generates near-maximum independent sets. Fourthly, we extend our techniques to accelerate the existing iterated local search algorithms. Extensive empirical studies show that all our algorithms output much larger independent sets than the existing linear-time algorithms while having a similar running time, as well as achieve significant speedup against the existing iterated local search algorithms.',\n",
              "  \"Quegel: A General-Purpose System for Querying Big Graphs.[SEP]Inspired by Google's Pregel, many distributed graph processing systems have been developed recently to process big graphs. These systems expose a vertex-centric programming interface to users, where a programmer thinks like a vertex when designing parallel graph algorithms. However, existing systems are designed for tasks where most vertices in a graph participate in the computation, and they are not suitable for processing light-workload graph queries which only access a small portion of vertices. This is because their programming model can seriously under-utilize the resources in a cluster for processing graph queries. In this demonstration, we introduce a general-purpose system for querying big graphs, called Quegel, which treats queries as first-class citizens in the design of its computing model. Quegel adopts a novel superstep-sharing execution model to overcome the weaknesses of existing systems. We demonstrate it is user-friendly to write parallel graph-querying programs with Quegel's interface; and we also show that Quegel is able to achieve real-time response time in various applications, including the two applications that we plan to demonstrate: point-to-point shortest-path queries and XML keyword search.\",\n",
              "  'DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine.[SEP]Subgraph enumeration is important for many applications such as subgraph frequencies, network motif discovery, graphlet kernel computation, and studying the evolution of social networks. Most earlier work on subgraph enumeration assumes that graphs are resident in memory, which results in serious scalability problems. Recently, efforts to enumerate all subgraphs in a large-scale graph have seemed to enjoy some success by partitioning the data graph and exploiting the distributed frameworks such as MapReduce and distributed graph engines. However, we notice that all existing distributed approaches have serious performance problems for subgraph enumeration due to the explosive number of partial results. In this paper, we design and implement a disk-based, single machine parallel subgraph enumeration solution called DualSim that can handle massive graphs without maintaining exponential numbers of partial results. Specifically, we propose a novel concept of the dual approach for subgraph enumeration. The dual approach swaps the roles of the data graph and the query graph. Specifically, instead of fixing the matching order in the query and then matching data vertices, it fixes the data vertices by fixing a set of disk pages and then finds all subgraph matchings in these pages. This enables us to significantly reduce the number of disk reads. We conduct extensive experiments with various real-world graphs to systematically demonstrate the superiority of DualSim over state-of-the-art distributed subgraph enumeration methods. DualSim outperforms the state-of-the-art methods by up to orders of magnitude, while they fail for many queries due to explosive intermediate results.',\n",
              "  'GTS: A Fast and Scalable Graph Processing Method based on Streaming Topology to GPUs.[SEP]A fast and scalable graph processing method becomes increasingly important as graphs become popular in a wide range of applications and their sizes are growing rapidly. Most of distributed graph processing methods require a lot of machines equipped with a total of thousands of CPU cores and a few terabyte main memory for handling billion-scale graphs. Meanwhile, GPUs could be a promising direction toward fast processing of large-scale graphs by exploiting thousands of GPU cores. All of the existing methods using GPUs, however, fail to process large-scale graphs that do not fit in main memory of a single machine. Here, we propose a fast and scalable graph processing method GTS that handles even RMAT32 (64 billion edges) very efficiently only by using a single machine. The proposed method stores graphs in PCI-E SSDs and executes a graph algorithm using thousands of GPU cores while streaming topology data of graphs to GPUs via PCI-E interface. GTS is fast due to no communication overhead and scalable due to no data duplication from graph partitioning among machines. Through extensive experiments, we show that GTS consistently and significantly outperforms the major distributed graph processing methods, GraphX, Giraph, and PowerGraph, and the state-of-the-art GPU-based method TOTEM.',\n",
              "  'Unsupervised Differentiable Multi-aspect Network Embedding.[SEP]Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end differentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.',\n",
              "  \"DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph Classification.[SEP]Graph data widely exist in many high-impact applications. Inspired by the success of deep learning in grid-structured data, graph neural network models have been proposed to learn powerful node-level or graph-level representation. However, most of the existing graph neural networks suffer from the following limitations: (1) there is limited analysis regarding the graph convolution properties, such as seed-oriented, degree-aware and order-free; (2) the node's degreespecific graph structure is not explicitly expressed in graph convolution for distinguishing structure-aware node neighborhoods; (3) the theoretical explanation regarding the graph-level pooling schemes is unclear.\",\n",
              "  'AM-GCN: Adaptive Multi-channel Graph Convolutional Networks.[SEP]Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytics tasks on graph and network data. However, some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph with rich information. In this paper, we first present an experimental investigation. Surprisingly, our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks, since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an adaptive multi-channel graph convolutional networks for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features, topological structures, and their combinations simultaneously, and use the attention mechanism to learn adaptive importance weights of the embeddings. Our extensive experiments on benchmark data sets clearly show that AM-GCN extracts the most correlated information from both node features and topological structures substantially, and improves the classification accuracy with a clear margin.',\n",
              "  'Consistency Meets Inconsistency: A Unified Graph Learning Framework for Multi-view Clustering.[SEP]Graph Learning has emerged as a promising technique for multi-view clustering, and has recently attracted lots of attention due to its capability of adaptively learning a unified and probably better graph from multiple views. However, the existing multi-view graph learning methods mostly focus on the multi-view consistency, but neglect the potential multi-view inconsistency (which may be incurred by noise, corruptions, or view-specific characteristics). To address this, this paper presents a new graph learning-based multi-view clustering approach, which for the first time, to our knowledge, simultaneously and explicitly formulates the multi-view consistency and the multi-view inconsistency in a unified optimization model. To solve this model, a new alternating optimization scheme is designed, where the consistent and inconsistent parts of each single-view graph as well as the unified graph that fuses the consistent parts of all views can be iteratively learned. It is noteworthy that our multi-view graph learning model is applicable to both similarity graphs and dissimilarity graphs, leading to two graph fusion-based variants, namely, distance (dissimilarity) graph fusion and similarity graph fusion. Experiments on various multi-view datasets demonstrate the superiority of our approach. The MATLAB source code is available at https://github.com/youweiliang/ConsistentGraphLearning.',\n",
              "  'Dual active feature and sample selection for graph classification.[SEP]Graph classification has become an important and active research topic in the last decade. Current research on graph classification focuses on mining discriminative subgraph features under supervised settings. The basic assumption is that a large number of labeled graphs are available. However, labeling graph data is quite expensive and time consuming for many real-world applications. In order to reduce the labeling cost for graph data, we address the problem of how to select the most important graph to query for the label. This problem is challenging and different from conventional active learning problems because there is no predefined feature vector. Moreover, the subgraph enumeration problem is NP-hard. The active sample selection problem and the feature selection problem are correlated for graph data. Before we can solve the active sample selection problem, we need to find a set of optimal subgraph features. To address this challenge, we demonstrate how one can simultaneously estimate the usefulness of a query graph and a set of subgraph features. The idea is to maximize the dependency between subgraph features and graph labels using an active learning framework. We propose a branch-and-bound algorithm to search for the optimal query graph and optimal features simultaneously. Empirical studies on nine real-world tasks demonstrate that the proposed method can obtain better accuracy on graph data than alternative approaches.',\n",
              "  'Shortest-Path Kernels on Graphs.[SEP]Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels.'],\n",
              " 5: ['Spectral compression of mesh geometry.[SEP]We show how spectral methods may be applied to 3D mesh data to obtain compact representations. This is achieved by projecting the mesh geometry onto an orthonormal basis derived from the mesh topology. To reduce complexity, the mesh is partitioned into a number of balanced submeshes with minimal interaction, each of which are compressed independently. Our methods may be used for compression and progressive transmission of 3D content, and are shown to be vastly superior to existing methods using spatial techniques, if slight loss can be tolerated.',\n",
              "  'Compressing Polygon Mesh Geometry with Parallelogram Prediction.[SEP]We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.',\n",
              "  'Connectivity Compression for Three-Dimensional Planar Triangle Meshes.[SEP]We describe a new algorithm for coding the connectivity information of three-dimensional planar triangle meshes. Vertices of a mesh are placed on a two-dimensional grid. The connectivity pattern of the grid is implicit and hence the only information that needs to be encoded is the diagonal links. We present experimental results that show that the new method has a low connectivity cost of 2.1 bits per vertex on average.',\n",
              "  'A Unified Interpolatory and Approximation sqrt-3 Subdivision Scheme.[SEP]We have found that there is a relationship between the cubic B-spline and four-point curve subdivision method. In the paper it is used to deduce interpolatory subdivision schemes from cubic B-spline based approximation subdivision schemes directly and construct unified schemes for compositing approximation and interpolatory subdivision. A new interpolatory p3 subdivision scheme and a interpolatory and approximation blended p3 subdivision scheme are created by this straightforward method. The former produces C1 limit surface and avoids the problem in the exsiting interpolatory p3 subdivision mask where the weight coefficients on extraordinary vertices can not be described by explicit formulation. The latter can be used to solve the \"popping effect\" problem when switching between meshes at different levels of resolution, provide the possibility to locally choose an interpolating variant of the conventionally approximating subdivision scheme, and give more flexibility for feature modeling. These are realized by only changing the value of a parameter. The method is thoroughly simple without needs of constructing and solving equations.',\n",
              "  'Quad/Triangle Subdivision.[SEP]In this paper we introduce a new subdivision operator that unifies triangular and quadrilateral subdivision schemes. Designers often want the added flexibility of having both quads and triangles in their models. It is also well known that triangle meshes generate poor limit surfaces when using a quad scheme, while quad‐only meshes behave poorly with triangular schemes. Our new scheme is a generalization of the well known Catmull‐Clark and Loop subdivision algorithms. We show that our surfaces are C 1 everywhere and provide a proof that it is impossible to construct such a C 2 scheme at the quad/triangle boundary. However, we provide rules that produce surfaces with bounded curvature at the regular quad/triangle boundary and provide optimal masks that minimize the curvature divergence elsewhere. We demonstrate the visual quality of our surfaces with several examples.',\n",
              "  'A New Interpolatory Subdivision for Quadrilateral Meshes.[SEP]This paper presents a new interpolatory subdivision scheme for quadrilateral meshes based on a 1–4 splitting operator. The scheme generates surfaces coincident with those of the Kobbelt interpolatory subdivision scheme for regular meshes. A new group of rules are designed for computing newly inserted vertices around extraordinary vertices. As an extension of the regular masks,the new rules are derived based on a reinterpretation of the regular masks. Eigen‐structure analysis demonstrates that subdivision surfaces generated using the new scheme are C1 continuous and, in addition, have bounded curvature.',\n",
              "  'Planar Shape Interpolation Based On Teichm[SEP]Shape interpolation is a classical problem in computer graphics and has been widely investigated in the past two decades. Ideal shape interpolation should be natural and smooth which have good properties such as affine and conformal reproduction, bounded distortion, no fold‐overs, etc. In this paper, we present a new approach for planar shape interpolation based on Teichmüller maps ‐ a special type of maps in the class of quasi‐conformal maps. The algorithm consists of two steps. In the first step, a Teichmüller map is computed from the source shape to the target shape, and then the Beltrami coefficient is interpolated such that the conformal distortion is linear with respect to the time variable. In the second step, the intermediate shape is reconstructed by solving the Beltrami equation locally over each triangle and then stitching the mapped triangles by conformal transformations. The new approach preserves all the good properties mentioned above and produces more natural and more uniform intermediate shapes than the start‐of‐the‐art methods. Especially, the conformal distortion changes linearly with respect to the time variable. Experiment results show that our method can produce appealing results regardless of interpolating between the same or different objects.',\n",
              "  'Locally Injective Mappings.[SEP]Mappings and deformations are ubiquitous in geometry processing, shape modeling, and animation. Numerous deformation energies have been proposed to tackle problems like mesh parameterization and volumetric deformations. We present an algorithm that modifies any deformation energy to guarantee a locally injective mapping, i.e., without inverted elements. Our formulation can be used to compute continuous planar or volumetric piecewise‐linear maps and it uses a barrier term to prevent inverted elements. Differently from previous methods, we carefully design both the barrier term and the associated numerical techniques to be able to provide immediate feedback to the user, enabling interactive manipulation of inversion‐free mappings. Stress tests show that our method robustly handles extreme deformations where previous techniques converge very slowly or even fail. We demonstrate that enforcing local injectivity increases fidelity of the results in applications such as shape deformation and parameterization.',\n",
              "  'As-Rigid-As\\ue4f8Possible Distance Field Metamorphosis.[SEP]Widely used for morphing between objects with arbitrary topology, distance field interpolation (DFI) handles topological transition naturally without the need for correspondence or remeshing, unlike surface‐based interpolation approaches. However, lack of correspondence in DFI also leads to ineffective control over the morphing process. In particular, unless the user specifies a dense set of landmarks, it is not even possible to measure the distortion of intermediate shapes during interpolation, let alone control it. To remedy such issues, we introduce an approach for establishing correspondence between the interior of two arbitrary objects, formulated as an optimal mass transport problem with a sparse set of landmarks. This correspondence enables us to compute non‐rigid warping functions that better align the source and target objects as well as to incorporate local rigidity constraints to perform as‐rigid‐as\\ue4f8possible DFI. We demonstrate how our approach helps achieve flexible morphing results with a small number of landmarks.',\n",
              "  'Vega: Non-Linear FEM Deformable Object Simulator.[SEP]This practice and experience paper describes a robust C++ implementation of several non‐linear solid three‐dimensional deformable object strategies commonly employed in computer graphics, named the Vega finite element method (FEM) simulation library. Deformable models supported include co‐rotational linear FEM elasticity, Saint–Venant Kirchhoff FEM model, mass–spring system and invertible FEM models: neo‐Hookean, Saint–Venant Kirchhoff and Mooney–Rivlin. We provide several timestepping schemes, including implicit Newmark and backward Euler integrators, and explicit central differences. The implementation of material models is separated from integration, which makes it possible to employ our code not only for simulation, but also for deformable object control and shape modelling. We extensively compare the different material models and timestepping schemes. We provide practical experience and insight gained while using our code in several computer animation and simulation research projects.',\n",
              "  \"Modal Warping: Real-Time Simulation of Large Rotational Deformation and Manipulation.[SEP]This work proposes a real-time simulation technique for large deformations. Green's nonlinear strain tensor accurately models large deformations; however, time stepping of the resulting nonlinear system can be computationally expensive. Modal analysis based on a linear strain tensor has been shown to be suitable for real-time simulation, but is accurate only for moderately small deformations. In the present work, we identify the rotational component of an infinitesimal deformation and extend traditional linear modal analysis to track that component. We then develop a procedure to integrate the small rotations occurring at the nodal points. An interesting feature of our formulation is that it can implement both position and orientation constraints in a straightforward manner. These constraints can be used to interactively manipulate the shape of a deformable solid by dragging/twisting a set of nodes. Experiments show that the proposed technique runs in real-time, even for a complex model, and that it can simulate large bending and/or twisting deformations with acceptable realism.\",\n",
              "  'Geometric Stiffness for Real-time Constrained Multibody Dynamics.[SEP]This paper focuses on the stable and efficient simulation of articulated rigid body systems for real‐time applications. Specifically, we focus on the use of geometric stiffness which can dramatically increase simulation stability. We examine several numerical problems with the inclusion of geometric stiffness in the equations of motion, as proposed by previous work, and address these issues by introducing a novel method for efficiently building the linear system. This offers improved tractability and numerical efficiency. Furthermore, geometric stiffness tends to significantly dissipate kinetic energy. We propose an adaptive damping scheme, inspired by the geometric stiffness, that uses a stability criterion based on the numerical integrator to determine the amount of non‐constitutive damping required to stabilize the simulation. With this approach, not only is the dynamical behavior better preserved, but the simulation remains stable for mass ratios of 1,000,000‐to‐1 at time steps up to 0.1 s. We present a number of challenging scenarios to demonstrate that our method improves efficiency, and that it increases stability by orders of magnitude compared to previous work.',\n",
              "  'Simplifying surfaces with color and texture using quadric error metrics.[SEP]There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.',\n",
              "  'Locally Toleranced Surface Simplification.[SEP]We present a technique for simplifying a triangulated surface. Simplifying consists of approximating the surface with another surface of lower triangle count. Our algorithm can preserve the volume of a solid to within machine accuracy; it favors the creation of near-equilateral triangles. We develop novel methods for reporting and representing a bound to the approximation error between a simplified surface and the original, and respecting a variable tolerance across the surface. A different positive error value is reported at each vertex. By linearly blending the error values in between vertices, we define a volume of space, called the error volume, as the union of balls of linearly varying radii. The error volume is built dynamically as the simplification progresses, on top of preexisting error volumes that it contains. We also build a tolerance volume to forbid simplification errors exceeding a local tolerance. The information necessary to compute error values is local to the star of a vertex; accordingly, the complexity of the algorithm is either linear or in O(n log n) in the original number of surface edges, depending on the variant. We extend the mechanisms of error and tolerance volumes to preserve during simplification scalar and vector attributes associated with surface vertices. Assuming a linear variation across triangles, error and tolerance volumes are defined in the same fashion as for positional error. For normals, a corrective term is applied to the error measured at the vertices to compensate for nonlinearities.',\n",
              "  'Coarse-to-fine surface simplification with geometric guarantees.[SEP]Let PC be a 3D point cloud and ε be a positive value called tolerance. We aim at constructing a triangulated surface S based on a subset PCU of PC such that all the points in PCL=PC∖PCU are at distance at most ε from a facet of S. (PCU and PCL respectively stand for Point Cloud Used and Point Cloud Left.) We call this problem simplification with geometric guarantees.',\n",
              "  'Crest Lines for Surface Segmentation and Flattening.[SEP]We present a method for extracting feature curves called crest lines from a triangulated surface. Then, we calculate the geodesic Voronoi diagram of crest lines to segment the surface into several regions. Afterward, barycentric surface flattening using theory from graph embeddings is implemented and, using the geodesic Voronoi diagram, we develop a faster surface flattening algorithm.',\n",
              "  'On stochastic methods for surface reconstruction.[SEP]In this article, we present and discuss three statistical methods for surface reconstruction. A typical input to a surface reconstruction technique consists of a large set of points that has been sampled from a smooth surface and contains uncertain data in the form of noise and outliers. We first present a method that filters out uncertain and redundant information yielding a more accurate and economical surface representation. Then we present two methods, each of which converts the input point data to a standard shape representation; the first produces an implicit representation while the second yields a triangle mesh.',\n",
              "  'Applied Geometry: Discrete Differential Calculus for Graphics.[SEP]Geometry has been extensively studied for centuries, almost exclusively from a differential point of view. However, with the advent of the digital age, the interest directed to smooth surfaces has now partially shifted due to the growing importance of discrete geometry. From 3D surfaces in graphics to higher dimensional manifolds in mechanics, computational sciences must deal with sampled geometric data on a daily basis‐hence our interest in Applied Geometry.',\n",
              "  'One Point Isometric Matching with the Heat Kernel.[SEP]A common operation in many geometry processing algorithms consists of finding correspondences between pairs of shapes by finding structure‐preserving maps between them. A particularly useful case of such maps is isometries, which preserve geodesic distances between points on each shape. Although several algorithms have been proposed to find approximately isometric maps between a pair of shapes, the structure of the space of isometries is not well understood. In this paper, we show that under mild genericity conditions, a single correspondence can be used to recover an isometry defined on entire shapes, and thus the space of all isometries can be parameterized by one correspondence between a pair of points. Perhaps surprisingly, this result is general, and does not depend on the dimensionality or the genus, and is valid for compact manifolds in any dimension. Moreover, we show that both the initial correspondence and the isometry can be recovered efficiently in practice. This allows us to devise an algorithm to find intrinsic symmetries of shapes, match shapes undergoing isometric deformations, as well as match partial and incomplete models efficiently.',\n",
              "  'Computing Teichm[SEP]Shape indexing, classification, and retrieval are fundamental problems in computer graphics. This work introduces a novel method for surface indexing and classification based on Teichmuller theory. The Teichmuller space for surfaces with the same topology is a finite dimensional manifold, where each point represents a conformal equivalence class, a curve represents a deformation process from one class to the other. We apply Teichmuller space coordinates as shape descriptors, which are succinct, discriminating and intrinsic; invariant under the rigid motions and scalings, insensitive to resolutions. Furthermore, the method has solid theoretic foundation, and the computation of Teichmuller coordinates is practical, stable and efficient. This work focuses on the surfaces with negative Euler numbers, which have a unique conformal Riemannian metric with -1 Gaussian curvature. The coordinates which we will compute are the lengths of a special set of geodesics under this special metric. The metric can be obtained by the curvature flow algorithm, the geodesics can be calculated using algebraic topological method. We tested our method extensively for indexing and comparison of about one hundred of surfaces with various topologies, geometries and resolutions. The experimental results show the efficacy and efficiency of the length coordinate of the Teichmuller space.',\n",
              "  'Bilateral Maps for Partial Matching.[SEP]Feature‐driven analysis forms the basis of many shape processing tasks, where detected feature points are characterized by local shape descriptors. Such descriptors have so far been defined to capture regions of interest centred at individual points. Using such regions to compare feature points can be problematic when performing partial shape matching, because the region of interest is typically defined as an isotropic neighbourhood around a point, which does not adapt to the geometry of the shape parts. We introduce the bilateral map, a local shape descriptor whose region of interest is defined by two feature points. Compared to the classical descriptor definition using a single point, the bilateral approach exploits the use of a second point to place more constraints on the selection of the spatial context for feature analysis. This leads to a descriptor where the shape of the region of interest adapts to the context of the two points, making it more refined for shape matching. In particular, we show that our new descriptor is more effective for partial matching, because potentially extraneous regions of the models are selectively ignored owing to the adaptive nature of the bilateral map. This property also renders the bilateral map partially insensitive to topological changes. We demonstrate the effectiveness of the bilateral map for partial matching via several correspondence and retrieval experiments and evaluate the results both qualitatively and quantitatively.'],\n",
              " 6: [\"Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games.[SEP]Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses to recent events like #gamergate implies that the gender of the participant is not paramount to experience, but that their beliefs about gender roles are. To explore the role of sexist beliefs on experience in sexist games, we created three versions of a game that were identical except for the presence of sexist imagery and/or dialogue. We show that enjoyment of sexist games is not predicted by player gender, but by the player's pre-existing beliefs about gender. Furthermore, avatar identification is the pathway through which enjoyment is facilitated. Finally, sexist dialogue does not improve the play experience for anyone rather it harms experience for players of all genders who do not hold sexist beliefs.\",\n",
              "  \"Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience.[SEP]Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.\",\n",
              "  \"Negative Emotion, Positive Experience?: Emotionally Moving Moments in Digital Games.[SEP]Emotions are key to the player experience (PX) and interest in the potential of games to provide unique emotional, sometimes uncomfortable experiences is growing. Yet there has been little empirical investigation of what game experiences players consider emotionally moving, their causes and effects, and whether players find these experiences rewarding at all. We analyzed 121 players' accounts of emotionally moving game experiences in terms of the feelings and thoughts they evoked, different PX constructs, as well as game-related and personal factors contributing to these. We found that most players enjoyed and appreciated experiencing negatively valenced emotions, such as sadness. Emotions were evoked by a variety of interactive and non-interactive game aspects, such as in-game loss, character attachment and (lack of) agency, but also personal memories, and were often accompanied by (self-)reflection. Our findings highlight the potential of games to provide emotionally rewarding and thought-provoking experiences, as well as outline opportunities for future research and design of such experiences. They also showcase that negative affect may contribute to enjoyment, thereby extending our notion of positive player experience.\",\n",
              "  'Exergame Training of Executive Function in Preschool Children: Generalizability and Long-term Effects.[SEP]Studies with older children and adults have found that physically engaging video games (i.e., Exergames) that promote both cognitive control and physical activity improve executive function (EF) skills; yet, children below school age remain understudied with regard to the impact of Exergames on EF. Additionally, research on the extent of the impact of Exergames resulting in prolonged changes, and whether training generalizes to EF-related behaviors in a real-world context remains scarce. This study examined the short- and long-term changes in EF of 4- to 5-year-olds after participation in two 20-minute Exergame sessions. Results indicate that Exergame training improved performance on EF tasks and resulted in higher teacher ratings of EF in the classroom compared to a sex-/classroom-/age-matched control group. The improvements in EF persisted over a one-month period. This study provides novel insights into the short-term and long-term effects of Exergame training on executive function in preschool-aged children.',\n",
              "  'Exploring  designing tools to enhance falls rehabilitation in the home.[SEP]Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.',\n",
              "  'Fitmersive Games: Fitness Gamification through Immersive VR.[SEP]The decreasing hardware cost makes it affordable to pair Immersive Virtual Environments (IVR) visors with treadmills and exercise bikes. In this paper, we discuss the application of different gamification techniques in IVR for supporting physical exercise. We describe both the hardware setting and the design of Rift-a-bike, a cycling fitmersive game (immersive games for fitness). We evaluate the effectiveness of such techniques through a user study, which provides different insights on their effectiveness in designing such applications.',\n",
              "  'Chalkboarding: A New Spatiotemporal Query Paradigm for Sports Play Retrieval.[SEP]The recent explosion of sports tracking data has dramatically increased the interest in effective data processing and access of sports plays (i.e., short trajectory sequences of players and the ball). And while there exist systems that offer improved categorizations of sports plays (e.g., into relatively coarse clusters), to the best of our knowledge there does not exist any retrieval system that can effectively search for the most relevant plays given a specific input query. One significant design challenge is how best to phrase queries for multi-agent spatiotemporal trajectories such as sports plays.We have developed a novel query paradigm and retrieval system, which we call Chalkboarding, that allows the user to issue queries by drawing a play of interest (similar to how coaches draw up plays). Our system utilizes effective alignment, templating, and hashing techniques tailored to multi-agent trajectories, and achieves accurate play retrieval at interactive speeds.We showcase the efficacy of our approach in a user study, where we demonstrate orders-of-magnitude improvements in search quality compared to baseline systems.',\n",
              "  'Baseball Timeline: Summarizing Baseball Plays Into a Static Visualization.[SEP]In sports, Play Diagrams are the standard way to represent and convey information. They are widely used by coaches, managers, journalists and fans in general. There are situations where diagrams may be hard to understand, for example, when several actions are packed in a certain region of the field or there are just too many actions to be transformed in a clear depiction of the play. The representation of how actions develop through time, in particular, may be hardly achieved on such diagrams. The time, and the relationship among the actions of the players through time, is critical on the depiction of complex plays. In this context, we present a study on how player actions may be clearly depicted on 2D diagrams. The study is focused on Baseball plays, a sport where diagrams are heavily used to summarize the actions of the players. We propose a new and simple approach to represent spatiotemporal information in the form of a timeline. We designed our visualization with a requirement driven approach, conducting interviews and fulfilling the needs of baseball experts and expert‐fans. We validate our approach by presenting a detailed analysis of baseball plays and conducting interviews with four domain experts.',\n",
              "  'Sports Tournament Predictions Using Direct Manipulation.[SEP]An advanced interface for sports tournament predictions uses direct manipulation to allow users to make nonlinear predictions. Unlike previous interface designs, the interface helps users focus on their prediction tasks by enabling them to first choose a winner and then fill out the rest of the bracket. In real-world tests of the proposed interface (for the 2014 FIFA World Cup tournament and 2015/2016 UEFA Champions League), the authors validated the use of direct manipulation as an alternative to widgets. Using visitor interaction logs, they were able to determine the strategies people use to perform predictions and identify potential areas of improvement for further prediction interfaces.',\n",
              "  'Usability Planner: A Tool to Support the Process of Selecting Usability Methods.[SEP]There is increasing pressure on developers to produce usable systems, which requires the use of appropriate methods to support user centred design during development. There is currently no consistent advice on which methods are appropriate in which circumstances, so the selection of methods relies on individual experience and expertise. Considerable effort is required to collate information from various sources and to understand the applicability of each method in a particular situation. Usability Planner is a tool aimed to support the selection of the most appropriate methods depending on project and organizational constraints. Many of the rules employed are derived from ISO standards, complemented with rules from the authors’ experience.',\n",
              "  'Usability Evaluation in a Digitally Emerging Country: A Survey Study.[SEP]Several emerging countries experience increasing software development activities. With the purpose of provide useful feedback on possible courses of action for increasing application of usability evaluation in such countries, this paper explores the status of usability evaluation in a digitally emerging country. Our aim is to identifying common characteristics or behavioral patterns that could be compared with digitally advanced countries. We used an online survey answered by 26 software development organizations, which gave a snapshot of the application of usability evaluation in these organizations. We found many similarities with advanced countries, several completely new obstacles more connected with software development matters and a relatively positive improvement in the lack of “usability culture”. These findings suggest good conditions to improve conduction of usability evaluations in digitally emerging countries.',\n",
              "  'Usability testing: what have we overlooked?[SEP]For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.'],\n",
              " 7: ['Unified Mathematical Model for Multilayer-Multiframe Compressive Light Field Displays Using LCDs.[SEP]We propose a unified mathematical model for multilayer-multiframe compressive light field displays that supports both attenuation-based and polarization-based architectures. We show that the light field decomposition of such a display can be cast as a bound constrained nonlinear matrix optimization problem. Efficient light field decomposition algorithms are developed using the limited-memory BFGS (L-BFGS) method for automultiscopic displays with high resolution and high image fidelity. In addition, this framework is the first to support multilayer polarization-based compressive light field displays with time multiplexing. This new architecture significantly reduces artifacts compared with attenuation-based multilayer-multiframe displays; thus, it can allow the requirements regarding the number of layers or the refresh rate to be relaxed. We verify the proposed methods by constructing two 3-layer prototypes using high-speed LCDs, one based on the attenuation architecture and one based on the polarization architecture. Moreover, an efficient CUDA-based program is implemented. Our displays can produce images with higher spatial resolution with thinner form factors compared with traditional automultiscopic displays in both simulations and experiments.',\n",
              "  'Polarization Demosaicking for Monochrome and Color Polarization Focal Plane Arrays.[SEP]Division-of-focal-plane (DoFP) polarization image sensors allow for snapshot imaging of linear polarization effects with inexpensive and straightforward setups. However, conventional interpolation based image reconstruction methods for such sensors produce unreliable and noisy estimates of quantities such as degree of linear polarization (DoLP) or angle of linear polarization (AoLP). In this paper, we propose a polarization demosaicking algorithm by inverting the polarization image formation model for both monochrome and color DoFP cameras. Compared to previous interpolation methods, our approach can significantly reduce noise induced artifacts and drastically increase the accuracy in estimating polarization states. We evaluate and demonstrate the performance of the methods on a new high-resolution color polarization dataset. Simulation and experimental results show that the proposed reconstruction and analysis tools offer an effective solution to polarization imaging.',\n",
              "  'Depth of Field in Plenoptic Cameras.[SEP]Certain new algorithms used by plenoptic cameras require focused microlens images. The range of applicability of these algorithms therefore depends on the depth of field of the relay system comprising the plenoptic camera. We analyze the relationships and tradeoffs between camera parameters and depth of field and characterize conditions for optimal refocusing, stereo, and 3D imaging.',\n",
              "  'A Composite BRDF Model for Hazy Gloss.[SEP]We introduce a bidirectional reflectance distribution function (BRDF) model for the rendering of materials that exhibit hazy reflections, whereby the specular reflections appear to be flanked by a surrounding halo. The focus of this work is on artistic control and ease of implementation for real‐time and off‐line rendering. We propose relying on a composite material based on a pair of arbitrary BRDF models; however, instead of controlling their physical parameters, we expose perceptual parameters inspired by visual experiments [VBF17]. Our main contribution then consists in a mapping from perceptual to physical parameters that ensures the resulting composite BRDF is valid in terms of reciprocity, positivity and energy conservation. The immediate benefit of our approach is to provide direct artistic control over both the intensity and extent of the haze effect, which is not only necessary for editing purposes, but also essential to vary haziness spatially over an object surface. Our solution is also simple to implement as it requires no new importance sampling strategy and relies on existing BRDF models. Such a simplicity is key to approximating the method for the editing of hazy gloss in real‐time and for compositing.',\n",
              "  'Improving the Selection of Bases of BRDFs for Appearance Preservation.[SEP]An important step in the appearance preservation of real materials is the analysis of how they interact with light. Since this phenomena happens at a microscopic level, heuristics with different complexity have been developed to capture and reproduce it. In order to minimize sampling efforts, one of these approaches consists in representing the reflectance of a material as a linear combination of a basis of known reflectance functions. To accomplish realistic and efficient representations, this basis must be expressive and contain a reduced number of elements. This work presents three approaches to select such basis. The first one performs an empirical leave-one-out optimization procedure. The other two are based on classical and evolutionary clustering algorithms. To improve clustering results, a new BRDF-oriented fitness function is designed. These approaches are evaluated using NNLS algorithm to estimate sampled materials and a comparison based on numerical precision is performed.',\n",
              "  'Accurate fitting of measured reflectances using a Shifted Gamma micro-facet distribution.[SEP]Material models are essential to the production of photo‐realistic images. Measured BRDFs provide accurate representation with complex visual appearance, but have larger storage cost. Analytical BRDFs such as Cook‐Torrance provide a compact representation but fail to represent the effects we observe with measured appearance. Accurately fitting an analytical BRDF to measured data remains a challenging problem. In this paper we introduce the SGD micro‐facet distribution for Cook‐Torrance BRDF. This distribution accurately models the behavior of most materials. As a consequence, we accurately represent all measured BRDFs using a single lobe. Our fitting procedure is stable and robust, and does not require manual tweaking of the parameters.'],\n",
              " 8: ['Synthesizing Type-Detection Logic for Rich Semantic Data Types using Open-source Code.[SEP]Given a table of data, existing systems can often detect basic atomic types (e.g., strings vs. numbers) for each column. A new generation of data-analytics and data-preparation systems are starting to automatically recognize rich semantic types such as date-time, email address, etc., for such metadata can bring an array of benefits including better table understanding, improved search relevance, precise data validation, and semantic data transformation. However, existing approaches only detect a limited number of types using regular-expression-like patterns, which are often inaccurate, and cannot handle rich semantic types such as credit card and ISBN numbers that encode semantic validations (e.g., checksum).',\n",
              "  'A New Characterization of Independence.[SEP]We introduce a restriction on the structure of a database scheme, called the primary key condition, and show that this condition characterizes independent database schemes when constraints are presented as keys. The primary key condition provides added insight into the structure of independent schemes, and leads to a general design methodology. We describe a linear-time algorithm for recognizing independent schemes.',\n",
              "  'Efficient and Extensible Algorithms for Multi Query Optimization.[SEP]Complex queries are becoming commonplace, with the growing use of decision support systems. These complex queries often have a lot of common sub-expressions, either within a single query, or across multiple such queries run as a batch. Multiquery optimization aims at exploiting common sub-expressions to reduce evaluation cost. Multi-query optimization has hither-to been viewed as impractical, since earlier algorithms were exhaustive, and explore a doubly exponential search space.',\n",
              "  'Leveraging compression in the tableau data engine.[SEP]Data sets are growing rapidly and there is an attendant need for tools that facilitate human analysis of them in a timely manner. To help meet this need, column-oriented databases (or \"column stores\") have come into wide use because of their low latency on analytic workloads. Column stores use a number of techniques to produce these dramatic performance techniques, including the ability to perform operations directly on compressed data. In this paper, we describe how the Tableau Data Engine (an internally developed column store) leverages a number of compression techniques to improve query performance. The approach is simpler than existing systems for operating on compressed data and more unified, removing the necessity for custom data access mechanisms. The approach also uses some novel metadata extraction techniques to improve the choices made by the system\\'s run-time optimizer.',\n",
              "  'ByteSlice: Pushing the Envelop of Main Memory Data Processing with a New Storage Layout.[SEP]Scan and lookup are two core operations in main memory column stores. A scan operation scans a column and returns a result bit vector that indicates which records satisfy a filter. Once a column scan is completed, the result bit vector is converted into a list of record numbers, which is then used to look up values from other columns of interest for a query. Recently there are several in-memory data layout proposals that aim to improve the performance of in-memory data processing. However, these solutions all stand at either end of a trade-off --- each is either good in lookup performance or good in scan performance, but not both. In this paper we present ByteSlice, a new main memory storage layout that supports both highly efficient scans and lookups. ByteSlice is a byte-level columnar layout that fully leverages SIMD data-parallelism. Micro-benchmark experiments show that ByteSlice achieves a data scan speed at less than 0.5 processor cycle per column value --- a new limit of main memory data scan, without sacrificing lookup performance. Our experiments on TPC-H data and real data show that ByteSlice offers significant performance improvement over all state-of-the-art approaches.',\n",
              "  'A Padded Encoding Scheme to Accelerate Scans by Leveraging Skew.[SEP]In-memory data analytic systems that use vertical bit-parallel scan methods generally use encoding techniques. We observe that in such environments, there is an opportunity to turn skew in both the data and predicate distributions (usually a problem for query processing) into a benefit that can be leveraged to encode the column values. This paper proposes a padded encoding scheme to address this opportunity. The proposed scheme creates encodings that map common attribute values to codes that can easily be distinguished from other codes by only examining a few bits in the full code. Consequently, scans on columns stored using the padded encoding scheme can safely prune the computation without examining all the bits in the code, thereby reducing the memory bandwidth and CPU cycles that are consumed when evaluating scan queries. Our padded encoding method results in a fixed-length encoding, as fixed-length encodings are easier to manage. However, the proposed padded encoding may produce longer (fixed-length) codes than those produced by popular order-preserving encoding methods, such as dictionary-based encoding. This additional space overhead has the potential to negate the gains from early pruning of the scan computation. However, as we demonstrate empirically, the additional space overhead is generally small, and the padded encoding scheme provides significant performance improvements.',\n",
              "  'Secondary-storage confidence computation for conjunctive queries with inequalities.[SEP]This paper investigates the problem of efficiently computing the confidences of distinct tuples in the answers to conjunctive queries with inequalities (<) on tuple-independent probabilistic databases. This problem is fundamental to probabilistic databases and was recently stated open.',\n",
              "  'A Query Engine for Probabilistic Preferences.[SEP]Models of uncertain preferences, such as Mallows, have been extensively studied due to their plethora of application domains. In a recent work, a conceptual and theoretical framework has been proposed for supporting uncertain preferences as first-class citizens in a relational database. The resulting database is probabilistic, and, consequently, query evaluation entails inference of marginal probabilities of query answers. In this paper, we embark on the challenge of a practical realization of this framework. We first describe an implementation of a query engine that supports querying probabilistic preferences alongside relational data. Our system accommodates preference distributions in the general form of the Repeated Insertion Model (RIM), which generalizes Mallows and other models. We then devise a novel inference algorithm for conjunctive queries over RIM, and show that it significantly outperforms the state of the art in terms of both asymptotic and empirical execution cost. We also develop performance optimizations that are based on sharing computation among different inference tasks in the workload. Finally, we conduct an extensive experimental evaluation and demonstrate that clear performance benefits can be realized by a query engine with built-in probabilistic inference, as compared to a stand alone implementation with a black-box inference solver.',\n",
              "  'US-SQL: managing uncertain schemata.[SEP]In this paper we describe a demo concerning the management of uncertain schemata. Many works have studied the problem of representing uncertainty on attribute values or tuples, like the fact that a value is 10 with probability .3 or 20 with probability .7, leading to the implementation of probabilistic database management systems. In our demo we deal with the representation of uncertainty about the meta-data, i.e., about the meaning of these values. Using our system it is possible to create alternative probabilistic schemata on a database, execute queries over uncertain schemata and verify how this additional information is stored in an underlying relational database and how queries are executed.',\n",
              "  'High-Performance Geospatial Analytics in HyPerSpace.[SEP]In the past few years, massive amounts of location-based data has been captured. Numerous datasets containing user location information are readily available to the public. Analyzing such datasets can lead to fascinating insights into the mobility patterns and behaviors of users. Moreover, in recent times a number of geospatial data-driven companies like Uber, Lyft, and Foursquare have emerged. Real-time analysis of geospatial data is essential and enables an emerging class of applications. Database support for geospatial operations is turning into a necessity instead of a distinct feature provided by only a few databases. Even though a lot of database systems provide geospatial support nowadays, queries often do not consider the most current database state. Geospatial queries are inherently slow given the fact that some of these queries require a couple of geometric computations. Disk-based database systems that do support geospatial datatypes and queries, provide rich features and functions, but they fall behind when performance is considered: specifically if real-time analysis of the latest transactional state is a requirement. In this demonstration, we present HyPerSpace, an extension to the high-performance main-memory database system HyPer developed at the Technical University of Munich, capable of processing geospatial queries with sub-second latencies.',\n",
              "  'Incremental Distance Join Algorithms for Spatial Databases.[SEP]Two new spatial join operations, distance join and distance semi-join, are introduced where the join output is ordered by the distance between the spatial attribute values of the joined tuples. Incremental algorithms are presented for computing these operations, which can be used in a pipelined fashion, thereby obviating the need to wait for their completion when only a few tuples are needed. The algorithms can be used with a large class of hierarchical spatial data structures and arbitrary spatial data types in any dimensions. In addition, any distance metric may be employed. A performance study using R-trees shows that the incremental algorithms outperform non-incremental approaches by an order of magnitude if only a small part of the result is needed, while the penalty, if any, for the incremental processing is modest if the entire join result is required.',\n",
              "  'STAR: A Distributed Stream Warehouse System for Spatial Data.[SEP]The proliferation of mobile phones and location-based services gives rise to an explosive growth of spatial data. This spatial data contains valuable information, and calls for data stream warehouse systems that can provide real-time analytical results with the latest integrated spatial data. In this demonstration, we present the STAR (Spatial Data Stream Warehouse) system. STAR is a distributed in-memory spatial data stream warehouse system that provides low-latency and up-to-date analytical results over a fast spatial data stream. STAR supports a rich set of aggregate queries for spatial data analytics, e.g., contrasting the frequencies of spatial objects that appear in different spatial regions, or showing the most frequently mentioned topics being tweeted in different cities. STAR processes aggregate queries by maintaining distributed materialized views. Additionally, STAR supports dynamic load adjustment that makes STAR scalable and adaptive. We demonstrate STAR on top of Amazon EC2 clusters using real data sets.'],\n",
              " 9: ['SADIRE: a context-preserving sampling technique for dimensionality reduction visualizations.[SEP]Sampling techniques are widely used in the effort to reduce complexity and improve interpretability of datasets. Given the enormous availability of data, these techniques try to select representative data points that inherently reflect the data structure. In this work, we propose a novel sampling technique that preserves the structures imposed by dimensionality reduction techniques when visualized as scatter plots. In the experiments, we demonstrate how our technique is able to reflect the class boundaries and layout structures, besides decreasing redundancy of the datasets visualized as scatter plots. We also provide an user experiment regarding the perception of sampling from scatter plot visualizations.',\n",
              "  'Role of Human Perception in Cluster-based Visual Analysis of Multidimensional Data Projections.[SEP]Visualization of high-dimensional data requires a mapping to a visual space. Whenever the goal is to preserve similarity relations, multidimensional projections or other dimension reduction techniques are commonly used to project high-dimensional data point to a 2D point using a certain strategy for the 2D layout.Typical analysis tasks for projected multidimensional data do not necessarily match the expectations of human perception. Learning more about the effectiveness of projection layouts from a users perspective is an important step towards consolidating their role in supporting visual analytics tasks. Those tasks often involve detecting and correlating clusters. To understand the role of orientation and cluster properties of size, shape and density, we first conducted a study with synthetic 2D scatter plots, where we can set the respective properties manually. Then we picked five projection methods representative of different approaches to generate layouts of high dimensional dat',\n",
              "  \"Voronoi Diagram Based Dimensional Anchor Assessment for Radial Visualizations.[SEP]Selecting the most expressed dimensions from high dimensional data sets has motivated the design and application of a variety of statistical and machine learning techniques. Here, in our current work, we introduce a metric for assessing the effectiveness of these methods. Our formulation is based on the broad concepts of: (a) devising a formal method of partitioning a visualization's image space; (b) identifying regions that indicate the relative strength of the dimension selection based on how well they are populated by data images; and (c) similarily identifying those regions indicating a poor selection of dimensions. In particular, we explore assessing the quality of radial visualizations. Dimension selection in this class of visualizations strongly effects visualization quality and the sensitivity of cluster formation. We demonstrate the usefulness of Voronoi partitioning the RadViz image space; quantifying radial visualization quality is a direct measure of dimension selection. This work continues to develop and refine the formal theory behind the general class of Normalized Radial Visualizations, including RadViz.\"],\n",
              " 10: ['Real time animation of dynamic processes.[SEP]Animation and simulation processes are facilitated by the use of high level graphic languages. The results of these processes are not generally available in real time, developing of microfilm delaying the screening of the process until some time after the computer run.A technique is described which overcomes this problem whilst still allowing the use of a high level graphical language.The addition of a single feature to a \"static\" graphical language has transformed it into a \"dynamic\" graphical language allowing real time illustration of time varying processes.The technique is not restricted to the language described but may well be employed by other high level graphical languages.',\n",
              "  'Real time falling animation with active and protective responses.[SEP]Combined with motion capture and dynamic simulation, characters in animation have realistic motion details and can respond to unexpected contact forces. This paper proposes a novel and real-time character motion generation approach which introduces a parallel process, and uses an approximate nearest neighbor optimization search method. Besides, we employ a support vector machine (SVM), which is trained on a set of samples and predicts a subset of our ‘return-to’ motion capture (mocap) database in order to reduce the search time. In the dynamic simulation process, we focus on designing a biomechanics based controller which detects the balance of the characters in locomotion and drives them to take several active and protective responses when they fall to the ground in order to reduce the injuries to their bodies. Finally, we show the time costs in synthesis and the visual results of our approach. The experimental results indicate that our motion generation approach is suitable for interactive games or other real-time applications.',\n",
              "  'A system for algorithm animation.[SEP]A software environment is described which provides facilities at a variety of levels for “animating” algorithms: exposing properties of programs by displaying multiple dynamic views of the program and associated data structures. The system is operational on a network of graphics-based, personal workstations and has been used successfully in several applications for teaching and research in computer science and mathematics. In this paper, we outline the conceptual framework that we have developed for animating algorithms, describe the system that we have implemented, and give several examples drawn from the host of algorithms that we have animated.'],\n",
              " 11: ['Dogmas of Understanding in Western Art Music Performance.[SEP]This paper presents an exploration of the ontological shift from musical materials (i.e. melody, harmony, rhythm, texture, timbre, register) to activities in music performance analysis. The “dogmas” extend Herbert H. Clark’s conceptual framework for the study of joint activity in language use to explore music performance in the WAM tradition. A systematic analysis of London Symphony Orchestra masterclasses examines the basic mechanisms of music making in four main areas: representation, audience, interaction, and tacit knowledge. This exploration leads to a broader account of cognition and creativity in music performance, one that bridges inner and outer processes of awareness around domains of coordination in joint activities. In this view, material conceptualizations are viewed as targets of focal awareness rather than the basis for cognition in music making. This account, grounded in a rich third-person phenomenological analysis of instructional materials, paves the way for a “meaningful analytics” of musical practice.',\n",
              "  'Visualizing the Semantic Structure in Classical Music Works.[SEP]A major obstacle in the appreciation of classical music is that extensive training is required to understand musical structure and compositional techniques toward comprehending the thoughts behind the musical work. In this paper, we propose an innovative visualization solution to reveal the semantic structure in classical orchestral works such that users can gain insights into musical structure and appreciate the beauty of music. We formulate the semantic structure into macrolevel layer interactions, microlevel theme variations, and macro-micro relationships between themes and layers to abstract the complicated construction of a musical composition. The visualization has been applied with success in understanding some classical music works as supported by highly promising user study results with the general audience and very positive feedback from music students and experts, demonstrating its effectiveness in conveying the sophistication and beauty of classical music to novice users with informative and intuitive displays.',\n",
              "  'Entrain: Encouraging Social Interaction in Collective Music Making.[SEP]Entrain is an adaptive agent designed to stimulate social interaction among users in collective music making. It registers individual user behavior and provides sonic feedback to encourage users to look up from their mobiles and interact with each other. We demonstrate a use case of Entrain in Coloop, a distributed and collective musical instrument.',\n",
              "  'Short-term memory for tonal and verbal information: Comparison with absolute and non-absolute pitch possessors.[SEP]This study examined the difference in the storage of pitch and phonological information in absolute pitch (AP) and non-AP (NAP) possessors. In a recognition task using musical tones (pitch information), speech sounds (phonological information), and visual patterns, participants were asked to retain two stimulus sequences. In the same type condition, the nature of the first and second stimulus set was different (e.g., one sequence was musical tones and the other was speech sounds). In the different type condition, the nature of the two sequences was the same (e.g., both sequences were musical tones). We found that, in NAP possessors, the recognition rate of musical tones and speech sounds in the different type condition was higher than in the same type condition. In AP possessors, however, the recognition rate of musical tones revealed no difference between these two conditions. These results suggest the use of different strategy in retaining musical tones between AP and NAP possessors.',\n",
              "  'What We Move to Moves Us: Biological Rhythmicity Predicts Musical Preferences.[SEP]For at least 350 centuries, humans have invented music that offered special aesthetic appeal. Yet, the reasons for these preferences and effects are not understood. Here, we show that listeners prefer music with an underlying rhythmic structure that closely approximates our biological structure. Specifically, listeners preferred music with musical (rhythmic) structures that correspond to biological rhythmicity (motions). This finding, grounded in a straightforward biological framework, provided an intellectual advancement in the long history of thought and experimental work on the basis of musical preferences.',\n",
              "  'Embodying Theoretical Research in Music Cognition: Four Proposals for Theory-Driven Experimentation.[SEP]Research in the field of music cognition typically focuses either on low-level, technically oriented approaches or on highly abstract ontological discussions that lack direct grounding in evidence. To bridge this gap, we propose a revision of the ontology underlying such research, from a perspective restricted to the acoustic and individual aspects of music to an embodied, extended, and anti-individualist approach. We explore the application of these ideas to empirical research by discussing two experiments conducted by our group. One of them tests whether the ability to play an instrument has an influence in how a subject listens to music; the other one explores the impact of visual information in the perception of sound as music. We comment on the results obtained and its theoretical significance. Our work shows that it is possible for abstract theorizing and concrete experimentation to go hand in hand in the field of music studies.',\n",
              "  \"Using language complexity to measure cognitive load for adaptive interaction design.[SEP]An adaptive interaction system, which is aware of the users' current cognitive load, can change its response, presentation and interaction flow to improve users' experience and their task performance. In this paper, we propose a novel speech content analysis approach for measuring users' cognitive load, based on their language and dialogue complexity. We have analysed the transcribed speech of operators working in computerized incident control rooms and involved in highly complex bushfire management tasks in Australia. The resulting patterns of language complexity show significant differences between the speech from cognitively low load and high load tasks. We also discuss the value of using this approach of cognitive load measurement for user interface evaluation and interaction design improvement.\",\n",
              "  'The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives.[SEP]The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives.',\n",
              "  'Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition System.[SEP]A study was conducted to evaluate user performance and satisfaction in completion of a set of text creation tasks using three commercially available continuous speech recognition systems. The study also compared user performance on similar tasks using keyboard input. One part of the study (Initial Use) involved 24 users who enrolled, received training and carried out practice tasks, and then completed a set of transcription and composition tasks in a single session. In a parallel effort (Extended Use), four researchers used speech recognition to carry out real work tasks over 10 sessions with each of the three speech recognition software products. This paper presents results from the Initial Use phase of the study along with some preliminary results from the Extended Use phase. We present details of the kinds of usability and system design problems likely in current systems and several common patterns of error correction that we found.',\n",
              "  \"Aural Proxies and Directionally-Varying Reverberation for Interactive Sound Propagation in Virtual Environments.[SEP]We present an efficient algorithm to compute spatially-varying, direction-dependent artificial reverberation and reflection filters in large dynamic scenes for interactive sound propagation in virtual environments and video games. Our approach performs Monte Carlo integration of local visibility and depth functions to compute directionally-varying reverberation effects. The algorithm also uses a dynamically-generated rectangular aural proxy to efficiently model 2-4 orders of early reflections. These two techniques are combined to generate reflection and reverberation filters which vary with the direction of incidence at the listener. This combination leads to better sound source localization and immersion. The overall algorithm is efficient, easy to implement, and can handle moving sound sources, listeners, and dynamic scenes, with minimal storage overhead. We have integrated our approach with the audio rendering pipeline in Valve's Source game engine, and use it to generate realistic directional sound propagation effects in indoor and outdoor scenes in real-time. We demonstrate, through quantitative comparisons as well as evaluations, that our approach leads to enhanced, immersive multi-modal interaction.\",\n",
              "  'Efficient and Accurate Sound Propagation Using Adaptive Rectangular Decomposition.[SEP]Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design (Monks et al., 2000). Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the wave equation in rectangular domains, and utilizes an efficient implementation of the discrete cosine transform on graphics processors (GPU) to achieve at least a 100-fold performance gain compared to a standard finite-difference time-domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.',\n",
              "  \"Source and Listener Directivity for Interactive Wave-Based Sound Propagation.[SEP]We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source. At runtime, we perform the SH decomposition of the varying source directivity interactively and compute the total sound field at the listener position as a weighted sum of precomputed SH sound fields. We propose a novel plane-wave decomposition approach based on higher-order derivatives of the sound field that enables dynamic HRTF-based listener directivity at runtime. We provide a generic framework to incorporate our source and listener directivity in any offline or online frequency-domain wave-based sound propagation algorithm. We have integrated our sound propagation system in Valve's Source game engine and use it to demonstrate realistic acoustic effects such as sound amplification, diffraction low-passing, scattering, localization, externalization, and spatial sound, generated by wave-based propagation of directional sources and listener in complex scenarios. We also present results from our preliminary user study.\"],\n",
              " 12: ['Distinctive Approaches to Computer Graphics Education.[SEP]This paper presents the latest advances and research in Computer Graphics education in a nutshell. It is concerned with topics that were presented at the Education Track of the Eurographics Conference held in Lisbon in 2016. We describe works corresponding to approaches to Computer Graphics education that are unconventional in some way and attempt to tackle unsolved problems and challenges regarding the role of arts in computer graphics education, the role of research‐oriented activities in undergraduate education and the interaction among different areas of Computer Graphics, as well as their application to courses or extra‐curricular activities. We present related works addressing these topics and report experiences, successes and issues in implementing the approaches.',\n",
              "  'Interactive computer graphics applied to chemistry: experiences and new developments.[SEP]This paper is essentially a progress report on three years of effort in computer graphics applied to chemistry. The major technical and human problems encountered when running our facility and integrating it into a chemistry department are described. Then progress of our research project, which is developing application programs in several areas of computer graphics applied to chemical education and research, is reviewed. Recent developments in the field of the representation of dynamic processes in molecules and illustrating some basic concepts of reaction mechanisms in organic chemistry are presented, and the important role of graphics in depicting adequately 3D reaction paths is stressed. Finally, some technical problems arising when using the calligraphic system as an audio‐visual tool for teaching chemistry are discussed and some possible solutions are presented.',\n",
              "  \"Integrating User Studies into Computer Graphics-Related Courses.[SEP]This paper presents computer graphics. Computer graphics and visualization are essentially about producing images for a target audience, be it the millions watching a new CG-animated movie or the small group of researchers trying to gain insight into the large amount of numerical data resulting from a scientific experiment. To ascertain the final images' effectiveness for their intended audience or the designed visualizations' accuracy and expressiveness, formal user studies are often essential. In human-computer interaction (HCI), such user studies play a similar fundamental role in evaluating the usability and applicability of interaction methods and metaphors for the various devices and software systems we use.\",\n",
              "  \"Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent.[SEP]Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.\",\n",
              "  \"How Peripheral Data Visualisation Systems Support Secondary School Teachers during VLE-Supported Lessons.[SEP]Through the integration of technology-enhanced learning (TEL) in the classrooms, there is an increase in Virtual Learning Environment-supported classes in secondary schools, which brings unintentional complexities in terms of monitoring for teachers [25]. To support secondary school teachers during VLE-supported lessons, a peripheral data visualisation system was designed and implemented in a three-week field study. Both qualitative and quantitative data were gathered and analysed through methodological triangulation in order to get an in-depth understanding about the use of the system by teachers. The key findings from our study were that the peripheral data visualisation tool, by being a distributed, highly visible system, was well integrated in the teachers' practice. The peripheral visualisation served as a trigger for teacher interventions where the teacher could confront the student's level of concentration and provide support when a student needs it. Furthermore, by offloading the secondary tasks of checking the students' level of concentration and progress to the visualisation, most teachers experienced more peace of mind and space to manage their primary teaching practice. Lastly, approximately 95% of 89 students experienced the data visualisation as neutral or motivating, while 5.7% of the students experienced violation of privacy by this medium.\",\n",
              "  'The Design of an Authoring Interface to Make eLearning Content Accessible.[SEP]This paper presents the rationale and design process of an authoring interface that enables didactic experts to create or modify eLearning content to make it accessible by learners with special needs. The tool has been designed according to a methodological framework and a set of guidelines for eLearning accessibility previously developed by our group. A key aspect of our framework consists in helping authors to preserve the didactic quality of the eLearning experiences provided to disabled learners (in particular, visually impaired ones) beyond assuring their mere physical access to online materials. A user-centred design process has been adopted to develop a usable prototype of the authoring interface, named aLearning, that we describe below.'],\n",
              " 13: ['The SKYNIVI Experience: Evoking Startle and Frustration in Dyads and Single Drivers.[SEP]To study naturalistic in-cabin emotion we developed SKYNIVI, a modified open source driving simulator, with scenarios designed to elicit startle and frustration. We target generating these emotions because we believe that by detecting these it will be possible for autonomous vehicles to learn to drive better. We show how to use SKYNIVI to develop datasets that capture naturalistic emotions in drivers and passengers for algorithmic development. We recruited 51 participants as dyads and single drivers to participate in two different scenarios. We show that we were able to evoke hundreds of instances of our target emotions in this cohort and present an analysis of factors we found to impact emotional expression including: scenario design , demographic factors, personality and baseline affect . We find that having a second person in the vehicle impacts observed expressions of emotion even when no difference in baseline affect is reported.',\n",
              "  'Autonomous Vehicle-Cyclist Interaction: Peril and Promise.[SEP]Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.',\n",
              "  'CarNote: Reducing Misunderstanding between Drivers by Digital Augmentation.[SEP]The road environment can be seen as a social situation: Drivers need to coordinate with each other to share the infrastructure. In addition to the driving behaviour itself, lights, horn and speed are the most frequently used means to exchange information, limiting both the range and the bandwidth of the connectivity and leading to misunderstanding and conflict. With everywhere available connectivity and the broad penetration of social network services, the relationship between drivers on the road may gain more transparency, enabling social information to pass through the steel shell of the cars and giving opportunities to reduce misunderstanding and strengthen empathy. In this study, we present \"CarNote\", a concept that aims to reduce misunderstanding and conflict between drivers by showing their emergency driving status to others. This concept was prototyped and evaluated with users in a driving simulator. The results showed that CarNote enhances drivers\\' empathy, increases forgiveness and decreases anger to others on the road.',\n",
              "  \"Learning to Estimate the Travel Time.[SEP]Vehicle travel time estimation or estimated time of arrival (ETA) is one of the most important location-based services (LBS). It is becoming increasingly important and has been widely used as a basic service in navigation systems and intelligent transportation systems. This paper presents a novel machine learning solution to predict the vehicle travel time based on floating-car data. First, we formulate ETA as a pure spatial-temporal regression problem based on a large set of effective features. Second, we adapt different existing machine learning models to solve the regression problem. Furthermore, we propose a Wide-Deep-Recurrent (WDR) learning model to accurately predict the travel time along a given route at a given departure time. We then jointly train wide linear models, deep neural networks and recurrent neural networks together to take full advantages of all three models. We evaluate our solution offline with millions of historical vehicle travel data. We also deploy the proposed solution on Didi Chuxing's platform, which services billions of ETA requests and benefits millions of customers per day. Our extensive evaluations show that our proposed deep learning algorithm significantly outperforms the state-of-the-art learning algorithms, as well as the solutions provided by leading industry LBS providers.\",\n",
              "  'Exploiting Spatio-Temporal Correlations with Multiple 3D Convolutional Neural Networks for Citywide Vehicle Flow Prediction.[SEP]Predicting vehicle flows is of great importance to traffic management and public safety in smart cities, and very challenging as it is affected by many complex factors, such as spatio-temporal dependencies with external factors (e.g., holidays, events and weather). Recently, deep learning has shown remarkable performance on traditional challenging tasks, such as image classification, due to its powerful feature learning capabilities. Some works have utilized LSTMs to connect the high-level layers of 2D convolutional neural networks (CNNs) to learn the spatio-temporal features, and have shown better performance as compared to many classical methods in traffic prediction. However, these works only build temporal connections on the high-level features at the top layer while leaving the spatio-temporal correlations in the low-level layers not fully exploited. In this paper, we propose to apply 3D CNNs to learn the spatio-temporal correlation features jointly from low-level to high-level layers for traffic data. We also design an end-to-end structure, named as MST3D, especially for vehicle flow prediction. MST3D can learn spatial and multiple temporal dependencies jointly by multiple 3D CNNs, combine the learned features with external factors and assign different weights to different branches dynamically. To the best of our knowledge, it is the first framework that utilizes 3D CNNs for traffic prediction. Experiments on two vehicle flow datasets Beijing and New York City have demonstrated that the proposed framework, MST3D, outperforms the state-of-the-art methods.',\n",
              "  'Co-Prediction of Multiple Transportation Demands Based on Deep Spatio-Temporal Neural Network.[SEP]Taxi and sharing bike bring great convenience to urban transportation. A lot of efforts have been made to improve the efficiency of taxi service or bike sharing system by predicting the next-period pick-up or drop-off demand. Different from the existing research, this paper is motivated by the following two facts: 1) From a micro view, an observed spatial demand at any time slot could be decomposed as a combination of many hidden spatial demand bases; 2) From a macro view, the multiple transportation demands are strongly correlated with each other, both spatially and temporally. Definitely, the above two views have great potential to revolutionize the existing taxi or bike demand prediction methods. Along this line, this paper provides a novel Co-prediction method based on Spatio-Temporal neural Network, namely, CoST-Net. In particular, a deep convolutional neural network is constructed to decompose a spatial demand into a combination of hidden spatial demand bases. The combination weight vector is used as a representation of the decomposed spatial demand. Then, a heterogeneous Long Short-Term Memory (LSTM) is proposed to integrate the states of multiple transportation demands, and also model the dynamics of them mixedly. Last, the environmental features such as humidity and temperature are incorporated with the achieved overall hidden states to predict the multiple demands simultaneously. Experiments have been conducted on real-world taxi and sharing bike demand data, results demonstrate the superiority of the proposed method over both classical and the state-of-the-art transportation demand prediction methods.',\n",
              "  'End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks.[SEP]Despite extraordinary progress of Advanced Driver Assistance Systems (ADAS), an alarming number of over 1,2 million people are still fatally injured in traffic accidents every year 1 . Human error is mostly responsible for such casualties, as by the time the ADAS system has alarmed the driver, it is often too late. We present a vision-based system based on deep neural networks with 3D convolutions and residual learning for anticipating the future maneuver based on driver observation. While previous work focuses on hand-crafted features (e.g. head pose), our model predicts the intention directly from video in an end-to-end fashion. Our architecture consists of three components: a neural network for extraction of optical flow, a 3D residual network for maneuver classification and a Long Short-Term Memory network (LSTM) for handling temporal data of varying length. To evaluate our idea, we conduct thorough experiments on the publicly available Brain4Cars benchmark, which covers both inside and outside views for future maneuver anticipation. Our model is able to predict driver intention with an accuracy of 83,12% and 4,07s before the beginning of the maneuver, outperforming state-of-the-art approaches, while considering the inside view only.',\n",
              "  \"Learning Interaction-Aware Probabilistic Driver Behavior Models from Urban Scenarios.[SEP]Human drivers have complex and individual behavior characteristics which describe how they act in a specific situation. Accurate behavior models are essential for many applications in the field of autonomous driving, ranging from microscopic traffic simulation, intention estimation and trajectory prediction, to interactive and cooperative motion planning. Designing such models by hand is cumbersome and inaccurate, especially in urban environments, with their high variety of situations and the corresponding diversity in human behavior. Learning how humans act from recorded scenarios is a promising way to overcome these problems. However, predicting complete trajectories at once is challenging, as one needs to account for multiple hypotheses and long-term interactions between multiple agents. In contrast, we propose to learn Markovian action models with deep neural networks that are conditioned on a driver's route intention (such as turning left or right) and the situational context. Step-wise forward simulation of these models for the different possible routes of all agents allows for multi-modal and interaction-aware scene predictions at arbitrary road layouts. Learning to predict only one time step ahead given a specific route reduces learning complexity, such that simpler and faster models are obtained. This enables the integration into particle-based algorithms such as Monte Carlo tree search or particle filtering. We evaluate the learned model both on its own and integrated into our previously presented dynamic Bayesian network for intention estimation and show that it outperforms our previous hand-tuned rule-based model.\",\n",
              "  'Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning.[SEP]For highly automated driving above SAE level 3, behavior generation algorithms must reliably consider the inherent uncertainties of the traffic environment, e.g. arising from the variety of human driving styles. Such uncertainties can generate ambiguous decisions, requiring the algorithm to appropriately balance low-probability hazardous events, e.g. collisions, and high-probability beneficial events, e.g. quickly crossing the intersection. State-of-the-art behavior generation algorithms lack a distributional treatment of decision outcome. This impedes a proper risk evaluation in ambiguous situations, often encouraging either unsafe or conservative behavior. Thus, we propose a two-step approach for risk-sensitive behavior generation combining offline distribution learning with online risk assessment. Specifically, we first learn an optimal policy in an uncertain environment with Deep Distributional Reinforcement Learning. During execution, the optimal risk-sensitive action is selected by applying established risk criteria, such as the Conditional Value at Risk, to the learned state-action return distributions. In intersection crossing scenarios, we evaluate different risk criteria and demonstrate that our approach increases safety, while maintaining an active driving style. Our approach shall encourage further studies about the benefits of risk-sensitive approaches for self-driving vehicles.',\n",
              "  'Deep, spatially coherent Inverse Sensor Models with Uncertainty Incorporation using the evidential Framework.[SEP]To perform high speed tasks, sensors of autonomous cars have to provide as much information in as few time steps as possible. However, radars, one of the sensor modalities autonomous cars heavily rely on, often only provide sparse, noisy detections. These have to be accumulated over time to reach a high enough confidence about the static parts of the environment. For radars, the state is typically estimated by accumulating inverse detection models (IDMs). We employ the recently proposed evidential convolutional neural networks which, in contrast to IDMs, compute dense, spatially coherent inference of the environment state. Moreover, these networks are able to incorporate sensor noise in a principled way which we further extend to also incorporate model uncertainty. We present experimental results which show that this approach leads to a denser environment perception in only one time step while at the same time reducing the false positive and negative rates.',\n",
              "  \"Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image.[SEP]In this paper, we present a method for estimating a position, size, and orientation using a single monocular image. The proposed method makes use of an inverse perspective mapping to effectively estimate the distance from the image. The proposed method consists of two stages: 1) cancel the pitch and roll motion of the camera using inertial measurement unit and project the corrected front view image onto the bird's eye view using inverse perspective mapping. 2) detect the position, size, and orientation of the vehicle using a convolutional neural network. The camera motion cancellation process makes vanishing point to be located at the same point regardless of the ego vehicle attitude change. Through this process, the projected bird's eye view image can be parallel and linear to the x-y plane of the vehicle coordinate system. The convolutional neural network predicts not only the position and size but also the orientation of the vehicle for the 3D localization. The predicted oriented bounding box from the bird's eye view image is converted in the meter unit by the inverse projection matrix. The proposed method was evaluated on the KITTI raw dataset on the metric of the root mean square error, mean average percentage error, and average precision. Despite the conceptually simple architecture, the proposed method achieves promising performance compared to other image based approaches. The video demonstration is available online [1].\",\n",
              "  'Camera and LiDAR Fusion for On-road Vehicle Tracking with Reinforcement Learning.[SEP]We formulate camera and LiDAR fusion tracking as a sequential decision-making process. With our deep reinforcement learning framework, we try to optimize the tracking trajectory to be as accurate, smooth, and long as possible. In contrast to traditional fusion algorithms involving complex feature and strategy design and hyperparameters tuned for different scenarios, our fusion agent can learn the confidence of each input by tracking the results from raw observation in a data-driven fashion. Given the input states of different sensors, our approach chooses one input with a higher expected cumulative reward as the observation of a Kalman filter to iteratively predict the target position. The expected cumulative reward is estimated with a convolutional neural network, trained with a modified DQN algorithm, which takes inputs from both LiDAR and a camera. Through case studies and quantitative result evaluation on our dataset from the 4th Ring Road in Beijing, our algorithm is validated to achieve more accurate and robust tracking performance.',\n",
              "  \"An Integrated Path-following and Yaw Motion Control Strategy for Autonomous Distributed Drive Electric Vehicles with Differential Steering.[SEP]This paper proposes a novel control strategy integrated path-following with yaw motion control for autonomous distributed drive electric vehicles with differential steering (DS) technology. First, the path-following and vehicle dynamics model, and DS system are introduced and analyzed. Then, the control framework is proposed, where the model predictive control (MPC) is adopted for path-following and yaw motion control. Given the optimized command by MPC, the quadratic programming (QP) algorithm is applied for in-wheel motors' torque allocation optimization. Series of simulation validations are carried out, proving that the proposed strategy can effectively achieve superior path-following effect, guarantee the vehicle yaw stability, and implement the steering control in DS system, simultaneously.\",\n",
              "  \"Predictive Trajectory Planning in Situations with Hidden Road Users Using Partially Observable Markov Decision Processes.[SEP]State of the art emergency brake assistant systems solely based on sensor measurements reduced the number of traffic accidents and casualties drastically in recent years. In order to be able to react on road users who elude a vehicle's field of view because of sensor limits or occlusions, this paper presents an approach to anticipate potential hidden traffic participants in occluded areas in the decision making process of an autonomous vehicle. A Partially Observable Markov Decision Process is used to determine the vehicle's longitudinal motion. Observations are made using the vehicle's field of view. Therefore the field of view is calculated with a generic model of a sensor setup in dependence of the current or the predicted environment. In this way, the vehicle can either observe that it detects a previously hidden road user or receives information that the road is clear. In total, that allows the vehicle to better anticipate future developments. Therefore, assumptions about vehicles that may be located in hidden areas need to be made. We demonstrate the approach in two scenarios. Firstly in a scenario, where the vehicle has to move cautiously into the intersection with a minimum number of actions and secondly in a typical scenario for urban traffic. Evaluation shows, that the approach is able to anticipate hidden road users correctly and act accordingly.\",\n",
              "  'Semi-Active Suspension Control on Bicycles: Anti-Dive during Road Excitation.[SEP]Suspension systems on bicycles have a tendency to severe brake-induced dive-in, caused by the small wheelbase in combination with a high center of gravity. Semi-active dampers allow the implementation of anti-dive functionality, preventing this behavior. Experimental analysis has shown that this yields significant advantages during brake control on level surfaces. In the presence of additional road excitation, however, a strong conflict arises. A specific test case is a bump occurring while braking, when the damping is set to the hardest value in order to mitigate dive-in. A simulative analysis illustrates that especially the dynamic wheel load is affected, which during braking is safety critical. By simulation and experimental implementation it is shown that using a simple semi-active control rule a decent trade-off can be found. Finally, the influence of the actuator response time is evaluated.'],\n",
              " 14: ['Preschoolers understand the representational and communicative nature of iconic gestures.[SEP]Twenty 3.5- to 4-year-olds participated in a study to investigate children’s understanding of the representative and communicative nature of iconic gestures. Two toys, one of them with a sticker attached, were presented to the child. It was not possible to request the toy with the sticker by asking (experimenter wore headphones) or pointing (toys were too close together), but they could show the experimenter which toy they wanted by performing the correct gesture. Children had to generate the correct iconic gestures themselves as the gestures were not modeled during test trials. On 70% of the trials children performed a correct gesture (p = .045), instead of only producing other response types (no response, verbal request, wrong gesture, pointing). This study shows that children understand that iconic gestures can represent objects, and also that they can use iconic gestures to communicate.',\n",
              "  'Gesture structure affects syntactic structure in speech.[SEP]Different functions have been proposed for the hand gestures speakers spontaneously produce while speaking. The Information Packaging Hypothesis (Kita, 2000) states that gestures can structure rich spatio-motoric information into packages suitable for speaking. It therefore predicts that how information is divided over different gestures affects how it is divided over different processing units in speech: clauses. We indeed found that if participants were asked to express the manner and path of a motion in one gesture, they were also more likely to conflate this information into one clause in speech, whereas if they were asked to produce separate gestures, they were more likely to express manner and path in separate clauses too. These results support the view that there are speaker-internal motivations for gesture production. They confirm predictions made by the Information Packaging Hypothesis, which the Lexical Retrieval Hypothesis and the Image Activation Hypothesis do not make.',\n",
              "  'Sign processes in emergence of communication.[SEP]Communication depends on the production and interpretation of representations, but the study of representational processes underlying communication finds little discussion in computational experiments. Here we present an experiment on the emergence of both interpretation and production of multiple representations, with multiple referents, where referential processes can be tracked. Results show the dynamics of semiotic processes during the evolution of artificial creatures and the emergence of a variety of semiotic processes, such as sign production, sign interpretation, and sign-object-interpretant relations.',\n",
              "  \"Understanding users' preferences for surface gestures.[SEP]We compare two gesture sets for interactive surfaces---a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures' authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.\",\n",
              "  'Designer Led Computational Approach to Generate Mappings for Devices with Low Gestural Resolution.[SEP]We present an approach for the semi-automatic generation of gesture mappings for devices with low gestural resolution such as the Myo Armband, an off-the-shelf EMG capture device. As an exemplar interactive task, we use text-entry: a pervasive and highly complex interaction. We quantify data related to interaction combining systematic studies (i.e., error, speed, accuracy) and semi-structured workshops with experts (e.g., cognitive load, heuristics). We then formalize these factors in a mathematical model and use optimization algorithms (i.e. simulated annealing) to find an optimum gesture mapping. We demonstrated our method in a text-entry application (i.e., complex interactive dialogue) comparing our approach with other computationally determined mappings using naive cost functions. Our results showed that the designers mapping (with all factors weighted by designers) presented a good balance on performance in all factors involved (speed, accuracy, comfort, memorability, etc.), consistently performing better than purely computational mappings. The results indicate that our hybrid approach can yield better results than either pure user-driven methodologies or pure data-driven approaches, for our application context featuring a large solution space and complex high-level factors.',\n",
              "  'Designing Mid-Air TV Gestures for Blind People Using User- and Choice-Based Elicitation Approaches.[SEP]Mid-air gestures enable intuitive and natural interactions. However, few studies have investigated the use of mid-air gestures for blind people. TV interactions are one promising use of mid-air gestures for blind people, as \"listening\"\\' to TV is one of their most common activities. Thus, we investigated mid-air TV gestures for blind people through two studies. Study 1 used a user-elicitation approach where blind people were asked to define gestures given a set of commands. Then, we present a classification of gesture types and the frequency of body parts usage. Nevertheless, our participants had difficulty imagining gestures for some commands. Thus, we conducted Study 2 that used a choice-based elicitation approach where the participants selected their favorite gesture from a predefined list of choices. We found that providing choices help guide users to discover suitable gestures for unfamiliar commands. We discuss concrete design guidelines for mid-air TV gestures for blind people.',\n",
              "  'CyclopsRing: Enabling Whole-Hand and Context-Aware Interactions Through a Fisheye Ring.[SEP]This paper presents CyclopsRing, a ring-style fisheye imaging wearable device that can be worn on hand webbings to en- able whole-hand and context-aware interactions. Observing from a central position of the hand through a fisheye perspective, CyclopsRing sees not only the operating hand, but also the environmental contexts that involve with the hand-based interactions. Since CyclopsRing is a finger-worn device, it also allows users to fully preserve skin feedback of the hands. This paper demonstrates a proof-of-concept device, reports the performance in hand-gesture recognition using random decision forest (RDF) method, and, upon the gesture recognizer, presents a set of interaction techniques including on-finger pinch-and-slide input, in-air pinch-and-motion input, palm-writing input, and their interactions with the environ- mental contexts. The experiment obtained an 84.75% recognition rate of hand gesture input from a database of seven hand gestures collected from 15 participants. To our knowledge, CyclopsRing is the first ring-wearable device that supports whole-hand and context-aware interactions.',\n",
              "  \"Small gestures go a long way: how many bits per gesture do recognizers actually need?[SEP]We investigate in this work the effect of bit depth on the performance of today's commonly used nearest-neighbor gesture recognizers. As current bit representations are typically an artifact of today's hardware and file formats, they are not reflective of the true cardinality of gesture data. We show that as few as 4-5 bits per gesture channel (x/y) are enough in order to attain peak recognition for Euclidean, Cosine, DTW, and Hausdorff distances. We also show how reduction in bit depth can lead to 85 times less memory for storing the training set without ruining recognition performance. The results will benefit practitioners of the next age of gesture sensing gadgets and devices that need to optimize speed, memory, and bit depth representation in their software and hardware designs.\",\n",
              "  'Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.[SEP]We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.'],\n",
              " 15: ['Regularized discriminant analysis for high dimensional, low sample size data.[SEP]Linear and Quadratic Discriminant Analysis have been used widely in many areas of data mining, machine learning, and bioinformatics. Friedman proposed a compromise between Linear and Quadratic Discriminant Analysis, called Regularized Discriminant Analysis (RDA), which has been shown to be more flexible in dealing with various class distributions. RDA applies the regularization techniques by employing two regularization parameters, which are chosen to jointly maximize the classification performance. The optimal pair of parameters is commonly estimated via cross-validation from a set of candidate pairs. It is computationally prohibitive for high dimensional data, especially when the candidate set is large, which limits the applications of RDA to low dimensional data.In this paper, a novel algorithm for RDA is presented for high dimensional data. It can estimate the optimal regularization parameters from a large set of parameter candidates efficiently. Experiments on a variety of datasets confirm the claimed theoretical estimate of the efficiency, and also show that, for a properly chosen pair of regularization parameters, RDA performs favorably in classification, in comparison with other existing classification methods.',\n",
              "  'Binary Classifier Calibration Using an Ensemble of Near Isotonic Regression Models.[SEP]Learning accurate probabilistic models from data is crucial in many practical tasks in data mining. In this paper we present a new non-parametric calibration method called Ensemble of Near Isotonic Regression (ENIR). The method can be considered as an extension of BBQ, a recently proposed calibration method, as well as the commonly used calibration method based on isotonic regression (IsoRegC). ENIR is designed to address the key limitation of IsoRegC which is the monotonicity assumption of the predictions. Similar to BBQ, the method post-processes the output of a binary classifier to obtain calibrated probabilities. Thus it can be used with many existing classification models to generate accurate probabilistic predictions. We demonstrate the performance of ENIR on synthetic and real datasets for commonly applied binary classification models. Experimental results show that the method outperforms several common binary classifier calibration methods. In particular on the real data, ENIR commonly performs statistically significantly better than the other methods, and never worse. It is able to improve the calibration power of classifiers, while retaining their discrimination power. The method is also computationally tractable for large scale datasets, as it is O(N log N) time, where N is the number of samples.',\n",
              "  'Transductive Component Analysis.[SEP]In this paper, we study semisupervised linear dimensionality reduction. Beyond conventional supervised methods which merely consider labeled instances, the semisupervised scheme allows to leverage abundant and ample unlabeled instances into learning so as to achieve better generalization performance. Under semisupervised settings, our objective is to learn a smooth as well as discriminative subspace and linear dimensionality reduction is thus achieved by mapping all samples into the subspace. Specifically, we present the transductive component analysis (TCA) algorithm to generate such a subspace founded on a graph-theoretic framework. Considering TCA is nonorthogonal, we further present the orthogonal transductive component analysis (OTCA) algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better discriminating power than TCA. Experiments carried out on synthetic and real-world datasets by OTCA show a clear improvement over the results of representative dimensionality reduction algorithms.',\n",
              "  'Extracting key-substring-group features for text classification.[SEP]In many text classification applications, it is appealing to take every document as a string of characters rather than a bag of words. Previous research studies in this area mostly focused on different variants of generative Markov chain models. Although discriminative machine learning methods like Support Vector Machine (SVM) have been quite successful in text classification with word features, it is neither effective nor efficient to apply them straightforwardly taking all substrings in the corpus as features. In this paper, we propose to partition all substrings into statistical equivalence groups, and then pick those groups which are important (in the statistical sense) as features (named key-substring-group features) for text classification. In particular, we propose a suffix tree based algorithm that can extract such features in linear time (with respect to the total number of characters in the corpus). Our experiments on English, Chinese and Greek datasets show that SVM with key-substring-group features can achieve outstanding performance for various text classification tasks.',\n",
              "  'A parallel learning algorithm for text classification.[SEP]Text classification is the process of classifying documents into predefined categories based on their content. Existing supervised learning algorithms to automatically classify text need sufficient labeled documents to learn accurately. Applying the Expectation-Maximization (EM) algorithm to this problem is an alternative approach that utilizes a large pool of unlabeled documents to augment the available labeled documents. Unfortunately, the time needed to learn with these large unlabeled documents is too high. This paper introduces a novel parallel learning algorithm for text classification task. The parallel algorithm is based on the combination of the EM algorithm and the naive Bayes classifier. Our goal is to improve the computational time in learning and classifying process. We studied the performance of our parallel algorithm on a large Linux PC cluster called PIRUN Cluster. We report both timing and accuracy results. These results indicate that the proposed parallel algorithm is capable of handling large document collections.',\n",
              "  \"A Bayesian Hierarchical Model for Comparing Average F1 Scores.[SEP]In multi-class text classification, the performance (effectiveness) of a classifier is usually measured by micro-averaged and macro-averaged F1 scores. However, the scores themselves do not tell us how reliable they are in terms of forecasting the classifier's future performance on unseen data. In this paper, we propose a novel approach to explicitly modelling the uncertainty of average F1 scores through Bayesian reasoning, and demonstrate that it can provide much more comprehensive performance comparison between text classifiers than the traditional frequentist null hypothesis significance testing (NHST).\"],\n",
              " 16: [\"Detecting eye contact using wearable eye-tracking glasses.[SEP]We describe a system for detecting moments of eye contact between an adult and a child, based on a single pair of gaze-tracking glasses which are worn by the adult. Our method utilizes commercial gaze tracking technology to determine the adult's point of gaze, and combines this with computer vision analysis of video of the child's face to determine their gaze direction. Eye contact is then detected as the event of simultaneous, mutual looking at faces by the dyad. We report encouraging findings from an initial implementation and evaluation of this approach.\",\n",
              "  'VRpursuits: interaction in virtual reality using smooth pursuit eye movements.[SEP]Gaze-based interaction using smooth pursuit eye movements (Pursuits) is attractive given that it is intuitive and overcomes the Midas touch problem. At the same time, eye tracking is becoming increasingly popular for VR applications. While Pursuits was shown to be effective in several interaction contexts, it was never explored in-depth for VR before. In a user study (N=26), we investigated how parameters that are specific to VR settings influence the performance of Pursuits. For example, we found that Pursuits is robust against different sizes of virtual 3D targets. However performance improves when the trajectory size (e.g., radius) is larger, particularly if the user is walking while interacting. While walking, selecting moving targets via Pursuits is generally feasible albeit less accurate than when stationary. Finally, we discuss the implications of these findings and the potential of smooth pursuits for interaction in VR by demonstrating two sample use cases: 1) gaze-based authentication in VR, and 2) a space meteors shooting game.',\n",
              "  'Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets.[SEP]Although gaze is an attractive modality for pervasive interactions, the real-world implementation of eye-based interfaces poses significant challenges, such as calibration. We present Pursuits, an innovative interaction technique that enables truly spontaneous interaction with eye-based interfaces. A user can simply walk up to the screen and readily interact with moving targets. Instead of being based on gaze location, Pursuits correlates eye pursuit movements with objects dynamically moving on the interface. We evaluate the influence of target speed, number and trajectory and develop guidelines for designing Pursuits-based interfaces. We then describe six realistic usage scenarios and implement three of them to evaluate the method in a usability study and a field study. Our results show that Pursuits is a versatile and robust technique and that users can interact with Pursuits-based interfaces without prior knowledge or preparation phase.'],\n",
              " 17: [\"Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation.[SEP]We present Haptic Links, electro-mechanically actuated physical connections capable of rendering variable stiffness between two commodity handheld virtual reality (VR) controllers. When attached, Haptic Links can dynamically alter the forces perceived between the user's hands to support the haptic rendering of a variety of two-handed objects and interactions. They can rigidly lock controllers in an arbitrary configuration, constrain specific degrees of freedom or directions of motion, and dynamically set stiffness along a continuous range. We demonstrate and compare three prototype Haptic Links: Chain, Layer-Hinge, and Ratchet-Hinge. We then describe interaction techniques and scenarios leveraging the capabilities of each. Our user evaluation results confirm that users can perceive many two-handed objects or interactions as more realistic with Haptic Links than with typical unlinked VR controllers.\",\n",
              "  \"Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality.[SEP]Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.\",\n",
              "  'Haptic Device Control - Will it Fit Standardized Input Models?[SEP]Over recent years a wide variety of interaction devices involving haptic feedback have been brought to the market, but they vary widely in terms of input measures recorded. These range from one dimensional input on a haptic feedback steering wheel to a six degree of freedom position and orientation device and further, to assemblies of such devices. On the surface most of the variations can be accommodated logically with standardized input models combining existing logical input devices and haptic feedback processes as acknowledgement/echos. However it is very uncertain whether such a model can adequately model the system requirements for effective haptic feedback.'],\n",
              " 18: ['Graphics processing on a graphics supercomputer.[SEP]A description is given of the Titan Graphics Supercomputer. The primary design philosophy was to have as little redundant hardware as possible and to make as much of the hardware available to compiled application code as possible. This led to a design with multiple parallel processors, each with an integer unit and a vector floating-point unit. The system provides 3D graphics and image processing, using the main processors for most computations. The graphics subsystem consists of only a frame buffer with rasterization (vector and triangle pixel drawing) support. The Titan architecture provides a very good balance of computation and graphics but to make it more competitive in graphics or imaging-intensive applications, a special-purpose accelerator also fits into the architecture.< >',\n",
              "  'A display system for the Stellar graphics supercomputer model GS1000.[SEP]This paper describes a high performance display system that has been incorporated into the overall architecture of the Stellar Graphics Supercomputer Model GS1000. The display system is tightly coupled to the CPU, memory system and vector processing unit of this supercomputer, and is capable of rendering 150,000 shaded triangles/sec, and 600,000 short vectors/sec. The goal of the architecture is to share hardware resources between the CPU and display system and achieve a high bandwidth connection between them. This coupling of the display system and the processor, the architecture of the rendering processor, and the two ASICs that are used to implement the rendering processor are described.In addition, the display system architecture is contrasted to other approaches to high performance graphics, and design trade-offs and possible extensions are described. The implementation of popular display algorithms on the architecture is discussed, and their performance specified. The reader is advised that Stellar Computer Inc. is seeking patent protection for work described in this paper.',\n",
              "  'The Truga001: A Scalable Rendering Processor.[SEP]To support the increasing interest in virtual reality systems, computer graphics must now be extremely powerful to obtain realistic images. VR systems are based on two technical tools: graphics accelerators and pixel renderers. The paper discusses the Truga001 single-chip rendering processor for virtual reality and multimedia systems. It embeds 12 graphics processors and 7 special modules in a single chip.',\n",
              "  'An efficient multi-resolution framework for high quality interactive rendering of massive point clouds using multi-way kd-trees.[SEP]We present an efficient technique for out-of-core multi-resolution construction and high quality interactive visualization of massive point clouds. Our approach introduces a novel hierarchical level of detail (LOD) organization based on multi-way kd-trees, which simplifies memory management and allows control over the LOD-tree height. The LOD tree, constructed bottom up using a fast high-quality point simplification method, is fully balanced and contains all uniformly sized nodes. To this end, we introduce and analyze three efficient point simplification approaches that yield a desired number of high-quality output points. For constant rendering performance, we propose an efficient rendering-on-a-budget method with asynchronous data loading, which delivers fully continuous high quality rendering through LOD geo-morphing and deferred blending. Our algorithm is incorporated in a full end-to-end rendering system, which supports both local rendering and cluster-parallel distributed rendering. The method is evaluated on complex models made of hundreds of millions of point samples.',\n",
              "  \"Optimized Pattern-Based Adaptive Mesh Refinement Using GPU.[SEP]The high performance of GPUs and the increasing use of their programming mechanisms have fostered the development of graphics applications that better exploit the raw power of these devices to achieve higher levels of realism. Silhouette refinement, as one of the techniques that help to improve realism, has profited from GPUs' advances in recent years. In this paper, we present a method for triangular mesh refinement which alleviates the problem of rugged silhouettes. We demonstrate that, through a clever indexing scheme, our method is able to use adaptive patterns in an optimized way, taking full advantage of the GPU's parallelism. The ideas we used were adapted from distinct previous works, but our method presents astounding performance gains. Also, our method works very well with existing meshes, therefore, it can improve the visual appearance of existing models without mesh redesign.\",\n",
              "  'Optimized View-Dependent Rendering for Large Polygonal Datasets.[SEP]In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.',\n",
              "  'Volume Rendering on a Distributed Memory Parallel Computer.[SEP]A prototype implementation of a splatting volume renderer (SVR) on a commercially available distributed memory MIMD (multiple instruction stream, multiple data stream) parallel processor, the nCUBE2, is described. Some relatively good rendering times can be achieved with the nCUBE SVR. Message-passing bottlenecks occur when large numbers of floating-point values have to be collected from every processor for every picture. For large images this is a severe limitation. An initial implementation of a SVR on a distributed memory parallel computer demonstrates the need for parallel computers with high-bandwidth connections between processors, and also for new parallelizable volume rendering algorithms.< >',\n",
              "  'Algorithms for rendering realistic terrain image sequences and their parallel implementation.[SEP]We present algorithms for rendering realistic images of large terrains and their implementation on a parallel computer for rapid production of terrain-animation sequences. “Large” means datasets too large for RAM. A hybrid ray-casting and projection technique incorporates quadtree subdivision techniques and filtering using precomputed bit masks. Hilbert space-filling curves determine the imagepixel rendering order. A parallel version of the algorithm is based on a Meiko parallel computer architecture, designed to relieve dataflow bottlenecks and exploit temporal image coherence. Our parallel system, incorporating 26 processors, can generate a full color-terrain image at video resolution (without noticable aliasing artifacts) every 2 s, including I/O and communication overheads.',\n",
              "  'A sorting classification of parallel rendering.[SEP]We describe a classification scheme that we believe provides a more structured framework for reasoning about parallel rendering. The scheme is based on where the sort from object coordinates to screen coordinates occurs, which we believe is fundamental whenever both geometry processing and rasterization are performed in parallel. This classification scheme supports the analysis of computational and communication costs, and encompasses the bulk of current and proposed highly parallel renderers - both hardware and software. We begin by reviewing the standard feed-forward rendering pipeline, showing how different ways of parallelizing it lead to three classes of rendering algorithms. Next, we consider each of these classes in detail, analyzing their aggregate processing and communication costs, possible variations, and constraints they may impose on rendering applications. Finally, we use these analyses to compare the classes and identify when each is likely to be preferable.< >'],\n",
              " 19: ['Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking.[SEP]Mining for frequent item sets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficient mining of frequent item sets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.',\n",
              "  'Optimizing Constraint-Based Mining by Automatically Relaxing Constraints.[SEP]In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.',\n",
              "  'DualMiner: a dual-pruning algorithm for itemsets with constraints.[SEP]Constraint-based mining of itemsets for questions such as \"find all frequent itemsets where the total price is at least $50\" has received much attention recently. Two classes of constraints, monotone and antimonotone, have been identified as very useful. There are algorithms that efficiently take advantage of either one of these two classes, but no previous algorithms can efficiently handle both types of constraints simultaneously. In this paper, we present the first algorithm (called DualMiner) that uses both monotone and antimonotone constraints to prune its search space. We complement a theoretical analysis and proof of correctness of DualMiner with an experimental study that shows the efficacy of DualMiner compared to previous work.',\n",
              "  'CoLe: A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection.[SEP]We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.',\n",
              "  'MMAC: A New Multi-Class, Multi-Label Associative Classification Approach.[SEP]Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.',\n",
              "  'Brute-Force Mining of High-Confidence Classification Rules.[SEP]This paper investigates a brute-force technique for mining classification rules from large data sets. We employ an association rule miner enhanced with new pruning strategies to control combinatorial explosion in the number of candidates counted with each database pass. The approach effectively and efficiently extracts high confidence classification rules that apply to most if not all of the data in several classification benchmarks.'],\n",
              " 20: ['A Strategy for Boundary Detection Combining Region and Edge Information.[SEP]A method to detect boundaries in in natural color images is here proposed, combining edge information and region information. This unsupervised fully automatic process uses edge map information to eliminate false boundaries in the image region map, and region map information to remove noise in the image edge map. Thus, it integrates these two maps into a single one to get the final result. This proposal is extensively compared to the multi-label graph cut approach, since both approaches are unsupervised and fully automatic, as well as receive the same two inputs, although performing different processing. Experiments performed on a large set of natural color images were the base for such comparison. The results show that the approach here proposed is promising, besides allowing interesting interpretations about boundary detection.',\n",
              "  'How to Complete Any Segmentation Process Interactively via Image Foresting Transform.[SEP]The segmentation of poorly defined structures in medical imaging and heterogeneous objects in natural images usually call for considerable user assistance. Consequently, automatic results are often far from desirable and interactive repairs become an essential feature to consider. However, how to import automatic results obtained from external processes and complete their segmentation interactively is an issue, since different tools are based on different optimization criteria. Another simpler related problem concerns how to continue a previous segmentation obtained by the same interactive tool. This ability to stop and later resume interactive segmentation sessions is specially important for tridimensional images and video. However, very often crucial data (e.g., the history of user input) are no longer available; or are no longer reliable, as consequence of some post-processing. How to offer a comprehensive recovery and resume capability, comprising all these different scenarios, under the framework of the \"Image Foresting Transform\" (IFT) is the central focus of this paper.',\n",
              "  'Interactive Segmentation by Image Foresting Transform on Superpixel Graphs.[SEP]There are many scenarios in which user interaction is essential for effective image segmentation. In this paper, we present a new interactive segmentation method based on the Image Foresting Transform (IFT). The method over segments the input image, creates a graph based on these segments (super pixels), receives markers (labels) drawn by the user on some super pixels and organizes a competition to label every pixel in the image. Our method has several interesting properties: it is effective, efficient, capable of segmenting multiple objects in almost linear time on the number of super pixels, readily extendable through previously published techniques, and benefits from domain-specific feature extraction. We also present a comparison with another technique based on the IFT, which can be seen as its pixel-based counterpart. Another contribution of this paper is the description of automatic (robot) users. Given a ground truth image, these robots simulate interactive segmentation by trained and untrained users, reducing the costs and biases involved in comparing segmentation techniques.',\n",
              "  'Spatio-Temporal Frames in a Bag-of-Visual-Features Approach for Human Actions Recognition.[SEP]The recognition of human actions from videos has several interesting and important applications, and a vast amount of different approaches has been proposed for this task in different settings. Such approaches can be broadly categorized in model-based and model-free. Typically, model-based approaches work only in very constrained settings, and because of that, a number of model-free approaches appeared in the last years. Among them, those based in bag-of-visual-features (BoVF) have been proving to be the most consistently successful, being used by several independent authors. For videos to be represented by BoVFs, though, an important issue that arises is how to represent dynamic information. Most existing proposals consider the video as a spatio-temporal volume and then describe \"volumetric patches\" around 3D interest points. In this work, we propose to build a BoVF representation for videos by collecting 2D interest points directly. The basic idea is to gather such points not only from the traditional frames (xy planes), but also from those planes along the time axis, which we call the spatio-temporal frames. Our assumption is that such features are able to capture dynamic information from the videos, and are therefore well-suited to recognize human actions from them, without the need of 3D extentions for the descriptors. In our experiments, this approach achieved state-of-the-art recognition rates on a well-known human actions database, even when compared to more sophisticated schemes.',\n",
              "  'A survey on activity recognition and behavior understanding in video surveillance.[SEP]This paper provides a comprehensive survey for activity recognition in video surveillance. It starts with a description of simple and complex human activity, and various applications. The applications of activity recognition are manifold, ranging from visual surveillance through content based retrieval to human computer interaction. The organization of this paper covers all aspects of the general framework of human activity recognition. Then it summarizes and categorizes recent-published research progresses under a general framework. Finally, this paper also provides an overview of benchmark databases for activity recognition, the market analysis of video surveillance, and future directions to work on for this application.',\n",
              "  'Online robust action recognition based on a hierarchical model.[SEP]Action recognition solely based on video data has known to be very sensitive to background activity, and also lacks the ability to discriminate complex 3D motion. With the development of commercial depth cameras, skeleton-based action recognition is becoming more and more popular. However, the skeleton-based approach is still very challenging because of the large variation in human actions and temporal dynamics. In this paper, we propose a hierarchical model for action recognition. To handle confusing motions, a motion-based grouping method is proposed, which can efficiently assign each video a group label, and then for each group, a pre-trained classifier is used for frame-labeling. Unlike previous methods, we adopt a bottom-up approach that first performs action recognition for each frame. The final action label is obtained by fusing the classification to its frames, with the effect of each frame being adaptively adjusted based on its local properties. To achieve online real-time performance and suppressing noise, bag-of-words is used to represent the classification features. The proposed method is evaluated using two challenge datasets captured by a Kinect. Experiments show that our method can robustly recognize actions in real-time.',\n",
              "  'A co-boost framework for learning object categories from Google Images with 1st and 2nd order features.[SEP]Conventional object recognition techniques rely heavily on manually annotated image datasets to achieve good performances. However, collecting high quality datasets is really laborious. The image search engines such as Google Images seem to provide quantities of object images. Unfortunately, a large portion of the search images are irrelevant. In this paper, we propose a semi-supervised framework for learning visual categories from Google Images. We exploit a co-training algorithm, the CoBoost algorithm, and integrate it with two kinds of features, the 1st and 2nd order features, which define bag of words representation and spatial relationship between local features, respectively. We create two boosting classifiers based on the 1st and 2nd order features in the training, during which one classifier provides labels for the other. The 2nd order features are generated dynamically rather than extracted exhaustively to avoid high computation. An active learning technique is also introduced to further improve the performance. Experimental results show that the object models learned from Google Images by our method are competitive with the state-of-the-art unsupervised approaches and some supervised techniques on the standard benchmark datasets.',\n",
              "  'Fast Feature-Oriented Visual Connection for Large Image Collections.[SEP]Deriving the visual connectivity across large image collections is a computationally expensive task. Different from current image‐oriented match graph construction methods which build on pairwise image matching, we present a novel and scalable feature‐oriented image matching algorithm for large collections. Our method improves the match graph construction procedure in three ways. First, instead of building trees repeatedly, we put the feature points of the input image collection into a single kd‐tree and select the leaves as our anchor points. Then we construct an anchor graph from which each feature can intelligently find a small portion of related candidates to match. Finally, we design a new form of adjacency matrix for fast feature similarity measuring, and return all the matches in different photos across the whole dataset directly. Experiments show that our feature‐oriented correspondence algorithm can explore visual connectivity between images with significant improvement in speed.',\n",
              "  'Delimitation of Regions of Interest in Similarity Queries Visualization.[SEP]In Content Based Image Retrieval (CBIR) systems, the visualization of queries allows to add the human visual perception in the analysis process and facilitate the discovery of knowledge. Content-based queries can be performed comparing features extracted from images, such as color, texture, and shape. In this paper we propose ways to delimit the region of interest to be visualized in the execution of queries by similarity in complex datasets. Limiting the amount of data to be visualized allows keeping the distribution of mapped data closer to the real distribution, besides allowing the application of more expensive computational methods for multidimensional projection. The proposed techniques were implemented in a prototype that allows visualizing only the region in which the query is being performed, mapping the data in three-dimensional spaces and allowing users to interact with them, being favored by human perception to improve the analysis and understanding of the data.',\n",
              "  'Computer-Aided Diagnosis in Brain Computed Tomography Screening.[SEP]Currently, interpretation of medical images is almost exclusively made by specialized physicians. Although, the next decades will most certainly be of change and computer-aided diagnosis systems will play an important role in the reading process. Assisted interpretation of medical images has become one of the major research subjects in medical imaging and diagnostic radiology. From a methodological point of view, the main attraction for the resolution of this kind of problem arises from the combination of the image reading made by the radiologists, with the results obtained from using Artificial Intelligence based applications that will contribute to the reduction and eventually the elimination of perception errors. This article describes how machine learning algorithms can help distinguish normal readings in brain Computed Tomography from all its variations. The goal is to have a system that is able to detect normal appearing structures, thus identifying normal studies, making the reading by the radiologist unnecessary for a large proportion of the brain Computed Tomography scans.',\n",
              "  'Effect of layer-wise fine-tuning in magnification-dependent classification of breast cancer histopathological image.[SEP]A large and balanced training data are the foremost requirement in proper convergence of a deep convolutional neural network (CNN). Medical data always suffer from the problem of unbalancing and inadequacy that makes it difficult to train CNN from scratch. It is known that the transfer learning approach provides great potential to deal with inadequate dataset besides the benefit of faster training. The efficient transfer of knowledge from natural images to histopathological images has yet to be achieved. In view of the foregoing, an attempt has been made toward the classification of BreakHis dataset using pre-trained ‘AlexNet’ model with a suitable fine-tuning approach. The effective depth of fine-tuning is also determined at different levels of magnification (40×, 100×, 200× and 400 ×). The experimental trials conform that the moderate level of fine-tuning is an optimum choice for the classification of magnification-dependent histology images in contrast to the shallow and deep tuning of the pre-trained network which in turn depends on the size and relative distribution of a dataset. Additionally, the layer-wise fine-tuning approach provides a neck-to-neck performance with the latest state-of-the-art developments.',\n",
              "  'Semi-supervised Tissue Segmentation of 3D Brain MR Images.[SEP]Clustering algorithms have been popularly applied in tissue segmentation in MRI. However, traditional clustering algorithms could not take advantage of some prior knowledge of data even when it does exist. In this paper, we propose a new approach to tissue segmentation of 3D brain MRI using semi-supervised spectral clustering. Spectral clustering algorithm is more powerful than traditional clustering algorithms since it models the voxel-to-voxel relationship as opposed to voxel-to-cluster relationships. In the semi-supervised spectral clustering, two types of instance-level constraints: must-link and cannot-link as background prior knowledge are incorporated into spectral clustering, and the self-tuning parameter is applied to avoid the selection of the scaling parameter of spectral clustering. The semi-supervised spectral clustering is an effective tissue segmentation method because of its advantages in (1) better discovery of real data structure since there is no cluster shape restriction, (2) high quality segmentation results as it can obtain the global optimal solutions in the relaxed continuous domain by eigen-decomposition and combines the pairwise constraints information. Experimental results on simulated and real MRI data demonstrate its effectiveness.',\n",
              "  'Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring.[SEP]Locality-Sensitive Hashing (LSH) is one of the most popular methods for c-Approximate Nearest Neighbor Search (c-ANNS) in high-dimensional spaces. In this paper, we propose a novel LSH scheme based on the Longest Circular Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee. We introduce a novel concept of LCCS and a new data structure named Circular Shift Array (CSA) for k-LCCS search. The insight of LCCS search framework is that close data objects will have a longer LCCS than the far-apart ones with high probability. LCCS-LSH is LSH-family-independent, and it supports c-ANNS with different kinds of distance metrics. We also introduce a multi-probe version of LCCS-LSH and conduct extensive experiments over five real-life datasets. The experimental results demonstrate that LCCS-LSH outperforms state-of-the-art LSH schemes.',\n",
              "  'PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension.[SEP]Similarity search has been widely used in various fields, particularly in the Alibaba ecosystem. The open-source solutions to a similarity search of vectors can only support a query with a single vector, whereas real-life scenarios generally require a processing of compound queries. Moreover, existing open-source implementations only provide runtime libraries, which have difficulty meeting the requirements of industrial applications. To address these issues, we designed a novel scheme for extending the index-type of PostgreSQL (PG), which enables a similar vector search and achieves a high-performance level and strong reliability of PG. Two representative types of nearest neighbor search (NNS) algorithms are presented herein. These algorithms achieve a high performance, and afford advantages such as the support of composite queries and seamless integration of existing business data. The other NNS algorithms can be easily implemented under the proposed framework. Experiments were conducted on large datasets to illustrate the efficiency of the proposed retrieval mechanism.',\n",
              "  'A General and Efficient Querying Method for Learning to Hash.[SEP]As an effective solution to the approximate nearest neighbors (ANN) search problem, learning to hash (L2H) is able to learn similarity-preserving hash functions tailored for a given dataset. However, existing L2H research mainly focuses on improving query performance by learning good hash functions, while Hamming ranking (HR) is used as the default querying method. We show by analysis and experiments that Hamming distance, the similarity indicator used in HR, is too coarse-grained and thus limits the performance of query processing. We propose a new fine-grained similarity indicator, quantization distance (QD), which provides more information about the similarity between a query and the items in a bucket. We then develop two efficient querying methods based on QD, which achieve significantly better query performance than HR. Our methods are general and can work with various L2H algorithms. Our experiments demonstrate that a simple and elegant querying method can produce performance gain equivalent to advanced and complicated learning algorithms.'],\n",
              " 21: ['Variolite: Supporting Exploratory Programming by Data Scientists.[SEP]How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.',\n",
              "  'Consistency maintenance in real-time collaborative graphics editing systems.[SEP]Real-time collaborative graphics editing systems allow a group of users to view and edit the same graphics document at the same time from geographically dispersed sites connected by communication networks. Consistency maintenance in the face of concurrent accesses to shared objects is one of the core issues in the design of these types of systems. In this article, we propose an object-level multiversioning approach to consistency maintenance in real-time collaborative graphic editors. This approach is novel in achieving intention preservation and convergence, in preserving the work concurrently produced by multiple users in the face of conflict, and in minimizing the number of object versions for conflict resolution. Major technical contributions of this work include a formal specification of a unique combined effect for an arbitrary group of conflict and compatible operations, a distributed algorithm for incremental creation of multiple object versions, a consistent object identification scheme for multiple object versions, and a convergent layering scheme for overlapping objects. All algorithms and schemes presented in this article have been implemented in an Internet-based GRACE (graphics collaborative editing) system.',\n",
              "  'DistEdit: A Distributed Toolkit for Supporting Multiple Group Editors.[SEP]The purpose of our project is to provide toolkits for building applications that support collaboration between people in distributed environments. In this paper, we describe one such toolkit, called DistEdit, that can be used to build interactive group editors for distributed environments. This toolkit has the ability to support different editors simultaneously and provides a high degree of fault-tolerance against machine crashes. To evaluate the toolkit, we modified two editors to make use of the toolkit. The resulting editors allow users to take turns at making changes while other users observe the changes as they occur. We give an evaluation of the toolkit based on the development and use of these editors.',\n",
              "  'Elucidate: employing information visualisation to aid pedagogy for students.[SEP]Understanding the intricacies behind concurrency within object-oriented programming languages has always been a challenge for undergraduate students. While the lecture is a relatively passive learning experience for the student, the use of software visualisation offers the chance to examine the concepts covered in the lecture in an interactive, visual environment. Students can add further dimensions and greater depth to their understanding previously hindered by the pedagogy of this passive environment. Elucidate makes use of the JDI architecture in the Java language to create its own environment that allows students to execute any program within it. Elucidate utilises several information workspaces, each presenting a different perspective about the information, thus facilitating a students ability to employ it in a manner that best allows them to construct their own understanding. Students are able to navigate around multiple views, and through various levels of abstraction, revealing the inner workings and sequence of events in what would otherwise be a black-box program.',\n",
              "  'Viewing Object-Oriented Software with MetricAttitude: An Empirical Evaluation.[SEP]MetricAttitude is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In this paper, we present a preliminary empirical investigation based on a questionnaire-based survey to assess Metric Attitude with respect to source code comprehension tasks. Participants involved in this study were Computer Science students and software professionals. The results suggest that Metric Attitude is a viable means to comprehend source code and that both kinds of participants in the empirical investigation considered it to be appropriate in source code comprehension.',\n",
              "  'Enhancing Software Visualization with Information Retrieval.[SEP]I have enhanced Metric Attitude. It is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In particular, we have integrated an Information Retrieval engine and named this new version of visualization tool as Metric Attitude++. It allows the user to formulate a textual query and to show on the visual representation of the subject software the elements that are more similar to that query. This could be useful in all those cases in which a user needs to identify (or to localize) features implemented in the source code. Several filters are also available to hide possibly irrelevant details and to ease the browsing and then the comprehension of a software system. Finally, we have applied Metric Attitude++ on a number of object-oriented software systems. In this paper, we report preliminary results of a quantitative study on a widely studied open-source software, namely JEdit. On the basis of our results it seems that Metric Attitude++ can be effectively applied to different kinds of source code comprehension tasks and to concept location in source code, in particular.'],\n",
              " 22: ['Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation.[SEP]The rich literature on multiple object tracking (MOT) conclusively demonstrates that humans are able to visually track a small number of objects (Pylyshyn & Storm 1988, Alvarez & Franconeri 2007). There is considerably less agreement on what perceptual and cognitive processes are involved. While it is clear that MOT is attentionally demanding, various accounts of MOT performance centrally involve pre-attentional mechanisms as well. In this paper we present an account of object tracking in the ARCADIA framework (Bridewell & Bello 2015) that treats MOT as dependent upon both pre-attentive and attention-bound processes. We show that with minimal addition this model replicates a variety of core phenomena in the MOT literature and provides an algorithmic explanation of human performance limitations.',\n",
              "  'A Bayesian Model of the Effect of Object Context on Visual Attention.[SEP]Research in visual cognition has demonstrated that scene understanding is influenced by the contextual properties of objects, and a number of computational models have been proposed that capture specific context effects. However, a general model that predicts the fit of an arbitrary object with the context established by the rest of the scene is until now lacking. In this paper, we explain the contextual fit of objects in visual scenes using Bayesian topic models, which we induce from a database of annotated images. We evaluate our models firstly on synthetic object intrusion data, and then on eye-tracking data from a spot-the-difference task and from an object naming experiment. For the synthetic data, we find that our models are able to detect object intrusions accurately. For the eye-tracking data, we show that context scores derived from our models are associated with fixation latencies on target objects.',\n",
              "  'Inattentional Blindness in Visual Search.[SEP]Models of visual salience normally belong to one of two camps: models such as Experience Guided Search (E-GS), which emphasize top-down guidance based on task features, and models such as Attention as Information Maximisation (AIM), which emphasize the role of bottom-up saliency. In this paper, we show that E-GS and AIM are structurally similar and can be unified to create a general model of visual search with includes a generic prior over potential non-task related objects. We demonstrate that this model displays inattentional blindness, and that blindness can be modulated by adjusting the relative precisions of several terms within the model. At the same time, our model correctly accounts for a series of classical visual search results.',\n",
              "  'Learning and Variability in Spiking Neural Networks.[SEP]Neural networks exhibit ongoing, spatio-temporal patterns of spiking activity. Evidence shows that these patterns are metastable, i.e. temporary, transient, and non-stationary. Metastability is theorized to be adaptive for neural and cognitive function, but learning must somehow remain stable in the context of highly variable spike dynamics. In the present study, a neural network learning algorithm is developed to co-exist with intrinsic variability that arises from regulating spike propagation to stay near its critical branching point. The learning algorithm is based on reinforcement traces stored at synapses that change much more slowly than synaptic switches triggered to maintain critical branching. As a result, learning establishes a stable synaptic space within which variability and metastability can arise from critical branching. Model efficacy is demonstrated using time-delayed XOR learning, and spike dynamics are compared with evidence of metastability in hippocampal recordings.',\n",
              "  'Improving with Practice: A Neural Model of Mathematical Development.[SEP]The ability to improve in speed and accuracy as a result of repeating some task is an important hallmark of intelligent biological systems. We model the progression from a counting-based strategy for addition to a recall-based strategy. The model consists of two networks working in parallel: a slower basal ganglia loop, and a faster cortical network. The slow network methodically computes the count from one digit given another, corresponding to the addition of two digits, while the fast network gradually \"memorizes\" the output from the slow network. The faster network eventually learns how to add the same digits that initially drove the behaviour of the slower network. Performance of this model is demonstrated by simulating a fully spiking neural network that includes basal ganglia, thalamus and various cortical areas.',\n",
              "  'Thermodynamics and Cognition: Towards a Lawful Explanation of the Mind.[SEP]An argument is developed to show that the theoretical methods of description for biological and physical systems can be corroborated by appealing to the second law of thermodynamics. The separation dates back to Modern western philosophy, but we show that the second law’s influence on the evolutionary history of life at the scale of the global Earth system—a system that has demonstrated an exponential increase of entropy production over time— justifies rescinding this separation. From this perspective it appears that the necessity of ever increasing entropy in nature may constrain the organization and behavior of living organisms and cognitive processes. We suggest a new framework for understanding cognition by explaining memory at the scale of the brain-body-environment system with respect to its role in increasing entropy in nature. This framework, if developed further, may lead to a fruitful understanding of cognition by appealing to the necessity of physical laws.',\n",
              "  'This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.[SEP]This project represents a first step towards bridging the gap between HCI and cognition research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.',\n",
              "  'Visualizing and manipulating brain dynamics.[SEP]Brain is not a mere input-output information transformation system, but a dynamical system that generates spontaneous spatiotemporal patterns even without sensory inputs, executed movements, or cognitive tasks. These spontaneously generated patterns by brain dynamics are called spontaneous brain activities for experimental animals, and resting state brain activities for humans. The resting state brain activity of an individual contains much information about age, cognitive capability, mental disorder etc. By combining information decoding from brain activity and its neurofeedback in reinforcement learning paradigms, we can unconsciously control brain activity patterns corresponding to specific information. This leads to therapies of psychiatric disorders, unconscious manipulation of facial preferences, color qualia, confidence in decision making, increase of cognitive capability, etc. Ubicomp community can expect this technology will soon be available in much cheaper and lighter devices such as EEG and near infrared spectroscopy instead of heavy and expensive fMRI or MEG.',\n",
              "  'Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks.[SEP]Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential value for brain sensing in HCI user studies. Research has shown that, although large head movement significantly affects fNIRS data, typical keyboard use, mouse movement, and non-task-related verbalisations do not affect measurements during Verbal tasks. This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings, and 2) significantly extending our understanding of how artefacts affect recordings during Spatial tasks, since much of user interfaces and interaction is inherently spatial. Our results show that artefacts have a significantly different impact during Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool within HCI user studies.',\n",
              "  \"Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze.[SEP]We introduce an image annotation approach for the analysis of volumetric electron microscopic imagery of brain tissue. The core task is to identify and link tubular objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain tissue. In our approach an individual 'flies' through the 3D data at a high speed and maintains eye gaze focus on a single neuronal fiber, aided by navigation with a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing). In a participant experiment we validate the approach by demonstrating a tracing accuracy of about the respective radiuses of the traced fibers with browsing speeds of up to 40 brain sections per second.\",\n",
              "  'NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity.[SEP]We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.',\n",
              "  \"The Neuron Navigator: Exploring the information pathway through the neural maze.[SEP]Recent advances in microscopic imaging technology have enabled neuroscientists to obtain unprecedentedly clear images of neurons. To extract additional knowledge from the tangled neurons, for example, their connective relationships, is key to understanding how information is processed and transmitted within the brain. In this paper, we will introduce our recent endeavor, the Neuron Navigator (NNG), which integrates a 3D neuron image database into an easy-to-use visual interface. Via a flexible and user-friendly interface, NNG is designed to help researchers analyze and observe the connectivity within the neural maze and discover possible pathways. With NNG's 3D neuron image database, researchers can perform volumetric searches using the location of neural terminals, or the occupation of neuron volumes within the 3D brain space. Also, the presence of the neurons under a combination of spatial restrictions can be shown as well. NNG is a result of a multi-discipline collaboration between neuroscientists and computer scientists, and NNG has now been implemented on a coordinated brain space, that being, the Drosophila (fruit fly) brain. NNG is accessible through: http://211.73.64.34/NNG.\"],\n",
              " 23: ['Visual Exploration of Sparse Traffic Trajectory Data.[SEP]In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.',\n",
              "  'Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit.[SEP]The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.',\n",
              "  'Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats.[SEP]We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.',\n",
              "  'Mining large-scale, sparse GPS traces for map inference: comparison of approaches.[SEP]We address the problem of inferring road maps from large-scale GPS traces that have relatively low resolution and sampling frequency. Unlike past published work that requires high-resolution traces with dense sampling, we focus on situations with coarse granularity data, such as that obtained from thousands of taxis in Shanghai, which transmit their location as seldom as once per minute. Such data sources can be made available inexpensively as byproducts of existing processes, rather than having to drive every road with high-quality GPS instrumentation just for map building - and having to re-drive roads for periodic updates. Although the challenges in using opportunistic probe data are significant, successful mining algorithms could potentially enable the creation of continuously updated maps at very low cost.',\n",
              "  'Traveling Salesman in Reverse: Conditional Markov Entropy for Trajectory Segmentation.[SEP]We are interested in inferring the set of waypoints (or intermediate destinations) of a mobility trajectory in the absence of timing information. We find that, by mining a dataset of real mobility traces, computing the entropy of conditional Markov trajectory enables us to uncover waypoints, even though no timing information nor absolute geographic location is provided. We build on this observation and design an efficient algorithm for trajectory segmentation. Our empirical evaluation demonstrates that the entropy-based heuristic used by our segmentation algorithm outperforms alternative approaches as it is 43% more accurate than a geometric approach and 20% more accurate than path-stretch based approach. We further explore the link between trajectory entropy, mobility predictability and the nature of intermediate locations using a route choice model on real city maps.',\n",
              "  \"CityMomentum: an online approach for crowd behavior prediction at a citywide level.[SEP]Human movements are difficult to predict, especially, when we consider rare behaviors that deviate from normal daily routines. By tracing the behavior of a person over a long period, we can model their daily routines and predict periodical behaviors, whereas rare behaviors, such as participating in the New Year's Eve countdown, can hardly be predicted readily and thus they have usually been treated as outliers of the daily routines in most existing studies. However, for scenarios such as emergency management or intelligent traffic regulation, we are more interested in rare behaviors than daily routines. Using human mobility Big Data, the rare behavior of each individual in a social crowd is no longer rare and thus it may be predicted when we analyze the crowd behavior at a citywide level. Therefore in this study, instead of predicting movement based on daily routines, we make short-term predictions based on the recent movement observations. We propose a novel model called CityMomentum as a predicting-by-clustering framework for sampling future movement using a mixture of multiple random Markov chains, each of which is a Naive Movement Predictive model trained with the movements of the subjects that belong to each cluster. We apply our approach to a big mobile phone GPS log dataset and predict the short-term future movements, especially during the Comiket 80 and New Year's Eve celebration. We evaluate our prediction by a Earth Mover Distance (EMD) based metric, and show our approach accurately predicts the crowd behavior during the rare crowd events, which makes an early crowd event warning and regulation possible in the emergent situations.\"],\n",
              " 24: ['Object-Oriented Data Modelling for Graphics Databases: a Declarative Approach.[SEP]This paper presents a new scheme to integrate the declarative approach to graphics and object‐oriented data modelling techniques to form a fruitful symbiosis for constraint‐based graphics database systems. It has rich modelling constructs to describe graphics data and allows sharing of representation. It also provides useful mechanisms for management of integrity constraints. We have also identified important classes of constraints in the context of object‐oriented graphics database systems. Examples are given for maintenance of constraints at the time of insertion, deletion and modification.',\n",
              "  'GKS-9x: The Design Output Primitive, an Approach to a Specification.[SEP]This paper describes an approach to the formal definition of the design primitive introduced in the revision of the ISO/IEC computer graphics standard, GKS. The paper starts with a general description of the design primitive and then describes the specification (which is given in the Z notation) and the motivation for the approach taken in some detail. The paper concludes with a reflection on the contribution of this work, and the descriptive style adopted an the GKS revision, to the role of formal description in the presentation of graphics standards.',\n",
              "  'The Effectiveness of High-level Graphical Languages in Dealing with Various Graphical Domains.[SEP]There are many domains in which graphical programming languages can be applied. Use of a particular graphical programing language will be limited if the domains in which it can be applied are restricted. High-level graphical languages provide simply expressed constructs for the definition, manipulation, inquiry, and external representation of graphical data. These capabilities permit the application to various domains of high-level graphical languages. Five specific domains are discussed; an example of an application of the graphical language LIG is presented in each domain.',\n",
              "  'Preface.[SEP]In this issue, we have four additional papers from 35th Computer Graphics International conference (CGI 2018) held on 11–14 June, 2018 in Bintan, Indonesia. Moreover, three papers from Euro VA 2017 held on 12–13 June 2017 in Barcelona, Spain and three papers from Cyberworlds 2017 held on 20–22 September 2017 in Chester, UK are included.',\n",
              "  'A Breezy Summer Read.[SEP]Editor in Chief Torsten Möller discusses the articles in the July/August 2018 issue of IEEE Computer Graphics and Applications.',\n",
              "  'Steps to Effective Business Graphics.[SEP]Europe is becoming aware that a political determination to collaborate is required, if it wants to attain the position it could claim on the basis of its research achievements. This is especially true in the field of Computer Graphics. The program ESPRIT is hopefully a decisive step in this direction.'],\n",
              " 25: ['Dual-Domain Hierarchical Classification of Phonetic Time Series.[SEP]Phonemes are the smallest units of sound produced by a human being. Automatic classification of phonemes is a well-researched topic in linguistics due to its potential for robust speech recognition. With the recent advancement of phonetic segmentation algorithms, it is now possible to generate datasets of millions of phonemes automatically. Phoneme classification on such datasets is a challenging data mining task because of the large number of classes (over a hundred) and complexities of the existing methods. In this paper, we introduce the phoneme classification problem as a data mining task. We propose a dual-domain (time and frequency) hierarchical classification algorithm. Our method uses a Dynamic Time Warping (DTW) based classifier in the top layers and time-frequency features in the lower layer. We cross-validate our method on phonemes from three online dictionaries and achieved up to 35% improvement in classification compared to existing techniques. We provide case studies on classifying accented phonemes and speaker invariant phoneme classification.',\n",
              "  \"Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels.[SEP]Unsupervised semantic segmentation in the time series domain is a much-studied problem due to its potential to detect unexpected regularities and regimes in poorly understood data. However, the current techniques have several shortcomings, which have limited the adoption of time series semantic segmentation beyond academic settings for three primary reasons. First, most methods require setting/learning many parameters and thus may have problems generalizing to novel situations. Second, most methods implicitly assume that all the data is segmentable, and have difficulty when that assumption is unwarranted. Finally, most research efforts have been confined to the batch case, but online segmentation is clearly more useful and actionable. To address these issues, we present an algorithm which is domain agnostic, has only one easily determined parameter, and can handle data streaming at a high rate. In this context, we test our algorithm on the largest and most diverse collection of time series datasets ever considered, and demonstrate our algorithm's superiority over current solutions. Furthermore, we are the first to show that semantic segmentation may be possible at superhuman performance levels.\",\n",
              "  'On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis.[SEP]Multivariate time series (MTS) data sets are common in-various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as principal component analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficients concisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.',\n",
              "  \"Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations.[SEP]We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs - a space-efficient time series visualization technique - across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception.\",\n",
              "  'Visual-Interactive Preprocessing of Multivariate Time Series Data.[SEP]Pre‐processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre‐processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre‐processing pipelines, human‐in‐the‐loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in‐depth research in visual analytics. We present a visual‐interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre‐processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty‐aware pre‐processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre‐processing in general and for uncertainty‐aware pre‐processing of multivariate time series in particular.',\n",
              "  'Qualizon graphs: space-efficient time-series visualization with qualitative abstractions.[SEP]In several application fields, the joint visualization of quantitative data and qualitative abstractions can help analysts make sense of complex time series data by associating precise numeric values with corresponding domain-specific interpretations, such as good, bad, high, low, normal. At the same time, the need to analyse large multivariate time-oriented datasets often calls for keeping visualizations as compact as possible. In this paper, we introduce Qualizon Graphs, a compact visualization that combines quantitative data and qualitative abstractions. It is based on the well known Horizon Graphs, but instead of a predefined number of equally sized bands, it uses as many bands as qualitative categories with corresponding different sizes. In this way, Qualizon Graphs increase the data density of visualized quantitative values and inherently integrate qualitative abstractions. A user study shows that Qualizon Graphs are as fast and accurate as Horizon Graphs for quantitative data, and are an alternative to state-of-the-art visualizations for both quantitative and qualitative data, enabling a trade-off between speed and accuracy.'],\n",
              " 26: ['Stress-Constrained Thickness Optimization for Shell Object Fabrication.[SEP]We present an approach to fabricate shell objects with thickness parameters, which are computed to maintain the user‐specified structural stability. Given a boundary surface and user‐specified external forces, we optimize the thickness parameters according to stress constraints to extrude the surface. Our approach mainly consists of two technical components: First, we develop a patch‐based shell simulation technique to efficiently support the static simulation of extruded shell objects using finite element methods. Second, we analytically compute the derivative of stress required in the sensitivity analysis technique to turn the optimization into a sequential linear programming problem. Experimental results demonstrate that our approach can optimize the thickness parameters for arbitrary surfaces in a few minutes and well predict the physical properties, such as the deformation and stress of the fabricated object.',\n",
              "  'Computational Design and Fabrication.[SEP]Computer graphics research is increasingly interested in the high-level analysis and processing of geometric objects. By acquiring a structural or functional understanding of 3D shapes, researchers are able to tackle mid- to high-level design problems for which machine computations can replace or at least relieve human efforts. In parallel, with the rapid advances in 3D printing technologies, many design solutions explored by researchers and practitioners are focusing on the needs and constraints arising from physical fabrication. The contributions in this special issue are cross-disciplinary, connecting physical fabrication with design and processing tasks in new domains including circuit design, geospatial visualization, and 3D scanning, leading to never-before-seen 3D printing applications.',\n",
              "  'Cost-effective printing of 3D objects with self-supporting property.[SEP]The fused deposition modeling (FDM) printer is a simple, affordable and widely used device in the 3D printing society. However, the high price of printing materials is one of major restrictive factors for its further application. Based on the self-supporting property of printing materials, we present an optimization method to reduce the total material consumption of 3D printed objects themselves and their support structures for FDM printers in this paper. We first develop an orientation optimization scheme to reduce the outer support volume of a printed model. The volume is evaluated according to the depths of 3D model fragments obtained by the depth peeling technique in an optimization process. We then build a self-supporting frame with a set of scale-adaptive parallelepiped grids to replace the solid interior of the printed model for further reducing the material consumption. In our orientation optimization scheme, the overhanging area detecting function can detect the self-supporting regions of a 3D model in terms of the depths stored in the graphical processing unit memory. The self-supporting frame with grid structures inside printed models does not need to add additional support structures during the printing process. Experimental results indicate that our method is faster and consumes less printing materials than the state-of-the-art algorithms.',\n",
              "  'TuVe: A Shape-changeable Display using Fluids in a Tube.[SEP]We propose TuVe, a novel shape-changing display consisting of a flexible tube and fluids, in which the droplets flowing through the tube compose the display medium that represents information. In this system, every colored droplet is flowed by controlling valves and a pump connected to the tube. The display part employs a flexible tube that can be shaped to any structure (e.g., wrapped around a specific object), which is achieved by a calibration made to capture the tube structure using image processing with a camera. A performance evaluation reveals that our prototype succeeds in controlling each droplet with a positional error of 2 mm or less, which is small enough to show such simple characters as alphabetic characters using a 7 × 7-pixel resolution display. We also discuss example applications, such as large public displays and flow-direction visualization, that illustrate the characteristics of the TuVe display.',\n",
              "  'Happy Moves, Sad Grooves: Using Theories of Biological Motion and Affect to Design Shape-Changing Interfaces.[SEP]The design of shape-changing interfaces to show emotions relies on craft skill with few clear guidelines. Through two experiments, we explore how to design such interfaces using theories of the relation between biological motion and affect. In the first experiment, 19 participants viewed six shape-changing behaviors that varied the velocity, fluidity, direction, and orientation of the movement of an extrusion from a small box in accordance with existing theories of affective motion. Participants were able to recognize four of the six intended basic Ekman emotions (sadness, fear, happiness, surprise) with above-chance probability. The second experiment used 36 shape-changing behaviors that systematically varied speed, regularity of motion, and direction. For each behavior, 23 participants rated valence, arousal, and dominance. Speed, direction, and orientation impacted emotion ratings significantly and in the predicted directions. These results offer an initial basis for the systematic design of emotions in shape-changing interfaces.',\n",
              "  'Understanding the Benefits and Drawbacks of Shape Change in Contrast or Addition to other Modalities.[SEP]Shape changing interfaces enable exciting new ways to interact with devices, to communicate information, meaning and affect, and provide dynamic affordance. Such interfaces are often complex and more expensive to fabricate compared to tangible, screen-based and voice interfaces. The research field has yet to explore the advantages and drawbacks of shape change in contrast to other modalities. The research outlined in this paper aims to evaluate shape changing interfaces for different purposes in contrast to interfaces that rely on tangible, screen-based or voice interaction. Shape change will be explored in the context of explainable AI to examine how it affects aspects like usability, user experience, user engagement and trust. The aim of this research is to generate an understanding about the conditions under which shape changing interfaces are beneficial and when traditional or multimodal interfaces are more appropriate.',\n",
              "  'Instrumenting and Analyzing Fabrication Activities, Users, and Expertise.[SEP]The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces.',\n",
              "  \"Automatics: Dynamically Generating Fabrication Tasks to Adapt to Varying Contexts.[SEP]When fabricating, it is common to follow a prescribed set of steps in a tutorial or how-to. While popular, such explicit knowledge resources have many inconsistencies and omissions, use static illustrations, and cannot adapt to drop-in makers or a maker's mistakes. To overcome many of these issues, this work presents Automatics, a novel explicit knowledge resource system that dynamically generates fabrication activities for one or more makers based on their current environmental and fabrication context. Automatics assigns tasks to makers based on the past tools and components the maker was working with, enables makers to recover from mistakes through model regeneration, suggests alternative tools if a needed tool is unavailable or in use, and allows multiple makers to drop-in throughout a fabrication activity. Initial usage and feedback from novice makers showed that Automatics increases the number of tasks that can be completed compared to paper instructions, decreases frustration, and improves one's understanding of the global context of assigned tasks during fabrication activities.\",\n",
              "  \"Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures.[SEP]Digital fabrication tools have transformed how people work in micro- and small-scale manufacturing settings. While increasing efficiency and precision, these tools raise concerns around user agency and control. This paper describes an exploratory study investigating the felt work experience and desired futures of professionals who use fabrication tools. We conducted co-design workshops with 23 professionals who use 3D printers, laser cutters, and CNC routers. We probed about current practices; machine awareness and autonomy; and user agency. Our findings reveal that current tools are not very professional. They are unreliable and untrustworthy. Participants desired smarter tools that can actively prevent errors and perform self-calibration and self-maintenance. They had few concerns that more intelligence would impact agency. They desired tools that could negotiate trade-offs between time, cost, and quality; and that can operate as super-human shop assistants. We discuss the implications of these findings as opportunities for research that can improve professionals' work experience.\"],\n",
              " 27: [\"Mixed-initiative conflict resolution for context-aware applications.[SEP]A number of technologies have contributed to automatically resolving resource conflicts between multiple users in a smart space. However, such systems eliminate the users' ability to perform this conflict resolution by themselves, which they actually prefer to do in certain circumstances. Since both resolution approaches have their merits, we propose a mixed-initiative conflict resolution system, which combines automatic conflict resolution with mediated, or user-driven, resolution by exploiting contextual information in context-aware applications. An evaluation of our system found that users prefer to use a mediated resolution approach when their preferences about outcome are very different from others', but have no preferred method when their preferences about outcome are similar to others'.\",\n",
              "  \"A user's perspective of design for context-awareness.[SEP]Along with the development of microchip and sensing technologies, more and more Context-Aware applications have been introduced to our daily life to engage us in information-rich environments. Unlike many desktop applications, Context-Aware applications have usually been used to support users in dynamic situations by utilizing many resources available through physical environments. This research takes a user's perspective on Context-Aware activities, to focus on user's motivation and perception among dynamic surroundings, and aims to demonstrate the role and importance of user involvement for Context-Aware services.\",\n",
              "  'A goal-oriented interface to consumer electronics using planning and commonsense reasoning.[SEP]We are reaching a crisis with design of user interfaces for consumer electronics. Flashing 12:00 time indicators, push-and-hold buttons, and interminable modes and menus are all symptoms of trying to maintain a one-to-one correspondence between functions and physical controls, which becomes hopeless as the number of capabilities of devices grows. We propose instead to orient interfaces around the goals that users have for the use of devices.We present Roadie, a user interface agent that provides intelligent context-sensitive help and assistance for a network of consumer devices. Roadie uses a Commonsense knowledge base to map between user goals and functions of the devices, and an AI partial-order planner to provide mixed-initiative assistance with executing multi-step procedures and debugging help when things go wrong.',\n",
              "  'Modelling internet based applications for designing multi-device adaptive interfaces.[SEP]The wide spread of mobile devices in the consumer market has posed a number of new issues in the design of internet applications and their user interfaces. In particular, applications need to adapt their interaction modalities to different portable devices. In this paper we address the problem of defining models and techniques for designing internet based applications that automatically adapt to different mobile devices. First, we define a formal model that allows for specifying the interaction in a way that is abstract enough to be decoupled from the presentation layer, which is to be adapted to different contexts. The model is mainly based on the idea of describing the user interaction in terms of elementary actions. Then, we provide a formal device characterization showing how to effectively implements the AIUs in a multidevice context.',\n",
              "  'Robust Annotation of Mobile Application Interfaces in Methods for Accessibility Repair and Enhancement.[SEP]Accessibility issues in mobile apps make those apps difficult or impossible to access for many people. Examples include elements that fail to provide alternative text for a screen reader, navigation orders that are difficult, or custom widgets that leave key functionality inaccessible. Social annotation techniques have demonstrated compelling approaches to such accessibility concerns in the web, but have been difficult to apply in mobile apps because of the challenges of robustly annotating interfaces. This research develops methods for robust annotation of mobile app interface elements. Designed for use in runtime interface modification, our methods are based in screen identifiers, element identifiers, and screen equivalence heuristics. We implement initial developer tools for annotating mobile app accessibility metadata, evaluate our current screen equivalence heuristics in a dataset of 2038 screens collected from 50 mobile apps, present three case studies implementing runtime repair of common accessibility issues, and examine repair of real-world accessibility issues in 26 apps. These contributions overall demonstrate strong opportunities for social annotation in mobile accessibility.',\n",
              "  'Workshop W2: multi-user and ubiquitous user interfaces (MU3I 2006).[SEP]The main objective of the third workshop on Multi-User and Ubiquitous User Interfaces (MU3I 2006) is to bring people with relevant backgrounds (e.g. interface design, CSCW, ubiquitous computing) together to discuss two key questions in this field: How can we build interfaces, which span multiple devices so that the user knows that they can be used to control a specific application? How can we build interfaces for public displays? Therefore, the main outcome of the workshop is expected to consists of further insights into those problems, potential solutions and a research agenda to investigate these further.',\n",
              "  \"The Upcycled Home: Removing Barriers to Lightweight Modification of the Home's Everyday Objects.[SEP]The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home.\",\n",
              "  'Alternative Avenues for IoT: Designing with Non-Stereotypical Homes.[SEP]We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen.',\n",
              "  \"Making place for clutter and other ideas of home.[SEP]In this article, we examine the containment of clutter in family homes and, from this, outline considerations for design. Selected materials from an ethnographically informed study of home life are used to detail the ways in which families contain their clutter in bowls and drawers. Clutter, within these containers, is found to be made up of a heterogeneous collection of things that, for all manner of reasons, hold an ambiguous status in the home. It is shown that bowls and drawers provide a “safe” site of containment for clutter, giving the miscellany of content the “space” to be properly dealt with and classified, or to be left unresolved. The shared but idiosyncratic practices families use to contain their clutter are seen to be one of the ways in which the home, or at least the idea of home, is collectively produced. It is also part of the means by which families come to make their homes distinct and unique. These findings are used to consider what it might mean to design for the home, and to do so in ways that are sensitive to the idiosyncratic systems of household organization. In conclusion, thought is given to how we design for people's ideas of home, and how we might build sites of uncertainty into homes, where physical as well as digital things might coalesce.\",\n",
              "  'Applications of mobile activity recognition.[SEP]Activity Recognition (AR), which identifies the activity that a user performs, is attracting a tremendous amount of attention, especially with the recent explosion of smart mobile devices. These ubiquitous mobile devices, most notably but not exclusively smartphones, provide the sensors, processing, and communication capabilities that enable the development of diverse and innovative activity recognition-based applications. However, although there has been a great deal of research into activity recognition, surprisingly little practical work has been done in the area of applications in mobile devices. In this paper we describe and categorize a variety of activity recognition-based applications. Our hope is that this work will encourage the development of such applications and also influence the direction of activity recognition research.',\n",
              "  'Learning from less for better: semi-supervised activity recognition via shared structure discovery.[SEP]Despite the active research into, and the development of, human activity recognition over the decades, existing techniques still have several limitations, in particular, poor performance due to insufficient ground-truth data and little support of intra-class variability of activities (i.e., the same activity may be performed in different ways by different individuals, or even by the same individuals with different time frames). Aiming to tackle these two issues, in this paper, we present a robust activity recognition approach by extracting the intrinsic shared structures from activities to handle intra-class variability, and the approach is embedded into a semi-supervised learning framework by utilizing the learned correlations from both labeled and easily-obtained unlabeled data simultaneously. We use l2,1 minimization on both loss function and regularizations to effectively resist outliers in noisy sensor data and improve recognition accuracy by discerning underlying commonalities from activities. Extensive experimental evaluations on four community-contributed public datasets indicate that with little training samples, our proposed approach outperforms a set of classical supervised learning methods as well as those recently proposed semi-supervised approaches.',\n",
              "  \"Supporting activity recognition by visual analytics.[SEP]Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.\"],\n",
              " 28: ['HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments.[SEP]High Intensity Focused Ultrasound (HIFU) is a non invasive therapeutic method, which has been a subject of interest for the treatment of various kinds of tumors. Despite the numerous advantages, HIFU techniques do not reach the high delivery precision like other therapies (e.g., radiotherapy). For this reason, a correct therapy planning and monitoring in HIFU treatments remains a challenge. We propose HIFUpm, a visual analytics approach which enables the visualization of the HIFU simulation results, while guiding the user in the evaluation of the procedure. We illustrate the use of HIFUpm for an ablative treatment of an osteoid osteoma. This use case demonstrates that HIFUpm provides a flexible visual environment to plan and monitor HIFU procedures.',\n",
              "  '3D heart-vessel reconstruction from biplane angiograms.[SEP]Biplane angiography generates just two time equivalent X-ray images. These X-ray systems can be rotated independently from each other (restricted by possible collisions only). The article explains how highly accurate 3D models of vessel systems can be reconstructed, visualized, and quantitatively evaluated from these X-ray images.',\n",
              "  \"Automatic Transfer Function Specification for Visual Emphasis of Coronary Artery Plaque.[SEP]Cardiovascular imaging with current multislice spiral computed tomography (MSCT) technology enables a non‐invasive evaluation of the coronary arteries. Contrast‐enhanced MSCT angiography with high spatial resolution allows for a segmentation of the coronary artery tree. We present an automatically adapted transfer function (TF) specification to highlight pathologic changes of the vessel wall based on the segmentation result of the coronary artery tree. The TFs are combined with common visualization techniques, such as multiplanar reformation and direct volume rendering for the evaluation of coronary arteries in MSCT image data. The presented TF‐based mapping of CT values in Hounsfield Units (HU) to color and opacity leads to a different color coding for different plaque types. To account for varying HU values of the vessel lumen caused by the contrast medium, the TFs are adapted to each dataset by local histogram analysis. We describe an informal evaluation with three board‐certified radiologists which indicates that the represented visualizations guide the user's attention to pathologic changes of the vessel wall as well as provide an overview about spatial variations.\",\n",
              "  'Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms.[SEP]Blood flow simulations play an important role for the understanding of vascular diseases, such as aneurysms. However, analysis of the resulting flow patterns, especially comparisons across patient groups, are challenging. Typically, the hemodynamic analysis relies on trial and error inspection of the flow data based on pathline visualizations and surface renderings. Visualizing too many pathlines at once may obstruct interesting features, e.g., embedded vortices, whereas with too little pathlines, particularities such as flow characteristics in aneurysm blebs might be missed. While filtering and clustering techniques support this task, they require the pre-computation of pathlines densely sampled in the space-time domain. Not only does this become prohibitively expensive for large patient groups, but the results often suffer from undersampling artifacts. In this work, we propose the usage of evolutionary algorithms to reduce the overhead of computing pathlines that do not contribute to the analysis, while simultaneously reducing the undersampling artifacts. Integrated in an interactive framework, it efficiently supports the evaluation of hemodynamics for clinical research and treatment planning in case of cerebral aneurysms. The specification of general optimization criteria for entire patient groups allows the blood flow data to be batch-processed. We present clinical cases to demonstrate the benefits of our approach especially in presence of aneurysm blebs. Furthermore, we conducted an evaluation with four expert neuroradiologists. As a result, we report advantages of our method for treatment planning to underpin its clinical potential.',\n",
              "  'Illustration-Inspired Visualization of Blood Flow Dynamics.[SEP]Image-based computational fluid dynamics (CFD) is a central tool in the evaluation of hemodynamic factors in cardiovascular disease development and treatment, to the point where major vendors are now seeking to deploy CFD solvers on their medical imaging platforms. Detailed hemodynamic data available from CFD generate large data sets due to complex flow, which are difficult to render clearly - and thus communicate to clinical stakeholders - using conventional engineering flow visualization techniques. This is especially challenging considering the four-dimensional nature of the flow patterns (i.e., Rapidly varying in space and time), as well as the clinical need for generating static reports rather than cumbersome digital animations. Taking a cue from the rich history of biomedical illustration, our goal is to use this opportunity for developing new data-driven paradigms for visualizing blood flow based on the principles of illustration, sequential art, and the visual vocabularies and conventions of radiology and vascular surgery.',\n",
              "  'Occlusion-free Blood Flow Animation with Wall Thickness Visualization.[SEP]We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.'],\n",
              " 29: ['Texture Synthesis for Mobile Data Communications.[SEP]This paper presents an approach to image coding that first paints a regularly arranged dotted pattern, using colors picked from a texture sample with features corresponding to the embedded data. It then camouflages the dotted pattern using the same texture sample while preserving quality comparable to that of existing synthesis techniques.',\n",
              "  'Deterministic Texture Analysis and Synthesis Using Tree Structure Vector Quantization.[SEP]Texture analysis and synthesis is very important for computer graphics, vision, and image processing. This paper describes an algorithm which can produce new textures with a matching visual appearance from a given example image. Our algorithm is based on a model that characterizes textures using a nonlinear deterministic function. During analysis, an example texture is summarized into this function using tree structure vector quantization. An output texture, initially random noise, is then synthesized from this estimated function. Compared to existing approaches, our algorithm can efficiently generate a wide variety of textures. The effectiveness of our approach is demonstrated using standard test images from the Brodatz texture album.',\n",
              "  'Hidden message in a deformation-based texture.[SEP]We present stego-texture, a unique texture synthesis method that allows users to deliver personalized messages with beautiful, decorative textures. Our approach was inspired by the success of recent work generating marbling textures using mathematical functions. We were able to transform an input image or a text message into an intricate texture by combining the seven basic, reversible functions provided in the system. Later, the input image or message could be recovered by reversing the process of these functions. During the design process, the parameters of operations were automatically recorded, encrypted and invisibly embedded into the final pattern to create a stego-texture. In this way, the receiver could extract the hidden message from the stego-texture without the need for extra information from the sender. To ensure that the delivered message is unnoticeably covered by the texture, we propose a new technique for automatically creating a background that is harmonious with the message based on a set of visual perception cues.',\n",
              "  'Application-Specific Tone Mapping Via Genetic Programming.[SEP]High dynamic range (HDR) imagery permits the manipulation of real‐world data distinct from the limitations of the traditional, low dynamic range (LDR), content. The process of retargeting HDR content to traditional LDR imagery via tone mapping operators (TMOs) is useful for visualizing HDR content on traditional displays, supporting backwards‐compatible HDR compression and, more recently, is being frequently used for input into a wide variety of computer vision applications. This work presents the automatic generation of TMOs for specific applications via the evolutionary computing method of genetic programming (GP). A straightforward, generic GP method that generates TMOs for a given fitness function and HDR content is presented. Its efficacy is demonstrated in the context of three applications: Visualization of HDR content on LDR displays, feature mapping and compression. For these applications, results show good performance for the generated TMOs when compared to traditional methods. Furthermore, they demonstrate that the method is generalizable and could be used across various applications that require TMOs but for which dedicated successful TMOs have not yet been discovered.',\n",
              "  'A Tone Reproduction Operator for All Luminance Ranges Considering Human Color Perception.[SEP]In this paper, we present a novel tone reproduction operator that is able to handle the color shift that occurs in photopic, mesopic, and scotopic vision, using a model based on a two-stage model of human color vision and psychophysical data obtained from measurements of human color perception. Since conventional methods are limited to generating images under a certain visual condition, it is difficult to apply just one operator to deal with scenes with continuous change within a wide luminance range, such as various scenes in movies. To overcome this problem, we have developed a model based on psychophysical data involving wavelength discrimination within a wide luminance range, which provides us with clues about the change of color perception. That is, the spectral sensitivity shifts toward the short wavelengths and decreases according to the adaptation light levels. By integrating the wavelength discrimination into our model, the proposed operator enables us to compute the transition of color perception under a wide range of viewing conditions.',\n",
              "  'Style Aware Tone Expansion for HDR Displays.[SEP]The vast majority of video content existing today is in Standard Dynamic Range (SDR) format and there is a strong interest in upscaling this content for upcoming High Dynamic Range (HDR) displays. Tone expansion or inverse tone mapping converts SDR content into HDR format using Expansion Operators (EO). In this paper, we show that current EO’s do not perform as well when dealing with content of various lighting style aesthetics. In addition to this, we present a series of perceptual user studies evaluating user preference for lighting style in HDR content. This study shows that tone expansion of stylized content takes the form of gamma correction and we propose a method that adapts the gamma value to the style of the video. We validate our method through a subjective evaluation against state-of-the-art methods. Furthermore, our work has been oriented for 1000 nits HDR displays and we present a framework positioning our method in conformance with existing SDR standards and upcoming HDR TV standards.'],\n",
              " 30: ['Bar-Gain Boxes: An Informative Illustration of the Pairing Problem.[SEP]A practical problem in command and control is to assign assets (e.g., bomber planes) to targets (e.g., hostile sites), one-on-one, in order to optimize an overall operation. The asset-target pairing must be completed quickly (before targets act), and the expected effectiveness of an asset against a target depends on a number of factual and judgmental factors. Here I present a diagram called ”Bar-Gain Boxes” designed to help people solve the problem. The diagram uses a matrix of boxes to illustrate the possible pairings, along with color-coded bars (in each box) to illustrate the gain associated with each individual asset-target pair. The diagram is informative because it displays algorithmic results and underlying reasons, for normative and alternative solutions.',\n",
              "  'Context effects and risk amplification: Why more is risky.[SEP]Research on risky choice has been dominantly based on studies of choice between two alternatives, with the findings often generalized to environments with more than two alternatives. One prominent claim of this research is that choices differ with respect to risk when alternatives are described (the description paradigm) as opposed to experienced (the experience paradigm): Individuals appear to make decisions as if they over-weight small probabilities in the description paradigm, but under-weight the same probabilities in the experience paradigm. Here, we show that the under-weighting in the experience paradigm is sensitive to the choice set size in the gain domain. Two experiments show that as set sizes increase, choices systematically favour risky alternatives in the experience paradigm. Using simulations of three choice models, we further demonstrate that this risk-amplification is independent of choice and search strategies and is predicted by the statistical structure of pay-offs. The results suggest caution in generalising findings from two-choice environments to many-choice environments and further indicate a robust and systematic problem with increasing choice set sizes.',\n",
              "  \"How Does Prospect Theory Reflect Heuristics' Probability Sensitivity in Risky Choice?[SEP]Two prominent approaches to describing how people make decisions between risky options are algebraic models and heuristics. The two approaches are based on fundamentally different algorithms and are thus usually treated as antithetical, suggesting that they may be incommensurable. Using cumulative prospect theory (CPT; Tversky & Kahneman, 1992) as an illustrative case of an algebraic model, we demonstrate how algebraic models and heuristics can mutually inform each other. Specifically, we highlight that CPT describes decisions in terms of psychophysical characteristics, such as diminishing sensitivity to probabilities, and we show that this holds even when the underlying process is heuristic in nature. Our results suggest that algebraic models and heuristics might offer complementary rather than rival modeling frameworks and highlight the potential role of heuristic principles in information processing for prominent descriptive constructs in risky choice.\"],\n",
              " 31: ['User-defined feature comparison for vector field ensembles.[SEP]Most of the existing approaches to visualize vector field ensembles are to reveal the uncertainty of individual variables, for example, statistics, variability, etc. However, a user-defined derived feature like vortex or air mass is also quite significant, since they make more sense to domain scientists. In this paper, we present a new framework to extract user-defined derived features from different simulation runs. Specially, we use a detail-to-overview searching scheme to help extract vortex with a user-defined shape. We further compute the geometry information including the size, the geo-spatial location of the extracted vortexes. We also design some linked views to compare them between different runs. At last, the temporal information such as the occurrence time of the feature is further estimated and compared. Results show that our method is capable of extracting the features across different runs and comparing them spatially and temporally.',\n",
              "  \"Analysis of Decadal Climate Predictions with User-guided Hierarchical Ensemble Clustering.[SEP]In order to gain probabilistic results, ensemble simulation techniques are increasingly applied in the weather and climate sciences (as well as in various other scientific disciplines). In many cases, however, only mean results or other abstracted quantities such as percentiles are used for further analyses and dissemination of the data. In this work, we aim at a more detailed visualization of the temporal development of the whole ensemble that takes the variability of all single members into account. We propose a visual analytics tool that allows an effective analysis process based on a hierarchical clustering of the time‐dependent scalar fields. The system includes a flow chart that shows the ensemble members' cluster affiliation over time, reflecting the whole cluster hierarchy. The latter one can be dynamically explored using a visualization derived from a dendrogram. As an aid in linking the different views, we have developed an adaptive coloring scheme that takes into account cluster similarity and the containment relationships. Finally, standard visualizations of the involved field data (cluster means, ground truth data, etc.) are also incorporated. We include results of our work on real‐world datasets to showcase the utility of our approach.\",\n",
              "  'Extraction and Visual Analysis of Potential Vorticity Banners around the Alps.[SEP]Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.',\n",
              "  'Exploratory Hierarchical Clustering for Management Zone Delineation in Precision Agriculture.[SEP]Precision Agriculture has become an emerging topic over the last ten years. It is concerned with the integration of information technology into agricultural processes. This is especially true for the ongoing and growing data collection in agriculture. Novel ground-based sensors, aerial and satellite imagery as well as soil sampling provide large georeferenced data sets with high spatial resolution. However, these data lead to the data mining problem of finding novel and useful information in these data sets.',\n",
              "  'Gaussian multiple instance learning approach for mapping the slums of the world using very high resolution imagery.[SEP]In this paper, we present a computationally efficient algorithm based on multiple instance learning for mapping informal settlements (slums) using very high-resolution remote sensing imagery. From remote sensing perspective, informal settlements share unique spatial characteristics that distinguish them from other urban structures like industrial, commercial, and formal residential settlements. However, regular pattern recognition and machine learning methods, which are predominantly single-instance or per-pixel classifiers, often fail to accurately map the informal settlements as they do not capture the complex spatial patterns. To overcome these limitations we employed a multiple instance based machine learning approach, where groups of contiguous pixels (image patches) are modeled as generated by a Gaussian distribution. We have conducted several experiments on very high-resolution satellite imagery, representing four unique geographic regions across the world. Our method showed consistent improvement in accurately identifying informal settlements.',\n",
              "  'Regression Models for Spatial Data: An Example from Precision Agriculture.[SEP]The term precision agriculture refers to the application of state-of-the-art GPS technology in connection with small-scale, sensor-based treatment of the crop. This data-driven approach to agriculture poses a number of data mining problems. One of those is also an obviously important task in agriculture: yield prediction. Given a precise, geographically annotated data set for a certain field, can a season’s yield be predicted?'],\n",
              " 32: ['Adaptive Ray Tracing of Subdivision Surfaces.[SEP]Subdivision Surfaces as well as (interactive) ray tracing have become an important issue in computer graphics.But ray tracing of subdivision surfaces has received only little attention. We present a new approach for raytracing of subdivision surfaces. The algorithm uses a projection of the ray onto the surface and works mainly intwo dimensions along this projection. While proceeding from patch to patch, we examine the bounding volume oftheir borders: the lower the distance between ray and subdivision surface, the more refinement steps are adaptivelyapplied to the surface but only along the projection of the ray. The adaptive refinement of a patch is controlled bycurvature, size, its membership to the silhouette, and its potential contribution to the light transport. The algorithmis simple and mainly consists of elementary geometric computations. Hence it is fast and easy to implementwithout the need for elaborate preprocessing. The algorithm is robust in the sense that it deals with all features ofsubdivision surfaces like creases and corners.',\n",
              "  'Octree-R: An Adaptive Octree for Efficient Ray Tracing.[SEP]Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves.',\n",
              "  'Improved techniques for ray tracing parametric surfaces.[SEP]Several techniques for acceleration of ray tracing parametric surfaces are presented. Some of these are entirely new to ray tracing, while others are improvements of previously known techniques. First a uniform spatial subdivision scheme is adapted to parametric surfaces. A new space- and time-efficient algorithm for finding raysurface intersections is introduced. It combines numerical and subdivision techniques, thus allowing utilization of ray coherence and greatly reducing the average ray-surface intersection time. Non-scanline sampling orders of the image plane are proposed that facilitate utilization of coherence. Finally, a method to handle reflected, refracted, and shadow rays in a more efficient manner is described. Results of timing tests indicating the efficiency of these techniques for various environments are presented.'],\n",
              " 33: ['#Indigenous: Tracking the Connective Actions of Native American Advocates on Twitter.[SEP]With fewer than 66% of eligible voters registered and voter turnout rates 5-14 percentage points lower than any other ethnic group, Native Americans comprise the least participatory ethnic group in U.S. political elections [42, 57, 49, 25]. While discourse surrounding Native American issues and interests has increasingly moved to social media [55, 56], there is a lack of data about Native American political discourse on these platforms. Given the heterogeneity of Native American peoples in the U.S., one way to begin approaching a holistic understanding of Native American political discourse on social media is to characterize how Native American advocates utilize social media platforms for connective action. Using a post-structural, interdisciplinary, mixed methods approach, we use theories of connective action [5] and media richness [14] to analyze a Twitter data set culled from influential Native American advocates and their followers during the 2016 primary presidential election season. Our study sheds light on how Native American advocates use social media to propagate political information and identifies which issues are central to the political discourse of Native American advocates. Furthermore, we demonstrate how the bandwidth characteristics of content impact its propagation and we discuss this in the context of pernicious digital divide effects present in Indian Country.',\n",
              "  'Thanks and tweets: comparing two public displays.[SEP]Two public display systems, with different methods of posting, were deployed over several years. One, the Thank You Board, was designed to give people an outlet specifically for publicly thanking and acknowledging others in the community. The other, SI Display, showed any Twitter post directed to the display and did not have explicit usage guidelines. People preferred the flexibility of the latter, but ambiguity about its purpose and norms of usage persisted even six months after deployment and made some people hesitant to post. Also, using Twitter as the posting mechanism facilitated participation for some but also created barriers for those not using Twitter and for Twitter users who were wary of mixing their professional and non-professional contexts.',\n",
              "  '(How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian uprising.[SEP]This paper examines microblogging information diffusion activity during the 2011 Egyptian political uprisings. Specifically, we examine the use of the retweet mechanism on Twitter, using empirical evidence of information propagation to reveal aspects of work that the crowd conducts. Analysis of the widespread contagion of a popular meme reveals interaction between those who were \"on the ground\" in Cairo and those who were not. However, differences between information that appeals to the larger crowd and those who were doing on-the-ground work reveal important interplay between the two realms. Through both qualitative and statistical description, we show how the crowd expresses solidarity and does the work of information processing through recommendation and filtering. We discuss how these aspects of work mutually sustain crowd interaction in a politically sensitive context. In addition, we show how features of this retweet-recommendation behavior could be used in combination with other indicators to identify information that is new and likely coming from the ground.',\n",
              "  \"ScatterBlogs: Geo-spatial document analysis.[SEP]We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system's combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.\",\n",
              "  'TimeSets: Temporal Sensemaking in Intelligence Analysis.[SEP]TimeSets is a temporal data visualization technique designed to reveal insights into event sets, such as all the events linked to one person or organization. In this article, we describe two TimeSets-based visual analytics tools for intelligence analysis. In the first case, TimeSets is integrated with other visual analytics tools to support open-source intelligence analysis with Twitter data, particularly the challenge of finding the right questions to ask. The second case uses TimeSets in a participatory design process with analysts that aims to meet their requirements of uncertainty analysis involving fake news. Lessons learned are potentially beneficial to other application domains.',\n",
              "  \"Can Twitter Save Lives? A Broad-Scale Study on Visual Social Media Analytics for Public Safety.[SEP]The use of social media monitoring for public safety is on the brink of commercialization and practical adoption. To close the gap between research and application, this paper presents results of a two-phase study on visual analytics of social media for public safety. For the first phase, we conducted a large field study, in which 29 practitioners from disaster response and critical infrastructure management were asked to investigate crisis intelligence tasks based on Twitter data recorded during the 2013 German Flood. To this end, the ScatterBlogs visual analytics system, a platform that provides reference implementations of tools and techniques popular in research, was given to them as an integrated toolbox. We reviewed the domain experts' individual performances with the system as well as their comments about the usefulness of techniques. In the second phase, we built on this feedback about ScatterBlogs in order to sketch out a system and create additional tools specifically adapted to the collected requirements. The performance of the old lab prototype is finally compared against the re-design in a controlled user study.\"],\n",
              " 34: ['Systematic Integration of Solution Elements: How Does Digital Creativity Support Change Group Dynamics?[SEP]In practice, most creativity techniques are still performed with traditional tools, such as pen and paper, whiteboards, and flipcharts. When transforming these techniques into a digital environment, the reduction of organizational overhead is the main goal to foster accessibility. Still, we do not know if overhead reduction fosters creativity or if it eliminates an important part of the creative process. To get a deeper understanding of these effects, we compare the performance of the creativity technique SIS (Systematic Integration of Solution Elements) in a traditional setting with a setup based on multiple interactive surfaces. By using a mix of diverse evaluation methods, we show how the use of a digital interactive creativity room can really foster creativity and produce better results.',\n",
              "  'Understanding Creativity Methods in Design.[SEP]This paper contributes an analytical framework to improve understanding of the composition of recognized creativity methods used in design. Based on an extensive literature review, our framework synthesizes key concepts from design and particularly creativity research, and is further supported by significant experience with creativity methods in design. We propose that nine concepts are relevant for analyzing creativity methods in design: process structure, materials, tools, combination, metaphor, analogy, framing, divergence, and convergence. To test their relevance as components of an analytical framework, we use these key concepts to analyze three recognized creativity methods that we have often used ourselves: Inspiration Card Workshops, Fictional Inquiry, and Extreme Characters. Our analytical framework expands current categorizations of methods and offers new insight into how creativity methods are composed, how and why they work, and how they potentially may be tweaked or refined for enhanced deployment in design.',\n",
              "  'What You See Is What You Get: The Impact of Visual Perceived Finishedness (PF) on Collaboration Comments during Electronic Idea Generation.[SEP]Micro-level visual phenomena significantly impact visually-supported interactions, and require further exploration. This study uses a laboratory experiment with managerial participants to examine the impact of typeface appearance on number of comments concerning collaboration process during use of an electronic ideation platform. The typefaces verifiably differed on perceived finishedness (PF) level. Low typeface PF was expected to lead to freer, more frequent interaction on the collaboration process. Contrary to expectations, this study found that participant familiarity with the high PF typeface led to a significant increase in the amount of collaboration process comments. This study examines the complementary new ideation metric of collaboration comment number in light of the benefits social metacognition can bring to the structuring of group creativity processes.',\n",
              "  'The Best of Both Realities.[SEP]This paper looks at the work of Dan Turner, who creates art based on digital imagery.',\n",
              "  'Her Work Is All the Buzz.[SEP]This installment looks at the work of Lita Albuquerque, who creates art based on digital imagery.',\n",
              "  \"A Space to Dream.[SEP]Dolores Kaufmann's work is a cross between photo manipulation and computer-generated imagery. She creates her works using Kai Power Tools' Hyper Tiling plug in.\",\n",
              "  'Image-Based Color Ink Diffusion Rendering.[SEP]This paper proposes an image-based painterly rendering algorithm for automatically synthesizing an image with color ink diffusion. We suggest a mathematical model with a physical base to simulate the phenomenon of color colloidal ink diffusing into absorbent paper. Our algorithm contains three main parts: a feature extraction phase, a Kubelka-Munk (KM) color mixing phase, and a color ink diffusion synthesis phase. In the feature extraction phase, the information of the reference image is simplified by luminance division and color segmentation. In the color mixing phase, the KM theory is employed to approximate the result when one pigment is painted upon another pigment layer. Then, in the color ink diffusion synthesis phase, the physically-based model that we propose is employed to simulate the result of color ink diffusion in absorbent paper using a texture synthesis technique. Our image-based ink diffusing rendering (IBCIDR) algorithm eliminates the drawback of conventional Chinese ink simulations, which are limited to the black ink domain, and our approach demonstrates that, without using any strokes, a color image can be automatically converted to the diffused ink style with a visually pleasing appearance',\n",
              "  'Pixel Art with Refracted Light by Rearrangeable Sticks.[SEP]Pixel art is a kind of digital art that through per‐pixel manipulation enables production of a diverse array of artistic images. In this paper, we present a new way for people to experience and express pixel art. Our digital art consists of a set of sticks made of acrylate resin, each of which refracts light from a parallel light source, in certain directions. Artistic users are able to easily rearrange these sticks and view their digital art through the refracted light projection on any planar surface. As we demonstrate in this paper, a user can generate various artistic images using only a single set of sticks. We additionally envision that our pixel art with rearrangeable sticks would have great entertainment appeal, e.g., as an art puzzle.',\n",
              "  'Artistic relighting of paintings and drawings.[SEP]We present a practical solution to the problem of subject relighting in paintings and drawings. Our interactive technique uses 3-D shading proxies and can be applied to objects with arbitrary geometries. Given a user-provided guess for the shading of an object in a painting/drawing and its corresponding target shading, we refine them using shading-color correlation and a multi-scale scheme. These refined shadings are then used to create a multi-channel shading-ratio image to perform relighting, while taking into account the colors used by the artists to convey shading information. We demonstrate the effectiveness of our solution on a variety of artistic styles, including paintings with strong brush strokes and unconventional shading encodings, drawings, and other types of artwork. Our method is the first to perform relighting of paintings and drawings and, in addition to relighting, can transfer smooth normal and depth maps from 3-D proxies to images.'],\n",
              " 35: ['Stable Causal Relationships are Better Causal Relationships.[SEP]We report two experiments investigating whether people’s judgments about causal relationships are sensitive to the robustness or stability of such relationships across a wide range of background circumstances. We demonstrate that people prefer stable causal relationships even when overall causal strength is held constant, and show that this effect is unlikely to be driven by a causal generalization’s actual scope of application. This documents a previously unacknowledged factor that shapes people’s causal reasoning.',\n",
              "  'Informative Transitions: A Heuristic for Conditionalized Causal Strength Learning.[SEP]Controlling for alternative causes is essential for learning the strength of any one cause on an effect. Several processes have been proposed for how people control for alternative causes, including probabilistic contrasts within focal sets and associative processes. We investigated another mechanism called the informative transitions heuristic; people selectively attend to temporally adjacent observations (informative transitions; IT) in which the state of the target cause changes but the alternative causes remain the same. Within ITs, whether the effect also changes in the same direction, does not change, or changes in the opposite direction implies that the target cause has a positive, neutral, or negative influence on the effect. Participants judged the strength of the relationship between two drugs and a side effect in a trial-by-trial learning task. Causes with more positive as opposed to neutral ITs were judged to have stronger causal relations, consistent with the IT heuristic.',\n",
              "  'Causal Reasoning with Continuous Outcomes.[SEP]We describe an attempt to understand causal reasoning in situations where a binary cause produces a change on a continuous magnitude dimension. We consider established theories of binary probabilistic causal inference – ΔP and Power PC – and adapt them to continuous non-probabilistic outcomes. While ΔP describes causal strength as the difference of effect occurrence between the presence and absence of the cause, Power PC normalizes this difference with the effect base-rate to obtain a proportional measure of causal power, relative to the maximum possible strength. Two experiments compared the applicability of each approach by creating scenarios where binary probabilistic scenarios were directly mapped onto inference problems involving continuous magnitude dimensions. Results from counterfactual judgments tentatively indicate that people reason about causal relations with continuous outcomes by adopting a proportional approach when evaluation preventive causal powers, and a difference approach in generative scenarios.'],\n",
              " 36: ['Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security Practices.[SEP]A primary goal of research in usable security and privacy is to understand the differences and similarities between users. While past researchers have clustered users into different groups, past categories of users have proven to be poor predictors of end-user behaviors. In this paper, we perform an alternative clustering of users based on their behaviors. Through the analysis of data from surveys and interviews of participants, we identify five user clusters that emerge from end-user behaviors-Fundamentalists, Lazy Experts, Technicians, Amateurs and the Marginally Concerned. We examine the stability of our clusters through a survey-based study of an alternative sample, showing that clustering remains consistent. We conduct a small-scale design study to demonstrate the utility of our clusters in design. Finally, we argue that our clusters complement past work in understanding privacy choices, and that our categorization technique can aid in the design of new computer security technologies.',\n",
              "  \"Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps.[SEP]Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone apps may help people make more informed privacy-related decisions. To investigate this question, we designed and prototyped a new class of privacy indicators, called Data Controller Indicators (DCIs), that expose previously hidden information flows out of the apps. Our lab study of DCIs suggests that such indicators do support people in making more confident and consistent choices, informed by a more diverse range of factors, including the number and nature of third-party companies that access users' data. Furthermore, personalised DCIs, which are contextualised against the other apps an individual already uses, enable them to reason effectively about the differential impacts on their overall information exposure.\",\n",
              "  'Privacy as part of the app decision-making process.[SEP]Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts\\' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.',\n",
              "  'Maximum Likelihood Postprocessing for Differential Privacy under Consistency Constraints.[SEP]When analyzing data that has been perturbed for privacy reasons, one is often concerned about its usefulness. Recent research on differential privacy has shown that the accuracy of many data queries can be improved by post-processing the perturbed data to ensure consistency constraints that are known to hold for the original data. Most prior work converted this post-processing step into a least squares minimization problem with customized efficient solutions. While improving accuracy, this approach ignored the noise distribution in the perturbed data.',\n",
              "  'Inference Analysis in Privacy-Preserving Data Re-publishing.[SEP]Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.',\n",
              "  'Concentrated Differentially Private Gradient Descent with Adaptive per-Iteration Privacy Budget.[SEP]Iterative algorithms, like gradient descent, are common tools for solving a variety of problems, such as model fitting. For this reason, there is interest in creating differentially private versions of them. However, their conversion to differentially private algorithms is often naive. For instance, a fixed number of iterations are chosen, the privacy budget is split evenly among them, and at each iteration, parameters are updated with a noisy gradient.'],\n",
              " 37: ['Staging Urban Interactions with Media Fa[SEP]Using media façades as a subcategory of urban computing, this paper contributes to the understanding of spatial interaction, sense-making, and social mediation as part of identifying key characteristics of interaction with media façades. Our research addresses in particular the open-ended but framed nature of interaction, which in conjunction with varying interpretations enables individual sense-making. Moreover, we contribute to the understanding of flexible social interaction by addressing urban interaction in relation to distributed attention, shared focus, dialogue and collective action. Finally we address challenges for interaction designers encountered in a complex spatial setting calling for a need to take into account multiple viewing and action positions. Our research-through-design approach has included a real-life design intervention in terms of the design, implementation, and reflective evaluation of a 180 m2 (1937 square feet) interactive media façade in operation 24/7 for more than 50 days.',\n",
              "  'Immersive Street-level Social Media in the 3D Virtual City: Anticipated User Experience and Conceptual Development.[SEP]In this paper we explore immersive street-level integration of social media content into collaborative virtual 3D city environments on two levels: i) public, where the virtual environment is populated with relevant social media content (e.g. Twitter and Facebook feeds of shops, non-governmetal organizations, the City organization); and ii) personal, where the virtual user, through his/her avatar, is able to access his/her personal social media feeds while immersed in the virtual city. We conducted a qualitative anticipated user experience study with 14 participants in four focus groups, who were asked to create designs of how they imagined social networking services could be integrated into virtual city environments. Further, participants were asked to comment on two visual concepts created by researchers. Results show that people appreciate the concept of having virtual cities populated with up-to-date content from social media services, but linking their own social media accounts is a more complex issue.',\n",
              "  'Projected Realities: Conceptual Design for Cultural Effect.[SEP]As a part of a European Union sponsored project, we have proposed a system which aggregates peoples expressions over a widening network of public electronic displays in a massive Dutch housing development. Reflecting ideas from contemporary arts as well as from research on media spaces, this is an example of a conceptual design intended to produce meaningful effects on a local culture. In this paper, we describe the methods and ideas that led to this proposal, as an example of research on technologies from the traditions of artist-designers.',\n",
              "  'A Survey of Urban Reconstruction.[SEP]This paper provides a comprehensive overview of urban reconstruction. While there exists a considerable body of literature, this topic is still under very active research. The work reviewed in this survey stems from the following three research communities: computer graphics, computer vision, and photogrammetry and remote sensing. Our goal is to provide a survey that will help researchers to better position their own work in the context of existing solutions, and to help newcomers and practitioners in computer graphics to quickly gain an overview of this vast field. Further, we would like to bring the mentioned research communities to even more interdisciplinary work, since the reconstruction problem itself is by far not solved.',\n",
              "  'Generating 3D Building Models from Architectural Drawings: A Survey.[SEP]Automatically generating 3D building models from 2D architectural drawings has many useful applications in the architecture engineering and construction community. This survey of model generation from paper and CAD-based architectural drawings covers the common pipeline and compares various algorithms for each step of the process.',\n",
              "  \"Automatic Integration of Facade Textures into 3D Building Models with a Projective Geometry Based Line Clustering.[SEP]Visualization of city scenes is important for many applications including entertainment and urban mission planning. Models covering wide areas can be efficiently constructed from aerial images. However, only roof details are visible from aerial views; ground views are needed to provide details of the building facades for high quality 'fly‐through' visualization or simulation applications. We present an automatic method of integrating facade textures from ground view images into 3D building models for urban site modeling. We first segment the input image into building facade regions using a hybrid feature extraction method, which combines global feature extraction with Hough transform on an adaptively tessellated Gaussian Sphere and local region segmentation. We estimate the external camera parameters by using the corner points of the extracted facade regions to integrate the facade textures into the 3D building models. We validate our approach with a set of experiments on some urban sites.\"],\n",
              " 38: ['Efficient Concurrency Control for Broadcast Environments.[SEP]A crucial consideration in environments where data is broadcast to clients is the low bandwidth available for clients to communicate with servers. Advanced applications in such environments do need to read data that is mutually consistent as well as current. However, given the asymmetric communication capabilities and the needs of clients in mobile environments, traditional serializability-based approaches are too restrictive, unnecessary, and impractical. We thus propose the use of a weaker correctness criterion called update consistency and outline mechanisms based on this criterion that ensure (1) the mutual consistency of data maintained by the server and read by clients, and (2) the currency of data read by clients. Using these mechanisms, clients can obtain data that is current and mutually consistent “off the air”, i.e., without contacting the server to, say, obtain locks. Experimental results show a substantial reduction in response times as compared to existing (serializability-based) approaches. A further attractive feature of the approach is that if caching is possible at a client, weaker forms of currency can be obtained while still satisfying the mutual consistency of data.',\n",
              "  \"Concepts for Transaction Recovery in Nested Transactions.[SEP]The concept of nested transactions offers more decomposable execution units and finer grained control over recovery and concurrency as compared to 'flat' transactions. To exploit these advantages, especially transaction recovery has to be refined and adjusted to the requirements of the control structure.\",\n",
              "  'Implementing Recoverable Requests Using Queues.[SEP]Transactions have been rigorously defined and extensively studied in the database and transaction processing literature, but little has been said about the handling of the requests for transaction execution in commercial TP systems, especially distributed ones, managing the flow of requests is often as important as executing the transactions themselves.'],\n",
              " 39: [\"360° panoramic overviews for location-based services.[SEP]We investigate 360° panoramas as overviews to support users in the task of locating objects in the surrounding environment. Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment. In this paper, we conduct a series of studies with three different shapes: Frontal, Top-Down and Bird's Eye; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment. Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role. This paper is the first to provide understanding on how users exploit 360° panoramic over-views to locate objects in the surrounding environment and how different design factors can affect user performance.\",\n",
              "  'Effects of display size and navigation type on a classification task.[SEP]The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.',\n",
              "  'Wedge: clutter-free visualization of off-screen locations.[SEP]To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge, a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.',\n",
              "  \"Elastic windows: improved spatial layout and rapid multiple window operations.[SEP]Most windowing systems follow the independent overlapping windows approach, which emerged as an answer to the needs of the 80s' application and technology. Advances in computers, display technology, and the applications demand more functionality from window management systems. Based on these changes and the problems of current windowing appraoches, we have updated the requirements for multiwindow systems to guide new methods of window management. We propose elastic windows with improved spatial layout and rapid multi-window operations. Multi-window operations are achieved by issuing operations on window groups hierachically organized in a space-filling tiled layout. Sophisticated multi-window operations and spatial layout dynamics helps users to handle fast task-switching and to structure thier work environment to their rapidly changing needs. We claim that these multi-window operations and the improved spatial layout decrease the cognitive load on users. Users found our prototype system to be comprehensible and enjoyable as they playfully explored the way multiple windows are reshaped.\",\n",
              "  'Copy-and-paste between overlapping windows.[SEP]Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.',\n",
              "  'A window system with leafing through mode: BookWindow.[SEP]This paper describes “Book Window” that we implemented, a window system based on the “book” metaphor, that displays information not by scrolling but by using the animation of paging through. The BookWindow system equips some bookmarks, tabs, etc., by which we can access to an expected page through our requirements. BookWindow can support our work environment which navigates us through information space flexibly, because human beings are quite familiar with “books”.',\n",
              "  \"ThinVR: Heterogeneous microlens arrays for compact, 180 degree FOV VR near-eye displays.[SEP]Today's Virtual Reality (VR) displays are dramatically better than the head-worn displays offered 30 years ago, but today's displays remain nearly as bulky as their predecessors in the 1980's. Also, almost all consumer VR displays today provide 90-110 degrees field of view (FOV), which is much smaller than the human visual system's FOV which extends beyond 180 degrees horizontally. In this paper, we propose ThinVR as a new approach to simultaneously address the bulk and limited FOV of head-worn VR displays. ThinVR enables a head-worn VR display to provide 180 degrees horizontal FOV in a thin, compact form factor. Our approach is to replace traditional large optics with a curved microlens array of custom-designed heterogeneous lenslets and place these in front of a curved display. We found that heterogeneous optics were crucial to make this approach work, since over a wide FOV, many lenslets are viewed off the central axis. We developed a custom optimizer for designing custom heterogeneous lenslets to ensure a sufficient eyebox while reducing distortions. The contribution includes an analysis of the design space for curved microlens arrays, implementation of physical prototypes, and an assessment of the image quality, eyebox, FOV, reduction in volume and pupil swim distortion. To our knowledge, this is the first work to demonstrate and analyze the potential for curved, heterogeneous microlens arrays to enable compact, wide FOV head-worn VR displays.\",\n",
              "  \"Gaussian Light Field: Estimation of Viewpoint-Dependent Blur for Optical See-Through Head-Mounted Displays.[SEP]We propose a method to calibrate viewpoint-dependent, channel-wise image blur of near-eye displays, especially of Optical See-Through Head-Mounted Displays (OST-HMDs). Imperfections in HMD optics cause channel-wise image shift and blur that degrade the image quality of the display at a user's viewpoint. If we can estimate such characteristics perfectly, we could mitigate the effect by applying correction techniques from the computational photography in computer vision as analogous to cameras. Unfortunately, directly applying existing calibration techniques of cameras to OST-HMDs is not a straightforward task. Unlike ordinary imaging systems, image blur in OST-HMDs is viewpoint-dependent, i.e., the optical characteristic of a display dynamically changes depending on the current viewpoint of the user. This constraint makes the problem challenging since we must measure image blur of an HMD, ideally, over the entire 3D eyebox in which a user can see an image. To overcome this problem, we model the viewpoint-dependent blur as a Gaussian Light Field (GLF) that stores spatial information of the display screen as a (4D) light field with depth information and the blur as point-spread functions in the form of Gaussian kernels, respectively. We first describe both our GLF model and a calibration procedure to learn a GLF for a given OST-HMD. We then apply our calibration method to two HMDs that use different optics: a cubic prism or holographic gratings. The results show that our method achieves significantly better accuracy in Point-Spread Function (PSF) estimations with an accuracy about 2 to 7 dB in Peak SNR.\",\n",
              "  \"A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays.[SEP]Optical see-through head-mounted displays (OST HMDs) are a major output medium for Augmented Reality, which have seen significant growth in popularity and usage among the general public due to the growing release of consumer-oriented models, such as the Microsoft Hololens. Unlike Virtual Reality headsets, OST HMDs inherently support the addition of computer-generated graphics directly into the light path between a user's eyes and their view of the physical world. As with most Augmented and Virtual Reality systems, the physical position of an OST HMD is typically determined by an external or embedded 6-Degree-of-Freedom tracking system. However, in order to properly render virtual objects, which are perceived as spatially aligned with the physical environment, it is also necessary to accurately measure the position of the user's eyes within the tracking system's coordinate frame. For over 20 years, researchers have proposed various calibration methods to determine this needed eye position. However, to date, there has not been a comprehensive overview of these procedures and their requirements. Hence, this paper surveys the field of calibration methods for OST HMDs. Specifically, it provides insights into the fundamentals of calibration techniques, and presents an overview of both manual and automatic approaches, as well as evaluation methods and metrics. Finally, it also identifies opportunities for future research.\",\n",
              "  \"The Immersive Visualization Probe for Exploring n-Dimensional Spaces.[SEP]A new tool uses two types of dimensional navigation to display continuous 4D subsets of n-dimensional data. Thanks to the tool's embedded coordinate systems, researchers can better understand a model's underlying physical or mathematical process. Here, we describe a new method for visualizing data structure or models defined in higher-dimensional spaces. This technique is suitable for applications in which a scalar function, defined mathematically or procedurally, depends on n variables or parameters. The function's values essentially describe a set of points in n-dimensional space. To visualize these sets, we fix all but three of the parameters and then sample the resulting 4D set (the three parameters and the function's resulting value) on several discrete grids located on planes in the 3D space. We compose the image by using color to represent the fourth dimension (the function's value) at discrete locations on these grids. Interactive control over the way the parameters are fixed results in a highly dynamic system that researchers can easily use to explore the n-dimensional space's structure.\",\n",
              "  'Multidimensional virtual reality-MVR method: a new method of visualization of multidimensional worlds.[SEP]The paper presents a new, original method of multidimensional worlds’ visualization. It allows to present views of any dimension objects out of which it is possible to construct even the most complicated multidimensional virtual world on a computer screen. Due to this, it is possible to observe multidimensional worlds modeled in this way, analyze mutual relations between multidimensional objects, move between them and, most importantly, verify whether human brain is able to adapt to the perception of more than three-dimensional space. This paper presents example interior views of four-dimensional and five-dimensional labyrinths. It also presents results of the research performed on 97 IT students at the AGH University of Science and Technology. Students in total made 357 attempts to leave virtual four-dimensional and five-dimensional labyrinths, each having three difficulty levels. The method presented in this paper is sufficiently general to allow observation of objects in an n-dimensional space for any 𝑛≥3n≥3. Simultaneously, it is the natural extension of our reality perception because using this method for 𝑛=3n=3 we obtain views known to us from our human experience from the three-dimensional space.',\n",
              "  'ImAxes: Immersive Axes as Embodied Affordances for Interactive Multivariate Data Visualisation.[SEP]We introduce ImAxes immersive system for exploring multivariate data using fluid, modeless interaction. The basic interface element is an embodied data axis. The user can manipulate these axes like physical objects in the immersive environment and combine them into sophisticated visualisations. The type of visualisation that appears depends on the proximity and relative orientation of the axes with respect to one another, which we describe with a formal grammar. This straight-forward composability leads to a number of emergent visualisations and interactions, which we review, and then demonstrate with a detailed multivariate data analysis use case.'],\n",
              " 40: [\"Internet Search Roles of Adults in their Homes.[SEP]Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews and observations of search task performance with 40 adult participants, we identify and describe characteristics of 9 search roles. By comparing these roles with those of youths, we explain how previously identified roles, such as Power Searcher and Social Searcher, have evolved in adult populations, and how new roles, such as Efficient Searcher and Interest-driven Searcher, have emerged. We also review the challenges and benefits associated with search roles and their potential impacts on search performance. The findings of this study provide a better understanding of how contextual factors influence search roles in relation to ELIS, what can be learned from search roles, and opportunities to support different search roles.\",\n",
              "  'Designing the Search Experience.[SEP]This half-day tutorial provides a practical introduction to Human-Centred Design for information search, access and discovery. We present a concise overview of the fundamental concepts and principles of human information-seeking behaviour and show how to apply these in the design of search user experiences. A key element of the tutorial is the opportunity to practice these skills in a group exercise.',\n",
              "  'Adaptive information search: age-dependent interactions between cognitive profiles and strategies.[SEP]Previous research has shown that older adults performed worse in web search tasks, and attributed poorer performance to a decline in their cognitive abilities. We conducted a study involving younger and older adults to compare their web search behavior and performance in ill-defined and well-defined information tasks using a health information website. In ill-defined tasks, only a general description about information needs was given, while in well-defined tasks, information needs as well as the specific target information were given. We found that older adults performed worse than younger adults in well-defined tasks, but the reverse was true in ill-defined tasks. Older adults compensated for their lower cognitive abilities by adopting a top-down knowledge-driven strategy to achieve the same level of performance in the ill-defined tasks. Indeed, path models showed that cognitive abilities, health literacy, and knowledge influenced search strategies adopted by older and younger adults. Design implications are also discussed.',\n",
              "  \"Exploring multi-session web tasks.[SEP]Users are now performing more sophisticated web tasks. In this work, we explore web tasks that require multiple web sessions to complete (multi-session tasks) to satisfy a goal. We conducted a web-based diary study and a field study that used a customized version of Firefox which logged the participants' interactions for multi-session tasks and all their web activity. We found that multi-session tasks occur frequently and that users utilize a variety of browser tools and actions to help complete these tasks.\",\n",
              "  'Interest-Determining Web Browser.[SEP]This paper investigates the application of data-mining techniques on a user’s browsing history for the purpose of determining the user’s interests. More specifically, a system is outlined that attempts to determine certain keywords that a user may or may not be interested in. This is done by first applying a term-frequency/inverse-document frequency filter to extract keywords from webpages in the user’s history, after which a Self-Organizing Map (SOM) neural network is utilized to determine if these keywords are of interest to the user. Such a system could enable web-browsers to highlight areas of web pages that may be of higher interest to the user. It is found that while the system is indeed successful in identifying many keywords of user-interest, it also mis-classifies many uninteresting words boasting only a 62% accuracy rate.',\n",
              "  \"How do people find information on a familiar website?[SEP]Previous research has investigated how people either navigate the web as a whole, or find information on websites of which they have little previous knowledge. However, it is now common for people to make frequent use of one site (e.g., their employer's intranet). This paper reports how participants recalled and navigated a familiar website they had used for 8--20 months. Sketch maps showed that participants' memory for the site's content and structure was very limited in extent, but generally accurate. Navigation data showed that participants had much more difficulty finding the region of the site that contained a piece of information, than then finding the information itself. These data highlight the need for directly accessed pages to be given greater prominence in browser history mechanisms and designers to make information regions memorable. Finally, two navigational path metrics (stratum and percentage of revisit actions) that correlated with participants' performance were identified.\",\n",
              "  'Freebase: a collaboratively created graph database for structuring human knowledge.[SEP]Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.',\n",
              "  'Hybrid in-database inference for declarative information extraction.[SEP]In the database community, work on information extraction (IE) has centered on two themes: how to effectively manage IE tasks, and how to manage the uncertainties that arise in the IE process in a scalable manner. Recent work has proposed a probabilistic database (PDB) based declarative IE system that supports a leading statistical IE model, and an associated inference algorithm to answer top-k-style queries over the probabilistic IE outcome. Still, the broader problem of effectively supporting general probabilistic inference inside a PDB-based declarative IE system remains open. In this paper, we explore the in-database implementations of a wide variety of inference algorithms suited to IE, including two Markov chain Monte Carlo algorithms, the Viterbi and the sum-product algorithms. We describe the rules for choosing appropriate inference algorithms based on the model, the query and the text, considering the trade-off between accuracy and runtime. Based on these rules, we describe a hybrid approach to optimize the execution of a single probabilistic IE query to employ different inference algorithms appropriate for different records. We show that our techniques can achieve up to 10-fold speedups compared to the non-hybrid solutions proposed in the literature.',\n",
              "  'ONDUX: on-demand unsupervised learning for information extraction.[SEP]Information extraction by text segmentation (IETS) applies to cases in which data values of interest are organized in implicit semi-structured records available in textual sources (e.g. postal addresses, bibliographic information, ads). It is an important practical problem that has been frequently addressed in the recent literature. In this paper we introduce ONDUX (On Demand Unsupervised Information Extraction), a new unsupervised probabilistic approach for IETS. As other unsupervised IETS approaches, ONDUX relies on information available on pre-existing data to associate segments in the input string with attributes of a given domain. Unlike other approaches, we rely on very effective matching strategies instead of explicit learning strategies. The effectiveness of this matching strategy is also exploited to disambiguate the extraction of certain attributes through a reinforcement step that explores sequencing and positioning of attribute values directly learned on-demand from test data, with no previous human-driven training, a feature unique to ONDUX. This assigns to ONDUX a high degree of flexibility and results in superior effectiveness, as demonstrated by the experimental evaluation we report with textual sources from different domains, in which ONDUX is compared with a state-of-art IETS approach.'],\n",
              " 41: ['Similarity-based Ordering of Instances for Efficient Concept Learning.[SEP]Theories in concept learning predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning low-similarity concept structures. This suggests that the performance in concept learning tasks can be improved by grouping the instances of given concepts based on their similarity. To explore this hypothesis, we use Physical Bongard Problems, a rich categorization task with an open feature space, to analyze the combined effects of comparing dissimilar and similar instances within and across categories. We manipulate the within- and between-category similarity of instances presented close to each other in blocked, interleaved and simultaneous presentation schedules. The results show that grouping instances to promote dissimilar within- and similar between-category comparisons improves the learning results, to a degree depending on the strategy used by the learner.',\n",
              "  'Models of Human Category Learning: Do they Generalize?[SEP]Generalization to new examples is an essential aspect of categorization. However, recent category learning research has not focused on how people generalize their category knowledge. Taking generalization to be a critical basis for evaluating formal models of category learning, we employed a ‘minimal case’ approach to begin a systematic investigation of generalization. Human participants received supervised training on a two-way artificial classification task based on two dimensions that were each perfect predictors. Learners were then asked to classify new examples sampled from the stimulus space. Most participants based their judgments on one or the other dimension. Varying the relative levels of dimension salience influenced generalization outcomes, but varying category size (2, 4, or 8 items) did not. We fit two theoretically distinct similarity-based models (ALCOVE and DIVA) to aggregate learning data and tested on the generalization set. Both models could explain important aspects of human performance, but DIVA produced a superior overall account.',\n",
              "  'Perceptual Learning in Correlation Estimation: The Role of Learning Category Organization.[SEP]Research has shown that estimation of correlation from scatter plots is done poorly by both novices and experts. We tested whether proficiency in correlation estimation could be improved by perceptual learning interventions, in the form of perceptual-adaptive learning modules (PALMs). We also tested learning effects of alternative category structures in perceptual learning. We organized the same set of 252 scatter plot displays either into a PALM that implemented spacing in learning by shape categories or one in which the categories were ranges of correlation strength. Both PALMs produced markedly reduced errors, and both led trained participants to classify near transfer items as accurately as trained items. Differences in category organization produced modest effects on learning; there was some indication of more consistent reduction of absolute error when learning categories were organized by shape, whereas average bias of judgments was best reduced by categories organized by different numerical ranges of correlation.'],\n",
              " 42: ['Demonstration of Qurk: a query processor for humanoperators.[SEP]Crowdsourcing technologies such as Amazon\\'s Mechanical Turk (\"MTurk\") service have exploded in popularity in recent years. These services are increasingly used for complex human-reliant data processing tasks, such as labelling a collection of images, combining two sets of images to identify people that appear in both, or extracting sentiment from a corpus of text snippets. There are several challenges in designing a workflow that filters, aggregates, sorts and joins human-generated data sources. Currently, crowdsourcing-based workflows are hand-built, resulting in increasingly complex programs. Additionally, developers must hand-optimize tradeoffs among monetary cost, accuracy, and time to completion of results. These challenges are well-suited to a declarative query interface that allows developers to describe their worflow at a high level and automatically optimizes workflow and tuning parameters. In this demonstration, we will present Qurk, a novel query system that allows human-based processing for relational databases. The audience will interact with the system to build queries and monitor their progress. The audience will also see Qurk from an MTurk user\\'s perspective, and complete several tasks to better understand how a query is processed.',\n",
              "  \"CrowdFill: collecting structured data from the crowd.[SEP]We present CrowdFill, a system for collecting structured data from the crowd. While a typical microtask-based approach would pose specific questions to each worker and assemble the answers, CrowdFill shows a partially-filled table to all participating workers. Workers contribute by filling in empty cells, as well as upvoting and downvoting data entered by other workers. The system's synchronization scheme, based on a careful model of primitive operations, enables workers to collaboratively complete the table without latency overhead. CrowdFill allows the specification of constraints on the collected data, and has mechanisms for resolving inconsistencies. Its compensation scheme takes into account each worker's contribution to the final table, and the varying difficulty of data entry tasks. The paper includes some preliminary experimental results.\",\n",
              "  'CrowdDQS: Dynamic Question Selection in Crowdsourcing Systems.[SEP]In this paper, we present CrowdDQS, a system that uses the most recent set of crowdsourced voting evidence to dynamically issue questions to workers on Amazon Mechanical Turk (AMT). CrowdDQS posts all questions to AMT in a single batch, but delays the decision of the exact question to issue a worker until the last moment, concentrating votes on uncertain questions to maximize accuracy. Unlike previous works, CrowdDQS also (1) optionally can decide when it is more beneficial to issue gold standard questions with known answers than to solicit new votes (both can help us estimate worker accuracy, but gold standard questions provide a less noisy estimate of worker accuracy at the expense of not obtaining new votes), (2) estimates worker accuracies in real-time even with limited evidence (with or without gold standard questions), and (3) infers the distribution of worker skill levels to actively block poor workers. We deploy our system live on AMT to over 1000 crowdworkers, and find that CrowdDQS can accurately answer questions using up to 6x fewer votes than standard approaches. We also find there are many non-obvious practical challenges involved in deploying such a system seamlessly to crowdworkers, and discuss techniques to overcome these challenges.'],\n",
              " 43: ['Local-universality: designing EMR to support localized informal documentation practices.[SEP]In this paper, we describe a practice that is common across multiple heterogeneous contexts but enacted differently depending on the unique constellation of resources and demands present in each local context. Using the case of informal documentation practices in two departments of a single hospital, Emergency and Labor & Delivery, we describe how clinicians in each department develop contextualized informal documentation practices after deployment of a new EMR system. We describe three underlying functions of informal documentation that are inherent to the practice of medical personnel: \"memory work,\" abstraction work,\" and \"future work.\" We then find that the newly deployed EMR technology does not support these kinds of work. We argue that hospital documentation work systems should be designed with an eye to such universal work practices, while keeping in mind that the effectiveness of informal documentation practices is rooted in its adaptive and flexible deployment in heterogeneous work settings.',\n",
              "  \"Accountability in an alarming environment.[SEP]This paper considers how adjustable alarms support collaborative monitoring work within the intensive care unit. Drawing on examples from an observational study, it hopes to stimulate new ways of thinking about the role that alarms play in supporting awareness of not only changes in the environment but also awareness of colleagues' actions. Adjustable alarms allow nurses to fit the alarm limits to both the patient state and the nurse's level of experience. The setting of alarm limits is an accountable activity, being visible to and observed by colleagues.\",\n",
              "  \"Documenting transitional information in EMR.[SEP]An observational study was conducted to examine EMR-based documentation in an Emergency Department (ED), with an emphasis on computerized documentation activities in the complex flow of clinical processes. This study revealed a gap between the formal EMR documentation and the actual clinical workflow, which leads ED staff to rely on intermediate - transitional artifacts to facilitate their work. The analysis of these transitional artifacts in four different clinical workflows shows that the EMR system's inability to document procedural information, capture key information, and present information according to the actual clinical workflow are accountable for leading to the use of transitional artifacts. The findings of this study call for designing EMR system not only for keeping patients' formal records, but also for documenting transitional information in the chart-writing process.\",\n",
              "  'Patient Subtyping via Time-Aware LSTM Networks.[SEP]In the study of various diseases, heterogeneity among patients usually leads to different progression patterns and may require different types of therapeutic intervention. Therefore, it is important to study patient subtyping, which is grouping of patients into disease characterizing subtypes. Subtyping from complex patient data is challenging because of the information heterogeneity and temporal dynamics. Long-Short Term Memory (LSTM) has been successfully used in many domains for processing sequential data, and recently applied for analyzing longitudinal patient records. The LSTM units are designed to handle data with constant elapsed times between consecutive elements of a sequence. Given that time lapse between successive elements in patient records can vary from days to months, the design of traditional LSTM may lead to suboptimal performance. In this paper, we propose a novel LSTM unit called Time-Aware LSTM (T-LSTM) to handle irregular time intervals in longitudinal patient records. We learn a subspace decomposition of the cell memory which enables time decay to discount the memory content according to the elapsed time. We propose a patient subtyping model that leverages the proposed T-LSTM in an auto-encoder to learn a powerful single representation for sequential records of patients, which are then used to cluster patients into clinical subtypes. Experiments on synthetic and real world datasets show that the proposed T-LSTM architecture captures the underlying structures in the sequences with time irregularities.',\n",
              "  'Dynamic Illness Severity Prediction via Multi-task RNNs for Intensive Care Unit.[SEP]Most of the existing analytics on ICU data mainly focus on mortality risk prediction and phenotyping analysis. However, they have limitations in providing sufficient evidence for decision making in a dynamically changing clinical environment. In this paper, we propose a novel approach that simultaneously analyses different organ systems to predict the illness severity of patients in an ICU, which can intuitively reflect the condition of the patients in a timely fashion. Specifically, we develop a novel deep learning model, namely MTRNN-ATT, which is based on multi-task recurrent neural networks. The physiological features of each organ system in time-series representations are learned by a single long short-term memory unit as a specific task. To utilize the relationships between organ systems, we use a shared LSTM unit to exploit the correlations between different tasks for further performance improvement. Also, we apply an attention mechanism in our deep model to learn the selective features at each stage to achieve better prediction results. We conduct extensive experiments on a real-world clinical dataset (MIMIC-III) to compare our method with many state-of-the-art methods. The experiment results demonstrate that the proposed approach performs better on the prediction tasks of illness severity scores.',\n",
              "  'Multi-layer Representation Learning for Medical Concepts.[SEP]Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.'],\n",
              " 44: ['Aristotelian and Duality Relations Beyond the Square of Opposition.[SEP]Nearly all squares of opposition found in the literature represent both the Aristotelian relations and the duality relations, and exhibit a very close correspondence between both types of logical relations. This paper investigates the interplay between Aristotelian and duality relations in diagrams beyond the square. In particular, we study a Buridan octagon, a Lenzen octagon, a Keynes-Johnson octagon and a Moretti octagon. Each of these octagons is a natural extension of the square, both from an Aristotelian perspective and from a duality perspective. The results of our comparative analysis turn out to be highly nuanced.',\n",
              "  'A Semiotic-Conceptual Analysis of Euler and Hasse Diagrams.[SEP]Semiotic-Conceptual Analysis (SCA) considers diagrams (and in general any signs) as consisting of representamens, denotations and interpretations which supports investigating these three components individually and jointly. A core notion for diagram research is “observability” which refers to logically valid statements that can be visually extracted from diagrams. This notion is included into the SCA vocabulary and discussed with respect to Euler and Hasse diagrams.',\n",
              "  'Euler Diagrams for Defeasible Reasoning.[SEP]We investigate Euler diagrammatic systems for defeasible reasoning by extending the usual systems for Euler and Venn diagrams corresponding to standard classical logic. To achieve this, we use the generalized quantifier “most” to formalize defeasible reasoning, as proposed by Schlechta (1995), where defeasible knowledge is represented as “Most A are B” and axioms for “most” are defined. We introduce an Euler diagrammatic system for defeasible reasoning by introducing circle mA that represents “most A” for each circle A. We show that our Euler diagrammatic system is a diagrammatic representation of the symbolic system of the generalized quantifier “most”. Furthermore, we investigate skeptical and credulous strategies in defeasible reasoning with our Euler diagrams.',\n",
              "  'The Diagram of Flow: Its Departure from Software Engineering and Its Return.[SEP]The first diagrammatic notation used in software engineering represented the concept of flow. This paper considers the factors that affected the apparent departure of the flowchart from software engineering practice during the 1970s and 1980s and its subsequent return in the 1990s. A new emphasis on hierarchy (as level of abstraction) and on data structure meant that the general concept of flow was completely superseded, only to re-emerge later as a new duality of control flow and data flow. This reappearance took a variety of forms with varying semantics until its stabilisation in the latest version of the Unified Modeling Language. Flow is there re-instated as a fundamental concept in software engineering although its importance, and that of the activity diagram used to represent it, diminished as a consequence of its becoming just one among a wider set of paradigms for software systems development, each associated with its own diagrams.',\n",
              "  'Notations for Software Engineering Class Structures.[SEP]This builds on previous work in which we have developed diagramming principles based on theories of structural object perception. We call these geon diagrams. We have previously shown that such diagrams are easy to remember and to analyze. To evaluate our hypothesis that geon diagrams should also be easy to understand we carried out an empirical study to evaluate the learnability of geon diagram semantics in comparison with the well-established UML convention. The results support our theory of learnability. Both ”novices” and ”experts” found the geon diagram syntax easier to apply in a diagram-to-textual description matching task than the equivalent UML syntax.',\n",
              "  'Enhancing State-Space Tree Diagrams for Collaborative Problem Solving.[SEP]State-space search methods in problem solving have often been illustrated using tree diagrams. We explore a set of issues related to coordination in collaborative problem solving and design, and we present a variety of interactive features for state-space search trees intended to facilitate such activity. Issues include how to show provenance of decisions, how to combine work and views produced separately, and how to represent work performed by computer agents. Some of the features have been implemented in a kit “TStar” and a design tool “PRIME Designer.”'],\n",
              " 45: ['Color, Change and Control for Quantitative Data Display.[SEP]Calico, a dynamic tool for the creation and manipulation of color mappings for the exploration of multivariate, quantitative data, was used to study the effects of user control and smooth change on user preference, accuracy, and confidence. The results of the study, as well as other user experiences with Calico, support the hypothesis that dynamic manipulation of color mappings is a useful feature of systems for the exploration of quantitative data using color. The main effect observed is a clear user preference for representations providing control over the mapping, a small but significant increase in accuracy, and greater confidence in information gleaned from manipulable displays. A smaller and less consistent effect showed greater user preference for an confidence in representations which provided smooth change between images.< >',\n",
              "  \"Examining Implicit Discretization in Spectral Schemes.[SEP]Two of the primary reasons rainbow color maps are considered ineffective trace back to the idea that they implicitly discretize encoded data into hue‐based bands, yet no research addresses what this discretization looks like or how consistent it is across individuals. This paper presents an exploratory study designed to empirically investigate the implicit discretization of common spectral schemes and explore whether the phenomenon can be modeled by variations in lightness, chroma, and hue. Our results suggest that three commonly used rainbow color maps are implicitly discretized with consistency across individuals. The results also indicate, however, that this implicit discretization varies across different datasets, in a way that suggests the visualization community's understanding of both rainbow color maps, and more generally effective color usage, remains incomplete.\",\n",
              "  \"Modeling Color Difference for Visualization Design.[SEP]Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.\"],\n",
              " 46: ['Metaprobes, Metaphysical Workshops and Sketchy Philosophy.[SEP]The intersection of philosophy and HCI is a longstanding site of interest for the field that has been attracting special attention in recent years. In this paper, we present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry. A Metaprobe is a design artifact used to study a metaphysical idea without concealing the philosophical tools mobilized by the designers or the designerly knowledge attained after deployment. We introduce the concept of a Metaphysical Workshop. This is the set of sketchy philosophical notions that a designer mobilizes in order to research a philosophical idea through design. We then present a case study that comprises: the philosophical issue under examination, the Metaprobes designed to study it, the metaphysical workshop used and the designerly insight produced. We conclude with a discussion of the potentials and weaknesses of Metaprobes in relation to other critical and speculative research-through-design practices. We aim to provide one way to make philosophies already present in design more explicit and make other philosophical concepts relevant to HCI more accessible and workable for designers.',\n",
              "  'From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product.[SEP]As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact.',\n",
              "  'Design Justice and User Interface Design.[SEP]In this keynote talk, Dr. Costanza-Chock will explore the theory and practice of design justice, discuss how design affordances, disaffordances, and dysaffordances distribute benefits and burdens unequally according to users? location within the matrix of domination (white supremacy, heteropatriarchy, ableism, capitalism, and settler colonialism), and invite us to consider how user interface designers can intentionally contribute to building ?a better world?, a world where many worlds fit; linked worlds of collective liberation and ecological sustainability.'],\n",
              " 47: ['Museum guide robot based on sociological interaction analysis.[SEP]We are currently working on a museum guide robot with an emphasis on \"friendly\" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.',\n",
              "  \"A Survey of Users' Expectations Towards On-body Companion Robots.[SEP]Being as a robotic companion is an extensive application of on-body robots; yet, as an emerging type of robots, few previous works focus on the design of on-body companion robots from the users' perspective, remaining users' expectations towards this type of robots unclear. To assist designers in the design process of on-body companion robots, we surveyed users' expectations towards on-body companion robots (n=215) by a questionnaire constituting of questions on factors that may affect robot acceptance, including robot functionality, robot appearance, and robot social ability. Based on the survey results, we stated design guidelines for the design of on-body companion robots supporting designers with insights into users. To demonstrate how to design on-body companion robots based on our findings, we organized a workshop with experienced designers to develop a conceptual on-body companion robot, and they proposed Bubo, an example prototype of on-body companion robot.\",\n",
              "  \"Authoring and Verifying Human-Robot Interactions.[SEP]As social agents, robots designed for human interaction must adhere to human social norms. How can we enable designers, engineers, and roboticists to design robot behaviors that adhere to human social norms and do not result in interaction breakdowns? In this paper, we use automated formal-verification methods to facilitate the encoding of appropriate social norms into the interaction design of social robots and the detection of breakdowns and norm violations in order to prevent them. We have developed an authoring environment that utilizes these methods to provide developers of social-robot applications with feedback at design time and evaluated the benefits of their use in reducing such breakdowns and violations in human-robot interactions. Our evaluation with application developers (N=9) shows that the use of formal-verification methods increases designers' ability to identify and contextualize social-norm violations. We discuss the implications of our approach for the future development of tools for effective design of social-robot applications.\"],\n",
              " 48: ['Active Learning from Multiple Noisy Labelers with Varied Costs.[SEP]In active learning, where a learning algorithm has to purchase the labels of its training examples, it is often assumed that there is only one labeler available to label examples, and that this labeler is noise-free. In reality, it is possible that there are multiple labelers available (such as human labelers in the online annotation tool Amazon Mechanical Turk) and that each such labeler has a different cost and accuracy. We address the active learning problem with multiple labelers where each labeler has a different (known) cost and a different (unknown) accuracy. Our approach uses the idea of adjusted cost, which allows labelers with different costs and accuracies to be directly compared. This allows our algorithm to find low-cost combinations of labelers that result in high-accuracy labelings of instances. Our algorithm further reduces costs by pruning under-performing labelers from the set under consideration, and by halting the process of estimating the accuracy of the labelers as early as it can. We found that our algorithm often outperforms, and is always competitive with, other algorithms in the literature.',\n",
              "  'Neural Conditional Energy Models for Multi-label Classification.[SEP]Multi-label classification (MLC) is a type of structured output prediction problems where a given instance can be associated to more than one labels at a time. From the probabilistic point of view, a model predicts a set of labels y given an input vector v by learning a conditional distribution p(y|v). This paper presents a powerful model called a Neural Conditional Energy Model (NCEM) to solve MLC. The model can be viewed as a hybrid deterministic-stochastic network of which we use a deterministic neural network to transform the input data, before contributing to the energy landscape of v, y, and a single stochastic hidden layer h. Non-linear transformation given by the neural network makes our model more expressive and more capable of capturing complex relations between input and output, and using deterministic neurons facilitates exact inference. We present an efficient learning algorithm that is simple to implement. We conduct extensive experiments on 15 real-world datasets from wide variety of domains with various evaluation metrics to confirm that NCEM is significantly superior to current state-of-the-art models most of the time based on pair-wise t-test at 5% significance level. The MATLAB source code to replicate our experiments are available at https://github.com/Kublai-Jing/NCEM.',\n",
              "  'Inductive Semi-supervised Multi-Label Learning with Co-Training.[SEP]In multi-label learning, each training example is associated with multiple class labels and the task is to learn a mapping from the feature space to the power set of label space. It is generally demanding and time-consuming to obtain labels for training examples, especially for multi-label learning task where a number of class labels need to be annotated for the instance. To circumvent this difficulty, semi-supervised multi-label learning aims to exploit the readily-available unlabeled data to help build multi-label predictive model. Nonetheless, most semi-supervised solutions to multi-label learning work under transductive setting, which only focus on making predictions on existing unlabeled data and cannot generalize to unseen instances. In this paper, a novel approach named COINS is proposed to learning from labeled and unlabeled data by adapting the well-known co-training strategy which naturally works under inductive setting. In each co-training round, a dichotomy over the feature space is learned by maximizing the diversity between the two classifiers induced on either dichotomized feature subset. After that, pairwise ranking predictions on unlabeled data are communicated between either classifier for model refinement. Extensive experiments on a number of benchmark data sets show that COINS performs favorably against state-of-the-art multi-label learning approaches.'],\n",
              " 49: ['Alphabetically constrained keypad designs for text entry on mobile devices.[SEP]The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.',\n",
              "  'DualKey: Miniature Screen Text Entry via Finger Identification.[SEP]Fast and accurate access to keys for text entry remains an open question for miniature screens. Existing works typically use a cumbersome two-step selection process, first to zero-in on a particular zone and second to make the key selection. We introduce DualKey, a miniature screen text entry technique with a single selection step that relies on finger identification. We report on the results of a 10 day longitudinal study with 10 participants that evaluated speed, accuracy, and learning. DualKey outperformed the existing techniques on long-term performance with a speed of 19.6 WPM. We then optimized the keyboard layout for reducing finger switching time based on the study data. A second 10 day study with eight participants showed that the new sweqty layout improved upon DualKey even further to 21.59 WPM for long-term speed, was comparable to existing techniques on novice speed and outperformed existing techniques on novice accuracy rate.',\n",
              "  'Language modeling for soft keyboards.[SEP]Language models predict the probability of letter sequences. Soft keyboards are images of keyboards on a touch screen for input on Personal Digital Assistants. When a soft keyboard user hits a key near the boundary of a key position, the language model and key press model are combined to select the most probable key sequence. This leads to an overall error rate reduction by a factor of 1.67 to 1.87. An extended version of this paper [4] is available.'],\n",
              " 50: ['nuSketch battlespace: a demonstration.[SEP]Sketching provides a natural means of interaction for many spatially-oriented tasks. One task where sketching is used extensively is when military planners are formulating battle plans, called Courses of Action (COAs). This paper describes a system we have built, nuSketch Battlespace (nSB), which provides a sketching interface for creating COAs. The system is described in the paper \"Sketching for Military Courses of Action\" in these proceedings. The demonstration will highlight:',\n",
              "  'Getting Started with Sketch Tools.[SEP]Diagrams are an important, if not pivotal, part in both education and design. In an effort to understand abstract concepts, students play an active role in their education by specifying visual and abstract concepts in hand-sketched diagrams. While students are understanding abstract concepts through hand-drawn diagrams, designers are creating those abstract concepts. Just as the act of hand-drawing a diagram (as opposed to using a mouse-and-palette CAD tool) better engages the student in the learning process, the act of hand-drawing a diagram also improves the design process by freeing the designer of constraints that may otherwise impede creativity and innovation.',\n",
              "  'Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals.[SEP]Sketching is a practical and useful skill that can benefit communication and problem solving. However, it remains a difficult skill to learn because of low confidence and motivation among students and limited availability for instruction and personalized feedback among teachers. There is an need to improve the educational experience for both groups, and we hypothesized that integrating technology could provide a variety of benefits. We designed and developed an intelligent tutoring system for sketching fundamentals called Sketchtivity, and deployed it in to six existing courses at the high school and university level during the 2017-2018 school year. 268 students used the tool and produced more than 116,000 sketches of basic primitives. We conducted semi-structured interviews with the six teachers who implemented the software, as well as nine students from a course where the tool was used extensively. Using grounded theory, we found ten categories which unveiled the benefits and limitations of integrating an intelligent tutoring system for sketching fundamentals in to existing pedagogy.'],\n",
              " 51: ['Bilinear interpolation for facial expression and metamorphosis in real-time animation.[SEP]This paper describes a new method for generating facial animation in which facial expression and shape can be changed simultaneously in real time. A 2D parameter space independent of facial shape is defined, on which facial expressions are superimposed so that the expressions can be applied to various facial shapes. A facial model is transformed by a bilinear interpolation, which enables a rapid change in facial expression with metamorphosis. The practical efficiency of this method has been demonstrated by a real-time animation system based on this method in live theater.',\n",
              "  'Transferring of Speech Movements from Video to 3D Face Space.[SEP]We present a novel method for transferring speech animation recorded in low quality videos to high resolution 3D face models. The basic idea is to synthesize the animated faces by an interpolation based on a small set of 3D key face shapes which span a 3D face space. The 3D key shapes are extracted by an unsupervised learning process in 2D video space to form a set of 2D visemes which are then mapped to the 3D face space. The learning process consists of two main phases: 1) isomap-based nonlinear dimensionality reduction to embed the video speech movements into a low-dimensional manifold and 2) k-means clustering in the low-dimensional space to extract 2D key viseme frames. Our main contribution is that we use the isomap-based learning method to extract intrinsic geometry of the speech video space and thus to make it possible to define the 3D key viseme shapes. To do so, we need only to capture a limited number of 3D key face models by using a general 3D scanner. Moreover, we also develop a skull movement recovery method based on simple anatomical structures to enhance 3D realism in local mouth movements. Experimental results show that our method can achieve realistic 3D animation effects with a small number of 3D key face models',\n",
              "  'Design, transformation and animation of human faces.[SEP]Creation of new human faces for synthetic actors is a tedious and painful task. The situation may be improved by introducing tools for the creation. Two approaches are discussed in this paper: modification and edition of an existing synthetic actor using local transformations; generation of new synthetic actors obtained by interpolation between two existing actors; creation of a synthetic actor by composition of different parts. This paper also describes the methods used in the facial animation of synthetic actors who change their personalities from one person to another. This means that our purpose is to transform one character into another, and also to transform the animation at the same time. The interpolation must be at several levels: the shape level, the parameter level, the expression level and the script level. For the animation, we introduce three levels of inbetweens: inbetween parameters, inbetween expressions and inbetween scripts. The method has been completely implemented and integrated into the Human Factory software.',\n",
              "  'Spatial pyramid face feature representation and weighted dissimilarity matching for improved face recognition.[SEP]In this paper, we present a novel face recognition (FR) algorithm based on multiresolution spatial pyramid. In our method, a face is subdivided into increasingly finer subregions (local regions) and represented at multiple levels of histogram representations. To address image misalignment problem, overlapped patch-based local descriptor extraction has been also developed in an effective way. To preserve multiple levels of detail in facial local characteristics and to encode holistic spatial configuration, face features obtained for concatenated histograms (coming from all levels of spatial pyramid) are integrated into a combined feature set, termed spatial pyramid face feature representation (SPFR). In addition, to perform recognition by matching between the pair of probe and gallery SPFR sets, we propose the use of a weighted sum of the dissimilarity scores computed at all spatial pyramid levels. For this purpose, we develop a novel weight determination solution based on class-wise discriminant power estimation for face feature at a specific pyramid level. We incorporate our proposed algorithm into general FR pipeline and achieve encouraging identification results on the CMU-PIE, FERET, and LFW datasets, compared to previously developed methods. In addition, the feasibility of our method has been successfully demonstrated by making comparisons with other state-of-the-art FR methods (including deep CNN based method) under the FERET and FRGC 2.0 evaluation protocols. Based on results, our method is advantageous in terms of high recognition accuracy and low complexity, as well as straightforward implementation.',\n",
              "  'On the Learning of Deep Local Features for Robust Face Spoofing Detection.[SEP]Biometrics emerged as a robust solution for security systems. However, given the dissemination of biometric applications, criminals are developing techniques to circumvent them by simulating physical or behavioral traits of legal users (spoofing attacks). Despite face being a promising characteristic due to its universality, acceptability and presence of cameras almost everywhere, face recognition systems are extremely vulnerable to such frauds since they can be easily fooled with common printed facial photographs. State-of-the-art approaches, based on Convolutional Neural Networks (CNNs), present good results in face spoofing detection. However, these methods do not consider the importance of learning deep local features from each facial region, even though it is known from face recognition that each facial region presents different visual aspects, which can also be exploited for face spoofing detection. In this work we propose a novel CNN architecture trained in two steps for such task. Initially, each part of the neural network learns features from a given facial region. Afterwards, the whole model is fine-tuned on the whole facial images. Results show that such pre-training step allows the CNN to learn different local spoofing cues, improving the performance and the convergence speed of the final model, outperforming the state-of-the-art approaches.',\n",
              "  'Analysis of the Eyes on Face Images for Compliance with ISO/ICAO Requirements.[SEP]The face has been used in identity documents and represents the ideal biometric characteristic in many applications. The International Civil Aviation Organization endorsed the use of face as the globally interoperable biometric characteristic. Successively, the International Standard Organization proposed the ISO/IEC 19794-5 standard for face usage in travel documents. The purpose of this work is to evaluate the quality of face images for identification documents and check if the face images satisfy the requirements defined by the ISO/IEC 19794-5. This work presents approaches for the evaluation of the following ISO/ICAO requirements: eyes state, red eyes and looking away. In addition, an approach to estimate the location of the center of the eyes is proposed. The proposed methods to check ISO/ICAO requirements were evaluated using the BioLab-ICAO Framework. The results achieved by the proposed methods were satisfactory, overcoming almost all the works in the literature for this purpose.'],\n",
              " 52: ['Chainer: A Deep Learning Framework for Accelerating the Research Cycle.[SEP]Software frameworks for neural networks play a key role in the development and application of deep learning methods. In this paper, we introduce the Chainer framework, which intends to provide a flexible, intuitive, and high performance means of implementing the full range of deep learning models needed by researchers and practitioners. Chainer provides acceleration using Graphics Processing Units with a familiar NumPy-like API through CuPy, supports general and dynamic models in Python through Define-by-Run, and also provides add-on packages for state-of-the-art computer vision models as well as distributed training.',\n",
              "  'The business impact of deep learning.[SEP]In the last year deep learning has gone from being a special purpose machine learning technique used mainly for image and speech recognition, to becoming a general purpose machine learning tool. This has broad implications for all organizations that rely on data analysis. It represents the latest development in a general trend towards more automated algorithms, and away from domain specific knowledge. For organizations that rely on domain expertise for their competitive advantage, this trend could be extremely disruptive. For start-ups interested in entering established markets, this trend could be a major opportunity. This talk will be a non-technical introduction to general-purpose deep learning, and its potential business impact.',\n",
              "  \"Principles of Explanatory Debugging to Personalize Interactive Machine Learning.[SEP]How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.\"],\n",
              " 53: ['ScreenCrayons: annotating anything.[SEP]ScreenCrayons is a system for collecting annotations on any type of document or visual information from any application. The basis for the system is a screen capture upon which the user can highlight the relevant portions of the image. The user can define any number of topics for organizing notes. Each topic is associated with a highlighting \"crayon.\" In addition the user can supply annotations in digital ink or text. Algorithms are described that summarize captured images based on the highlight strokes so as to provide overviews of many annotations as well as being able to \"zoom in\" on particular information about a given note and the context of that note.',\n",
              "  'Reflowing digital ink annotations.[SEP]Annotating paper documents with a pen is a familiar and indispensable activity across a wide variety of work and educational settings. Recent developments in pen-based computing promise to bring this experience to digital documents. However, digital documents are more flexible than their paper counterparts. When a digital document is edited, or displayed on different devices, its layout adapts to the new situation. Freeform digital ink annotations made on such a document must likewise adapt, or \"reflow.\" But their unconstrained nature yields only vague guidelines for how these annotations should be transformed. Few systems have considered this issue, and still fewer have addressed it from a user\\'s point of view. This paper reports the results of a study of user expectations for reflowing digital ink annotations. We explore user reaction to reflow in common cases, how sensitive users are to reflow errors, and how important it is that personal style survive reflow. Our findings can help designers and system builders support freeform annotation more effectively.',\n",
              "  'The Breadth and Depth of E-reading and Paper-reading.[SEP]The present study investigated the differences between e-reading and paper-reading in their breadth and depth. Our results showed that (1) breadth and depth of reading were both greater in e-reading than in paper-reading; (2) possession of a tablet tended to facilitate breadth of e-reading; (3) breadth of e-reading was greater than breadth of paper-reading for news, magazines, and others, but not for novels; (4) depth of e-reading was greater than depth of paper-reading for novels, but the reverse was true for news and magazines; (5) people tended to read research articles, books and magazines on paper, but news and others on digital devices; (6) people tended to read longer on paper than on digital devices, but the percentage of contents they could remember was no different between e-reading and paper-reading. We conclude that modern readers have become accustomed to e-reading and can do it more efficiently than paper-reading.',\n",
              "  'Preface.[SEP]In this issue, we have fourteen regular papers and two corrections for previously published papers:',\n",
              "  'VIS capstone address.[SEP]Useful as each of them can be, a large body of tips and tricks is impossible to remember, at least in a practical, usable way, unless it is structured into a balanced, meaningful hierarchy. This talk proposes and illustrates three simple yet solid ideas that lead to more effective communication and that underpin every other guideline: easy to remember, readily applicable, and always relevant—in short, valuable for the rest of your life.',\n",
              "  'Preface.[SEP]In this issue, we have ten regular papers and one erratum:',\n",
              "  'A Survey of Topology-based Methods in Visualization.[SEP]This paper presents the state of the art in the area of topology‐based visualization. It describes the process and results of an extensive annotation for generating a definition and terminology for the field. The terminology enabled a typology for topological models which is used to organize research results and the state of the art. Our report discusses relations among topological models and for each model describes research results for the computation, simplification, visualization, and application. The paper identifies themes common to subfields, current frontiers, and unexplored territory in this research area.',\n",
              "  'Editor\\'s Note [2013 Best Associate Editor Award  2013 Best Reviewer Award].[SEP]The success of a journal relies heavily on the quality of submissions and of their reviews. The latter is primarily the work and efforts of the associate editors and the anonymous reviewers. The dedication of associate editors and of external reviewers is essential to the continuing growth of the journal. To continue recognizing these \"unsung heroes\" who drive the scientific peer review process for IEEE Transactions on Visualization and Computer Graphics (TVCG), it is my pleasure to announce the 2013 Best Associate Editor Award and the 2013 Best Reviewer Award. Three associate editors (AEs) for are recognized their dedication and hard work in 2013: Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi. They handled a large number of submissions efficiently with the quickest turnaround (averaging less than 50 days) and provided consistently high-quality, thoughtful AE summary to the authors. In recognizing their distinguished service to the IEEE TVCG, the 2013 TVCG Best Associate Editor Award goes to Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi.',\n",
              "  \"Guest Editors' Introduction: Special Section on the IEEE Pacific Visualization Symposium 2012.[SEP]The papers in this special section are extended versions of three selected papers from the IEEE Pacific Visualization Symposium 2012 (PacificVis) which took place in Songdo, Korea from 28 February to 2 March 2012.\"],\n",
              " 54: ['Web3D representation and cultural heritage: from annotations to narrations.[SEP]Storytelling is a powerful means for teaching, often used for engaging pupils while educating them. This paper describes an innovative web tool for creating engaging narrations for educational purposes that can be shared on the web. The tool is integrated with ToBoA-3D, a web platform for annotating 3D environments and taking advantage of the crowdsourced effort of its users for creating linear stories that can be shared on the web. An example focused on an educational narration about Renaissance architecture will be shown.',\n",
              "  'Unearthing Virtual History: Using Diverse Interfaces to Reveal Hidden Virtual Worlds.[SEP]We describe an application in which museum visitors hunt for virtual history outdoors, capture it, and bring it back indoors for detailed inspection. This application provides visitors with ubiquitous access to a parallel virtual world as they move through an extended physical space. Diverse devices, including mobile wireless interfaces for locating hotspots of virtual activity outdoors, provide radically different experiences of the virtual depending upon location, task, and available equipment. Initial reflections suggest that the physical design of such devices needs careful attention so as to encourage an appropriate style of use. We also consider the extension of our experience to support enacted scenes. Finally, we discuss potential benefits of using diverse devices to make a shared underlying virtual world ubiquitously available throughout physical space.',\n",
              "  'Making Place: Designing and Building an Engaging, Interactive and Pedagogical Historical World.[SEP]Digital visualisation technologies have transformed the field of heritage. The digital re-creation of a place demands much more than architectural modeling. Designers of virtual heritage places can learn from commercial computer games which can be very successful at creating a sense of place. The Virtual Sydney Rocks is designed to undertake research into the role that user preference for interaction strategy has on engagement in a Virtual Heritage Environment. Users can explore an experiential model of Sydney Cove between 1788 and 2008 in three different ways; by self directed exploration, by playing a game or by taking a tour. Users set the date and time to determine the position of the sun, the weather, the sounds that are heard and the buildings that are displayed. Users can also alter the speed of time. Additional information is accessed via the interlinked Virtual Sydney Rocks Guidebook.',\n",
              "  \"Visitors' Evaluations of ICTs Used in Cultural Heritage.[SEP]Technology that serves to enhance the visitors experience is gradually becoming more commonplace at Cultural Heritage (CH) sites. However ICT is not usually the CH professional s area of expertise and they have to make choices from a bewildering array of technology, often without fully understanding their visitors ICT needs. This research aims to alleviate the situation by gathering visitors evaluations of technologies that are frequently used at CH sites along with advanced applications, to identify which technologies visitors use and what they need. The research took place in five CH attractions in the UK and incorporates the results of one hundred and sixty four interviews with visitors. Both CH professionals and technology developers can use this research to gain insights into the use of ICT applications at sites and to identify emerging needs in the marketplace. The findings of this research indicate that ICTs in use at the CH sites involved were underutilised. Despite this, respondents strongly supported the advanced applications which included: Augmented Reality; an Interactive Museum Installation; a Mobile Media Guide and an Avatar Application. This is because they could see how they would benefit. This paper concludes that the use of ICT was supported by visitors to some degree. However in order to encourage use, the benefits must be clearly communicated to visitors.\",\n",
              "  \"Digital Exhibit Labels in Museums: Promoting Visitor Engagement with Cultural Artifacts.[SEP]How can we use interactive displays in museums to help visitors appreciate authentic objects and artifacts that they can't otherwise touch or manipulate? This paper shares results from a design-based research study on the use of interactive displays to help visitors learn about artifacts in an exhibit on the history and culture of China. To explore the potential afforded by these displays, we unobtrusively video recorded 834 museum visitor groups who stopped in front of one collection of objects. Drawing on cognitive models of curiosity, we tested three redesigns of this display, each focusing on a different strategy to spark visitor curiosity, interest, and engagement. To understand the relative effectiveness of these designs, we analyzed visitor interaction and conversation. Our results uncovered significant differences across the conditions suggesting implications for the use of such technology in museums.\",\n",
              "  'Articulating Co-Design in Museums: Reflections on Two Participatory Processes.[SEP]In this paper we reflect on the process of co-design by detailing and comparing two strategies for the participatory development of interaction concepts and prototypes in the context of technologically-enhanced museum visiting experiences. While much work in CSCW, HCI and related disciplines has examined different role configurations in co-design, more research is needed on examining how collaborative design processes can unfold in different ways. Here we present two instances of co-design of museum visiting aids, one stemming from an open brief, another from an initial working prototype; we discuss the process in each case and discuss how these alternative strategies presented the team with different possibilities as well as constraints, and led to different patterns of collaboration within the design team. Finally, we draw a set of themes for discussion and reflection to inform and aid researchers and practitioners participating in similar co-design processes, particularly in the domain of cultural heritage.',\n",
              "  'Innovative Digital Heuristic Approaches in Architectural Historical Research.[SEP]In recent years a great debate has aroused concerning the deep transformations triggered by the so-called \"digital revolution\" in all research fields. Architecture has been highly affected by this phenomenon but, while it is commonplace to measure these changes in terms of \"science\", much less popular are those aspects connected with the Humanities integrated in any architectural work. History of Architecture represents from this standpoint a perfect example of how new digital tools and approaches can help to disclose novel research opportunities. The paper presents two projects regarding the Vatican Basilica (the Sangallo\\'s wooden model for the New St. Peter and the reconstruction of St. Peter\\'s square \"the day before\" the moving of the Vatican Obelisk led by Domenico Fontana) as paradigmatic showcases.',\n",
              "  'Managing the real with the virtual: A role for digital media recording in archaeological fieldwork.[SEP]Recent innovations in digital media have allowed for a surge of new techniques to be applied to an old problem - how to record and archive the archaeological record and the process of archaeological fieldwork. Like many new technologies, digital recording is rife with limitations and challenges - low resolution when compared to traditional film, a lack of standards for both media types and archiving methods, expensive entry costs and a relatively high technical skill level required for implementing a complete digital recording methodology, to name a few. However, the benefits of embracing digital recording techniques range from the practical to the profound, for once the initial investment has been made, digital media is relatively inexpensive and allows for a more rich and finer grain of recording, including exciting innovations in GIS-information systems and visualization tools. While the benefits may outweigh the costs, there is within the field of archaeology a strong \"Resistance To Change\" and a feeling that digital media recording, while novel and promising, is nonessential when compared to traditional photography and illustration.',\n",
              "  'A Repository for Heterogeneous and Complex Digital Cultural Objects.[SEP]The paper proposes a solution for a repository of digital cultural objects, which can manage complex data as 3D objects, videos and more, together with the related metadata. The repository is built with open source components and may be easily installed and managed. Basing on an example, interfaces are shown for the most common operations. The system allows for text searches, semantic searches as well as facet refinements. The proposed system can support a full-featured digital library for its modularity and easy personalization.'],\n",
              " 55: ['Magnitude Comparisons of Improper Fractions.[SEP]Previous studies examining the mental representations of fractions have focused on fractions with magnitudes less than one (e.g., 2/3). In the current study, we examine the mental representations of fractions with magnitudes greater than one, specifically those of improper fractions. Participants were asked to make magnitude comparisons of these improper fractions to a reference that was in an improper fraction, a mixed fraction, or a decimal format. Results show that magnitudes of improper fractions were more accurately accessed when they were compared to mixed fractions and decimals. This suggests that the reinterpretation of these improper fractions benefited magnitude processing. Distance effects on error rate and response time were observed for all three reference formats and more consistently took the form of a Welford function, which predicts worse performance above rather than below the reference. Possible explanations of these results are discussed.',\n",
              "  'Mathematical Model of Developmental Changes in Number Cognition.[SEP]Numerical discrimination is a primary measure of the acuity of children’s approximate number system (ANS). ANS acuity is associated with key developmental outcomes such as symbolic number skill, standardized test scores and even employment outcomes. The current study examines the factors that contribute to children’s performance on non-symbolic numerical discrimination tasks. The current study evaluates the contribution of absolute value in children’s numerical discrimination, and how that contribution may change during development. We use a combination of behavioral and computational results to illustrate a U-shaped developmental change in the factors that predict numerical discriminability. Computational modeling based on the neural coding of numerical perception demonstrates why the reported behavioral data is expected. The novel inclusion of absolute value as a predictive factor in children’s numerical discrimination suggests reevaluation of connections between numerical acuity and educational outcomes.',\n",
              "  'Are Fractions Natural Numbers, Too?[SEP]This study presents evidence in favor of a cognitive primitives hypothesis for processing fraction magnitudes. This account holds that humans have perceptual access to fractional magnitudes and that this may be used to support symbolic fraction knowledge. In speeded cross-format comparisons, participants picked the larger of two stimuli, which were either symbolic fractions or nonsymbolic ratios composed of pairs of dot arrays or pairs of circles. Participants demonstrated distance effects across formats, demonstrating that they could compare analog fractional magnitudes independently of the particular formats in which they were presented. These results pose a challenge to innate constraints accounts that argue that human cortical structures are ill-suited for processing fractions. These results may have important implications both for theorizing about the nature of human number sense and for optimizing instruction of fractional concepts.'],\n",
              " 56: ['\"Is it Weird to Still Be a Virgin\": Anonymous, Locally Targeted Questions on Facebook Confession Boards.[SEP]People have long sought answers to questions online, typically using either anonymous or pseudonymous forums or social network platforms that primarily use real names. Systems that allow anonymous communication afford freedom to explore identity and discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying. Identifiable communication systems allows one to reach a known audience and avoid negative disinhibition, but can constrain behavior with concerns about privacy and reputation. One persistent design issue is understanding how to leverage the benefits of anonymity without suffering its drawbacks. This paper presents a case study analysis of question asking on Facebook confession boards (FCBs), a tool popular on some college campuses. FCBs present a unique configuration in which members of an offline community (e.g., a university) anonymously submit content to a moderator who posts it to a Facebook page where others in the community can view it and respond. Response is via identifiable Facebook comments and likes. Our results show users asking about taboo and stigmatized topics with local others, and receiving relevant responses with little cyberbullying or negativity.',\n",
              "  \"The post that wasn't: exploring self-censorship on facebook.[SEP]Social networking site users must decide what content to share and with whom. Many social networks, including Facebook, provide tools that allow users to selectively share content or block people from viewing content. However, sometimes instead of targeting a particular audience, users will self-censor, or choose not to share. We report the results from an 18-participant user study designed to explore self-censorship behavior as well as the subset of unshared content participants would have potentially shared if they could have specifically targeted desired audiences. We asked participants to report all content they thought about sharing but decided not to share on Facebook and interviewed participants about why they made sharing decisions and with whom they would have liked to have shared or not shared. Participants reported that they would have shared approximately half the unshared content if they had been able to exactly target their desired audiences.\",\n",
              "  'Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content.[SEP]Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale.'],\n",
              " 57: ['Influence maximization: near-optimal time complexity meets practical efficiency.[SEP]Given a social network G and a constant $k$, the influence maximization problem asks for k nodes in G that (directly and indirectly) influence the largest number of nodes under a pre-defined diffusion model. This problem finds important applications in viral marketing, and has been extensively studied in the literature. Existing algorithms for influence maximization, however, either trade approximation guarantees for practical efficiency, or vice versa. In particular, among the algorithms that achieve constant factor approximations under the prominent independent cascade (IC) model or linear threshold (LT) model, none can handle a million-node graph without incurring prohibitive overheads.',\n",
              "  'Minimizing seed set selection with probabilistic coverage guarantee in a social network.[SEP]A topic propagating in a social network reaches its tipping point if the number of users discussing it in the network exceeds a critical threshold such that a wide cascade on the topic is likely to occur. In this paper, we consider the task of selecting initial seed users of a topic with minimum size so that {\\\\em with a guaranteed probability} the number of users discussing the topic would reach a given threshold. We formulate the task as an optimization problem called {\\\\em seed minimization with probabilistic coverage guarantee (SM-PCG)}. This problem departs from the previous studies on social influence maximization or seed minimization because it considers influence coverage with {\\\\em probabilistic} guarantees instead of guarantees on {\\\\em expected} influence coverage. We show that the problem is not submodular, and thus is harder than previously studied problems based on submodular function optimization. We provide an approximation algorithm and show that it approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplicative ratio is tight while the additive error would be small if influence coverage distributions of certain seed sets are well concentrated. For one-way bipartite graphs we analytically prove the concentration condition and obtain an approximation algorithm with an $O(\\\\log n)$ multiplicative ratio and an $O(\\\\sqrt{n})$ additive error, where $n$ is the total number of nodes in the social graph. Moreover, we empirically verify the concentration condition in real-world networks and experimentally demonstrate the effectiveness of our proposed algorithm comparing to commonly adopted benchmark algorithms.',\n",
              "  'Effective Large-Scale Online Influence Maximization.[SEP]In this paper, we study a highly generic version of influence maximization (IM), one of optimizing influence campaigns by sequentially selecting \"spread seeds\" from a set of candidates, a small subset of the node population, under the hypothesis that, in a given campaign, previously activated nodes remain \"persistently\" active throughout and thus do not yield further rewards. We call this problem online influence maximization with persistence. We introduce an estimator on the candidates\\' missing mass - the expected number of nodes that can still be reached from a given seed candidate - and justify its strength to rapidly estimate the desired value. We then describe a novel algorithm, GT-UCB, relying on upper confidence bounds on the missing mass. We show that our approach leads to high-quality spreads on classic IM datasets, even though it makes almost no assumptions on the diffusion medium. Importantly, it is orders of magnitude faster than state-of-the-art IM methods.'],\n",
              " 58: ['Velocity-Dependent Dynamic Curvature Gain for Redirected Walking.[SEP]Redirected walking techniques allow people to walk in a larger virtual space than the physical extents of the laboratory. We describe two experiments conducted to investigate human sensitivity to walking on a curved path and to validate a new redirected walking technique. In a psychophysical experiment, we found that sensitivity to walking on a curved path was significantly lower for slower walking speeds (radius of 10 m versus 22 m). In an applied study, we investigated the influence of a velocity-dependent dynamic gain controller and an avatar controller on the average distance that participants were able to freely walk before needing to be reoriented. The mean walked distance was significantly greater in the dynamic gain controller condition, as compared to the static controller (22 m versus 15 m). Our results demonstrate that perceptually motivated dynamic redirected walking techniques, in combination with reorientation techniques, allow for unaided exploration of a large virtual city model.',\n",
              "  \"Virtual locomotion system for human-scale virtual environments.[SEP]This paper presents a new virtual locomotion interface based on step-in-place action and a smart-turntable system. The interface provides a turntable as walking platform, on top of which users will stand at its center, and facing a large screen, to perform life-like walking actions that steer their navigation through the virtual environment. Steering actions are tracked seamlessly without attachment to the body through a set of pressure sensors embedded within the turntable and a computer vision system. For instance, in place stepping is treated as a gesture indicating the intention to move forward. Rotation about the body's vertical axis is treated as a gesture changing the walking direction. However, as large screens are usually limited in size and do not allow a surrounding projection, a large turning action may put users in a visual-less situation, which hamper considerably the effectiveness of the walking experience. To avoid such case and keep users always provided with sufficient visual feedback, the turntable will passively and smoothly rotate in opposite direction of users' turning. Rotation speed and acceleration of the turntable are well optimized to keep users well balanced and easily withstand the passive rotation. The interface is shown to be easy and simple to use in virtual environments equipped with large screen.\",\n",
              "  '15 Years of Research on Redirected Walking in Immersive Virtual Environments.[SEP]Virtual reality users wearing head-mounted displays can experience the illusion of walking in any direction for infinite distance while, in reality, they are walking a curvilinear path in physical space. This is accomplished by introducing unnoticeable rotations to the virtual environment-a technique called redirected walking. This paper gives an overview of the research that has been performed since redirected walking was first practically demonstrated 15 years ago.'],\n",
              " 59: ['Development of Adaptive Information Visualization Systems with Augmented Reality.[SEP]Augmented Reality combined with adaptive hypermedia plays an important role on providing effective information visualization systems. In this paper, we propose a comprehensive architecture model in order to provide adaptive information visualization systems with augmented reality. We also provide a novel visual metaphor for real-valued, low-dimensional data with optimal values for each feature inspired on the pseudo-flower metaphor.',\n",
              "  'Situated Visualization in The Decision Process Through Augmented Reality.[SEP]The decision-making process and the development of decision support systems (DSS) have been enhanced by a variety of methods originated from information science, cognitive psychology and artificial intelligence over the past years. Situated visualization (SV) is a method to present data representations in context. Its main characteristic is to display data representations near the data referent. As augmented reality (AR) is becoming more mature, affordable and widespread, using it as a tool for SV becomes feasible in several situations. In addition, it may provide a positive contribution to more effective and efficient decision-making, as the users have contextual, relevant and appropriate information to endorse their choices. As new challenges and opportunities arise, it is important to understand the relevance of intertwining these fields. Based on a literature analysis, this paper addresses and discusses current areas of application, benefits, challenges and opportunities of using SV through AR to visualize data in context and to support a decision-making process and its importance in future DSS.',\n",
              "  'Temporal Coherence Strategies for Augmented Reality Labeling.[SEP]Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.',\n",
              "  'Message from the Paper Chairs and Guest Editors.[SEP]The articles in this special issue contain the full paper proceedings of the IEEE Virtual Reality Conference 2012 (IEEE VR 2012), held March 4-8, 2012 in Orange County, California.',\n",
              "  \"Guest Editors' Introduction: Virtual Reality.[SEP]Presents the guest editorial for this issue of the publication.\",\n",
              "  'Future scenarios of mixed reality: the INTUITION roadmap scenarios.[SEP]INTUITION is a Network of Excellence that aims to integrate the European research efforts on the scientific and technological field of Virtual and Mixed Reality. To perform that, a series of activities have taken place in order to gather knowledge regarding actors and research profiles, projects and research results, products and patents. Having a clear view of research needs and technology trends the Network has envisioned the research goals that need to be pursued within the years to come. The starting point is a set of visionary scenarios which set out the picture for the technological and scientific advances that need to take place. Within this paper a set of indicative scenarios on a higher and descriptive level are provided and the way they contribute to the roadmap definition is explained. With this report we want to share these scenarios and our initial thoughts to stimulate a broader discussion and invite people from all relevant backgrounds to enter the knowledge creation process. The paper is a collective production of the INTUITION Consortium.'],\n",
              " 60: [\"Protein Tunnel Reprojection for Physico-Chemical Property Analysis.[SEP]Cavities are crucial for interactions of proteins with other molecules. While a variety of different cavity types exists, tunnels in particular play an important role, as they enable a ligand to deeply enter the active site of a protein where chemical reactions can undergo. Consequently, domain scientists are interested in understanding properties relevant for binding interactions inside molecular tunnels. Unfortunately, when inspecting a 3D representation of the molecule under investigation, tunnels are difficult to analyze due to occlusion issues. Therefore, within this paper we propose a novel reprojection technique that transforms the 3D structure of a molecule to obtain a 2D representation of the tunnel interior. The reprojection has been designed with respect to application-oriented design guidelines, we have identified together with our domain partners. To comply with these guidelines, the transformation preserves individual residues, while the result is capable of showing binding properties inside the tunnel without suffering from occlusions. Thus the reprojected tunnel interior can be used to display physico-chemical properties, e.g., hydrophobicity or amino acid orientation, of residues near a tunnel's surface. As these properties are essential for the interaction between protein and ligand, they can thus hint angles of attack for protein engineers. To demonstrate the benefits of the developed visualization, the obtained results are discussed with respect to domain expert feedback.\",\n",
              "  'Comparative Visualization of Molecular Surfaces Using Deformable Models.[SEP]The comparison of molecular surface attributes is of interest for computer aided drug design and the analysis of biochemical simulations. Due to the non‐rigid nature of molecular surfaces, partial shape matching is feasible for mapping two surfaces onto each other. We present a novel technique to obtain a mapping relation between two surfaces using a deformable model approach. This relation is used for pair‐wise comparison of local surface attributes (e.g. electrostatic potential). We combine the difference value as well as the comparability as derived from the local matching quality in a 3D molecular visualization by mapping them to color. A 2D matrix shows the global dissimilarity in an overview of different data sets in an ensemble. We apply our visualizations to simulation results provided by collaborators from the field of biochemistry to evaluate the effectiveness of our results.',\n",
              "  'CAVER Viewer - the explorer of behaviour of tunnels in proteins.[SEP]Protein exploration in order to discover new medication has been the principal aim of biochemists. In combination with informatics the solution of this task can be faster, more accurate and also more intuitive and straightforward in comparison with traditional methods. Our CAVER Viewer application allows the exploration of protein structures and the visualization of results. It enables to find certain paths from the outer space around the molecule to the specific site inside the protein called the active site. The existence of these important paths (also called tunnels or channels) is crucial in the process of transferring some small molecule of substrate into this active site. Namely, the substrate enters the active site via these precomputed tunnels. There the chemical reaction between the substrate and protein can undergo. The product of this reaction can form the basis of a new medication. This poster describes the key aim of our research in the field of protein visualization, when we have to visualize the protein dynamics - movements of the molecule as well as the behaviour of its tunnels in time space.'],\n",
              " 61: ['Constraints on Theories of Serial Order Memory Revisited: The Cases of the Fill-In and Protrusion Effects.[SEP]In his seminal dissertation, Henson (1996) identified a number of constraints on theories of serial order memory. Two constraints, the fill-in constraint, in which an item that is erroneously recalled early is likely to be followed by its predecessor rather than its successor (recall of ACB is more likely than ACD), and the protrusion constraint, in which prior list intrusions are likely to be recalled in the same output position as their previous serial position, were considered evidence against chaining theories. We present results from two experiments which investigate the extent to which these effects are dependent on experimental methodology. When participants are given an open set of items, an equal ratio of fill-in and in-fill errors was observed and a protrusion effect was obtained. However, when a reconstruction of order task was used, a fill-in effect was observed. Implications for theories of serial order memory are discussed.',\n",
              "  \"The Primary and Convergent Retrieval Model of Recall.[SEP]Memory models typically assume that recall is a two-stage process with learning affecting both processes to the same degree. This equal learning assumption is difficult to reconcile with studies of the 'testing effect', which reveal different forgetting rates following learning from test practice versus learning from restudy. Here we present a new memory model, termed Primary and Convergent Retrieval (PCR) that assumes successful recall leads to a selective enhancement for the second stage of recall (Convergent Retrieval). We applied this model to existing testing effect data. In two new experiments, we confirmed novel predictions of the PCR model for transfer between retrieval cues and for recall latencies. This is the first formally specified model of the testing effect and it has broad implications for the nature of learning and retrieval.\",\n",
              "  \"Now I like it, now I don't: Delay effects and retrospective judgment.[SEP]The present paper tests the widely accepted hypothesis that on-line judgment implies functional independence between memory for, and judgment of, verbal stimuli (e.g., Anderson, 1989; Hastie & Park, 1986). In the present study, participants recalled lists of words, after having assessed each for its pleasantness. Presentation position of a negative item within the lists was manipulated. Also, items memorability was manipulated after their presentation – by inserting a filled delay between presentation and the judgment task; in this way, on-line judgment formation was spared. The memory manipulation reduced recall rates for negative items presented in the last position – and their negative influence on pleasantness ratings accordingly. These results contradict the predictions of pure on-line approaches to judgment formation (e.g., Betsch, Plessner, Schwieren, & Gütig, 2001) and suggest that even in on-line judgment tasks, memory plays a role.\",\n",
              "  'Evaluating the Relationship Between Neuropsychological Function and Cognitive Performance.[SEP]The last 2 decades have produced a vast literature describing relationships between cognitive performance and neuropsychological data. This literature has provided the foundation for countless theories about the neural correlates of cognitive processing and specific theories regarding the role of different cortical areas in human cognition. In this paper, we examine a particular theory – the error likelihood model (Brown & Braver, 2005) – that attempts to account for the function of a particular brain area (the anterior cingulate cortex). A careful evaluation of behavioral data from humans raises questions about the error likelihood model and the implications of neuropsychological data for understanding cognitive performance.',\n",
              "  'Using a Cognitive Model for an In-Depth Analysis of the Tower of London.[SEP]The Tower of London (ToL) is a transformation task extensively used and well-established as a neuropsychological diagnostic tool for assessing human planning ability in clinical and research contexts. Behavioral experiments have recently shown that planning in the ToL is substantially influenced by structural task parameters. This work presents an ACT-R model of the ToL that explains structural influences by using different strategies, whereby, strategy selection depends on visually observable characteristics. Model evaluation was based on a problem selection that accounted for systematic variations of task demands. Based on comparisons with empirically observed planning latencies from previously published data, we argue that task-specific structural characteristics are necessary to explain human planning strategies.',\n",
              "  'A Mechanistic Account of Constraints on Control-Dependent Processing: Shared Representation, Conflict and Persistence.[SEP]One of the most fundamental and striking limitations of human cognitive function is the constraint on the number of control-dependent processes that can be executed simultaneously. However, the sources of this capacity constraint remain largely unexplored. Previous work has attributed the constraints on control-dependent processing to the sharing of representations between tasks in neural systems. Here, we examine how shared representations interact with two other factors in producing constraints on control-dependent processing. We first demonstrate that the detrimental effects of shared representations on multitasking performance are contingent on the amount of conflict that is induced by the tasks that share representations. We then examine how the persistence of shared representations between tasks affects processing interference during serial task execution. Finally, we discuss how this set of mechanisms can account for various phenomena in neural architectures, including the psychological refractory period, task switch costs, as well as constraints on cognitive control.'],\n",
              " 62: ['Surface approximation to scanned data.[SEP]A method to approximate scanned data points with a B-spline surface is presented. The data are assumed to be organized in the form of Q i,j, i=0,…,n; j=0,…,m i, i.e., in a row-wise fashion. The method produces a C (p-1, q-1) continuous surface (p and q are the required degrees) that does not deviate from the data by more than a user-specified tolerance. The parametrization of the surface is not affected negatively by the distribution of the points in each row, and it can be influenced by a user-supplied knot vector.',\n",
              "  \"A recursive evaluation algorithm for a class of Catmull-Rom splines.[SEP]It is known that certain Catmull-Rom splines [7] interpolate their control vertices and share many properties such as affine invariance, global smoothness, and local control with B-spline curves; they are therefore of possible interest to computer aided design. It is shown here that another property a class of Catmull-Rom splines shares with B-spline curves is that both schemes possess a simple recursive evaluation algorithm. The Catmull-Rom evaluation algorithm is constructed by combining the de Boor algorithm for evaluating B-spline curves with Neville's algorithm for evaluating Lagrange polynomials. The recursive evaluation algorithm for Catmull-Rom curves allows rapid evaluation of these curves by pipelining with specially designed hardware. Furthermore it facilitates the development of new, related curve schemes which may have useful shape parameters for altering the shape of the curve without moving the control vertices. It may also be used for constructing transformations to B&eacute;zier and B-spline form.\",\n",
              "  'B-spline surfaces for ship hull design.[SEP]The use of true sculptured surface descriptions for design applications has been proposed by numerous authors. The actual implementation and use of interactive sculptured surface description techniques for design and production has been limited. The use of such techniques for ship hull design has been even more limited. The present paper describes a preliminary implementation of such a system for the design of ship hulls and for the production of towing tank models using numerical control techniques. The present implementation is based on a Cartesian product B-spline surface description. Implementation is on an Evans and Sutherland Picture System supported by a PDP-11/45 minicomputer.'],\n",
              " 63: ['A robust and scalable clustering algorithm for mixed type attributes in large database environment.[SEP]Clustering is a widely used technique in data mining applications to discover patterns in the underlying data. Most traditional clustering algorithms are limited to handling datasets that contain either continuous or categorical attributes. However, datasets with mixed types of attributes are common in real life data mining problems. In this paper, we propose a distance measure that enables clustering data with both continuous and categorical attributes. This distance measure is derived from a probabilistic model that the distance between two clusters is equivalent to the decrease in log-likelihood function as a result of merging. Calculation of this measure is memory efficient as it depends only on the merging cluster pair and not on all the other clusters. Zhang et al [8] proposed a clustering method named BIRCH that is especially suitable for very large datasets. We develop a clustering algorithm using our distance measure based on the framework of BIRCH. Similar to BIRCH, our algorithm first performs a pre-clustering step by scanning the entire dataset and storing the dense regions of data records in terms of summary statistics. A hierarchical clustering algorithm is then applied to cluster the dense regions. Apart from the ability of handling mixed type of attributes, our algorithm differs from BIRCH in that we add a procedure that enables the algorithm to automatically determine the appropriate number of clusters and a new strategy of assigning cluster membership to noisy data. For data with mixed type of attributes, our experimental results confirm that the algorithm not only generates better quality clusters than the traditional k-means algorithms, but also exhibits good scalability properties and is able to identify the underlying number of clusters in the data correctly. The algorithm is implemented in the commercial data mining tool Clementine 6.0 which supports the PMML standard of data mining model deployment.',\n",
              "  'Foundations of Perturbation Robust Clustering.[SEP]Clustering is a fundamental data mining tool that aims to divide data into groups of similar items. Intuition about clustering reflects the ideal case - exact data sets endowed with flawless dissimilarity between individual instances. In practice however, these cases are in the minority, and clustering applications are typically characterized by noisy data sets with approximate pairwise dissimilarities. As such, the efficacy of clustering methods necessitates robustness to perturbations. In this paper, we address foundational questions on perturbation robustness, studying to what extent can clustering techniques exhibit this desirable characteristic. Our results also demonstrate the type of cluster structures required for robustness of popular clustering paradigms.',\n",
              "  'Scalable k -Means Clustering via Lightweight Coresets.[SEP]\\\\emphCoresets are compact representations of data sets such that models trained on a coreset are provably competitive with models trained on the full data set. As such, they have been successfully used to scale up clustering models to massive data sets. While existing approaches generally only allow for multiplicative approximation errors, we propose a novel notion of lightweight coresets that allows for both multiplicative and additive errors. We provide a single algorithm to construct lightweight coresets for k -means clustering as well as soft and hard Bregman clustering. The algorithm is substantially faster than existing constructions, embarrassingly parallel, and the resulting coresets are smaller. We further show that the proposed approach naturally generalizes to statistical k -means clustering and that, compared to existing results, it can be used to compute smaller summaries for empirical risk minimization. In extensive experiments, we demonstrate that the proposed algorithm outperforms existing data summarization strategies in practice.'],\n",
              " 64: [\"Design and user evaluation of a joystick-operated full-screen magnifier.[SEP]The paper reports on two development cycles of a joystick-operated full-screen magnifier for visually impaired users. In the first cycle of evaluation, seven visually impaired computer users evaluated the system in comprehension-based sessions using text documents. After considering feedback from these evaluators, a second version of the system was produced and evaluated by a further six visually impaired users. The second evaluation was conducted using information-seeking tasks using Web pages. In both evaluations, the 'thinking aloud protocol' was used. This study makes several contributions to the field. First, it is perhaps the first published study investigating the use of a joystick as an absolute and relative pointing device to control a screen magnifier. Second, the present study revealed that for most of the visually impaired users who participated in the study the joystick had good spatial, cognitive and ergonomic attributes, even for those who had never before used a joystick.\",\n",
              "  'Molder: An Accessible Design Tool for Tactile Maps.[SEP]Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.',\n",
              "  'Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: a Participatory Design Approach.[SEP]Current low-tech Orientation & Mobility (O&M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.'],\n",
              " 65: ['Distributed computing: new power for scientific visualization.[SEP]Distributed computing provides unique benefits for scientific visualization in this system (Discover) that supports interactive visualization and cooperative work for nonprogrammers. Discover (Distributed Interactive Scientific Computing and Visualization Environment), is suitable for many areas, but we have concentrated on medical image analysis and generation-one of the the most rapidly growing applications for scientific visualization. In its present form, Discover acts as a framework for clinical applications. True to its name, it allows a variety of users to discover the relevant information in a vast body of scientific data. Nonprogrammers, such as physicians and radiologists, interactively display and manipulate the two and three dimensional medical objects, visualize the results, control system computation, and generally drive the image analysis process. The emphasis is on the distributed nature of the software architecture and its functions. We also describe a unique load balancing algorithm designed to maximize workstation performance.',\n",
              "  \"Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations.[SEP]The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.\",\n",
              "  'A Concurrent Architecture Proposal for Information Visualization Pipeline.[SEP]This paper identifies an opportunity to reduce the latency in information visualization (InfoVis) systems, exploring the parallelization of the visualization pipeline architecture. We propose a concurrent architecture where the visualization pipeline stages are modified to execute as producers and consumers threads. The threads synchronization is done by memory barriers and the data flow pass the pipeline through a unique data structure, called ring buffer, which reuses a contiguous space preallocated in memory. Two InfoVis prototypes were developed in java, the first one using sequential pipeline and the other using concurrent pipeline. The results obtained with concurrent architecture in comparison with sequential pipeline presented less execution time and memory allocation for data visualization renderization.',\n",
              "  'A Weighted Aggregating SGD for Scalable Parallelization in Deep Learning.[SEP]We investigate the stochastic optimization problem and develop a scalable parallel computing algorithm for deep learning tasks. The key of our study involves a reformation of the objective function for the stochastic optimization in neural network models. We propose a novel update rule, named weighted aggregating stochastic gradient decent, after theoretically analyzing the characteristics of the newly formalized objective function. The new rule introduces a weighted aggregation scheme based on the performance of local workers and does not require a center variable. It assesses the relative importance of local workers and accepts them according to their contributions. Our new rule also allows the implementation of both synchronous and asynchronous parallelization and can result in varying convergence rates. For method evaluation, we benchmark our schemes against the mainstream algorithms, including the elastic averaging SGD in training deep neural networks for classification tasks. We conduct extensive experiments on several classic datasets, and the results confirm the strength of our scheme in accelerating the training of deep architecture and scalable parallelization.',\n",
              "  'Large-scale distributed non-negative sparse coding and sparse dictionary learning.[SEP]We consider the problem of building compact, unsupervised representations of large, high-dimensional, non-negative data using sparse coding and dictionary learning schemes, with an emphasis on executing the algorithm in a Map-Reduce environment. The proposed algorithms may be seen as parallel optimization procedures for constructing sparse non-negative factorizations of large, sparse matrices. Our approach alternates between a parallel sparse coding phase implemented using greedy or convex (l1) regularized risk minimization procedures, and a sequential dictionary learning phase where we solve a set of l0 optimization problems exactly. These two-fold sparsity constraints lead to better statistical performance on text analysis tasks and at the same time make it possible to implement each iteration in a single Map-Reduce job. We detail our implementations and optimizations that lead to the ability to factor matrices with more than 100 million rows and billions of non-zero entries in just a few hours on a small commodity cluster.',\n",
              "  'Parallelization with Multiplicative Algorithms for Big Data Mining.[SEP]We propose a nontrivial strategy to parallelize a series of data mining and machine learning problems, including 1-class and 2-class support vector machines, nonnegative least square problems, and \\\\ell_1 regularized regression (LASSO) problems. Our strategy fortunately leads to extremely simple multiplicative algorithms which can be straightforwardly implemented in parallel computational environments, such as Map Reduce, or CUDA. We provide rigorous analysis of the correctness and convergence of the algorithm. We demonstrate the scalability and accuracy of our algorithms in comparison with other current leading algorithms.'],\n",
              " 66: [\"Impression formation in online peer production: activity traces and personal profiles in github.[SEP]In this paper we describe a qualitative investigation of impression formation in an online distributed software development community with social media functionality. We find that users in this setting seek out additional information about each other to explore the project space, inform future interactions, and understand the potential future value of a new person. They form impressions around other users' expertise based on history of activity across projects, and successful collaborations with key high status projects in the community. These impressions influence their receptivity to strangers' work contributions.\",\n",
              "  'Community insights: helping community leaders enhance the value of enterprise online communities.[SEP]Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.',\n",
              "  \"SuggestBot: using intelligent task routing to help people find work in wikipedia.[SEP]Member-maintained communities ask their users to perform tasks the community needs. From Slashdot, to IMDb, to Wikipedia, groups with diverse interests create community-maintained artifacts of lasting value (CALV) that support the group's main purpose and provide value to others. Said communities don't help members find work to do, or do so without regard to individual preferences, such as Slashdot assigning meta-moderation randomly. Yet social science theory suggests that reducing the cost and increasing the personal value of contribution would motivate members to participate more.We present SuggestBot, software that performs intelligent task routing (matching people with tasks) in Wikipedia. SuggestBot uses broadly applicable strategies of text analysis, collaborative filtering, and hyperlink following to recommend tasks. SuggestBot's intelligent task routing increases the number of edits by roughly four times compared to suggesting random articles. Our contributions are: 1) demonstrating the value of intelligent task routing in a real deployment; 2) showing how to do intelligent task routing; and 3) sharing our experience of deploying a tool in Wikipedia, which offered both challenges and opportunities for research.\"],\n",
              " 67: ['Spontaneous Analogy by Piggybacking on a Perceptual System.[SEP]Most computational models of analogy assume they are given a delineated source domain and often a specified target domain. These systems do not address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory, a process we call spontaneous analogy. We present a system that represents relational structures as feature bags. Using this representation, our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long-term memory. We provide a demonstration of our approach that takes a set of unsegmented stories, constructs an ontology of analogical schemas (corresponding to plot devices), and uses this ontology to efficiently find analogs within new stories, yielding significant time-savings over linear analog retrieval at a small accuracy cost.',\n",
              "  'Generalizing relations during analogical problem solving in preschool children: does blocked or interleaved training improve performance?[SEP]Analogical reasoning, the mapping of structured relations across conceptual domains, is commonly recognized as essential to human cognition, but young children often perform poorly in the classical A:B::C:? analogical reasoning task. Particularly, young children have trouble when the objects in the task are not strongly associated with each other, and/or when there are strong associative lures among the potential answers. Here, we examine whether successive trials that repeat the same relation needed to solve the analogy can help overcome some of the challenges with weakly associated items. In the first of two experiments, our results were mixed. In the second, we simplified the design, and were able to more clearly show a benefit of repeating relations across consecutively solved problems.',\n",
              "  'Analogy and Arithmetics: An HDTP-Based Model of the Calculation Circular Staircase.[SEP]Analogical reasoning and its applications are gaining attention not only in cognitive science but also in the context of education and teaching. In this paper we provide a short analysis and a detailed formal model (based on the Heuristic-Driven Theory Projection framework for computational analogy-making) of the Calculation Circular Staircase, a tool for teaching basic arithmetic and insights based on the ordinal number conception of the natural numbers to children in their first years of primary school. We argue that such formal methods and computational accounts of analogy-making can be used to gain additional insights in the inner workings of analogy-based educational methods and tools.',\n",
              "  'An Eye For Figurative Meaning: The Effects of Familiarity on Metaphor Comprehension.[SEP]The career of metaphor hypothesis suggests that processing preference is a result of conventionality whereby conventional metaphors are processed through categorization, and novel ones processed through comparison. Alternatively, the categorization model predicts that apt metaphors are processed as categorizations whether or not they are conventional. However, research has largely ignored another known factor to influence metaphor processing, namely familiarity. The categorization model predicts familiarity to play no role in deciding on processing strategy. On the other hand, the career of metaphor hypothesis predicts that familiarity to play a facilitating role in metaphor comprehension. In this experiment, we used the eye tracking paradigm and controlled for aptness and conventionality, and manipulated familiarity in order to test these predictions. Our initial results support the career of metaphor hypothesis suggesting that familiarity facilitates metaphor processing. We discuss the implications these results have on the psycholinguistic models and briefly speculate on their philosophical consequences.',\n",
              "  \"Formalizing the Pragmatics of Metaphor Understanding.[SEP]While the ubiquity and importance of nonliteral language are clear, people's ability to use and understand it remains a mystery. Metaphor in particular has been studied extensively across many disciplines in cognitive science. One approach focuses on the pragmatic principles that listeners utilize to infer meaning from metaphorical utterances. While this approach has generated a number of insights about how people understand metaphor, to our knowledge there is no formal model showing that effects in metaphor understanding can arise from basic principles of communication. Building upon recent advances in formal models of pragmatics, we describe a computational model that uses pragmatic reasoning to interpret metaphorical utterances. We conduct behavioral experiments to evaluate the model's performance and show that our model produces metaphorical interpretations that closely fit behavioral data. We discuss implications of the model for metaphor understanding, principles of communication, and formal models of language understanding.\",\n",
              "  'Computing Humorous Metaphors.[SEP]It was experimentally showed that humorous texts can be explained using approaches applied to metaphors, such as the salience-imbalance or the domain-interaction approach. It was also demonstrated that humorous metaphors often include a switch between positive and negative emotions. We propose to construct a computer system able to understand and generate such metaphors. Currently we are constructing a metaphor conceptual network, in which links between concepts are calculated accordingly to their roles in metaphor understanding. This will allow the computer to process metaphors. Next, we will adjust the links distance calculation to match the humorous metaphors (to increase the salience-imbalance, as demonstrated in existing research). We will also use an emotiveness-recognition-system to detect emotive associations towards particular phrases, in order to choose pairs with the emotional switch. The system will be evaluated in user-oriented experiments. Acknowledgements: This work was supported by KAKENHI (Project Number: 23-01348)'],\n",
              " 68: ['Improved Obstacle Relevancy, Distance, and Angle for Crowds Constrained to Arbitrary Manifolds in 3D Space.[SEP]Recent work has proposed crowd simulation algorithms on arbitrary manifolds in 3D space. These algorithms simulate crowds on far more realistic surfaces than previously possible, including multi-story structures, science fiction scenarios, and habitats for insects and other animals that can walk on walls. However, current implementations can have distinct artifacts, including collision false positives and false negatives. Also, current implementations fail to account for the cylindrical shape of the characters being simulated. The resulting crowds move unnaturally and have obvious collisions. After identifying the cause of these artifacts, we propose an algorithm that does not struggle from these false positives or false negatives and correctly accounts for the non-spherical shape of agents. The resulting crowds move on large surfaces (over 100k triangles) running with a thousand agents in real-time.',\n",
              "  \"A Graphical Simulator for Modeling Complex Crowd Behaviors.[SEP]Abnormal crowd behaviors of varied real-world settings could represent or pose serious threat to public safety. The video data required for relevant analysis are often difficult to acquire due to security, privacy and data protection issues. Without large amounts of realistic crowd data, it is difficult to develop and verify crowd behavioral models, event detection techniques, and corresponding test and evaluations. This paper presented a synthetic method for generating crowd movements and tendency based on existing social and behavioral studies. Graph and tree searching algorithms as well as game engine-enabled techniques have been adopted in the study. The main outcomes of this research include a categorization model for entity-based behaviors following a linear aggregation approach; and the construction of an innovative agent-based pipeline for the synthesis of A-Star path-finding algorithm and an enhanced Social Force Model. A Spatial-Temporal Texture (STT) technique has been adopted for the evaluation of the model's effectiveness. Tests have highlighted the visual similarities between STTs extracted from the simulations and their counterparts - video recordings - from the real-world.\",\n",
              "  'Perceptual evaluation of maneuvering motion illusion for virtual pedestrians.[SEP]Crowd simulations span a wide spectrum of application domains, most notably video games, evacuation scenarios, and the movie industry. However, it is not obligatory that all virtual populace applications have the primary objective of realistic simulation. In most instances, it is necessary and sufficient that viewers perceive the crowd as plausible. Even for a crowd consisting of agents navigating on linear trajectories without any maneuvers, visual motion illusion elicited by these trajectories might appear to be a natural consequence, causing them to be perceived as wriggling rather than straight. In this respect, we evaluate in this study whether simulated 3D human agents walking with constant, collision-free velocities, induce such a maneuvering motion illusion, aiming toward an efficient real-time crowd simulation. For this purpose, we recorded videos of virtual human crowds with different parameter combinations, such as the agent walking speed, crowd density, camera tilt angle, and camera distance. These videos were watched by human subjects who were instructed to mark the virtual agents who they thought had changed their gait directions. The analyzed results revealed that participants claimed the presence of maneuvering virtual agents in the videos, even though there were none in any of them. Spatial grouping of the markings highlighted that the participants mainly focused on the central area of the simulation environment, and spatiotemporal analysis of the click data also showed stronger evidence to such an illusion (see accompanying video). Furthermore, we found that all of the referred parameters have statistically significant main effects on the number of marked agents per watched video.'],\n",
              " 69: [\"Whose turn is it anyway? Same- and cross-person compound contributions in dialogue.[SEP]In natural conversation people sometimes build larger grammatical, semantic and pragmatic units out of multiple turns or installments. The incremental and collaborative character of these `compound contributions' presents challenges for theories of natural language processing. Compounds produced over successive turns by one person have often been analysed in essentially the same way as compounds produced by multiple people. In some recent accounts this putative equivalence has been taken as evidence for the claim that within- and cross-person language processing are fundamentally interchangeable. However, in this paper we present an analysis of compound contributions in a corpus of ordinary dialogues which shows that same- and cross-person compound contributions are constructed in different ways and have different semantic and pragmatic effects on the organisation of dialogue. In particular, we show that they differ in the pragmatic environments in which they occur and that they have different consequences for subsequent turn-taking and interpretation. This asymmetry highlights the need for models of dialogue that account for not just the inherent incrementality of dialogue, but the different status of each contributor towards a turn-in-progress.\",\n",
              "  'The Role of Feedback in Aligning Perspectives in Referential Communication.[SEP]Successful dialogue frequently requires that interlocutors construct and align their conceptualizations of referents. This study presents data from a referential communication experiment the manipulates contextual factors such as the availability of feedback and role constancy in order to investigate how conversational partners reconcile their perspectives in the face of mutual uncertainty about what constitutes common ground. The results show that speakers tend to incorporate information about the addressee’s perspective, and that this information tends to come through direct feedback rather than through indirect channels such as turn-taking.',\n",
              "  'Temporal Dynamics of Scan Patterns in Comprehension and Production.[SEP]Speakers and listeners in a dialogue establish mutual understanding by coordinating their linguistic responses. When a visual scene is present, scan patterns on that scene are also coordinated. However, it is an open question which linguistic and scene factors affect coordination. In this paper, we investigate the coordination of scan patterns during the comprehension and generation of scene descriptions. We manipulate the animacy of the subject and the number of visual referents associated with it. By using Cross Recurrence Analysis, we demonstrate that coordination emerges only during linguistic processing, and that it is especially pronounced for inanimate unambiguous subjects. When the subject is referentially ambiguous (more than one visual object associated with it), scan pattern variability increases to the extent that the animacy effect is neutralized.',\n",
              "  \"An Intelligent Assistant for High-Level Task Understanding.[SEP]People are able to interact with domain-specific intelligent assistants (IAs) and get help with tasks. But sometimes user goals are complex and may require interactions with multiple applications. However current IAs are limited to specific applications and users have to directly manage execution spanning multiple applications in order to engage in more complex activities. An ideal personal agent would be able to learn, over time, about tasks that span different resources. This paper addresses the problem of cross-domain task assistance in the context of spoken dialogue systems. We propose approaches to discover users' high-level intentions and using this information to assist users in their task. We collected real-life smartphone usage data from 14 participants and investigated how to extract high-level intents from users' descriptions of their activities. Our experiments show that understanding high-level tasks allows the agent to actively suggest apps relevant to pursuing particular user goals and reduce the cost of users' self-management.\",\n",
              "  '\"Do Animals Have Accents?\": Talking with Agents in Multi-Party Conversation.[SEP]In this paper we unpack the use of conversational agents, or so-called intelligent personal assistants (IPAs), in multi-party conversation amongst a group of friends while they are socialising in a café. IPAs such as Siri or Google Now can be found on a large proportion of personal smartphones and tablets, and are promoted as \\'natural language\\' interfaces. The question we pursue here is how they are actually drawn upon in conversational practice? In our work we examine the use of these IPAs in a mundane and common-place setting and employ an ethnomethodological perspective to draw out the character of the IPA-use in conversation. Additionally, we highlight a number of nuanced practicalities of their use in multi-party settings. By providing a depiction of the nature and methodical practice of their use, we are able to contribute our findings to the design of IPAs.',\n",
              "  'Iris: A Conversational Agent for Complex Tasks.[SEP]Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data scientists completed a modeling task 2.6 times faster with Iris than with Jupyter Notebook.'],\n",
              " 70: ['Projection Distortion-based Object Tracking in Shader Lamp Scenarios.[SEP]Shader lamp systems augment the real environment by projecting new textures on known target geometries. In dynamic scenes, object tracking maintains the illusion if the physical and virtual objects are well aligned. However, traditional trackers based on texture or contour information are often distracted by the projected content and tend to fail. In this paper, we present a model-based tracking strategy, which directly takes advantage from the projected content for pose estimation in a projector-camera system. An iterative pose estimation algorithm captures and exploits visible distortions caused by object movements. In a closed-loop, the corrected pose allows the update of the projection for the subsequent frame. Synthetic frames simulating the projection on the model are rendered and an optical flow-based method minimizes the difference between edges of the rendered and the camera image. Since the thresholds automatically adapt to the synthetic image, a complicated radiometric calibration can be avoided. The pixel-wise linear optimization is designed to be easily implemented on the GPU. Our approach can be combined with a regular contour-based tracker and is transferable to other problems, like the estimation of the extrinsic pose between projector and camera. We evaluate our procedure with real and synthetic images and obtain very precise registration results.',\n",
              "  \"Spatio-Temporal Point Path Analysis and Optimization of a Galvanoscopic Scanning Laser Projector.[SEP]Galvanoscopic scanning laser projectors are powerful vector graphic devices offering a tremendous local brightness advantage compared to standard video projection systems. However, such devices have inherent problems, such as temporal flicker and spatially inaccurate rendering. We propose a method to generate an accurate point-based projection with such devices. To overcome the mentioned problems, we present a camera-based method to automatically analyze the laser projector's motion behavior. With this information, a model database is generated that is used to optimize the scanning path of projected point sequences. The optimization considers the overall path length, its angular shape, acceleration behavior, and the spatio-temporal point neighborhood. The method minimizes perceived visual flickering while guaranteeing an accurate spatial point projection at the same time. Comparisons and timing measurements prove the effectiveness of our method. An informal user evaluation shows substantial visual quality improvement as well.\",\n",
              "  'Robust upright adjustment of 360 spherical panoramas.[SEP]With the recent advent of 360 cameras, spherical panorama images are becoming more popular and widely available. In a spherical panorama, alignment of the scene orientation to the image axes is important for providing comfortable and pleasant viewing experiences using VR headsets and traditional displays. This paper presents an automatic method for upright adjustment of 360 spherical panorama images without any prior information, such as depths and gyro sensor data. We take the Atlanta world assumption and use the horizontal and vertical lines in the scene to formulate a cost function for upright adjustment. In addition to fast optimization of the cost function, our method includes outlier handling to improve the robustness and accuracy of upright adjustment. Our method produces visually pleasing results for a variety of real-world spherical panoramas in less than a second, and the accuracy is verified using ground-truth data.',\n",
              "  'Coupled-layer based visual tracking via adaptive kernelized correlation filters.[SEP]Part-based visual model is particularly useful when the target appearance undergoes partial occlusion or deformation. The existing reliable patches tracking (RPT) method has achieved better result by identifying and exploiting the reliable patches that can be tracked correctly, yet it tends to fail in some challenging scenes since it ignores the holistic information of target completely, while, in fact, the target’s holistic appearance provides more discriminative features than local patches with low resolution. Based on the existing RPT and kernelized correlation filters tracking method, in this paper, we propose a coupled-layer visual model based tracker by combining the target’s global and local appearance in a coupled way. The global layer provides the holistic information and is treated as an approximation of the target. The local layer is composed of multiple small patches that are randomly initialized in the first frame. During tracking, the global tracker detects the target itself; its detection result is employed in the local layer to exploit the reliable patches and to estimate the target position corresponding to each patch. The exploited reliable patches are employed to estimate the target scale and to vote the current target location. Finally, both global and local models are updated with carefully designed updating mechanisms. Experiments conducted on 80 challenging benchmark sequences clearly show that our tracker improves the RPT tracker significantly both in overall and individual performance yet without obvious speed cost. Also, our tracker outperforms all the state-of-the-art trackers in overall datasets and eight independent datasets.',\n",
              "  'Object tracking by color distribution fields with adaptive hierarchical structure.[SEP]The essence of visual tracking is to distinguish the target from background, so how to describe the difference between target and background is a key problem. In this paper, tracking algorithm by color distribution fields with adaptive hierarchical structure is presented to solve this problem. First, multichannel color distribution fields are presented for appearance modeling, which represents color distinction between the target and background. Second, in order to adapt to the individuality of each target, the hierarchical structure of its color distribution fields are generated via k-means cluster. Third, weighted multichannel 𝐿1L1 distance is used to measure the similarity between the candidate region and the template; the weight of each channel is adjusted online according to its discrimination. Finally, a search strategy based on simulated annealing is proposed to improve the search efficiency and reduce the probability of falling into the local optimum. Experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art tracking algorithms.',\n",
              "  'An improved correlation filter tracking method with occlusion and drift handling.[SEP]Despite remarkable progress, visual object tracking is still a challenging task as objects usually suffer from significant appearance changes, fast motion, and serious occlusion. In this paper, we propose a correlation filter-based tracking method with reliability evaluation and re-detection mechanism (CF-RERM) to deal with drift and occlusion problems. We first propose a criterion that uses the fluctuation trend of the response values, the displacement difference of the object, and the peak-to-sidelobe ratio to comprehensively evaluate the reliability of the tracking process. Then, a re-detection mechanism with a two-stage screening strategy is proposed for implementing the re-detection task when the criterion is triggered. Experimental results show that our method has achieved considerable performance in terms of accuracy and success rate on widely used OTB-50, OTB-100 and Temple-Color-128 tracking benchmark dataset. In addition, CF-RERM is able to achieve real-time tracking speed.',\n",
              "  'A Backmapping Approach for Graph-Based Object Tracking.[SEP]Model-based methods play a central role to solve different problems in computer vision. A particular important class of such methods rely on graph models where an object is decomposed into a number of parts, each one being represented by a graph vertex. A graph model-based tracking algorithm has been recently introduced in which a model is generated for a given frame (reference frame) and used to track a target object in the subsequent ones. Because the view of an object changes along the video sequence, the solution updated the model using affine transformations. This paper proposes a different approach and improves the previous one in several ways. Firstly, instead of updating the model, each analyzed frame is backmapped to the model space, thus providing more robustness to the method because model parameters do not have to be modified. A different method for model generation based on user traces has also been implemented and used. This model generation approach is much simpler and user-friendly. Finally, a graph-matching algorithm that has been recently proposed is used for object tracking. This new algorithm is more efficient and leads to better matching results. Experimental results using synthetic and real sequences from the CAVIAR project are shown and discussed.',\n",
              "  'Automatic Detection of 2D Human Postures Based on Single Images.[SEP]Estimating human pose in static images is a challenging task due to the high dimensional state space, presence of image clutter and ambiguities of image observations. In this paper we propose a method to automatically detect human poses in a single image, based on a 2D model combined with anthropometric data. Furthermore, we use artificial neural networks to detect high level information about the human posture. Experimental results showed that the proposed technique performs well in non trivial images.',\n",
              "  'Robust motion flow for mesh tracking of freely moving actors.[SEP]4D multi-view reconstruction of moving actors has many applications in the entertainment industry and although studios providing such services become more accessible, efforts have to be done in order to improve the underlying technology to produce high-quality 4D contents. In this paper, we present a method to derive a time-evolving surface representation from a sequence of binary volumetric data representing an arbitrary motion in order to introduce coherence in the data. The context is provided by an indoor multi-camera system which performs synchronized video captures from multiple viewpoints in a chroma-key studio. Our input is given by a volumetric silhouette-based reconstruction algorithm that generates a visual hull at each frame of the video sequence. These 3D volumetric models lack temporal coherence, in terms of structure and topology, as each frame is generated independently. This prevents an easy post-production editing with 3D animation tools. Our goal is to transform this input sequence of independent 3D volumes into a single dynamic structure, directly usable in post-production. Our approach is based on a motion estimation procedure. An unsigned distance function on the volumes is used as the main shape descriptor and a 3D surface matching algorithm minimizes the interference between unrelated surface regions. Experimental results, tested on our multi-view datasets, show that our method outperforms other approaches based on optical flow when considering robustness over several frames.'],\n",
              " 71: ['ShadowPix: Multiple Images from Self Shadowing.[SEP]ShadowPixare white surfaces that display several prescribed images formed by the self‐shadowing of the surface when lit from certain directions. The effect is surprising and not commonly seen in the real world. We present algorithms for constructing ShadowPixthat allow up to four images to be embedded in a single surface. ShadowPixcan produce a variety of unusual effects depending on the embedded images: moving the light can animate or relight the object in the image, or three colored lights may be used to produce a single colored image. ShadowPixare easy to manufacture using a 3D printer and we present photographs, videos, and renderings demonstrating these effects.',\n",
              "  'Exponential shadow maps.[SEP]Rendering high-quality shadows in real-time is a challenging problem. Shadow mapping has proved to be an efficient solution, as it scales well for complex scenes. However, it suffers from aliasing problems. Filtering the shadow map alleviates aliasing, but unfortunately, native hardware-accelerated filtering cannot be applied, as the shadow test has to take place beforehand.',\n",
              "  \"Generating soft shadows with a depth buffer algorithm.[SEP]A pragmatic approach is taken to develop an algorithm that combines an existing shadowing method with a popular visible surface rendering technique, called a depth buffer, to generate soft shadows resulting from light sources of finite extent. The method extends F. Crow's shadow volume algorithm (1977) to produce multiple shadows overlapped to yield the characteristic soft edges of a shadow penumbra.\"],\n",
              " 72: ['SceneSkim: Searching and Browsing Movies Using Synchronized Captions, Scripts and Plot Summaries.[SEP]Searching for scenes in movies is a time-consuming but crucial task for film studies scholars, film professionals, and new media artists. In pilot interviews we have found that such users search for a wide variety of clips---e.g., actions, props, dialogue phrases, character performances, locations---and they return to particular scenes they have seen in the past. Today, these users find relevant clips by watching the entire movie, scrubbing the video timeline, or navigating via DVD chapter menus. Increasingly, users can also index films through transcripts---however, dialogue often lacks visual context, character names, and high level event descriptions. We introduce SceneSkim, a tool for searching and browsing movies using synchronized captions, scripts and plot summaries. Our interface integrates information from such sources to allow expressive search at several levels of granularity: Captions provide access to accurate dialogue, scripts describe shot-by-shot actions and settings, and plot summaries contain high-level event descriptions. We propose new algorithms for finding word-level caption to script alignments, parsing text scripts, and aligning plot summaries to scripts. Film studies graduate students evaluating SceneSkim expressed enthusiasm about the usability of the proposed system for their research and teaching.',\n",
              "  'CSIUI 2009: story understanding and generation for aware and interactive interface design.[SEP]In order to be helpful to people, the intelligent interfaces of the future will have to acquire, represent, and infer simple knowledge about everyday life and activities. While much work in AI has represented this knowledge at the word, sentence, and logical assertion level, we see a growing need to understand it at a larger granularity, that of stories.',\n",
              "  \"Declarative Optimization-Based Drama Management in Interactive Fiction.[SEP]Our work relates to automatically guiding experiences in large, open-world interactive dramas and story-based experiences where a player interacts with and influences a story. A drama manager (DM) is a system that watches a story as it progresses, reconfiguring the world to fulfill the author's goals. A DM might notice a player doing something that fits poorly with the current story and attempt to dissuade him or her. This is accomplished using soft actions such as having a nonplayer character start a conversation with a player to lure him or her to something else, or by more direct actions such as locking doors. We present work applying search-based drama management (SBDM) to the interactive fiction piece Anchorhead, to further investigate the algorithmic and authorship issues involved. Declarative optimization-based drama management (DODM) guides the player by projecting possible future stories and reconfiguring the story world based on those projections. This approach models stories as a set of possible plot points, and an author-specified evaluation function rates the quality of a particular plot-point sequence\",\n",
              "  'More Than Telling a Story: Transforming Data into Visually Shared Stories.[SEP]The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.',\n",
              "  'Formalizing Analytical Discourse in Visual Analytics.[SEP]This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse.',\n",
              "  \"A Deeper Understanding of Sequence in Narrative Visualization.[SEP]Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.\"],\n",
              " 73: [\"Do Users' Perceptions of Password Security Match Reality?[SEP]Although many users create predictable passwords, the extent to which users realize these passwords are predictable is not well understood. We investigate the relationship between users' perceptions of the strength of specific passwords and their actual strength. In this 165-participant online study, we ask participants to rate the comparative security of carefully juxtaposed pairs of passwords, as well as the security and memorability of both existing passwords and common password-creation strategies. Participants had serious misconceptions about the impact of basing passwords on common phrases and including digits and keyboard patterns in passwords. However, in most other cases, participants' perceptions of what characteristics make a password secure were consistent with the performance of current password-cracking tools. We find large variance in participants' understanding of how passwords may be attacked, potentially explaining why users nonetheless make predictable passwords. We conclude with design directions for helping users make better passwords.\",\n",
              "  'Age-related performance issues for PIN and face-based authentication systems.[SEP]Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population. We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period. We use this paradigm with two user populations, comparing the performance of younger and older adults. We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components. As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.',\n",
              "  'EpisoDAS: DAS-based password generation using episodic memories.[SEP]We introduce a simple and powerful visual interaction technique for managing strong passwords. Passwords have been used for authentication for decades, but appropriate handling of passwords is difficult because people can easily forget passwords and they can be easily attacked. Better authentication methods have been investigated, and various visual interaction methods have been proposed, including the DAS (draw-a-secret) method. Using DAS, users can log into a service just by drawing a secret pattern on the screen, but remembering complex secret patterns is as difficult as remembering passwords. We developed EpisoDAS, with which users can generate strong passwords based on their secret episodic memories with a simple DAS interface. A user can draw a secret pattern and generate a password, based on their secret episodic memories that they cannot easily forget.'],\n",
              " 74: ['Patterns of anxiety in algebraic problem solving in Australian adolescents: A three-step latent variable analysis.[SEP]Adolescents’ math anxiety is commonly assessed using questionnaires that identified the anxiety experienced solving arithmetic problems. A more nuanced understanding of math anxiety would be gained by investigating anxiety associated with math problems encountered in school at the time they are encountered. To this end, we investigated the anxiety associated with algebraic problem solving ability relationships in 129 14-year-olds. We varied problem difficulty and the time allowed to solve problems, and assessed students’ anxiety concurrently as they solved problems. Latent variable mixture modelling revealed meaningfully different patterns of algebra ability and anxiety relationships that changed as a function of problem difficulty and time pressure. A second study, examining 257 13- to 15-year-olds, successfully replicated the Study 1 findings. The results highlight the value of using latent variable analysis to identify subgroup patterns of abilities and caution against making overly general claims about the role of anxiety in math problem solving.',\n",
              "  'Problem-Solving Strategy Selection in Relation to Formal Schooling.[SEP]A study of the literacy-generated cognitive cultural gap was carried out on subjects of different literacy background ranging from illiterate individuals to university students in different majors. The characteristics that aid literate and illiterate people in solving mathematical problems efficiently were identified and analyzed. A field research was carried out in the field of algorithmic problem solving and in the reasoning domain, followed by constructing a software cognitive model to represent the findings. Findings showed that in both domains cognitive ability did not improve with level of literacy, rather the formality of the problem solving strategy selected demonstrating a link between these two domains.',\n",
              "  \"Study on Facilitation of Problem Posing by Learning Examples through Reproduction.[SEP]In general education, learning of production tasks is important but difficult due to it requires heavy cognitive activities such as generation of ideas and synthesis of structures. We proposed a method to facilitate a production task of mathematical problem posing through learning by reproducing examples. In the proposed method, learners learn essential ideas by reproducing examples based on process information indicating how to compose them. We then conducted an experimental investigation where undergraduate students posed their own problems after learning an example by reproducing or solving it. Our previous study had confirmed that undergraduate students without learning of any examples posed many problems that had simple and inappropriate solution structures. In this study, undergraduate students who learned by reproducing the example posed many complex problems, whereas those who learned by solving it didn't do. This proved that learning of ideas for a production task is more effective when it's done through a productive activity.\",\n",
              "  'Improving First-Year Writing Using Argument Diagramming.[SEP]There is substantial evidence from many domains that visual representations aid various forms of cognition. We aimed to determine whether learning to construct visual representations of argument structure enhanced the acquisition and development of argumentative writing skills within the context of first-year college writing course. We found a significant effect of the use of argument diagrams, and this effect was stable even when multiple plausible correlates were controlled for. These results suggest that natural⎯and relatively minor⎯modifications to standard first-year composition courses could provide substantial increases in student writing ability.',\n",
              "  \"Are Teachers Aware of Students' Lack of Spontaneity in Diagram Use? Suggestions from a Mathematical Model-Based Analysis of Teachers' Predictions.[SEP]Although many studies have shown that diagrams are effective tools for problem solving, research evidence shows that students do not always use diagrams effectively. One of the most serious problems is their lack of spontaneity in diagram use. However, no previous studies have examined whether teachers are adequately aware of this problem. In this investigation, data were gathered on students’ mathematics performance (including their spontaneous use of diagrams) and teachers’ predictions of the students’ performance. Using a mathematical model (Uesaka & Nakagawa, 2010) to analyze the data, it was found that the parameter representing the accuracy of teachers’ prediction was lower for their assessment of spontaneous diagram use compared to other mathematical tasks. This suggests that spontaneity in diagram use is an overlooked aspect in teachers’ view of student performance.\",\n",
              "  'The Effect of Graphical Format and Instruction on the Interpretation of Three-Variable Bar and Line Graphs.[SEP]We present a study that investigates how graph format and training can affect undergraduate psychology students’ ability to interpret three-variable bar and line graphs. A pre and post-test design was employed to assess 76 students’ conceptual understanding of three-variable graphs prior to and after a training intervention. The study revealed that significant differences in interpretation are produced by graph format prior to training; bar graph users outperform line graph users. Training also resulted in a statistically significant improvement in interpretation of both graph formats with effect sizes confirming the intervention resulted in substantial learning gains in graph interpretation. This resulted in bar graph users outperforming line graph users pre and post training making it the superior format even when training has occurred. The effect of graph format and training differed depending on task demands. Based on the results of this experiment, it is argued that undergraduate students’ interpretations of such three-variable data are more accurate when using the bar form. Findings also demonstrate how a brief tutorial can result in large gains in graph comprehension scores. We provide a test which can be used to assess students understanding of three-variable graphs and the tutorial developed for the study for educators to use.'],\n",
              " 75: ['Data, Data Everywhere, and Still Too Hard to Link: Insights from User Interactions with Diabetes Apps.[SEP]For those with chronic conditions, such as Type 1 diabetes, smartphone apps offer the promise of an affordable, convenient, and personalized disease management tool. However, despite significant academic research and commercial development in this area, diabetes apps still show low adoption rates and underwhelming clinical outcomes. Through user-interaction sessions with 16 people with Type 1 diabetes, we provide evidence that commonly used interfaces for diabetes self-management apps, while providing certain benefits, can fail to explicitly address the cognitive and emotional requirements of users. From analysis of these sessions with eight such user interface designs, we report on user requirements, as well as interface benefits, limitations, and then discuss the implications of these findings. Finally, with the goal of improving these apps, we identify 3 questions for designers, and review for each in turn: current shortcomings, relevant approaches, exposed challenges, and potential solutions.',\n",
              "  \"Designing Self-tracking Devices for Vulnerable Chronic Ill.[SEP]In my thesis, I take departure in a view on illness perception in design as found in the biopsychosocial (BPS) model. I expect that an equal focus on biological, psychological and social dimensions of illness will successfully assist the design of self-tracking devices. My thesis focusses on vulnerable patients with diabetes or prostate cancer. The objective is to improve patient wellbeing by making self-reflection accessible through the use of personal devices for self-tracking. The self-tracking devices and its surrounding system will be collaboratively developed with the participating patients. This collaboration is done to make sure that the patients lived experiences inform the design of the devices. The system will support communication in treatment between the patient, professional and relatives. Key challenges are in designing for vulnerable. How to create devices that respect patient's everyday life and how to bring the patient in control of self-tracked data, that is shared to others.\",\n",
              "  \"Findings of e-ESAS: a mobile based symptom monitoring system for breast cancer patients in rural Bangladesh.[SEP]Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how 'motivation' and 'automation' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.\",\n",
              "  'A Sociotechnical Mechanism for Online Support Provision.[SEP]Social support can significantly improve health outcomes for individuals living with disease, and online forums have emerged as an important vehicle for social support. Whereas research has focused on the delivery and use of social support, little is known about how these communities are sustained. We describe one sociotechnical mechanism that enables sustainable communities to provide social support to a large number of people. We focus upon thirteen disease-specific discussion forums hosted by the WebMD online health community. In these forums, small, densely connected cores of members who maintain strong relationships generate the majority of support for others. Through content analysis we find they provide informational support to a large number of more itinerant members, but provide one another with community support. Based on these observations, we describe a sociotechnical mechanism of online support that is distinct from non-support oriented communities, and has implications for the design of self-sustaining online support systems.',\n",
              "  \"Forum77: An Analysis of an Online Health Forum Dedicated to Addiction Recovery.[SEP]Prescription drug abuse is a pressing public health issue, and people who misuse prescription drugs are turning to online forums for help. Are such forums effective? We analyze the process of opioid withdrawal, recovery and relapse on Forum77, MedHelp.org's online health forum for substance abuse recovery. Applying Prochashka's Transtheoretical Model for behavior change, we develop a taxonomy describing phases of addiction expressed by Forum77 members. We examine activity and linguistic features across the phases USING, WITHDRAWING and RECOVERING. We train statistical classifiers to identify addiction phase, relapse and whether a user was RECOVERING at the time of her last post. Applying our classifiers to 2,848 users, we find that while almost 50% relapse, the prognosis for ending in RECOVERING is favorable. Supplementing our results with users' own accounts of their experiences, we discuss Forum77's efficacy and shortcomings, and implications for future technologies.\",\n",
              "  'HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers.[SEP]To address the needs of cancer patients and their caregivers, Microsoft Research and the Fred Hutchinson Cancer Research Center developed HutchWorld, an online community environment, to provide computer-mediated social and informational support. In a controlled clinical study, we deployed HutchWorld to bone marrow transplant patients and their caregivers and assessed the impact of Internet access and HutchWorld on their quality of life. We found that Internet access and the use of HutchWorld helped to buffer study participants against reductions in life satisfaction and social support following the transplant procedure. In particular, participants used the Internet to seek out support from family and friends'],\n",
              " 76: ['How Spatial Ability and Stress Impact Escape Path.[SEP]Individual differences and situational factors can both affect how and how well one navigates. This study examined the effects of stress and spatial ability, measured as mental rotation ability, on navigation during an emergency situation. Participants learned a virtual mall environment and were subsequently either told to meet a friend at the far exit (control) or to use the far exit to escape a fire. In an emergency, participants made an initial movement faster, made more errors during navigation, and overestimated the amount of time they took to exit relative to controls. Relative to controls, emergency low spatial participants more often reversed a learned path to exit the mall, whereas high spatial participants more often directly used a previously learned path. The results illustrate that stress from an emergency situation negatively impacts navigation, and that the behavioral consequences of this are in part dependent upon one’s spatial abilities.',\n",
              "  'Constraints, Inferences, and the Shortest Path: Which paths do we prefer?[SEP]How do we reason about incomplete spatio-temporal descriptions? How might a map influence formerly constructed preferred mental models? Little research so far focused on a combination of two central fields important for successful route planning: the way humans deal with constraint based reasoning (especially with some sort of spatio-temporal constraints) and the way in which humans plan with a given map (especially with problems inspired by typical Traveling Salesman Problems). This, however, becomes even more interesting in cases in which the spatio-temporal constraints allow for several solutions. Do the predictions of the preferred mental model theory still hold true in such situations? This article investigates the influence of maps on the generation of preferred models. The goal is to bring together the theory of (preferred) mental models and route planning.',\n",
              "  'The influence of structural salience and verbalisation on finding the return path.[SEP]Are some landmark positions at intersections better for finding a return path than others? This study investigated whether there is a variation in the influence of a landmark on performance and decision times when finding a return path depending on its position at an intersection. A variation of this influence is expected depending on the type of verbalisation of spatial directions used. First, participants learned a path either with direction specific (turn left at or turn right at) or direction unspecific material (turn into direction of or turn in the opposite direction of). In this path the positions of the landmarks were varied systematically. Secondly, participants had to find the return path of the learned route and their third task was to write down verbal route descriptions. An effect of the landmark position on finding the return path can be suggested, although it was barely insignificant, for direction specific and direction unspecific material. A significant influence on the accuracy of the information in the route descriptions depending on the position of a landmark and on the specificity of the spatial directions could be shown. The results are discussed in the context of current wayfinding and landmark research.',\n",
              "  'COPERNICUS: Context-Preserving Engine for Route Navigation with Interactive User-modifiable Scaling.[SEP]In this paper, we present an automated system for generating context‐preserving route maps that depict navigation routes as a path between nodes and edges inside a topographic network. Our application identifies relevant context information to support navigation and orientation, and generates customizable route maps according to design principles that communicate all relevant context information clearly visible on one single page. Interactive scaling allows seamless transition between the original undistorted map and our new map design, and supports user‐specified scaling of regions of interest to create personalized driving directions according to the drivers needs.',\n",
              "  'Drawing Road Networks with Focus Regions.[SEP]Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.',\n",
              "  'Designing and Annotating Metro Maps with Loop Lines.[SEP]Schematic metro maps provide an effective means of simplifying the geographical configuration of public rapid transportation systems. Nonetheless, travelers still find it difficult to identify routes of a specific topology on the maps because it is usually hidden behind the conventional octilinear layout of the entire map. In this paper, we present an approach to designing schematic maps with loop lines, which are drawn as circles together with annotation labels for guiding different traveling purposes. Our idea here is to formulate the aesthetic criteria as mathematical constraints in the mixed-integer programming model, which allows us to either align stations on the loop line at a grid if they are interchange stations or noninterchange stations on a circle otherwise. We then distribute the annotation labels associated with stations on the loop line evenly to the four side boundary of the map domain in order to make full use of the annotation space, while maximally avoiding intersections between leader lines and the metro network by employing a flow network algorithm. Finally, we present several experimental results generated by our prototype system to demonstrate the feasibility of the proposed approach.'],\n",
              " 77: ['Visualizing virus population variability from next generation sequencing data.[SEP]Advances in genomic sequencing techniques allow for larger scale generation and usage of sequence data. While these techniques afford new types of analysis, they also generate new concerns with regards to data quality and data scale. We present a tool designed to assist in the exploration of the genetic variability of the population of viruses at multiple time points and in multiple individuals, a task that necessitates considering large amounts of sequence data and the quality issues inherent in obtaining such data in a practical manner. Our design affords the examination of the amount of variability and mutation at each position in the genome for many populations of viruses. Our design contains novel visualization techniques that support this specific class of analysis while addressing the issues of data aggregation, confidence visualization, and interaction support that arise when making use of large amounts of sequence data with variable uncertainty. These techniques generalize to a wide class of visualization problems where confidence is not known a priori, and aggregation in multiple directions is necessary.',\n",
              "  'Interactive visual support for metagenomic contig binning.[SEP]Within metagenomics, \"Contig Binning\" is an important step in the process of reconstructing genomes of species in mixed cultures and environmental samples. We present an interactive visual environment which enables a biologist to statistically analyze the multiple dimensions of data that are typically used during binning, and integrate and compare the results of various binning methods. Our system features a web-based parallel coordinate visualization at the front end and a R server back end for analysis and semi-supervised clustering of contig data.',\n",
              "  'Visual analysis of next-generation sequencing data to detect overlapping genes in bacterial genomes.[SEP]Next generation sequencing (NGS) technologies are about to revolutionize biological research. Being able to sequence large amounts of DNA or, indirectly, RNA sequences in a short time period opens numerous new possibilities. However, analyzing the large amounts of data generated in NGS is a serious challenge, which requires novel data analysis and visualization methods to allow the biological experimenter to understand the results. In this paper, we describe a novel system to deal with the flood of data generated by transcriptome sequencing (RNA-seq) using NGS. Our system allows the analyzer to get a quick overview of the data and interactively explore interesting regions based on the three important parameters coverage, transcription, and fit. In particular, our system supports the NGS analysis in the following respects: (1) Representation of the coverage sequence in a way that no artifacts are introduced. (2) Easy determination of a fit of an open reading frame (ORF) to a transcript by mapping the coverage sequence directly into the ORF representation. (3) Providing automatic support for finding interesting regions to address the problems that the overwhelming volume of data comes with. (4) Providing an overview representation that allows parameter tuning and enables quick access to interesting areas of the genome. We show the usefulness of our system by a case study in the area of overlapping gene detection in a bacterial genome.'],\n",
              " 78: ['Two-level joint local laplacian texture filtering.[SEP]Extracting the structure component from an image with textures is a challenging problem. This paper presents a novel structure-preserving texture-filtering approach based on the two-level local Laplacian filter. The new texture-filtering method is developed by introducing local Laplacian filters into the joint filtering. Our study shows that local Laplacian filters can also be used for texture smoothing by defining a special remapping function, which is closely related to joint bilateral filtering. This finding leads to a variant of the joint bilateral filter, which produces smooth edges while preserving color variations. Our filter shares similar advantages with the joint bilateral filter, such as being simple to implement and easy to understand. Experiments demonstrate that the new filter can produce satisfactory filtering results with the properties of texture smoothing, smooth edges, and edge shape preserving. We compare our method with the state-of-the-art methods to demonstrate its improvements, and apply this filter to a variety of image-editing applications.',\n",
              "  'Non-blind deblurring of structured images with geometric deformation.[SEP]Non-blind deconvolution, which is to restore a sharp version of a given blurred image when the blur kernel is known, is a fundamental step in image deblurring. While the problem has been extensively studied, existing methods have conveniently ignored an important fact that deformation can significantly affect the statistical characteristics of an image and introduce additional blurring effect. In this paper, we show how to enhance non-blind deconvolution by recovering and undoing the deformation while deconvolving a given blurred image. We show that this is the case for almost all popular regularizers that have been proposed for image deblurring such as total variation and its variants. We conduct extensive simulations and experiments on real images and verify that the incorporation of geometric deformation in deconvolution can significantly improve the final deblurring results. Combined with existing blur kernel estimation techniques, our method can also be used to enhance blind image deblurring.',\n",
              "  'Fast high-quality non-blind deconvolution using sparse adaptive priors.[SEP]We present an efficient approach for high-quality non-blind deconvolution based on the use of sparse adaptive priors. Its regularization term enforces preservation of strong edges while removing noise. We model the image-prior deconvolution problem as a linear system, which is solved in the frequency domain. This clean formulation lends to a simple and efficient implementation. We demonstrate its effectiveness by performing an extensive comparison with existing non-blind deconvolution methods, and by using it to deblur photographs degraded by camera shake. Our experiments show that our solution is faster and its results tend to have higher peak signal-to-noise ratio than the state-of-the-art techniques. Thus, it provides an attractive alternative to perform high-quality non-blind deconvolution of large images, as well as to be used as the final step of blind-deconvolution algorithms.'],\n",
              " 79: ['Visual analysis method for cultural heritage site risk assessment.[SEP]Many significant cultural heritage sites are at risk caused by natural environment. A unique type of natural risk to heritage sites is deterioration risk. Conservators and managers of heritage sites are attempting to develop a risk management approach to reduce this type of risk. Risk assessment is the essential component part of risk management process. However, it is hindered by several challenges resulting from the complexity of deterioration risk. We propose the use of visual analysis method for deterioration risk assessment focusing on matching the major needs and objectives of deterioration risk analysis. Our purpose is to facilitate risk analysis which consists of perceiving risk as basis, risk level estimate, and risk cause analysis. A spatial view of deterioration risk is designed for the discovery of distribution patterns. Based on clustering technique, we propose a visual analytics method for risk level analysis. Lastly, the proposed multidimensional data analysis technique is used to detect the causes of deterioration risks.',\n",
              "  \"Applying 3D Dynamic Visualisation to (Palaeo) Geomorphic Reconstruction: Modelling a Tenth Century J[SEP]At Sólheimajökull glacier in southern Iceland, field evidence has been collected of a Tenth Century jökulhlaup (or glacial outburst flood). It was an exceptional event in terms of generation, scale, magnitude and geomorphic impact. Although now fragmented and piecemeal, many of its direct (and indirect) geomorphological and sedimentary markers have been identified, mapped and dated to unravel the sequence of events played out during this significant episode in the glacial history. 'VolcVis', an innovative, customised visualisation platform using computer gaming technology is developed and applied for the first time in coalescing and displaying field results from Sólheimajökull, creating an interactive, multi-perspective, three-dimensional (3D) prototype model. A visual simulation of Sólheimajökull's Tenth Century physical environment places the flood into geomorphic and topographic context. This ability to dynamically display and interpret field data presents new possibilities for testing hypotheses, and for data sharing with Icelandic hazard mitigation authorities and the general public.\",\n",
              "  'Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations.[SEP]For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.'],\n",
              " 80: ['Set models and Boolean operations for solids and assemblies.[SEP]Applications of solid modeling in computer-aided design, computer-aided manufacturing, and robotics, which often involve aggregates or assemblies of disconnected pieces, are addressed. Models for such assemblies must be subjected to some of the same operations as models for single parts. The mathematical basis of constructive solid geometry (CSG), the usual formalism in solid modelers, leads to difficulties in dealing with assemblies. An alternative CSG-like formalism based on open sets, in which both assemblies and connected pieces are modeled as point sets is presented. Consequently the same Boolean operations apply uniformly to connected pieces and assemblies.< >',\n",
              "  'Volume-Preserving Free-Form Solids.[SEP]Some important trends in geometric modeling are the reliance on solid models rather than surface-based models and the enhancement of the expressive power of models, by using free-form objects in addition to the usual geometric primitives and by incorporating physical principles. An additional trend is the emphasis on interactive performance. In this paper, we integrate all of these requirements into a single geometric primitive by endowing the tri-variate tensor-product free-form solid with several important physical properties, including volume and internal deformation energy. Volume preservation is of benefit in several application areas of geometric modeling, including computer animation, industrial design and mechanical engineering. However, previous physics-based methods, which have usually used some form of \"energy\", have neglected the issue of volume (or area) preservation. We present a novel method for modeling an object composed of several tensor-product solids while preserving the desired volume of each primitive and ensuring high-order continuity constraints between the primitives. The method utilizes the Uzawa algorithm for non-linear optimization, with objective functions based on deformation energy or least squares. We show how the algorithm can be used in an interactive environment by relaxing exactness requirements while the user interactively manipulates free-form solid primitives. On current workstations, the algorithm runs in real-time for tri-quadratic volumes and close to real-time for tri-cubic volumes.',\n",
              "  \"Eliminating redundant primitives from set-theoretic solid models by a consideration of constituents.[SEP]Set-theoretic solid models often contain redundant primitives, which slow down rendering and other processes. They are not simple to remove, especially as there can be alternative eliminations that may not be equally desirable. Existing techniques for eliminating such redundant primitives do not fully consider the possibilities and rely on repeated evaluation of parts of the object's boundary, a process that is likely to be very slow. A technique that allows alternative eliminations to be examined is proposed and a potentially efficient, but geometrically approximate, method of implementation is outlined.< >\"],\n",
              " 81: ['Beyond demand management: the value of sharing electricity information.[SEP]Technologies such as smart meters and electricity feedback are becoming an increasingly compelling focus for HCI researchers in light of rising power prices and peak demand. We argue, however, that a pre-occupation with the goal of demand management has limited the scope of design for these technologies. In this paper we present our work-in-progress investigating the potential value of socially sharing electricity information as a means of broadening the scope of design for these devices. This paper outlines some preliminary findings gathered from a design workshop and a series of qualitative interviews with householders in Brisbane, Australia, regarding their attitudes towards electricity feedback and sharing consumption information. Preliminary findings suggest that; (1) the social sharing of electricity feedback information has the potential to be of value in better informing consumption decisions, however; (2) the potential for sharing may be constrained by attitudes towards privacy, trust and the possibility of misinformation being shared. We conclude by outlining ideas for our future research on this topic and invite comments on these ideas.',\n",
              "  'Comparative Feedback in the Street: Exposing Residential Energy Consumption on House Fa[SEP]This study investigates the impact of revealing the changes in daily residential energy consumption of individual households on their respective house faç ades. While energy feedback devices are now commercially available, still little is known about the potential of making such private information publicly available in order to encourage various forms of social involvement, such as peer pressure or healthy competition. This paper reports on the design rationale of a custom-made chalkboard that conveys different visualizations of household energy consumption, which were updated daily by hand. An in-situ, between-subject study was conducted during which the effects of such a public display were compared with two different control groups over a total period of 7 weeks. The competitive aspects of the public display led to more sustained behavior change and more effective energy conservation, as some graphical depictions such as a historical line graph raised awareness about consumption behavior, and the public character of the display prompted discussions in the wider community. The paper concludes with several considerations for the design of public displays, and of household energy consumption in particular.',\n",
              "  \"Studying always-on electricity feedback in the home.[SEP]The recent emphasis on sustainability has made consumers more aware of their responsibility for saving resources, in particular, electricity. Consumers can better understand how to save electricity by gaining awareness of their consumption beyond the typical monthly bill. We conducted a study to understand consumers' awareness of energy consumption in the home and to determine their requirements for an interactive, always-on interface for exploring data to gain awareness of home energy consumption. In this paper, we describe a three-stage approach to supporting electricity conservation routines: raise awareness, inform complex changes, and maintain sustainable routines. We then present the findings from our study to support design implications for energy consumption feedback interfaces.\"],\n",
              " 82: ['Shape Approximation by a Fractal Model.[SEP]The use of fractals to synthesize complex objects is of current interest in the computer graphics community. A powerful way to compute fractals is the use of IFS (iterated function system) which is a set of contractions with associated probabilities which characterize the fractal. This theory, developed by M. Barnsley and al., can produce very complicated objects. We present a method to solve the inverse problem for these globally constructed fractals : given a set A (attractor), find an IFS that will approximately generate A. We use an optimisation method to minimize a distance between A and the current set L. Several distances have been tested and an algorithm has been implemented which gives good results. A test image is presented.',\n",
              "  'Visualizing Chemical Kinetics in Fractal Domains.[SEP]Chemical reactions occurring within complex domains, such as fractals, can display behavior which differs radically from the expectation of classical chemical kinetics. Rather than relaxing to a uniform distribution at the steady state, these nonclassical systems display large-scale order on many scales. Such self-organization is difficult to measure using the usual statistical techniques, but is visually apparent. The authors discuss some of the problems of visualizing chemical kinetics in fractal domains and describe evolution of the visualization as the chemist and visualization scientist collaborated.< >',\n",
              "  \"Transforming Fractals.[SEP]This issue's article examines the digital artwork of Rod Seeley, who transforms basic fractal images into complex works of art.\"],\n",
              " 83: ['Footprint tracker: supporting diary studies with lifelogging.[SEP]As HCI shifts \"to the wild\", in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.',\n",
              "  'Making love in the network closet: the benefits and work of family videochat.[SEP]In this paper, we explore the benefits of videochat for families and the corresponding work that home users engage in to make a video call run smoothly. We explore the varieties of social work required, including coordination work, presentation work, behavioral work, and scaffolding work, as well as the technical work necessary. We outline the benefits families enjoy for doing this work and discuss the ways in which families use videochat to reinforce their identity as a family and reinforce their family values, in effect making - as in creating - love. We conclude with recommendations for improving videochat and for designing with family values in mind more generally.',\n",
              "  \"AutoTypography: what can physical mementos tell us about digital memories?[SEP]Current technology makes it possible to capture huge amounts of information related to everyday experiences. Despite this, we know little about the processes by which people identify and manage mementos - objects which are directly meaningful to their memories. Among the millions of objects people encounter in a lifetime, few become such reminders of people, places or events. We report fieldwork where participants gave us a tour of their homes describing how and why particular objects become mementos. Our findings extend the existing digital memory literature; first our participants didn't view their activities as experiential 'capture', nor were mementos limited to pictorial representations of people and events; instead they included everyday objects. Furthermore, mementos were not only displayed and shared, but also integrated into everyday activities. Finally there were complex relations between house location and memento type. We discuss the theoretical and technical implications of our work.\"],\n",
              " 84: [\"Shared values/conflicting logics: working around e-government systems.[SEP]In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.\",\n",
              "  \"Civic Empowerment through Digitalisation: The Case of Greenlandic Women.[SEP]This paper explores the disruptive and transformative effects of digital technology on gendered security asymmetries in Greenland. Through ethnographic fieldwork conducted in Greenland and Denmark, research findings emerged through in-depth interviews, collaborative mappings and field observations with 51 participants. Employing a critical feminist lens, the paper identifies how Greenlandic women develop digital security practices to respond to Greenland's ecologically, politically and socially induced transformation processes. By connecting individual security concerns of Greenlandic women with the broader regional context, the findings highlight how digital technology has created transitory spaces in which collective security is cultivated, shaped and challenged. The contribution to HCI scholarship is therefore threefold: (1) identification and acknowledgement of gendered effects of increased usage of digital technology in remote and hard-to-reach communities, (2) a broader conceptualisation of digital security and (3) a recommendation for more contextualised, pluralistic digitalisation policies and design.\",\n",
              "  \"From Creating Spaces for Civic Discourse to Creating Resources for Action.[SEP]In this paper, we investigate the role of technology to address the concerns of a civil society group carrying out community-level consultation on the allocation of £1 million of community funds. We explore issues of devolved decision-making through the evaluation of a sociodigital system designed to foster deliberative virtues. We describe the ways in which this group used our system in their consultation practices. Our findings highlight how they adopted our technology to privilege specific forms of expression, ascertain issues in their community, make use of and make sense of community data, and create resources for action within their existing practices. Based on related fieldwork we discuss the impacts of structuring and configuring tools for 'talk-based' consultation in order to turn attention to the potential pitfalls and prospects for designing civic technologies that create resources for action for civil society.\"],\n",
              " 85: ['Holistic twig joins: optimal XML pattern matching.[SEP]XML employs a tree-structured data model, and, naturally, XML queries specify patterns of selection predicates on multiple elements related by a tree structure. Finding all occurrences of such a twig pattern in an XML database is a core operation for XML query processing. Prior work has typically decomposed the twig pattern into binary structural (parent-child and ancestor-descendant) relationships, and twig matching is achieved by: (i) using structural join algorithms to match the binary relationships against the XML database, and (ii) stitching together these basic matches. A limitation of this approach for matching twig patterns is that intermediate result sizes can get large, even when the input and output sizes are more manageable.In this paper, we propose a novel holistic twig join algorithm, TwigStack, for matching an XML query twig pattern. Our technique uses a chain of linked stacks to compactly represent partial results to root-to-leaf query paths, which are then composed to obtain matches for the twig pattern. When the twig pattern uses only ancestor-descendant relationships between elements, TwigStack is I/O and CPU optimal among all sequential algorithms that read the entire input: it is linear in the sum of sizes of the input lists and the final result list, but independent of the sizes of intermediate results. We then show how to use (a modification of) B-trees, along with TwigStack, to match query twig patterns in sub-linear time. Finally, we complement our analysis with experimental results on a range of real and synthetic data, and query twig patterns.',\n",
              "  \"Colorful XML: One Hierarchy Isn't Enough.[SEP]XML has a tree-structured data model, which is used to uniformly represent structured as well as semi-structured data, and also enable concise query specification in XQuery, via the use of its XPath (twig) patterns. This in turn can leverage the recently developed technology of structural join algorithms to evaluate the query efficiently. In this paper, we identify a fundamental tension in XML data modeling: (i) data represented as deep trees (which can make effective use of twig patterns) are often un-normalized, leading to update anomalies, while (ii) normalized data tends to be shallow, resulting in heavy use of expensive value-based joins in queries.Our solution to this data modeling problem is a novel multi-colored trees (MCT) logical data model, which is an evolutionary extension of the XML data model, and permits trees with multi-colored nodes to signify their participation in multiple hierarchies. This adds significant semantic structure to individual data nodes. We extend XQuery expressions to navigate between structurally related nodes, taking color into account, and also to create new colored trees as restructurings of an MCT database. While MCT serves as a significant evolutionary extension to XML as a logical data model, one of the key roles of XML is for information exchange. To enable exchange of MCT information, we develop algorithms for optimally serializing an MCT database as XML. We discuss alternative physical representations for MCT databases, using relational and native XML databases, and describe an implementation on top of the Timber native XML database. Experimental evaluation, using our prototype implementation, shows that not only are MCT queries/updates more succinct and easier to express than equivalent shallow tree XML queries, but they can also be significantly more efficient to evaluate than equivalent deep and shallow tree XML queries/updates.\",\n",
              "  'On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques.[SEP]Searching for all occurrences of a twig pattern in an XML document is an important operation in XML query processing. Recently a holistic method TwigStack. [2] has been proposed. The method avoids generating large intermediate results which do not contribute to the final answer and is CPU and I/O optimal when twig patterns only have ancestor-descendant relationships. Another important direction of XML query processing is to build structural indexes [3][8][13][15] over XML documents to avoid unnecessary scanning of source documents. We regard XML structural indexing as a technique to partition XML documents and call it streaming scheme in our paper. In this paper we develop a method to perform holistic twig pattern matching on XML documents partitioned using various streaming schemes. Our method avoids unnecessary scanning of irrelevant portion of XML documents. More importantly, depending on different streaming schemes used, it can process a large class of twig patterns consisting of both ancestor-descendant and parent-child relationships and avoid generating redundant intermediate results. Our experiments demonstrate the applicability and the performance advantages of our approach.'],\n",
              " 86: [\"Priming Effects of Religious Concepts on Moral Judgment: Between Mean Values and Variation.[SEP]Social psychological researchers have found that most conceptual structures can be primed, i.e. activated unobtrusively and exert an influence on subsequent behavior without the participant’s awareness of this influence. I investigated whether exposing people to words related to a punishing God or a forgiving Christian could influence subsequent moral judgment. Participants completed a 'scrambled sentence' task before rating five vignettes concerning various moral transgressions. Analysis showed that participants in the 'forgiving' condition on average made slightly less severe moral judgments than did participants in both the 'punishing' condition and a control condition. Whereas previous religious priming studies have often treated ‘religious’ concepts as a homogenous category with homogenous priming effects, the current experiment questions that assumption. Also, the study incorporated a measure of participants' associations with the prime words, revealing considerable variation. This suggests that participants’ different interpretations of religious words are an important topic and concern for future studies.\",\n",
              "  \"Apparent Paradoxes in Moral Reasoning; Or how you forced him to do it, even though he wasn't forced to do it.[SEP]The importance of situational constraint for moral evaluations is widely accepted in philosophy, psychology, and the law. However, recent work suggests that this relationship is actually bidirectional: moral evaluations can also influence our judgments of situational constraint. For example, if an agent is thought to have acted immorally rather than morally, that agent is often judged to have acted with greater freedom and under less situational constraint. Moreover, when considering interpersonal situations, we judge that an agent who forces another to act immorally (versus morally) uses more force. These two features can result in contradictory response patterns in which participants judge both that (1) a forcer forced a forcee to act and (2) the forcee was not forced by the forcer to act. Here, we characterize potential psychological mechanisms, in particular, “moral focus” and counterfactual reasoning that account for this paradoxical pattern of judgments.\",\n",
              "  'Mental states are more important in evaluating moral than conventional violations.[SEP]A perpetrator’s mental state – whether she had mens rea or a “guilty mind” – typically plays an important role in evaluating wrongness and assigning punishment. In two experiments, we find that this role for mental states is weaker in evaluating conventional violations relative to moral violations. We also find that this diminished role for mental states may be associated with the fact that conventional violations are wrong by virtue of having violated a rule, whereas moral violations are also wrong inherently.'],\n",
              " 87: ['Dataset Traversal with Motion-Controlled Transfer Functions.[SEP]In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.',\n",
              "  'ViSizer: A Visualization Resizing Framework.[SEP]Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.',\n",
              "  'Opacity Optimization for Surfaces.[SEP]In flow visualization, integral surfaces rapidly tend to expand, fold and produce vast amounts of occlusion. While silhouette enhancements and local transparency mappings proved useful for semi‐transparent depictions, they still introduce visual clutter when surfaces grow more complex. An effective visualization of the flow requires a balance between the presentation of interesting surface parts and the avoidance of occlusions that hinder the view. In this paper, we extend the concept of opacity optimization to surfaces to obtain a global approach to the occlusion problem. Starting with a partition of the surfaces into patches, we compute per‐patch opacity as minimizer of a bounded‐variable least‐squares problem. For the final rendering, opacity is interpolated on the surfaces. The resulting visualization technique is interactive, frame‐coherent, view‐dependent and driven by domain knowledge.'],\n",
              " 88: ['Control Theoretic Models of Pointing.[SEP]This article presents an empirical comparison of four models from manual control theory on their ability to model targeting behaviour by human users using a mouse: McRuer’s Crossover, Costello’s Surge, second-order lag (2OL), and the Bang-bang model. Such dynamic models are generative, estimating not only movement time, but also pointer position, velocity, and acceleration on a moment-to-moment basis. We describe an experimental framework for acquiring pointing actions and automatically fitting the parameters of mathematical models to the empirical data. We present the use of time-series, phase space, and Hooke plot visualisations of the experimental data, to gain insight into human pointing dynamics. We find that the identified control models can generate a range of dynamic behaviours that captures aspects of human pointing behaviour to varying degrees. Conditions with a low index of difficulty (ID) showed poorer fit because their unconstrained nature leads naturally to more behavioural variability. We report on characteristics of human surge behaviour (the initial, ballistic sub-movement) in pointing, as well as differences in a number of controller performance measures, including overshoot, settling time, peak time, and rise time. We describe trade-offs among the models. We conclude that control theory offers a promising complement to Fitts’ law based approaches in HCI, with models providing representations and predictions of human pointing dynamics, which can improve our understanding of pointing and inform design.',\n",
              "  'Modeling the Endpoint Uncertainty in Crossing-based Moving Target Selection.[SEP]Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.',\n",
              "  'A probabilistic approach to modeling two-dimensional pointing.[SEP]We investigate and model two-dimensional pointing where the target distance and size vary as does the angle of movement. We first study the spread of hits in a rapid approximate pointing task at varied distances and movement angles. Consistent with the literature, our results show that the spread of hits along the movement direction deviate more than the spread of hits in the direction perpendicular to movement, and both spreads increase with distance. Based on the distribution of this spread of hits, we propose and validate a new probabilistic model that describes two-dimensional pointing. Unlike previous models, our model accounts for more variables of two-dimensional pointing and can be generalized to any target shape, size, orientation, location, and dimension. In contrast to previous work, which suggests that target height has minimal impact on performance when it is larger than the width, our results show that, even when height is greater than width, it can significantly impact movement time.'],\n",
              " 89: ['A New Method for Auto-calibrated Object Tracking.[SEP]Ubiquitous computing technologies which are cheap and easy to use are more likely to be adopted by users beyond the ubiquitous computing community. We present an ultrasonic-only tracking system that is cheap to build, self-calibrating and self-orientating, and has a convenient form factor. The system tracks low-power tags in three dimensions. The tags are smaller than AAA batteries and last up to several years on their power source. The system can be configured to track either multiple near-stationary objects or a single fast moving object. Full test results are provided and use of the system within a home application is discussed.',\n",
              "  'Wideband powerline positioning for indoor localization.[SEP]Fingerprinting techniques for indoor localization have been widely explored. A particular approach by Patel et al. suggested leveraging of the residential powerline as the signaling mechanism for a domestic location capability. In this paper, we critically examine that initial work, called powerline positioning (PLP). We find the proposed technique lacking in temporal stability, requiring frequent and undesired recalibration in some environments. We also determine that there is no a priori method to determine a pair of signaling frequencies that will reliably work in any space. We propose a wideband approach to PLP (WPLP) that injects up to 44 different frequencies into the powerline. We show that this WPLP approach improves upon overall positioning accuracy, demonstrates greatly improved temporal stability and has the added advantage of working in commercial indoor spaces.',\n",
              "  'A Probabilistic Room Location Service for Wireless Networked Environments.[SEP]The popularity of wireless networks has increased in recent years and is becoming a common addition to LANs. In this paper we investigate a novel use for a wireless network based on the IEEE 802.11 standard: inferring the location of a wireless client from signal quality measures. Similar work has been limited to prototype systems that rely on nearest-neighbor techniques to infer location. In this paper, we describe Nibble, a Wi-Fi location service that uses Bayesian networks to infer the location of a device. We explain the general theory behind the system and how to use the system, along with describing our experiences at a university campus building and at a research lab. We also discuss how probabilistic modeling can be applied to a diverse range of applications that use sensor data.'],\n",
              " 90: ['Case Study: Reconstruction, Visualization, and Quantification of Neuronal Fiber Pathways.[SEP]It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.',\n",
              "  'Topological Visualization of Brain Diffusion MRI Data.[SEP]Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.',\n",
              "  'Visualizing crossing probabilistic tracts.[SEP]Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.'],\n",
              " 91: ['Statistical Schema Matching across Web Query Interfaces.[SEP]Schema matching is a critical problem for integrating heterogeneous information sources. Traditionally, the problem of matching multiple schemas has essentially relied on finding pairwise-attribute correspondence. This paper proposes a different approach, motivated by integrating large numbers of data sources on the Internet. On this \"deep Web,\" we observe two distinguishing characteristics that offer a new view for considering schema matching: First, as the Web scales, there are ample sources that provide structured information in the same domains (e.g., books and automobiles). Second, while sources proliferate, their aggregate schema vocabulary tends to converge at a relatively small size. Motivated by these observations, we propose a new paradigm, statistical schema matching: Unlike traditional approaches using pairwise-attribute correspondence, we take a holistic approach to match all input schemas by finding an underlying generative schema model. We propose a general statistical framework MGS for such hidden model discovery, which consists of hypothesis modeling, generation, and selection. Further, we specialize the general framework to develop Algorithm MGSsd, targeting at synonym discovery, a canonical problem of schema matching, by designing and discovering a model that specifically captures synonym attributes. We demonstrate our approach over hundreds of real Web sources in four domains and the results show good accuracy.',\n",
              "  'JSON Schema Matching: Empirical Observations.[SEP]Database schema specifies the desired logical organization of the data it stores. A major challenge in database integration is that of schema matching [10, 12], which seeks to determine schema elements in different databases that correspond to the same real world entity. For example, a simple matcher may determine that the attribute ID in one schema is semantically equivalent to Identification in another.',\n",
              "  'SourceSight: Enabling Effective Source Selection.[SEP]Recently there has been a rapid increase in the number of data sources and data services, such as cloud-based data markets and data portals, that facilitate the collection, publishing and trading of data. Data sources typically exhibit large heterogeneity in the type and quality of data they provide. Unfortunately, when the number of data sources is large, it is difficult for users to reason about the actual usefulness of sources for their applications and the trade-offs between the benefits and costs of acquiring and integrating sources. In this demonstration we present \\\\textsc{SourceSight}, a system that allows users to interactively explore a large number of heterogeneous data sources, and discover valuable sets of sources for diverse integration tasks. \\\\textsc{SourceSight}~uses a novel multi-level source quality index that enables effective source selection at different granularity levels, and introduces a collection of new techniques to discover and evaluate relevant sources for integration.',\n",
              "  'Visualizing Conceptual Relations in Legal Terminology.[SEP]Underlying all specialized terminology is a concept system, which is particularly important in the legal domain. However, this concept system is not explicitly available in terminology management systems. We present a tool that analyzes the relations in a terminological database and presents an interactive visualization of those relations. This tool helps terminologists manage their information, including quality assurance and analysis of the information, as well as aiding in didactic presentations of terminology work.',\n",
              "  'A Visualisation Approach for Collaborative Planning Systems Based on Ontologies.[SEP]In the last decades, many advances have been made in intelligent planning systems. Significant improvements related to core problems, providing faster search algorithms and shortest plans have been proposed. However, there is a lack in researches allowing a better support for a proper use and interaction with planners, where, for instance, visualization can play an important role. This work proposes a way to address the problem of visualization in intelligent planning systems via a more general approach. It consists in an integrated ontology set and reasoning mechanism for multi-modality visualisation destined to collaborative planning environments. This framework will permit organizing and modeling the domain from the visualization perspective, and give a tailored support for presentation of information.',\n",
              "  'User-Friendly Ontology Editing and Visualization Tools: The OWLeasyViz Approach.[SEP]This paper aims to propose solutions to the issue of ontology visualization, by presenting intuitive and user-friendly ontology editing and visualization environments mainly oriented to domain experts. It starts with an overview of existing ontology visualization methods; afterwards it describes the Semantic DB system and the OWLeasyViz ontology editor. Semantic DB is a web application framework to create simple complete semantic web applications, integrating an ontology editor, a resource editor, an inference rule editor, a reasoner, and a search engine. OWLeasyViz is an ontology editor that combines a textual and a graphical representation of OWL ontologies. It meets different user needs by providing a simple and intuitive interface to end-users who are not ontologists, and offering more advanced tools to ontology experts. The OWLeasyViz editor is intended to be a module of a semantic web integrated working environment, developed within the context of a Swiss Government funded CTI applied research project in the domain of waste water management.'],\n",
              " 92: ['Going with the flow: email awareness and task management.[SEP]Email use in the context of everyday work practices, or email flow, has not been heavily studied. We present the results of a pair of studies examining how users interlace email with their day-to-day, ongoing work processes. We demonstrate that our subjects use email as a tool for managing moment-to-moment attention and task focus. We also provide a model of this workflow that builds upon an existing model by Venolia et al. Finally, we provide specific design recommendations to enhance the usability of email clients in support of these modes of interaction.',\n",
              "  \"Overload is overloaded: email in the age of Gmail.[SEP]The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.\",\n",
              "  'Revisiting Whittaker  Sidner\\'s \"email overload\" ten years later.[SEP]Ten years ago, Whittaker and Sidner [8] published research on email overload, coining a term that would drive a research area that continues today. We examine a sample of 600 mailboxes collected at a high-tech company to compare how users organize their email now to 1996. While inboxes are roughly the same size as in 1996, our population\\'s email archives have grown tenfold. We see little evidence of distinct strategies for handling email; most of our users fall into a middle ground. There remains a need for future innovations to help people manage growing archives of email and large inboxes.'],\n",
              " 93: ['BubbleNet: A Cyber Security Dashboard for Visualizing Patterns.[SEP]The field of cyber security is faced with ever‐expanding amounts of data and a constant barrage of cyber attacks. Within this space, we have designed BubbleNet as a cyber security dashboard to help network analysts identify and summarize patterns within the data. This design study faced a range of interesting constraints from limited time with various expert users and working with users beyond the network analyst, such as network managers. To overcome these constraints, the design study employed a user‐centered design process and a variety of methods to incorporate user feedback throughout the design of BubbleNet. This approach resulted in a successfully evaluated dashboard with users and further deployments of these ideas in both research and operational environments. By explaining these methods and the process, it can benefit future visualization designers to help overcome similar challenges in cyber security or alternative domains.',\n",
              "  'situ: Situational understanding and discovery for cyber attacks.[SEP]Our entry into the VAST 2012 Mini Challenge 2 is a streaming visual analytic system that scores events based on anomalousness and maliciousness and presents each event to the user in a user-defined groupings in animated small-multiple views. The anomaly detection algorithm identifies low probability events, supporting awareness regarding atypical traffic patterns on the network. The maliciousness classifier incorporates both situated knowledge of an environment (policy and machine roles) and domain knowledge (encoded in the IDS alerts). We discuss the visualization design and classification techniques, as well as provide examples of timely detection from the challenge dataset.',\n",
              "  'Weaving a carpet from log entries: A network security visualization built with co-creation.[SEP]We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the \"Carpet\"). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers\\' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to define areas of interest for closer inspection.'],\n",
              " 94: ['Human-in-the-loop Outlier Detection.[SEP]Outlier detection is critical to a large number of applications from finance fraud detection to health care. Although numerous approaches have been proposed to automatically detect outliers, such outliers detected based on statistical rarity do not necessarily correspond to the true outliers to the interest of applications. In this work, we propose a human-in-the-loop outlier detection approach HOD that effectively leverages human intelligence to discover the true outliers. There are two main challenges in HOD. The first is to design human-friendly questions such that humans can easily understand the questions even if humans know nothing about the outlier detection techniques. The second is to minimize the number of questions. To address the first challenge, we design a clustering-based method to effectively discover a small number of objects that are unlikely to be outliers (aka, inliers) and yet effectively represent the typical characteristics of the given dataset. HOD then leverages this set of inliers (called context inliers) to help humans understand the context in which the outliers occur. This ensures humans are able to easily identify the true outliers from the outlier candidates produced by the machine-based outlier detection techniques. To address the second challenge, we propose a bipartite graph-based question selection strategy that is theoretically proven to be able to minimize the number of questions needed to cover all outlier candidates. Our experimental results on real data sets show that HOD significantly outperforms the state-of-the-art methods on both human efforts and the quality of the discovered outliers.',\n",
              "  'Angle-based outlier detection in high-dimensional data.[SEP]Detecting outliers in a large set of data objects is a major data mining task aiming at finding different mechanisms responsible for different groups of objects in a data set. All existing approaches, however, are based on an assessment of distances (sometimes indirectly by assuming certain distributions) in the full-dimensional Euclidean data space. In high-dimensional data, these approaches are bound to deteriorate due to the notorious \"curse of dimensionality\". In this paper, we propose a novel approach named ABOD (Angle-Based Outlier Detection) and some variants assessing the variance in the angles between the difference vectors of a point to the other points. This way, the effects of the \"curse of dimensionality\" are alleviated compared to purely distance-based approaches. A main advantage of our new approach is that our method does not rely on any parameter selection influencing the quality of the achieved ranking. In a thorough experimental evaluation, we compare ABOD to the well-established distance-based method LOF for various artificial and a real world data set and show ABOD to perform especially well on high-dimensional data.',\n",
              "  'Online Outlier Exploration Over Large Datasets.[SEP]Traditional outlier detection systems process each individual outlier detection request instantiated with a particular parameter setting one at a time. This is not only prohibitively time-consuming for large datasets, but also tedious for analysts as they explore the data to hone in on the appropriate parameter setting and desired results.'],\n",
              " 95: ['CoSummary: adaptive fast-forwarding for surgical videos by detecting collaborative scenes using hand regions and gaze positions.[SEP]This paper presents CoSummary, an adaptive video fast-forwarding technique for browsing surgical videos recorded by wearable cameras. Current wearable technologies allow us to record complex surgical skills, however, an efficient browsing technique for these videos is not well established. In order to assist browsing surgical videos, our study focuses on adaptively changing playback speeds through the learning and detecting collaborative scenes based on surgeon hand placement and gaze information. Our evaluation shows that the proposed method is able to highlight important collaborative scenes and skip less important scenes during surgical procedures. We have also performed a subjective study with surgeons in order to have professional feedback. The results confirmed the effectiveness of the proposed method in comparison to uniform video fast-forwarding.',\n",
              "  'Temporal Magic Lens: Combined Spatial and Temporal Query and Presentation.[SEP]We introduce the concept of a Temporal Magic Lens, a novel interaction technique that supports querying and browsing for video data. Video data is available from an increasing number of sources, and yet analyzing and processing it is still often a manual, tedious task. A Temporal Magic Lens is an interactive tool that combines spatial and temporal components of video, creating a unified mechanism for analyzing video data; it can be used for viewing real-time video data, as well as for browsing and searching archival data. In this paper, we define the Temporal Magic Lens concept and identify its four key components. We present a sample implementation for each component, and then describe two usage scenarios for a prototype surveillance application.',\n",
              "  \"SmartPlayer: user-centric video fast-forwarding.[SEP]In this paper we propose a new video interaction model called adaptive fast-forwarding to help people quickly browse videos with predefined semantic rules. This model is designed around the metaphor of scenic car driving, in which the driver slows down near areas of interest and speeds through unexciting areas. Results from a preliminary user study of our video player suggest the following: (1) the player should adaptively adjust the current playback speed based on the complexity of the present scene and predefined semantic events; (2) the player should learn user preferences about predefined event types as well as a suitable playback speed; (3) the player should fast-forward the video continuously with a playback rate acceptable to the user to avoid missing any undefined events or areas of interest. Furthermore, our user study results suggest that for certain types of video, our SmartPlayer yields better user experiences in browsing and fast-forwarding videos than existing video players' interaction models.\"],\n",
              " 96: ['A Visualization Tool for Studying the Development of the Moss Physcomitrella patens.[SEP]The investigation of mechanisms responsible for the morphogenesis of complex biological organisms is an important area in biology. P. patens is an especially suitable plant for this research because it is a rather simple organism, facilitating its observation, yet it possesses developmental phenomena analogous to those which occur in higher plants, allowing the extrapolation of hypotheses to more complex organisms. The visualization consists of three components: biological data collection, computer-modelling (using L-systems), and model verification. The simulated developmental process is quite realistic and provides an excellent means for verifying the underlying hypotheses of morphogenesis.',\n",
              "  'Data-Driven Synthetic Modeling of Trees.[SEP]In this paper, we develop a data-driven technique to model trees from a single laser scan. A multi-layer representation of the tree structure is proposed to guide the modeling process. In this process, a marching cylinder algorithm is first developed to construct visible branches from the laser scan data. Three levels of crown feature points are then extracted from the scan data to synthesize three layers of non-visible branches. Based on the hierarchical particle flow technique, the branch synthesis method has the advantage of producing visually convincing tree models that are consistent with scan data. User intervention is extremely limited. The robustness of this technique has been validated on both conifer and broadleaf trees.',\n",
              "  'Interactive Design of Bonsai Tree Models.[SEP]Because of their complexity, plant models used in computer graphics are commonly created with proceduralmethods. A difficult problem is the user control of these models: a small number of parameters is insufficient tospecify plant characteristics in detail, while large numbers of parameters are tedious to manipulate and difficultto comprehend. To address this problem, we propose a method for managing parameters involved in plant modelmanipulation. Specifically, we introduce decomposition graphs as multiscale representations of plant structuresand present interactive tools for designing trees that operate on decomposition graphs. The supported operationsinclude browsing of the parameter space, editing of generalized parameters (scalars, functions, and branchingsystem silhouettes), and the definition of dependencies between parameters. We illustrate our method by creatingmodels of bonsai trees.'],\n",
              " 97: [\"Automatic Entity Recognition and Typing in Massive Text Data.[SEP]In today's computerized and information-based society, individuals are constantly presented with vast amounts of text data, ranging from news articles, scientific publications, product reviews, to a wide range of textual information from social media. To extract value from these large, multi-domain pools of text, it is of great importance to gain an understanding of entities and their relationships. In this tutorial, we introduce data-driven methods to recognize typed entities of interest in massive, domain-specific text corpora. These methods can automatically identify token spans as entity mentions in documents and label their fine-grained types (e.g., people, product and food) in a scalable way. Since these methods do not rely on annotated data, predefined typing schema or hand-crafted features, they can be quickly adapted to a new domain, genre and language. We demonstrate on real datasets including various genres (e.g., news articles, discussion forum posts, and tweets), domains (general vs. bio-medical domains) and languages (e.g., English, Chinese, Arabic, and even low-resource languages like Hausa and Yoruba) how these typed entities aid in knowledge discovery and management.\",\n",
              "  'Robust Entity Resolution using Random Graphs.[SEP]Entity resolution (ER) seeks to identify which records in a data set refer to the same real-world entity. Given the diversity of ways in which entities can be represented, matched and distinguished, ER is known to be a challenging task for automated strategies, but relatively easier for expert humans. In our work, we abstract the knowledge of experts with the notion of a binary oracle. Our oracle can answer questions of the form \"do records u and v refer to the same entity?\" under a flexible error model, allowing for some questions to be more difficult to answer correctly than others.',\n",
              "  'Entity Resolution with Markov Logic.[SEP]Entity resolution is the problem of determining which records in a database refer to the same entities, and is a crucial and expensive step in the data mining process. Interest in it has grown rapidly, and many approaches have been proposed. However, they tend to address only isolated aspects of the problem, and are often ad hoc. This paper proposes a well-founded, integrated solution to the entity resolution problem based on Markov logic. Markov logic combines first-order logic and probabilistic graphical models by attaching weights to first-order formulas, and viewing them as templates for features of Markov networks. We show how a number of previous approaches can be formulated and seamlessly combined in Markov logic, and how the resulting learning and inference problems can be solved efficiently. Experiments on two citation databases show the utility of this approach, and evaluate the contribution of the different components.'],\n",
              " 98: [\"Investigating interruptions in the context of computerised cognitive testing for older adults.[SEP]Interruptions in the home pose a threat to the validity of self-administered computerised cognitive testing. We report the findings of a laboratory experiment investigating the effects of increased interruption workload demand on older adults' computerised cognitive test performance. Related work has reported interruptions having a range of inhibitory and facilitatory effects on primary task performance. Cognitive ageing literature suggests that increased interruption workload demand should have greater detrimental effects on older adults' performance, when compared to younger adults. With 36 participants from 3 age groups (20-54, 55-69, 70+), we found divergent effects of increased interruption demand on two primary tasks. Results suggest that older and younger adults experience interruptions differently, but at no age is test performance compromised by demanding interruptions. This finding is reassuring with respect to the success of a self-administered computerised cognitive assessment test, and is likely to be useful for other applications used by older adults.\",\n",
              "  \"Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors.[SEP]Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers.\",\n",
              "  'The effects of time constraints on user behavior for deferrable interruptions.[SEP]Previous studies of multitasking have highlighted the importance of cognitive load in interruptibility by showing that forced interruptions are least disruptive when cognitive load is low, and also that users prefer to address interruptions at low-load points when given a choice. We present an empirical study that uses a ringing-phone scenario to examine how users manage deferrable interruptions in the presence of varying time constraints. We found that while cognitive load did influence multitasking as expected, the time constraints placed on the user also had a significant impact. In particular, we observed three distinct strategies for addressing interruption: the expected strategy of switching at low-load points, but also two other strategies of continuing on after a low-load point or giving up at a high-load point. The presence of the latter two strategies strongly suggests that users can adapt their multitasking behavior with respect to the time constraints of the interrupting task.'],\n",
              " 99: ['Interpersonal Coordination of Perception and Memory in Real-Time Online Social Interaction.[SEP]The quiet hum of interpersonal coordination that runs throughout social communication and interaction shows how individuals can subtly influence one another’s behaviors, thoughts, and emotions over time. While the majority of research on coordination studies face-to-face interaction, recent advances in crowdsourcing afford the opportunity to conduct large-scale, real-time social interaction experiments. We take advantage of these tools to explore interpersonal coordination in a “minimally interactive context,” distilling the richness of natural communication into a tightly controlled setting to explore how people become coupled in their perceptual and memory systems while performing a task together. Consistent with previous work on postural sway and gaze, we found that individuals become coupled to one another’s cognitive processes without needing to be co-located or fully interactive with their partner; interestingly, although participants had no information about their partner and no means of direct communication, we also found hints that social forces can shape minimally interactive contexts, similar to effects observed in face-to-face interaction.',\n",
              "  'Facilitating interpersonal action coordination in a movement control task.[SEP]The present experiment examined how individuals and dyads coordinate action in a movement control task either with or without additional action effects. Participants pressed computer keys to keep a moving dot stimulus within a rectangle by certain key-movement mapping. Pressing a key could also cause visual, auditory, or no effect. Participants completed the task either alone or with a partner they could neither see nor hear. The results showed that individuals had better performance and longer key-press than dyads. The performance of dyads was improved by auditory effects, whereas the performance of individuals was not influenced by any additional action effect. In a subsequent STROOP-like task, participants were asked to press a computer key they used in the movement control task while being primed by either visual or auditory effects. The results revealed an association between auditory effects and correspondent key, whereas no such association was found for visual effects.',\n",
              "  'Synchronizing to Learn and Like.[SEP]Ever seen two people walking down the street in the exact same pace? This kind of interpersonal synchrony has been observed in both humans, as well as in animals (e.g., large groups of fireflies flash at the same time, schools of fish and flocks of birds synchronize their movement). For animals it appears to be beneficial (for survival) to synchronize their behavior, but what are the benefits for humans to do so? There are indications that interpersonal synchrony supports social bonding. Previous studies have shown that interpersonal synchrony can have both an effect on (e.g., increases memory), and can be affected by social factors (e.g., higher likeability ratings, more interpersonal synchrony). The goal of the present study was to examine whether social factors (e.g., popularity, friendship) affect interpersonal synchrony when working together. Furthermore, we looked at the relation between interpersonal synchrony and learning and likeability.'],\n",
              " 100: ['Stereoscopic View-Dependent Visualization of Terrain Height Fields.[SEP]Visualization of large geometric environments has always been an important problem of computer graphics. We present a framework for the stereoscopic view-dependent visualization of large scale terrain models. We use a quadtree based multiresolution representation for the terrain data. This structure is queried to obtain the view-dependent approximations of the terrain model at different levels of detail. In order not to lose depth information, which is crucial for the stereoscopic visualization, we make use of a different simplification criterion, namely, distance-based angular error threshold. We also present an algorithm for the construction of stereo pairs in order to speed up the view-dependent stereoscopic visualization. The approach we use is the simultaneous generation of the triangles for two stereo images using a single draw-list so that the view frustum culling and vertex activation is done only once for each frame. The cracking problem is solved using the dependency information stored for each vertex. We eliminate the popping artifacts that can occur while switching between different resolutions of the data using morphing. We implemented the proposed algorithms on personal computers and graphics workstations. Performance experiments show that the second eye image can be produced approximately 45 percent faster than drawing the two images separately and a smooth stereoscopic visualization can be achieved at interactive frame rates using continuous multiresolution representation of height fields.',\n",
              "  'LOD-Sprite Technique for Accelerated Terrain Rendering.[SEP]We present a new rendering technique, termed LOD-sprite rendering, which uses a combination of a level-of-detail (LOD) representation of the scene together with reusing image sprites (previously rendered images). Our primary application is accelerating terrain rendering. The LOD-sprite technique renders an initial frame using a high-resolution model of the scene geometry. It renders subsequent frames with a much lower-resolution model of the scene geometry and texture-maps each polygon with the image sprite from the initial high-resolution frame. As it renders these subsequent frames the technique measures the error associated with the divergence of the view position from the position where the initial frame was rendered. Once this error exceeds a user-defined threshold, the technique re-renders the scene from the high-resolution model. We have efficiently implemented the LOD-sprite technique with texture-mapping graphics hardware. Although to date we have only applied LOD-sprite to terrain rendering, it could easily be extended to other applications. We feel LOD-sprite holds particular promise for real-time rendering systems.',\n",
              "  'Interactive Terrain Rendering van Volume Visualization on the Princeton Engine.[SEP]The implementation of truly interactive volume visualization and terrain rendering algorithms on the Princeton Engine (PE) video supercomputer is described. The PE is a single-instruction multiple-data (SIMD) computer. Since it was originally developed as a real-time digital television system simulator, it possesses many of the attributes necessary for interactive visualization: high-resolution displays, high-bandwidth I/O, supercomputer class computational performance, and a local memory array large enough to store multiple Landsat scenes and data volumes. It is shown that it is possible to generate truly interactive terrain rendering and volume visualization by computing images in real-time, at multiple frames/second.< >'],\n",
              " 101: ['Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift.[SEP]Algorithms for tracking concept drift are important for many applications. We present a general method based on the weighted majority algorithm for using any online learner for concept drift. Dynamic weighted majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these \"experts\", and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and incremental tree inducer [ITI] as experts. For the sake of comparison, we also included Blum\\'s implementation of weighted majority. On the STAGGER concepts and on the SEA concepts, results suggest that the ensemble method learns drifting concepts almost as well as the base algorithms learn each concept individually. Indeed, we report the best overall results for these problems to date.',\n",
              "  'Polishing the Right Apple: Anytime Classification Also Benefits Data Streams with Constant Arrival Times.[SEP]Classification of items taken from data streams requires algorithms that operate in time sensitive and computationally constrained environments. Often, the available time for classification is not known a priori and may change as a consequence of external circumstances. Many traditional algorithms are unable to provide satisfactory performance while supporting the highly variable response times that exemplify such applications. In such contexts, anytime algorithms, which are amenable to trading time for accuracy, have been found to be exceptionally useful and constitute an area of increasing research activity. Previous techniques for improving anytime classification have generally been concerned with optimizing the probability of correctly classifying individual objects. However, as we shall see, serially optimizing the probability of correctly classifying individual objects K times, generally gives inferior results to batch optimizing the probability of correctly classifying K objects. In this work, we show that this simple observation can be exploited to improve overall classification performance by using an anytime framework to allocate resources among a set of objects buffered from a fast arriving stream. Our ideas are independent of object arrival behavior, and, perhaps unintuitively, even in data streams with constant arrival rates our technique exhibits a marked improvement in performance. The utility of our approach is demonstrated with extensive experimental evaluations conducted on a wide range of diverse datasets.',\n",
              "  'Detecting Recurring and Novel Classes in Concept-Drifting Data Streams.[SEP]Concept-evolution is one of the major challenges in data stream classification, which occurs when a new class evolves in the stream. This problem remains unaddressed by most state-of-the-art techniques. A recurring class is a special case of concept-evolution. This special case takes place when a class appears in the stream, then disappears for a long time, and again appears. Existing data stream classification techniques that address the concept-evolution problem, wrongly detect the recurring classes as novel class. This creates two main problems. First, much resource is wasted in detecting a recurring class as novel class, because novel class detection is much more computationally- and memory-intensive, as compared to simply recognizing an existing class. Second, when a novel class is identified, human experts are involved in collecting and labeling the instances of that class for future modeling. If a recurrent class is reported as novel class, it will be only a waste of human effort to find out whether it is really a novel class. In this paper, we address the recurring issue, and propose a more realistic novel class detection technique, which remembers a class and identifies it as \"not novel\" when it reappears after a long disappearance. Our approach has shown significant reduction in classification error over state-of-the-art stream classification techniques on several benchmark data streams.'],\n",
              " 102: [\"Generating Tile Maps.[SEP]Tile maps are an important tool in thematic cartography with distinct qualities (and limitations) that distinguish them from better‐known techniques such as choropleths, cartograms and symbol maps. Specifically, tile maps display geographic regions as a grid of identical tiles so large regions do not dominate the viewer's attention and small regions are easily seen. Furthermore, complex data such as time series can be shown on each tile in a consistent format, and the grid layout facilitates comparisons across tiles. Whilst a small number of handcrafted tile maps have become popular, the time‐consuming process of creating new tile maps limits their wider use. To address this issue, we present an algorithm that generates a tile map of the specified type (e.g. square, hexagon, triangle) from raw shape data. Since the ‘best’ tile map depends on the specific geography visualized and the task to be performed, the algorithm generates and ranks multiple tile maps and allows the user to choose the most appropriate. The approach is demonstrated on a range of examples using a prototype browser‐based application.\",\n",
              "  'A prototype Spatial Data Management System.[SEP]Spatial Data Management is a technique for organizing and retrieving information by positioning it in a spatial framework. Data is accessed in a Spatial Data Management System (SDMS) via pictorial representations which are arranged in space and viewed through a computer graphics system. These pictures can be created by an interactive graphical editor, allowing an SDMS to serve as a personal repository of diagrams, text, and photographs. Pictograms can also be generated from data in a symbolic database management system, allowing SDMS to be used as an interface to large, shared databases.',\n",
              "  'A fast and economic scan-to-line-conversion algorithm.[SEP]In order to generate cartographic data bases, it is necessary to digitize a large number of existing base maps. One way of replacing the error-prone and very time-consuming manual digitization by an automatic method is scanning the map and extracting the linework from the resulting binary matrix. A sufficiently fast and economic scan-to-line-conversion algorithm has to be developed for the line extraction.'],\n",
              " 103: [\"From codes to patterns: designing interactive decoration for tableware.[SEP]We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.\",\n",
              "  \"Bod-IDE: An Augmented Reality Sandbox for eFashion Garments.[SEP]Electronic fashion (eFashion) garments use technology to augment the human body with wearable interaction. In developing ideas, eFashion designers need to prototype the role and behavior of the interactive garment in context; however, current wearable prototyping toolkits require semi-permanent construction with physical materials that cannot easily be altered. We present Bod-IDE, an augmented reality 'mirror' that allows eFashion designers to create virtual interactive garment prototypes. Designers can quickly build, refine, and test on-the-body interactions without the need to connect or program electronics. By envisioning interaction with the body in mind, eFashion designers can focus more on reimagining the relationship between bodies, clothing, and technology.\",\n",
              "  \"What if HCI Becomes a Fashion Driven Discipline?[SEP]Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers' thinking and practices throughout the design process. In this note, we draw our insights from fashion related research within HCI and interaction design, provide some observations about fashion-related design and research practices, raise questions about our field as moving forward towards fashion driven discipline.\"],\n",
              " 104: ['Analytic Curve Skeletons for 3D Surface Modeling and Processing.[SEP]We present a new curve skeleton model designed for surface modeling and processing. This skeleton is defined as the geometrical integration of a piecewise harmonic parameterization defined over a disk‐cylinder surface decomposition. This decomposition is computed using a progressive Region Graph reduction based on both geometric and topological criteria which can be iteratively optimized to improve region boundaries. The skeleton has an analytical form with regularity inherited from the surface one. Such a form offers well‐defined surface‐skeleton and skeleton‐surface projections. The resulting skeleton satisfies quality criteria which are relevant for skeleton‐based modeling and processing. We propose applications that benefit from our skeleton model, including local thickness editing, inset surface creation for shell mapping, as well as a new mid‐scale feature preserving smoothing.',\n",
              "  'One-step Compact Skeletonization.[SEP]Computing a skeleton for a discretized boundary typically produces a noisy output, with a skeletal branch produced for each boundary pixel. A simplification step often follows to reduce these noisy branches. As a result, generating a clean skeleton is usually a 2-step process. In this article, we propose a skeletonization process that produces a clean skeleton in the first step, avoiding the creation of branches due to noise. The resulting skeleton compares favorably with the most common pruning methods on a large database of shapes. Our process also reduces execution time and requires only one parameter, e, that designates the desired boundary precision in the Hausdorff distance.',\n",
              "  'Skeleton computation of orthogonal polyhedra.[SEP]Skeletons are powerful geometric abstractions that provide useful representations for a number of geometric operations. The straight skeleton has a lower combinatorial complexity compared with the medial axis. Moreover, while the medial axis of a polyhedron is composed of quadric surfaces the straight skeleton just consist of planar faces. Although there exist several methods to compute the straight skeleton of a polygon, the straight skeleton of polyhedra has been paid much less attention. We require to compute the skeleton of very large datasets storing orthogonal polyhedra. Furthermore, we need to treat geometric degeneracies that usually arise when dealing with orthogonal polyhedra. We present a new approach so as to robustly compute the straight skeleton of orthogonal polyhedra. We follow a geometric technique that works directly with the boundary of an orthogonal polyhedron. Our approach is output sensitive with respect to the number of vertices of the skeleton and solves geometric degeneracies. Unlike the existing straight skeleton algorithms that shrink the object boundary to obtain the skeleton, our algorithm relies on the plane sweep paradigm. The resulting skeleton is only composed of axis‐aligned and 45° rotated planar faces and edges.'],\n",
              " 105: ['Unified Solution to Nonnegative Data Factorization Problems.[SEP]In this paper, we restudy the non-convex data factorization problems (regularized or not, unsupervised or supervised), where the optimization is confined in the nonnegative orthant, and provide a unified convergency provable solution based on multiplicative nonnegative update rules. This solution is general for optimization problems with block-wisely quadratic objective functions, and thus direct update rules can be derived by skipping over the tedious specific procedure deduction process and algorithmic convergence proof. By taking this unified solution as a general template, we i) re-explain several existing nonnegative data factorization algorithms, ii) develop a variant of nonnegative matrix factorization formulation for handling out-of-sample data, and Hi) propose a new nonnegative data factorization algorithm, called correlated co-decomposition (CCD), to simultaneously factorize two feature spaces by exploring the inter-correlated information. Experiments on both face recognition and multi-label image annotation tasks demonstrate the wide applicability of the unified solution as well as the effectiveness of two proposed new algorithms.',\n",
              "  'Multiplicative Algorithms for Constrained Non-negative Matrix Factorization.[SEP]Non-negative matrix factorization (NMF) provides the advantage of parts-based data representation through additive only combinations. It has been widely adopted in areas like item recommending, text mining, data clustering, speech denoising, etc. In this paper, we provide an algorithm that allows the factorization to have linear or approximately linear constraints with respect to each factor. We prove that if the constraint function is linear, algorithms within our multiplicative framework will converge. This theory supports a large variety of equality and inequality constraints, and can facilitate application of NMF to a much larger domain. Taking the recommender system as an example, we demonstrate how a specialized weighted and constrained NMF algorithm can be developed to fit exactly for the problem, and the tests justify that our constraints improve the performance for both weighted and unweighted NMF algorithms under several different metrics. In particular, on the Movie lens data with 94% of items, the Constrained NMF improves recall rate 3% compared to SVD50 and 45% compared to SVD150, which were reported as the best two in the top-N metric.',\n",
              "  'Recovering Low-Rank and Sparse Matrices via Robust Bilateral Factorization.[SEP]Recovering low-rank and sparse matrices from partial, incomplete or corrupted observations is an important problem in many areas of science and engineering. In this paper, we propose a scalable robust bilateral factorization (RBF) method to recover both structured matrices from missing and grossly corrupted data such as robust matrix completion (RMC), or incomplete and grossly corrupted measurements such as compressive principal component pursuit (CPCP). With the unified framework, we first present two robust trace norm regularized bilateral factorization models for RMC and CPCP problems, which can achieve an orthogonal dictionary and a robust data representation, simultaneously. Then, we apply the alternating direction method of multipliers to efficiently solve the RMC problems. Finally, we provide the convergence analysis of our algorithm, and extend it to address general CPCP problems. Experimental results verified both the efficiency and effectiveness of our RBF method compared with the state-of-the-art methods.'],\n",
              " 106: ['Speculative Execution and Branch Prediction on Parallel Machines.[SEP]Several recent studies on the limits of parallelism have reported that speculative execution can substantially increase the amount of exploitable parallelism in programs, especially non-numerical programs. This is true even for parallel machines models which allow multiple flows of control. However, most architectural techniques for speculation and branch prediction are geared toward conventional computers with a single flow of control, and little has been done in studying speculation models and techniques for parallel machines with multiple threads of control.',\n",
              "  'A Massively Parallel Optimizer for Expression Evaluation.[SEP]A number of “tricks” are known that trade multiplications for additions. The term “tricks” reflects the way these methods seem not to proceed from any general theory, but instead jump into existence as recipes that work. The Strassen method for 2 by 2 matrix product with 7 multiplications is a well-known example, as is the method for finding a complex number product in 3 multiplications. We have created a practical computer program for finding such tricks automatically, where massive parallelism makes the combinatorially explosive search tolerable for small problems. One result of this program is a method for computing cross products of 3-vectors using only 5 multiplications.',\n",
              "  \"Design considerations for parallel performance tools.[SEP]In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.\"],\n",
              " 107: [\"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization.[SEP]Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.\",\n",
              "  'Life on the Line: Interacting with Temporal Event Sequence Representations.[SEP]Sequences of events are part of people’s life, their travel, hospital visits, even web browsing experiences. Analysing collections of event sequences can be challenging even for skilled computer professionals. We will review a series of visualization techniques developed at the Human-Computer Interaction lab to handle temporal data.',\n",
              "  'Evaluating Alignment Approaches in Superimposed Time-Series and Temporal Event-Sequence Visualizations.[SEP]Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using single-event alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dual-event alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness-71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness-88% vs. 36% for DualStretch- completion time-55 seconds vs. 101 seconds for DualLeft-and error-1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5'],\n",
              " 108: ['Biorthogonal wavelet construction for hybrid quad/triangle meshes.[SEP]Ever since its introduction by Stam and Loop, the quad/triangle subdivision scheme, which is a generalization of the well-known Catmull–Clark subdivision and Loop subdivision, has attracted a great deal of interest due to its flexibility of allowing both quads and triangles in the same model. In this paper, we present a novel biorthogonal wavelet—constructed through the lifting scheme—that accommodates the quad/triangle subdivision. The introduced wavelet smoothly unifies the Catmull–Clark subdivision wavelet (for quadrilateral meshes) and the Loop subdivision wavelet (for triangular meshes) in a single framework. It can be used to flexibly and efficiently process any complicated semi-regular hybrid meshes containing both quadrilateral and triangular regions. Because the analysis and synthesis algorithms of the wavelet are composed of only local lifting operations allowing fully in-place calculations, they can be performed in linear time. The experiments demonstrate sufficient stability and fine fitting quality of the presented wavelet, which are similar to those of the Catmull–Clark subdivision wavelet and the Loop subdivision wavelet. The wavelet analysis can be used in various applications, such as shape approximation, progressive transmission, data compression and multiresolution edit of complex models.',\n",
              "  'Graph-Based Wavelet Representation of Multi-Variate Terrain Data.[SEP]Terrain data can be processed from the double perspective of computer graphics and graph theory. We propose a hybrid method that uses geometrical and vertex attribute information to construct a weighted graph reflecting the variability of the vertex data. As a planar graph, a generic terrain data set is subjected to a geometry‐sensitive vertex partitioning procedure. Through the use of a combined, thin‐plate energy and multi‐dimensional quadric metric error, feature estimation heuristic, we construct ‘even’ and ‘odd’ node subsets. Using an invertible lifting scheme, adapted from generic weighted graphs, detail vectors are extracted and used to recover or filter the node information. The design of the prediction and update filters improves the root mean squared error of the signal over general graph‐based approaches. As a key property of this design, preserving the mean of the graph signal becomes essential for decreasing the error measure and conserving the salient shape features.',\n",
              "  'Multiresolution Analysis on Irregular Surface Meshes.[SEP]Wavelet-based methods have proven their efficiency for visualization at different levels of detail, progressive transmission, and compression of large data sets. The required core of all wavelet-based methods is a hierarchy of meshes that satisfies subdivision-connectivity. This hierarchy has to be the result of a subdivision process starting from a base mesh. Examples include quadtree uniform 2D meshes, octree uniform 3D meshes, or 4-to-1 split triangular meshes. In particular, the necessity of subdivision-connectivity prevents the application of wavelet-based methods on irregular triangular meshes. In this paper, a \"wavelet-like\" decomposition is introduced that works on piecewise constant data sets over irregular triangular surface meshes. The decomposition/reconstruction algorithms are based on an extension of wavelet-theory allowing hierarchical meshes without property. Among others, this approach has the following features: it allows exact reconstruction of the data set, even for nonregular triangulations, and it extends previous results on Haar-wavelets over 4-to-1 split triangulations.'],\n",
              " 109: ['Child-personas: fact or fiction?[SEP]This paper introduces a practice-based, child-centric method of creating child-user archetypes which extends adult-based persona theory to interaction design with children. Persona construction can help interaction designers better understand real child-users and result in rich child-user archetypes which are developmentally situated and contextually valid. Key differences between adult-personas and child-personas are highlighted. A description of an online mentoring application created for CBC4Kids.ca illustrates the value of child-personas in design practice.',\n",
              "  \"Children and 'smart' technologies: can children's experiences be interpreted and coded?[SEP]This paper has a focus on young children and their emerging new technologies. It examines children's drawings as an evaluation tool for capturing their experiences of different novel interfaces.\",\n",
              "  \"Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding.[SEP]In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using these methods, while 4-year-olds were unable to use create solutions in a traditional format. How-ever, these younger children enthusiastically offered opportunities where, with methodological guidance, the research-er could have followed the child's lead and shifted the design question to one that was potentially more meaningful for the participant. We propose a future work to examine the effectiveness of giving these younger participants great-er authority in defining and scoping the problem space.\"],\n",
              " 110: [\"Evaluating the effectiveness of height visualizations for improving gestural communication at distributed tabletops.[SEP]In co-located collaboration, people use the space above the table for deictic gestures, and height is an important part of these gestures. However, when collaborators work at distributed tables, we know little about how to convey information about gesture height. A few visualizations have been proposed, but these have not been evaluated in detail. To better understand how remote embodiments can show gesture height, we developed several visualizations and evaluated them in three studies. First, we show that touch visualizations significantly improve people's accuracy in identifying the type and target of a gesture. Second, we show that visualizations of height above the table help to convey gesture qualities such as confidence, emphasis, and specificity. Third, we show that people quickly make use of height visualizations in realistic collaborative tasks, and that height-enhanced embodiments are strongly preferred. Our work illustrates several designs for effective visualization of height, and provides the first comprehensive evidence of the value of height information as a way to improve gestural communication in distributed tabletop groupware.\",\n",
              "  \"Making big gestures: effects of gesture size on observability and identification for co-located group awareness.[SEP]Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.\",\n",
              "  'Exploring the effects of group size and table size on interactions with tabletop shared-display groupware.[SEP]Interactive tabletops have been previously proposed and studied in the domain of co-located group applications. However, little fundamental research has been done to explore the issue of size. In this paper we identify a number of size considerations for tabletop design, and present an experiment to explore some of these issues, in particular the effects of group size and table size on the speed at which the task was performed, the distribution of work among group members, issues of shared resources, and user preference for table size. Our findings shed light on (1) how work strategies are affected by group size, (2) how social interaction varies with respect to table size, and (3) how the speed of task performance is influenced by group size but not by table size. In addition, our experiments revealed that for larger groups, designers might need to add additional vertical displays for shared information. This finding opens the door for extending single-display groupware to shared-display groupware settings that involve multiple, shared displays.'],\n",
              " 111: ['Interactive continuous collision detection for non-convex polyhedra.[SEP]We present a highly interactive, continuous collision detection algorithm for rigid, general polyhedra. Given initial and final configurations of a moving polyhedral model, our algorithm creates a continuous motion with constant translational and angular velocities, thereby interpolating the initial and final configurations of the model. Then, our algorithm reports whether the model under the interpolated motion collides with other rigid polyhedral models in environments, and if it does, the algorithm reports its first time of contact (TOC) with the environment as well as its associated contact features at TOC.',\n",
              "  'A Collision Detection and Response Scheme for Simplified Physically Based Animation.[SEP]In this paper we describe a system for physical animation of rigid and deformable objects. These are represented as groups of particles linked by linear constraints, while a Verlet integrator is used for motion computation. Unlike traditional approaches, we accomplish physical simulation without explicitly computing orientation matrices, torques or inertia tensors. The main contribution of our work is related to the way collisions are handled by the system, which employs different approaches for deformable and rigid bodies. In particular, we show how collision detection using the GJK algorithm [9] and bounding sphere hierarchies can be combined with the projection based collision response technique described by Jakobsen [14].',\n",
              "  'Continuous collision detection for deformable objects using permissible clusters.[SEP]In this paper, we propose a new data structure to perform continuous collision detection (CCD) for deformable triangular meshes. The critical component of this data structure is permissible clusters. At the preprocessing phase, the triangular meshes are divided into permissible clusters. Then, the features of the triangular meshes are assigned to the permissible clusters. At the runtime phase, the potentially colliding feature pairs are collected and they are processed only once in the elementary processing. Our method has been integrated with a normal cone-based method and compared with other CCD methods. Experimental results show that our method improves the overall performance of CCD for deformable objects.'],\n",
              " 112: ['Adding structured data in unstructured web chat conversation.[SEP]Web chat is becoming the primary customer contact channel in customer relationship management (CRM), and Question/Answer/Lookup (QAL) is the dominant communication pattern in CRM agent-to-customer chat. Text-based web chat for QAL has two main usability problems. Chat transcripts between agents and customers are not tightly integrated into agent-side applications, requiring customer service agents to re-enter customer typed data. Also, sensitive information posted in chat sessions in plain text raises security concerns. The addition of web form widgets to web chat not only solves both of these problems but also adds new usability benefits to QAL. Forms can be defined beforehand or, more flexibly, dynamically composed. Two preliminary user studies were conducted. An agent-side study showed that adding inline forms to web chat decreased overall QAL completion time by 47 percent and increased QAL accuracy by removing all potential human errors. A customer-side study showed that web chat with inline forms is intuitive to customers.',\n",
              "  \"Transformation through Provocation?[SEP]Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.\",\n",
              "  \"A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot.[SEP]Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.\"],\n",
              " 113: ['3D Hair sketching for real-time dynamic  key frame animations.[SEP]Physically based simulation of human hair is a well studied and well known problem. But the “pure” physically based representation of hair (and other animation elements) is not the only concern of the animators, who want to “control” the creation and animation phases of the content. This paper describes a sketch-based tool, with which a user can both create hair models with different styling parameters and produce animations of these created hair models using physically and key frame-based techniques. The model creation and animation production tasks are all performed with direct manipulation techniques in real-time.',\n",
              "  'Hybrid fur rendering: combining volumetric fur with explicit hair strands.[SEP]Hair is typically modeled and rendered using either explicitly defined hair strand geometry or a volume texture of hair densities. Taken each on their own, these two hair representations have difficulties in the case of animal fur as it consists of very dense and thin undercoat hairs in combination with coarse guard hairs. Explicit hair strand geometry is not well-suited for the undercoat hairs, while volume textures are not well-suited for the guard hairs. To efficiently model and render both guard hairs and undercoat hairs, we present a hybrid technique that combines rasterization of explicitly defined guard hairs with ray marching of a prismatic shell volume with dynamic resolution. The latter is the key to practical combination of the two techniques, and it also enables a high degree of detail in the undercoat. We demonstrate that our hybrid technique creates a more detailed and soft fur appearance as compared with renderings that only use explicitly defined hair strands. Finally, our rasterization approach is based on order-independent transparency and renders high-quality fur images in seconds.',\n",
              "  \"Modeling Dynamic Hair as a Continuum.[SEP]In this paper we address the difficult problem of hair dynamics, particularly hair‐hair and hair‐air interactions. To model these interactions, we propose to consider hair volume as a continuum. Subsequently, we treat the interaction dynamics to be fluid dynamics. This proves to be a strong as well as viable approach for an otherwise very complex phenomenon. However, we retain the individual character of hair, which is vital to visually realistic rendering of hair animation. For that, we develop an elaborate model for stiffness and inertial dynamics of individual hair strand. Being a reduced coordinate formulation, the stiffness dynamics is numerically stable and fast. We then unify the continuum interaction dynamics and the individual hair's stiffness dynamics.\"],\n",
              " 114: ['Secure Authentication Watermarking for Binary Images.[SEP]Authentication watermarking is a hidden data inserted into an image, in order to detect any alterations. It seems to be almost impossible to design a really secure authentication watermarking without making use of the solid cryptography theory and techniques. In a cryptography-based authentication watermarking, a message authentication code (or digital signature) of the whole image is computed and the resulting code is inserted into the image itself. However, inserting the code alters the image and consequently its authentication code, invalidating the watermark. To avoid this problem, for gray-scale or color image, usually the least significant bits (LSBs) are cleared, the authentication code of the LSB-cleared image is computed and then the code is inserted into LSBs. Surely, one cannot perform the same procedure for binary images. We propose a quite simple solution for inserting a secure authentication watermarking in dispersed-dot halftone images. This technique can also be applied to any kind of binary images (including clustered-dot halftones), though the visual quality is not as good as when applied to dispersed-dot halftones. The proposed technique can be used with both secret-key or public-key ciphers.',\n",
              "  'A new multi-secret image sharing scheme based on DCT.[SEP]Multi-secret image sharing scheme (MSIS) is a technique to share multiple secret images over the internet. Normally, most of the secret image sharing schemes can share only a single secret image. However, due to the rapid development of internet technology, the necessity of sharing multiple images arises. An (n, n) MSIS is employed to share n images to n authorized participants. All the n participants are required to submit their respective shares to recover the original secret images. If the number of the participants is less than n, then reconstruction of the secret images is impossible. Most of the existing schemes which are in the frequency domain do not have the capability to handle multiple secret images. In this paper, a MSIS that uses the Discrete Cosine Transform is proposed to overcome the limitation present in the existing schemes. Moreover, the proposed scheme requires less computational time than the existing schemes. Security of the proposed scheme is analyzed and shows that the proposed scheme is computationally secure. Also, the proposed scheme can recover the same original secret images.',\n",
              "  'Digital Watermarking: From Concepts to Real-Time Video Applications.[SEP]Digital watermarking has been increasingly applied to hide information in digital multimedia data, thus enlisting the watermarking technology in the difficult fight against intellectual property rights infringement. The authors have developed a secure, robust watermarking algorithm and applied it in digital streaming MPEG-2 format video-the format of choice in the broadcast and video stock industry.'],\n",
              " 115: ['Keynote Speaker: Virtual Reality: Current Uses in Medical Simulation and Future.[SEP]Virtual reality has gone from research to educational tool to indispensible clinical application in patient care. A brief review of the current status of the use of VR in medicine will provide the springboard for the current gaps that provide future opportunities in simulation as well as an introduction to new advanced technologies that are revolutionizing medicine and which will require VR for educational and training support and clinical applications. Some topics for discussion are virtual patients, cadavers and autopsies, surgical rehearsal, robotic surgery, suspended animation, regeneration and tissue engineering. The challenge: how creatively can VR support these incredible new technologies? The grand challenge ñ how will 3-D stereolithography revolutionize the practice of medicine? Have you bought your Makerbot yet?',\n",
              "  'Evaluation of a tool-mounted guidance display for computer-assisted surgery.[SEP]We attached a small LCD display and video camera to a surgical drill. The LCD shows the tool position with respect to a planned trajectory, overlaid on video captured by the camera. We performed a user study to determine whether such a tool-mounted guidance display yields faster and more accurate tool placement than the conventional guidance display on a separate computer monitor. Our study showed that the tool-mounted display provides better positional and angular accuracy than the conventional display but that the video camera provides no significant improvement in error.',\n",
              "  'Modelling Techniques for Enhanced Realism in an Open Surgery Simulation.[SEP]This paper is a continuation of work originating from the simulation of Inguinal Hernia Repair. Whilst the majority of research in the medical simulation field is for minimally invasive techniques, the objective of our research is to develop a general framework for open surgery simulation. We focus here on the finer details of implementing such a simulator using advanced rendering techniques, collision detection and haptic feedback.'],\n",
              " 116: ['Subspace Selection for Clustering High-Dimensional Data.[SEP]In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (subspaces relevant for clustering) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task \"clustering\" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant sub-spaces in high dimensional, sparse data sets and produces better results than comparative methods.',\n",
              "  'Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering.[SEP]A novel approach to subspace clustering is proposed to exhaustively and efficiently mine quantitative frequent item-sets (QFIs) from massive transaction data. For the computational tractability, our approach introduces adaptive density-based and Apriori-like algorithm. Its outstanding performance is shown through numerical experiments.',\n",
              "  \"Effective and Robust Mining of Temporal Subspace Clusters.[SEP]Mining temporal multivariate data by clustering is an important research topic. In today's complex data, interesting patterns are often neither bound to the whole dimensional nor temporal extent of the data domain. This challenge is met by temporal subspace clustering methods. Their effectiveness, however, is impeded by aspects unavoidable in real world data: Misalignments between time series, for example caused by out-of-sync sensors, and measurement errors. Under these conditions, existing temporal subspace clustering approaches miss the patterns contained in the data. In this paper, we propose a novel clustering method that mines temporal subspace clusters reflected by sets of objects and relevant intervals. We enable flexible handling of misaligned time series by adaptively shifting time series in the time domain, and we achieve robustness to measurement errors by allowing certain fractions of deviating values in each relevant point in time. We show the effectiveness of our method in experiments on real and synthetic data.\"],\n",
              " 117: [\"Towards social user profiling: unified and discriminative influence model for inferring home locations.[SEP]Users' locations are important to many applications such as targeted advertisement and news recommendation. In this paper, we focus on the problem of profiling users' home locations in the context of social network (Twitter). The problem is nontrivial, because signals, which may help to identify a user's location, are scarce and noisy. We propose a unified discriminative influence model, named as UDI, to solve the problem. To overcome the challenge of scarce signals, UDI integrates signals observed from both social network (friends) and user-centric data (tweets) in a unified probabilistic framework. To overcome the challenge of noisy signals, UDI captures how likely a user connects to a signal with respect to 1) the distance between the user and the signal, and 2) the influence scope of the signal. Based on the model, we develop local and global location prediction methods. The experiments on a large scale data set show that our methods improve the state-of-the-art methods by 13%, and achieve the best performance.\",\n",
              "  'Geo-activity recommendations by using improved feature combination.[SEP]In this paper, we propose a new model to integrate additional data, which is obtained from geospatial resources other than original data set in order to improve Location/Activity recommendations. The data set that is used in this work is a GPS trajectory of some users, which is gathered over 2 years. In order to have more accurate predictions and recommendations, we present a model that injects additional information to the main data set and we aim to apply a mathematical method on the merged data. On the merged data set, singular value decomposition technique is applied to extract latent relations. Several tests have been conducted, and the results of our proposed method are compared with a similar work for the same data set.',\n",
              "  \"Followee recommendation in asymmetrical location-based social networks.[SEP]Researches on recommending followees in social networks have attracted a lot of attentions in recent years. Existing studies on this topic mostly treat this kind of recommendation as just a type of friend recommendation. However, apart from making friends, the reason of a user to follow someone in social networks is inherently to satisfy his/her information needs in asymmetrical manner. In this paper, we propose a novel mining-based recommendation approach named Geographic-Textual-Social Based Followee Recommendation (GTS-FR), which takes into account the user movements, online texting and social properties to discover the relationship between users' information needs and provided information for followee recommendation. The core idea of our proposal is to discover users' similarity in terms of all the three properties of information which are provided by the users in a Location-Based Social Network (LBSN). To achieve this goal, we define three kinds of features to capture the key properties of users' interestingness from their provided information. In GTS-FR approach, we propose a series of novel similarity measurements to calculate similarity of each pair of users based on various properties. Based on the similarity, we make on-line recommendation for the followee a user might be interested in following. To our best knowledge, this is the first work on followee recommendation in LBSNs by exploring the geographic, textual and social properties simultaneously. Through a comprehensive evaluation using a real LBSN dataset, we show that the proposed GTS-FR approach delivers excellent performance and outperforms existing stat-of-the-art friend recommendation methods significantly.\"],\n",
              " 118: ['Dealing with death in design: developing systems for the bereaved.[SEP]Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world, and materiality. We conclude with a distillation of these considerations into practical design guidelines for working in this area.',\n",
              "  \"Looking for Respite and Support: Technological Opportunities for Spousal Caregivers.[SEP]Our research aims at informing the design of technological solutions to alleviate the stress resulting from the involvement of spouses of Alzheimer's disease patients as caregivers. For so doing, we have observed and analyzed the different offline solutions that are offered by a healthcare network in the Aube region (North-East of France). We discuss the key factors that we have identified for building an effective support network and identify five perspectives for the development of an online social support platform to lower the burden of spousal caregivers.\",\n",
              "  \"Understanding technology choices and values through social class.[SEP]This ethnographic study of 22 diverse families in the San Francisco Bay Area provides a holistic account of parents' attitudes about their children's use of technology. We found that parents from different socioeconomic classes have different values and practices around technology use, and that those values and practices reflect structural differences in their everyday lives. Calling attention to class differences in technology use challenges the prevailing practice in human-computer interaction of designing for those similar to oneself, which often privileges middle-class values and practices. By discussing the differences between these two groups and the advantages of researching both, this research highlights the benefits of explicitly engaging with socioeconomic status as a category of analysis in design.\"],\n",
              " 119: [\"Differential Location Privacy for Sparse Mobile Crowdsensing.[SEP]Sparse Mobile Crowdsensing (MCS) has become a compelling approach to acquire and make inference on urban-scale sensing data. However, participants risk their location privacy when reporting data with their actual sensing positions. To address this issue, we adopt e-differential-privacy in Sparse MCS to provide a theoretical guarantee for participants' location privacy regardless of an adversary's prior knowledge. Furthermore, to reduce the data quality loss caused by differential location obfuscation, we propose a privacypreserving framework with three components. First, we learn a data adjustment function to fit the original sensing data to the obfuscated location. Second, we apply a linear program to select an optimal location obfuscation function, which aims to minimize the uncertainty in data adjustment. We also propose a fast approximated variant. Third, we propose an uncertaintyaware inference algorithm to improve the inference accuracy of obfuscated data. Evaluations with real environment and traffic datasets show that our optimal method reduces the data quality loss by up to 42% compared to existing differential privacy methods.\",\n",
              "  'Secure and private proofs for location-based activity summaries in urban areas.[SEP]Activity-based social networks, where people upload and share information about their location-based activities (e.g., the routes of their activities), are increasingly popular. Such systems, however, raise privacy and security issues: The service providers know the exact locations of their users; the users can report fake location information in order to, for example, unduly brag about their performance. In this paper, we propose a secure privacy-preserving system for reporting location-based activity summaries (e.g., the total distance covered and the elevation gain). Our solution is based on a combination of cryptographic techniques and geometric algorithms, and it relies on existing Wi-Fi access-point networks deployed in urban areas. We evaluate our solution by using real data sets from the FON community networks and from the Garmin Connect activity-based social network, and we show that it can achieve tight (up to a median accuracy of 76%) verifiable lower-bounds of the distance covered and of the elevation gain, while protecting the location privacy of the users with respect to both the social network operator and the access-point network operator(s).',\n",
              "  'Active Sparse Mobile Crowd Sensing Based on Matrix Completion.[SEP]A major factor that prevents the large scale deployment of Mobile Crowd Sensing (MCS) is its sensing and communication cost. Given the spatio-temporal correlation among the environment monitoring data, matrix completion (MC) can be exploited to only monitor a small part of locations and time, and infer the remaining data. Rather than only taking random measurements following the basic MC theory, to further reduce the cost of MCS while ensuring the quality of missing data inference, we propose an Active Sparse MCS (AS-MCS) scheme which includes a bipartite-graph-based sensing scheduling scheme to actively determine the sampling positions in each upcoming time slot, and a bipartite-graph-based matrix completion algorithm to robustly and accurately recover the un-sampled data in the presence of sensing and communications errors. We also incorporate the sensing cost into the bipartite-graph to facilitate low cost sample selection and consider the incentives for MCS. We have conducted extensive performance studies using the data sets from the monitoring of PM 2.5 air condition and road traffic speed, respectively. Our results demonstrate that our AS-MCS scheme can recover the missing data at very high accuracy with the sampling ratio only around $11%$, while the peer matrix completion algorithms with similar recovery performance requires up to 4-9 times the number of samples of ours for both the data sets.'],\n",
              " 120: ['Physical Skill and Idea Interaction in the Creation of New Dance Movements.[SEP]It has been suggested that in creative activities, cognition and physical action are related to each other. This study focuses on this relationship in breakdance, which is a creative activity of artistic and acrobatic movements. For four months, we conducted field observations of practice sessions of three expert breakdancers, and held interviews with them to investigate the creation process of new and original movements. The video records of the 34 practices and the interview data were analyzed with respect to two aspects: 1) Whether or not the dancers performed important movements appropriately; and 2) What the dancers were thinking when generating new aspects of the movements. The results show an interactive process between the development of dance movements and the generation of ideas. The dancers gradually became able to perform the movements appropriately by generating new ideas, and they generated new ideas using the somatic sensation of the new movements.',\n",
              "  \"Dance Movement: A Focus on the Technology.[SEP]Dance notation systems, like music notes, enable documentation of symbolic representations of movement as signs on paper for individual analysis and interpretation. Today, dance notation systems operate within a digital environment in dance notation applications that facilitate the process of recording movement. The author argues that a key objective in the development of these applications should be to provide the user with an unambiguous method to record and represent movement. These applications offer varying functionality in their use of technology for the representation of movement and can be broadly defined in three different categories. Dance notation applications make up the first category - they help notate or record specific forms of movement using dance notation. Notation-based applications, the second category, include applications that use dance notation as a basis for their development. The last category, dance technology, consists of applications that use emerging technologies to record and visualize movement. While each application has a defined use, it's important to consider how effective the technologies they employ are in successfully achieving their objectives. In this article, the author focuses on dance applications in these three categories. The author considers the limitations of existing technologies in their ability to effectively describe and record movement within a specific context.\",\n",
              "  'Designing Expressions of Movement Qualities.[SEP]Tango is a form of partner dancing in which two bodies sense one another, and move accordingly, in a dynamic, physical dialogue that is known for its subtle complexities, beauty and intimate experience. In MoCap Tango, we explore how we can build on our skills as designers to highlight and unravel these embedded qualities and use them as inspiration in designing interactions. In this pictorial, we invite the reader to actively participate in the designerly engagement that turns objective data into subjective expressions; highlighting the qualities embedded in the movements of professional dancers.'],\n",
              " 121: ['Anti-Aliased Lines Using Run-Masks.[SEP]In recent work, a set of line digitization algorithms based on the hierarchy of runs in the digital line has unified and generalized the iterative line‐drawing algorithms used in computer graphics. In this paper, the additional structural information generated by these algorithms is leveraged to describe a run‐based approach to draw anti‐aliased line segments in which anti‐aliased run‐masks are substituted for the individual run lengths as the line is being drawn. The run‐masks are precomputed using a prefiltering technique such that one or more run‐masks are defined for each of the one or two possible run lengths that occur in the line. The run‐masks can be defined for any order or level of the hierarchy of runs in the digital line and the technique is illustrated using runs of pixels. Comparing the use of run‐masks to applying the prefiltering technique for each pixel in the line, a line of similar visual quality can be produced more efficiently. We place no restrictions on the placement of the end points of the line, which may reside anywhere on the two‐dimensional plane.',\n",
              "  'A new approach to line and line segment clipping in homogeneous coordinates.[SEP]The clipping operation is still the bottleneck of the graphics pipeline in spite of the latest developments in graphical hardware and a significant increase in performance. Algorithms for line and line segment clipping have been studied for a long time and many research papers have been published so far. This paper presents a new robust approach to line and line segment clipping using a rectangular window. A simple extension for the case of convex polygon clipping is presented as well.',\n",
              "  'A New Two Dimensional Line Clipping Algorithm for Small Windows.[SEP]A new algorithm for clipping lines against rectangular windows is described. It is suitable for computations in both object space (floating point arithmetic) and image space (integer arithmetic). The algorithm is compared with other object and image space algorithms and shown to be superior for small windows.'],\n",
              " 122: ['Towards Adaptive Occlusion Culling Using Camera Coherence.[SEP]Occlusion culling proves to be useful for the interactive visualization of environments that are not densely occluded. Those which are built up by dense geometric sets like aerospace engines composed of thousands of components and millions of polygons. In first place the convenience of using occlusion culling is studied with a simple scheme. Then improvements are analyzed. The key points to obtain frame rate speed-ups are: a convenient occlusion query scheduling provides the performance required; depth sorting is performed only when camera orientation changes more than a given threshold; coherence reduces the number of occlusion queries posted per frame. It is possible to select the percentage of occlusion queries that will be performed in each frame, from non-conservative schemes up to a conservative one. Furthermore, we propose a small addition to the GPU occlusion queries to perform faster renderings',\n",
              "  'Bent Normals and Cones in Screen-space.[SEP]Ambient occlusion (AO) is a popular technique for real-time as well as offline rendering. One of its benefits is a gain in efficiency due to the fact that occlusion and shading are decoupled which results in an average occlusion that modulates the surface shading. Its main drawback is a loss of realism due to the lack of directional occlusion and lighting. As a solution, the use of bent normals was proposed for offline rendering. This work describes how to compute bent normals and bent cones in combination with screen-space ambient occlusion. These extensions combine the speed and simplicity of AO with physically more plausible lighting.',\n",
              "  'Integrating Occlusion Culling with Levels of Detail through Hardly-Visible Sets.[SEP]Occlusion culling and level‐of‐detail rendering have become two powerful tools for accelerating the handling of very large models in real‐time visualization applications. We present a framework that combines both techniques to improve rendering times. Classical occlusion culling algorithms compute potentially visible sets (PVS), which are supersets of the sets of visible polygons. The novelty of our approach is to estimate the degree of visibility of each object of the PVS using synthesized coarse occluders. This allows to arrange the objects of each PVS into several Hardly‐Visible Sets (HVS) with similar occlusion degree. According to image accuracy and frame rate requirements, HVS provide a way to avoid sending to the graphics pipeline those objects whose pixel contribution is low due to partial occlusion. The image error can be bounded by the user at navigation time. On the other hand, as HVS offer a tighter estimation of the pixel contribution for each scene object, it can be used for a more convenient selection of the level‐of‐detail at which objects are rendered. In this paper, we describe the new framework technique, provide details of its implementation using a visibility octree as the chosen occlusion culling data structure and show some experimental results on the image quality.'],\n",
              " 123: ['Usability of user interfaces: from monomodal to multimodal.[SEP]This workshop is aimed at reviewing and comparing existing Usability Evaluation Methods (UEMs) which are applicable to monomodal and multimodal applications, whether they are web-oriented or not. It addresses the problem on how to assess the usability of monomodal user interfaces according to techniques involving one or several modalities, in parallel or combined. In particular, how to synchronize results provided by different UEMs producing various types of results (e.g., audio, video, text, log files) is concerned. It also addresses the problem on how to assess the usability of multimodal user interfaces according to techniques based on multiple modalities. In particular, the question of generalizing the applicability of existing UEMs to these new types of user interfaces is concerned.',\n",
              "  'Multimodal Interaction within Ambient Environments: An Exploratory Study.[SEP]Inputs and outputs are not two independent phenomena in multimodal systems. This paper examines the relationship that exists between them. We present the results of a Wizard of Oz experiment which shows that output modalities used by the system have an influence on the users’ input modalities for a large category of users. The experiment took place in a smart room. This kind of environment does not require any particular knowledge about computers and their use and thus allowed us to study the behavior of ordinary people including subjects who are not familiar with computers. The experiment also shows that speech is a favorite modality within smart room environments for a large part of users. We think that the results presented in this paper will be useful for the design of intelligent multimodal systems.',\n",
              "  \"Designing socially acceptable multimodal interaction in cooking assistants.[SEP]Cooking assistant is an application that needs to find a trade-off between providing efficient help to the users (e.g., reminding them to stir a meal if it is about to burn) and avoiding users' annoyance. This trade-off may vary in different contexts, such as cooking alone or in a group, cooking new or known recipe etc. The results of the user study, presented in this paper, show which features of a multimodal interface users perceive as socially acceptable or unacceptable in different situations, and how this perception depends on user's age.\"],\n",
              " 124: ['Immunity to error through misidentification and non-attributive self-reference.[SEP]Recent empirical literature (Jeannerod & Pacherie, 2004; Mizumoto & Ishikawa, 2005) purports to challenge the thesis that certain forms of self-awareness are immune to errors of misidentification with respect to the first-person (IEM). I argue, first, that these studies do not present a challenge to the IEM thesis, and furthermore that IEM is indicative of a fundamental distinction between two ways of being self-aware—a distinction that has real consequences for empirical studies of self-awareness. In the final section of the paper I suggest that the non-attributive self-reference (NSR) thesis better explains what is special about the distinction than IEM does by itself.',\n",
              "  'Predicting How People Feel: Ownership Matters for Preschoolers.[SEP]Ownership is central in our thinking about other people and objects. We consider ownership when deciding whether we are permitted to use an object and when predicting how owners would feel if their property was lost or broken. Recognizing and understanding ownership is not just evident in adults. Even young children appreciate ownership and its consequences. In this experiment, we show that children aged three years (N = 40) predict that an individual would be sadder when her property went missing than when someone else’s property went missing. These findings show that young children have a rich appreciation of ownership, and grasp relations between ownership and psychological states.',\n",
              "  'New Developments in the Cognitive Science of Religion. Hosted by the International Association for the Cognitive Science of Religion (IACSR).[SEP]The International Association for the Cognitive Science of Religion (IACSR) seeks to advance the naturalistic study of religion. The IACSR recognizes that the cognitive sciences encompass a wide array of disciplines and methods, including, among others, experimental research in psychology and neuroscience, computational modeling, ethnographic, historical, archaeological, and comparative studies of religious cognition, and the survey techniques of the social sciences. The main goal of the workshop is to introduce CSS members to topics that are cutting edge in the cognitive science of religion. Religion is obviously of global significance, and its study requires explanations from a variety of perspectives that involve broader issues relevant to cognitive science.'],\n",
              " 125: ['Visualization Exploration and Encapsulation via a Spreadsheet-Like Interface.[SEP]Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains.',\n",
              "  'Anti-Freeze for Large and Complex Spreadsheets: Asynchronous Formula Computation.[SEP]Spreadsheet systems enable users to store and analyze data in an intuitive and flexible interface. Yet the scale of data being analyzed often leads to spreadsheets hanging and freezing on small changes. We propose a new asynchronous formula computation framework: instead of freezing the interface we return control to users quickly to ensure interactivity, while computing the formulae in the background. To ensure consistency, we indicate formulae being computed in the background via visual cues on the spreadsheet. Our asynchronous computation framework introduces two novel challenges: (a) How do we identify dependencies for a given change in a bounded time? (b) How do we schedule computation to maximize the number of spreadsheet cells available to the user over time? We bound the dependency identification time by compressing the formula dependency graph lossily, a problem we show to be NP-Hard. A compressed dependency table enables us to quickly identify the spreadsheet cells that need recomputation and indicate them as such to users. Finding an optimal computation schedule to maximize cell availability is also NP-Hard, and even merely obtaining a schedule can be expensive-we propose an on-the-fly scheduling technique to address this. We have incorporated asynchronous computation in DataSpread, a scalable spreadsheet system targeted at operating on arbitrarily large datasets on a spreadsheet frontend.',\n",
              "  'Graphical Definitions: Expanding Spreadsheet Languages Through Direct Manipulation and Gestures.[SEP]In the past, attempts to extend the spreadsheet paradigm to support graphical objects, such as colored circles or user-defined graphical types, have led to approaches featuring either a direct way of creating objects graphically or strong compatibility with the spreadsheet paradigm, but not both. This inability to conveniently go beyond numbers and strings without straying outside the spreadsheet paradigm has been a limiting factor in the applicability of spreadsheet languages. In this article we present graphical definitions, an approach that removes this limitation, allowing both simple and complex graphical objects to be programmed directly using direct manipulation and gestures, in a manner that fits seamlessly within the spreadsheet paradigm. We also describe an empirical study, in which subjects programmed such objects faster and with fewer errors using this approach than when using a traditional approach to formula specification. Because the approach is expressive enough to be used with both built-in and user-defined types, it allows the directness of demonstrational and spreadsheet techniques to be used in programming a wider range of applications than has been possible before.'],\n",
              " 126: ['Tracing data errors with view-conditioned causality.[SEP]A surprising query result is often an indication of errors in the query or the underlying data. Recent work suggests using causal reasoning to find explanations for the surprising result. In practice, however, one often has multiple queries and/or multiple answers, some of which may be considered correct and others unexpected. In this paper, we focus on determining the causes of a set of unexpected results, possibly conditioned on some prior knowledge of the correctness of another set of results. We call this problem View-Conditioned Causality. We adapt the definitions of causality and responsibility for the case of multiple answers/views and provide a non-trivial algorithm that reduces the problem of finding causes and their responsibility to a satisfiability problem that can be solved with existing tools. We evaluate both the accuracy and effectiveness of our approach on a real dataset of user-generated mobile device tracking data, and demonstrate that it can identify causes of error more effectively than static Boolean influence and alternative notions of causality.',\n",
              "  \"Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes.[SEP]Various computational procedures or constraint-based methods for data repairing have been proposed over the last decades to identify errors and, when possible, correct them. However, these approaches have several limitations including the scalability and quality of the values to be used in replacement of the errors. In this paper, we propose a new data repairing approach that is based on maximizing the likelihood of replacement data given the data distribution, which can be modeled using statistical machine learning techniques. This is a novel approach combining machine learning and likelihood methods for cleaning dirty databases by value modification. We develop a quality measure of the repairing updates based on the likelihood benefit and the amount of changes applied to the database. We propose SCARE (SCalable Automatic REpairing), a systematic scalable framework that follows our approach. SCARE relies on a robust mechanism for horizontal data partitioning and a combination of machine learning techniques to predict the set of possible updates. Due to data partitioning, several updates can be predicted for a single record based on local views on each data partition. Therefore, we propose a mechanism to combine the local predictions and obtain accurate final predictions. Finally, we experimentally demonstrate the effectiveness, efficiency, and scalability of our approach on real-world datasets in comparison to recent data cleaning approaches.\",\n",
              "  'A Perspective on Databases and Data Mining.[SEP]We discuss the use of database methods for data mining. Recently impressive results have been achieved for some data mining problems using highly specialized and clever data structures. We study how well one can manage by using general purpose database management systems. We illustrate our ideas by investigating the use of a dbms for a well-researched area: the discovery of association rules. We present a simple algorithm, consisting of only union and intersection operations, and show that it achieves quite good performance on an efficient dbms. Our method can incorporate inheritance hierarchies to the association rule algorithm easily. We also present a technique that effectively reduces the number of database operations when searching large search spaces that contain only few interesting items. Our work shows that database techniques are promising for data mining: general architectures can achieve reasonable results.'],\n",
              " 127: ['The Implementation of a 2D Convex Hull Algorithm Using Perturbation.[SEP]This paper discusses the problem of geometric degeneracies and outlines possible solutions when converting geometric algorithms into practice. It concentrates on the application of one of the suggested solutions, a perturbation technique, to a 2D convex hull program. An outline of the relevant theory and its conversion into practice is given. Experimental results are presented and discussed.',\n",
              "  'On Compatible Star Decompositions of Simple Polygons.[SEP]The authors introduce the notion of compatible star decompositions of simple polygons. In general, given two polygons with a correspondence between their vertices, two polygonal decompositions of the two polygons are said to be compatible if there exists a one-to-one mapping between them such that the corresponding pieces are defined by corresponding vertices. For compatible star decompositions, they also require correspondence between star points of the star pieces. Compatible star decompositions have applications in computer animation and shape representation and analysis. They present two algorithms for constructing compatible star decompositions of two simple polygons. The first algorithm is optimal in the number of pieces in the decomposition, providing that such a decomposition exists without adding Steiner vertices. The second algorithm constructs compatible star decompositions with Steiner vertices, which are not minimal in the number of pieces but are asymptotically worst-case optimal in this number and in the number of added Steiner vertices. They prove that some pairs of polygons require /spl Omega/(n/sup 2/) pieces, and that the decompositions computed by the second algorithm possess no more than O(n/sup 2/) pieces. In addition to the contributions regarding compatible star decompositions, the paper also corrects an error in the only previously published polynomial algorithm for constructing a minimal star decomposition of a simple polygon, an error which might lead to a nonminimal decomposition.',\n",
              "  'Reducing the Number of Points on the Convex Hull Calculation Using the Polar Space Subdivision in E2.[SEP]A convex hull of points in E 2 is used in many applications. In spite of low computational complexity O(h logn) it takes considerable time if large data processing is needed. We present a new algorithm to speed up any planar convex hull calculation. It is based on a polar space subdivision and speed up known convex hull algorithms of 3,7 times and more. The algorithm estimates the central point using 10% of the data, this point is taken as the origin for the polar subdivision. The space subdivision enables a fast and very efficient reduction of the given points, which cannot contribute to the final convex hull. The proposed algorithm iteratively approximates the convex hull, leaving only a small number of points for the final processing, which is performed using a \"standard\" algorithm. Non-eliminated points are then processed by a selected standard convex hull algorithm. The algorithm is simple and easy to implement. Experiments proved numerical robustness as well.'],\n",
              " 128: ['Both symbolic and embodied representations contribute to spatial language processing; Evidence from younger and older adults.[SEP]Building on earlier neuropsychological work, we adopted a novel individual differences approach to examine the relationship between spatial language and a wide range of both verbal and nonverbal abilities. Three new measures were developed for the assessment of spatial language processing: spatial naming, spatial verbal memory, and verbal comprehension in spatial perspective taking. Results from a sample of young adults revealed significant correlations between performance on the spatial language tasks and performance on both the analogous (non-spatial) verbal measures as well as on the (non-verbal) visual-spatial measures. Visual-spatial abilities, however, were more predictive of spatial language processing than verbal abilities. Furthermore, results from a sample of older adults revealed impairments in visual-spatial tasks and on spatial verbal memory. The results support dual process accounts of meaning, and provide further evidence of the close connection between the language of space and non-linguistic visual-spatial cognition.',\n",
              "  '\"Natural concepts\" revisited in the spatial-topological domain: Universal tendencies in focal spatial relations.[SEP]It has long been noted that the best examples, or foci, of color categories tend to align across diverse languages (Berlin & Kay, 1969)--but there is limited documentation of such universal foci in other semantic domains. Here, we explore whether spatial topological categories, such as \"in\" and \"on\" in English, have focal members comparable to those in color. We document names and best examples of topological spatial relations in Dutch, English, French, Japanese, Korean, Mandarin Chinese, and Spanish, and find substantial consensus, both within and across languages, on the best examples of such spatial categories. Our results provide empirical evidence for focal best examples in the spatial domain and contribute further support for a theory of \"natural concepts\" in this domain.',\n",
              "  'Spatial language and visual attention: A new approach to test linguistic relativity.[SEP]It is debated how far-reaching effects of language on cognition are - if they exist at all. Using a visual search paradigm, we tested whether native Korean and German speakers are differentially sensitive to visual 3D-object composites that only the Korean, but not the German (nor the English), language semantically distinguishes as tight- versus loose-fit. We instructed our participants to search for a colour-defined target composite among distractors. However, targets were also implicitly signalled by their tight- or loose-fit composites. Only Korean speakers picked up on this implicit target-defining characteristic, reflected in attention capture by target-similar composites. As these concepts are not grammticalised in the German language, our results demonstrate that language can determine which visual features capture attention. Our research introduces a novel approach because processing of the linguistically discriminated visual characteristics was neither instructed nor necessary for the task, demonstrating a case of linguistic relativity of cognition.'],\n",
              " 129: ['Addressing Mobile Phone Diversity in Ubicomp Experience Development.[SEP]Mobile phones are a widely-available class of device with supporting communications infrastructure which can be appropriated and exploited to support ubicomp experiences. However mobile phones vary hugely in their capabilities. We explore how a single dimension of phone application type embodies the critical trade-off between capability and availability, i.e. between what can be done and the fraction of potential participants’ phones that can do this. We describe four different mobile phone ubicomp experiences that illustrate different points along this continuum (SMS, WAP/Web, and J2ME, Python and native applications) and the common software platform/toolkit, EQUIP2, that has been co-developed to support them. From this we propose four development strategies for addressing mobile phone diversity: prioritise support for server development (including web integration), migrate functionality between server(s) and handset(s), support flexible communication options, and use a loosely coupled (data-driven and component-based) software approach.',\n",
              "  'Towards Deeper Understanding of User Experience with Ubiquitous Computing Systems: Systematic Literature Review and Design Framework.[SEP]Over the past decades, a plethora of innovative ubiquitous computing (ubicomp) systems have been constructed. The acceptance of the systems, however, depends on how users experience them in real contexts. While many of the ubicomp research projects include some form of user study, there is no overview of how user experience (UX) is approached in ubicomp research. To this end, we conducted a systematic literature review of ubicomp UX studies. Our findings reveal that users‘experiences with ubicomp systems have often been investigated in rather lightweight ways, for example by addressing basic usability issues, collecting ratings by simple, predetermined scales, or producing descriptions of general experiences such as fun and trust. Based on the findings we argue that a deeper and more fine-grained understanding of user experience would help developing more successful ubicomp systems. We propose a ubicomp UX framework that can help design and evaluate ubicomp systems with a desirable set of target experiences.',\n",
              "  'Rapidly Exploring Application Design Through Speed Dating.[SEP]While the user-centered design methods we bring from human-computer interaction to ubicomp help sketch ideas and refine prototypes, few tools or techniques help explore divergent design concepts, reflect on their merits, and come to a new understanding of design opportunities and ways to address them. We present Speed Dating, a design method for rapidly exploring application concepts and their interactions and contextual dimensions without requiring any technology implementation. Situated between sketching and prototyping, Speed Dating structures comparison of concepts, helping identify and understand contextual risk factors and develop approaches to address them. We illustrate how to use Speed Dating by applying it to our research on the smart home and dual-income families, and highlight our findings from using this method.'],\n",
              " 130: ['The doing of doing stuff: understanding the coordination of social group-activities.[SEP]This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.',\n",
              "  \"Accessible Online Meetings and Presentations.[SEP]In our current situation, conferences, classes, and meetings are moving online. What steps can you take to ensure that your activities are welcoming to a diverse audience, including people with disabilities? This presentation will look at proactive strategies you can take to ensure that your meetings and presentations are accessible to a wide audience. We'll talk about communication with participants, preparation, presentation materials, technology, and accommodations.\",\n",
              "  'Automated Assistance for the Telemeeting Lifecycle.[SEP]We analyse eighteen months of national and international deployment of a prototype telemeeting system supporting synchronous remote meetings which make extensive use of shared documents as well as video and audio conferencing. Logistics of a telemeeting include scheduling people and equipment, document format conversion, pre-sending documents, training, equipment and call setup, and meeting followup. The logistics burden is much larger than expected and can be a barrier to adoption of telemeeting technology. Using a process model that recognises moving between solo and group, asynchronous and synchronous work modes, the paper explores the amenability of individual logistics tasks to automated assistance, proposes a framework for such assistance, and develops a set of design principles.'],\n",
              " 131: [\"C[SEP]Datasets are often derived by manipulating raw data with statistical software packages. The derivation of a dataset must be recorded in terms of both the raw input and the manipulations applied to it. Statistics packages typically provide limited help in documenting provenance for the resulting derived data. At best, the operations performed by the statistical package are described in a script. Disparate representations make these scripts hard to understand for users. To address these challenges, we created Continuous Capture of Metadata (C2Metadata), a system to capture data transformations in scripts for statistical packages and represent it as metadata in a standard format that is easy to understand. We do so by devising a Structured Data Transformation Algebra (SDTA), which uses a small set of algebraic operators to express a large fraction of data manipulation performed in practce. We then implement SDTA, inspired by relational algebra, in a data transformation specification language we call SDTL. In this demonstration, we showcase C2metadata's capture of data transformations from a pool of sample transformation scripts in at least two languages: SPSS and Stata (SAS and R are under development), for social science data in a large academic repository. We will allow the audience to explore C2Metadata using a web-based interface, visualize the intermediate steps and trace the provenance and changes of data at different levels for better understanding of the process.\",\n",
              "  \"When the Web is your Data Lake: Creating a Search Engine for Datasets on the Web.[SEP]There are thousands of data repositories on the Web, providing access to millions of datasets. National and regional governments, scientific publishers and consortia, commercial data providers, and others publish data for fields ranging from social science to life science to high-energy physics to climate science and more. Access to this data is critical to facilitating reproducibility of research results, enabling scientists to build on others' work, and providing data journalists easier access to information and its provenance. In this talk, I will discuss our work on Dataset Search, which provides search capabilities over potentially all dataset repositories on the Web. I will talk about the open ecosystem for describing and citing datasets that we hope to encourage and the technical details on how we went about building Dataset Search. Finally, I will highlight research challenges in building a vibrant, heterogeneous, and open ecosystem where data becomes a first-class citizen.\",\n",
              "  'Debugging Big Data Analytics in Spark with [SEP]To process massive quantities of data, developers leverage Data-Intensive Scalable Computing (DISC) systems such as Apache Spark. In terms of debugging, DISC systems support only post-mortem log analysis and do not provide any debugging functionality. This demonstration paper showcases BigDebug: a tool enhancing Apache Spark with a set of interactive debugging features that can help users in debug their Big Data Applications.']}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Alg7Mno_-RZ"
      },
      "source": [
        "topic_info = reduce_model2.get_topic_info()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_vi-D1o_-VB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a2c10d1-8e00-4845-9608-f3a8fe09d0b7"
      },
      "source": [
        "topic_name = topic_info['Name']\n",
        "topic_name = topic_name.iloc[1: ]\n",
        "topic_list = topic_name.tolist()\n",
        "topic_list"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0_flow_fluid_vortex_jet',\n",
              " '1_language_word_linguistic_lexical',\n",
              " '2_visualization_topic_visual_visualizations',\n",
              " '3_recommendation_recommender_recommendations_users',\n",
              " '4_graph_graphs_network_networks',\n",
              " '5_shape_mesh_meshes_subdivision',\n",
              " '6_game_games_sports_play',\n",
              " '7_light_illumination_rendering_lighting',\n",
              " '8_database_query_queries_join',\n",
              " '9_dimensional_visualization_multidimensional_scatterplots',\n",
              " '10_motion_animation_motions_animations',\n",
              " '11_music_musical_voice_sound',\n",
              " '12_education_educational_teaching_classroom',\n",
              " '13_driving_vehicle_vehicles_driver',\n",
              " '14_gesture_gestures_touch_finger',\n",
              " '15_classification_class_feature_kernel',\n",
              " '16_gaze_eye_attention_head',\n",
              " '17_haptic_tactile_force_virtual',\n",
              " '18_rendering_graphics_gpu_splatting',\n",
              " '19_mining_frequent_itemsets_rules',\n",
              " '20_image_images_retrieval_recognition',\n",
              " '21_software_programmers_collaboration_developers',\n",
              " '22_brain_cognitive_attention_visual',\n",
              " '23_trajectory_trajectories_mobility_urban',\n",
              " '24_graphics_graphic_standards_phigs',\n",
              " '25_series_time_patterns_mining',\n",
              " '26_fabrication_printing_print_manufacturing',\n",
              " '27_smart_activities_context_interfaces',\n",
              " '28_vessel_imaging_ultrasound_clinical',\n",
              " '29_texture_textures_synthesis_image',\n",
              " '30_decision_choice_risk_risky',\n",
              " '31_weather_visualization_climate_ocean',\n",
              " '32_ray_rays_traversal_rendering',\n",
              " '33_twitter_tweets_media_sentiment',\n",
              " '34_creativity_painting_art_creative',\n",
              " '35_causal_beliefs_evidence_belief',\n",
              " '36_privacy_security_private_protection',\n",
              " '37_urban_city_building_buildings',\n",
              " '38_transaction_transactions_concurrency_distributed',\n",
              " '39_displays_display_navigation_lenses',\n",
              " '40_search_web_information_pages',\n",
              " '41_category_categories_categorization_similarity',\n",
              " '42_crowdsourcing_workers_crowd_worker',\n",
              " '43_patient_patients_care_clinical',\n",
              " '44_diagrams_diagrammatic_diagram_logic',\n",
              " '45_color_colors_palette_palettes',\n",
              " '46_hci_design_research_practice',\n",
              " '47_robot_robots_robotic_robotics',\n",
              " '48_label_labels_unlabeled_classification',\n",
              " '49_keyboard_keyboards_touch_finger',\n",
              " '50_sketching_sketches_drawing_design',\n",
              " '51_facial_face_animation_faces',\n",
              " '52_machine_fairness_deep_explanations',\n",
              " '53_papers_conference_issue_editorial',\n",
              " '54_heritage_museum_visitors_museums',\n",
              " '55_number_symbolic_magnitude_numbers',\n",
              " '56_facebook_social_privacy_friends',\n",
              " '57_influence_social_networks_network',\n",
              " '58_walking_virtual_locomotion_reality',\n",
              " '59_reality_augmented_virtual_interaction',\n",
              " '60_molecules_atoms_molecule_halos',\n",
              " '61_memory_insight_solving_task',\n",
              " '62_spline_splines_curves_cubic',\n",
              " '63_clustering_clusters_cluster_clusterings',\n",
              " '64_impaired_visually_tactile_impairments',\n",
              " '65_distributed_parallel_scientific_convergence',\n",
              " '66_wikipedia_communities_community_newcomers',\n",
              " '67_metaphors_metaphor_analogical_analogy',\n",
              " '68_crowd_crowds_simulation_pedestrians',\n",
              " '69_conversational_dialogue_agent_conversation',\n",
              " '70_tracking_camera_tracker_pose',\n",
              " '71_shadow_shadows_light_rendering',\n",
              " '72_narrative_story_stories_storytelling',\n",
              " '73_authentication_passwords_password_security',\n",
              " '74_students_math_solving_achievement',\n",
              " '75_health_patients_self_online',\n",
              " '76_route_map_navigation_wayfinding',\n",
              " '77_gene_genome_genomic_visualization',\n",
              " '78_image_smoothing_denoising_inpainting',\n",
              " '79_construction_visualisation_building_heritage',\n",
              " '80_solid_solids_boundary_polyhedral',\n",
              " '81_electricity_households_heating_smart',\n",
              " '82_fractal_fractals_compression_chaos',\n",
              " '83_memories_diary_life_everyday',\n",
              " '84_civic_civics_infrastructure_citizens',\n",
              " '85_xml_query_xquery_queries',\n",
              " '86_moral_dilemmas_judgment_harm',\n",
              " '87_volume_volumetric_rendering_opacity',\n",
              " '88_pointing_target_movement_targets',\n",
              " '89_indoor_location_positioning_rfid',\n",
              " '90_diffusion_tensor_tracts_brain',\n",
              " '91_ontology_schema_ontologies_schemas',\n",
              " '92_email_emails_mail_inbox',\n",
              " '93_security_traffic_cyber_intrusion',\n",
              " '94_outlier_outliers_datasets_distance',\n",
              " '95_video_videos_frames_temporal',\n",
              " '96_tree_trees_plant_plants',\n",
              " '97_entity_entities_name_disambiguation',\n",
              " '98_interruptions_interruption_interruptibility_task',\n",
              " '99_coordination_interpersonal_synchrony_actions',\n",
              " '100_terrain_rendering_terrains_resolution',\n",
              " '101_stream_drift_ensemble_drifting',\n",
              " '102_cartograms_map_maps_cartographic',\n",
              " '103_design_clothing_clothes_designers',\n",
              " '104_skeleton_skeletons_segmentation_mesh',\n",
              " '105_matrix_factorization_nonnegative_matrices',\n",
              " '106_parallel_compiler_cache_parallelism',\n",
              " '107_event_events_sentinel_ranking',\n",
              " '108_wavelet_wavelets_multiresolution_subdivision',\n",
              " '109_children_participatory_child_technologies',\n",
              " '110_tabletop_collaboration_touch_groupware',\n",
              " '111_collision_collisions_deformable_rigid',\n",
              " '112_chatbot_chatbots_chat_conversation',\n",
              " '113_hair_hairs_cloth_hairstyles',\n",
              " '114_watermarking_watermark_watermarks_attacks',\n",
              " '115_surgical_surgery_laparoscopic_minimally',\n",
              " '116_subspace_clustering_clusters_subspaces',\n",
              " '117_location_recommendation_friends_locations',\n",
              " '118_parents_parenting_child_life',\n",
              " '119_location_privacy_crowdsensing_obfuscation',\n",
              " '120_dance_dancers_dancer_choreographers',\n",
              " '121_line_clipping_algorithms_polygon',\n",
              " '122_occlusion_culling_rendering_occluded',\n",
              " '123_multimodal_modality_modalities_speech',\n",
              " '124_religious_dreaming_religion_cultural',\n",
              " '125_spreadsheet_spreadsheets_web_programming',\n",
              " '126_cleaning_repairing_repair_tuples',\n",
              " '127_polygons_polygon_hull_algorithm',\n",
              " '128_spatial_languages_across_meaning',\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner',\n",
              " '130_meetings_communication_informal_messaging',\n",
              " '131_provenance_lakes_workflows_lake']"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nTqvC6zG-cz_",
        "outputId": "863bc0c6-31ef-49e9-db4c-b409eaa7ae6e"
      },
      "source": [
        "print(repre_docs[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Target Temperature Driven Dynamic Flame Animation.[SEP]Fire/flame plays an important role in virtual environment. Controlling the flame behavior in an intuitive yet precise manner remains a challenging open problem. In this paper, a target temperature driven simulation method is proposed to control flame animation. The diverse descriptions of target flame are unified by temperature field. An adaptive control force is presented to control the degree of target-driven changing over the temperature field. A bidirectional iterative method is proposed to subdivide the final goal into a plurality of intermediate targets. We take geometric model, image, and temperature field as target flames to test our method. Experimental results show that this method allows complex flame animations to be controllably generated with very little additional cost compared to ordinary flow simulations.', 'Simulation and interaction of fluid dynamics.[SEP]In the fluid simulation, the fluids and their surroundings may greatly change properties such as shape and temperature simultaneously, and different surroundings would characterize different interactions, which would change the shape and motion of the fluids in different ways. On the other hand, interactions among fluid mixtures of different kinds would generate more comprehensive behavior. To investigate the interaction behavior in physically based simulation of fluids, it is of importance to build physically correct models to represent the varying interactions between fluids and the environments, as well as interactions among the mixtures. In this paper, we will make a simple review of the interactions, and focus on those most interesting to us, and model them with various physical solutions. In particular, more detail will be given on the simulation of miscible and immiscible binary mixtures. In some of the methods, it is advantageous to be taken with the graphics processing unit (GPU) to achieve real-time computation for middle-scale simulation.', 'Visual simulation of smoke.[SEP]In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.', 'Construction of Vector Field Hierarchies.[SEP]Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.', 'Segmentation of Discrete Vector Fields.[SEP]In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement', 'PLIC: Briding the Gap Between Streamlines and LIC.[SEP]This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.', 'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow.[SEP]Numerical simulation of scramjet asymmetric nozzle flow is carried out to visualize and investigate the effects of interaction between engine exhaust and hypersonic external flow. The Single Expansion Ramp Nozzle (SERN) configuration studied here consists of flat ramp and a cowl with different combinations of ramp angle and cowl geometry. UsingPARAS 3D, simulations are performed for a free stream Mach number of 6.5 that constitutes the external flow around the vehicle. Appropriate specific heats ratio has been simulated for the jet and free stream flow. External shock wave due to jet plume interaction with free stream flow, the internal barrel shock wave and the shear layer emanating from the cowl trailing edge and sidewalls are well captured. Wall static pressure distribution on the nozzle ramp for different nozzle expansion angles has been computed for both with and without side fence. Axial thrust and normal force have been evaluated by integrating the wall static pressure. Effect of cowl length variation and side fence on the SERN performance has also been studied and found to be quite significant. Based on this study, an optimum ramp angle at which the SERN generates maximum axial thrust is obtained. SERN angle of 20° was found to be optimum when the flight axis coincides with nozzle axis.', 'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump.[SEP]Comparison between numerical simulation and experimental results for unsteady flow field in a radial diffuser pump is presented for the design operating point. The numerical result is obtained by solving three-dimensional, unsteady Reynolds-averaged Navier-Stokes equations by the commercial CFD code CFX-10 withk-ω based shear stress transport turbulence model. Two-dimensional PIV measurements are conducted to acquire the experiment result. The phase-averaged velocity and turbulent kinetic energy fields are compared in detail between the results by the two methods in the impeller, diffuser and return channel regions. The qualitative comparison between CFD and PIV results is quite good in the phase-averaged velocity field. Although the turbulence level by PIV is higher than that by CFD generally, the main turbulence features are nearly the same. Furthermore, the blade orientation effect and other associated unsteady phenomena are also examined, in order to enhance the understanding on impeller-diffuser interaction in a radial diffuser pump.', 'Characteristic flow phenomena on a tee-branch pipe.[SEP]Osao, A. et al., Advanced Materials Research, 33-37 (2008), 1037–1042.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPZIvA37IyzQ",
        "outputId": "a693e49f-9634-4bb5-f075-c35c2bf28346"
      },
      "source": [
        "type(topic_list[0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "str"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pifasOo_IJDm",
        "outputId": "a5404b41-03a3-4cce-b4b0-5ff910a6e32f"
      },
      "source": [
        "len(topic_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S6YLrGD5IKE8",
        "outputId": "3eece361-94a5-4fe9-b183-db96995151ac"
      },
      "source": [
        "len(repre_docs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s6n0y25ZIKtQ"
      },
      "source": [
        "for i in range(len(repre_docs)):\n",
        "  repre_docs[topic_list[i]] = repre_docs.pop(i)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_yX-vvewIJ4V",
        "outputId": "62220f13-4b9f-4b05-d6df-32311b131c90"
      },
      "source": [
        "repre_docs"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0_flow_fluid_vortex_jet': ['Target Temperature Driven Dynamic Flame Animation.[SEP]Fire/flame plays an important role in virtual environment. Controlling the flame behavior in an intuitive yet precise manner remains a challenging open problem. In this paper, a target temperature driven simulation method is proposed to control flame animation. The diverse descriptions of target flame are unified by temperature field. An adaptive control force is presented to control the degree of target-driven changing over the temperature field. A bidirectional iterative method is proposed to subdivide the final goal into a plurality of intermediate targets. We take geometric model, image, and temperature field as target flames to test our method. Experimental results show that this method allows complex flame animations to be controllably generated with very little additional cost compared to ordinary flow simulations.',\n",
              "  'Simulation and interaction of fluid dynamics.[SEP]In the fluid simulation, the fluids and their surroundings may greatly change properties such as shape and temperature simultaneously, and different surroundings would characterize different interactions, which would change the shape and motion of the fluids in different ways. On the other hand, interactions among fluid mixtures of different kinds would generate more comprehensive behavior. To investigate the interaction behavior in physically based simulation of fluids, it is of importance to build physically correct models to represent the varying interactions between fluids and the environments, as well as interactions among the mixtures. In this paper, we will make a simple review of the interactions, and focus on those most interesting to us, and model them with various physical solutions. In particular, more detail will be given on the simulation of miscible and immiscible binary mixtures. In some of the methods, it is advantageous to be taken with the graphics processing unit (GPU) to achieve real-time computation for middle-scale simulation.',\n",
              "  'Visual simulation of smoke.[SEP]In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.',\n",
              "  'Construction of Vector Field Hierarchies.[SEP]Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.',\n",
              "  'Segmentation of Discrete Vector Fields.[SEP]In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement',\n",
              "  'PLIC: Briding the Gap Between Streamlines and LIC.[SEP]This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.',\n",
              "  'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow.[SEP]Numerical simulation of scramjet asymmetric nozzle flow is carried out to visualize and investigate the effects of interaction between engine exhaust and hypersonic external flow. The Single Expansion Ramp Nozzle (SERN) configuration studied here consists of flat ramp and a cowl with different combinations of ramp angle and cowl geometry. UsingPARAS 3D, simulations are performed for a free stream Mach number of 6.5 that constitutes the external flow around the vehicle. Appropriate specific heats ratio has been simulated for the jet and free stream flow. External shock wave due to jet plume interaction with free stream flow, the internal barrel shock wave and the shear layer emanating from the cowl trailing edge and sidewalls are well captured. Wall static pressure distribution on the nozzle ramp for different nozzle expansion angles has been computed for both with and without side fence. Axial thrust and normal force have been evaluated by integrating the wall static pressure. Effect of cowl length variation and side fence on the SERN performance has also been studied and found to be quite significant. Based on this study, an optimum ramp angle at which the SERN generates maximum axial thrust is obtained. SERN angle of 20° was found to be optimum when the flight axis coincides with nozzle axis.',\n",
              "  'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump.[SEP]Comparison between numerical simulation and experimental results for unsteady flow field in a radial diffuser pump is presented for the design operating point. The numerical result is obtained by solving three-dimensional, unsteady Reynolds-averaged Navier-Stokes equations by the commercial CFD code CFX-10 withk-ω based shear stress transport turbulence model. Two-dimensional PIV measurements are conducted to acquire the experiment result. The phase-averaged velocity and turbulent kinetic energy fields are compared in detail between the results by the two methods in the impeller, diffuser and return channel regions. The qualitative comparison between CFD and PIV results is quite good in the phase-averaged velocity field. Although the turbulence level by PIV is higher than that by CFD generally, the main turbulence features are nearly the same. Furthermore, the blade orientation effect and other associated unsteady phenomena are also examined, in order to enhance the understanding on impeller-diffuser interaction in a radial diffuser pump.',\n",
              "  'Characteristic flow phenomena on a tee-branch pipe.[SEP]Osao, A. et al., Advanced Materials Research, 33-37 (2008), 1037–1042.'],\n",
              " '100_terrain_rendering_terrains_resolution': ['Stereoscopic View-Dependent Visualization of Terrain Height Fields.[SEP]Visualization of large geometric environments has always been an important problem of computer graphics. We present a framework for the stereoscopic view-dependent visualization of large scale terrain models. We use a quadtree based multiresolution representation for the terrain data. This structure is queried to obtain the view-dependent approximations of the terrain model at different levels of detail. In order not to lose depth information, which is crucial for the stereoscopic visualization, we make use of a different simplification criterion, namely, distance-based angular error threshold. We also present an algorithm for the construction of stereo pairs in order to speed up the view-dependent stereoscopic visualization. The approach we use is the simultaneous generation of the triangles for two stereo images using a single draw-list so that the view frustum culling and vertex activation is done only once for each frame. The cracking problem is solved using the dependency information stored for each vertex. We eliminate the popping artifacts that can occur while switching between different resolutions of the data using morphing. We implemented the proposed algorithms on personal computers and graphics workstations. Performance experiments show that the second eye image can be produced approximately 45 percent faster than drawing the two images separately and a smooth stereoscopic visualization can be achieved at interactive frame rates using continuous multiresolution representation of height fields.',\n",
              "  'LOD-Sprite Technique for Accelerated Terrain Rendering.[SEP]We present a new rendering technique, termed LOD-sprite rendering, which uses a combination of a level-of-detail (LOD) representation of the scene together with reusing image sprites (previously rendered images). Our primary application is accelerating terrain rendering. The LOD-sprite technique renders an initial frame using a high-resolution model of the scene geometry. It renders subsequent frames with a much lower-resolution model of the scene geometry and texture-maps each polygon with the image sprite from the initial high-resolution frame. As it renders these subsequent frames the technique measures the error associated with the divergence of the view position from the position where the initial frame was rendered. Once this error exceeds a user-defined threshold, the technique re-renders the scene from the high-resolution model. We have efficiently implemented the LOD-sprite technique with texture-mapping graphics hardware. Although to date we have only applied LOD-sprite to terrain rendering, it could easily be extended to other applications. We feel LOD-sprite holds particular promise for real-time rendering systems.',\n",
              "  'Interactive Terrain Rendering van Volume Visualization on the Princeton Engine.[SEP]The implementation of truly interactive volume visualization and terrain rendering algorithms on the Princeton Engine (PE) video supercomputer is described. The PE is a single-instruction multiple-data (SIMD) computer. Since it was originally developed as a real-time digital television system simulator, it possesses many of the attributes necessary for interactive visualization: high-resolution displays, high-bandwidth I/O, supercomputer class computational performance, and a local memory array large enough to store multiple Landsat scenes and data volumes. It is shown that it is possible to generate truly interactive terrain rendering and volume visualization by computing images in real-time, at multiple frames/second.< >'],\n",
              " '101_stream_drift_ensemble_drifting': ['Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift.[SEP]Algorithms for tracking concept drift are important for many applications. We present a general method based on the weighted majority algorithm for using any online learner for concept drift. Dynamic weighted majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these \"experts\", and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and incremental tree inducer [ITI] as experts. For the sake of comparison, we also included Blum\\'s implementation of weighted majority. On the STAGGER concepts and on the SEA concepts, results suggest that the ensemble method learns drifting concepts almost as well as the base algorithms learn each concept individually. Indeed, we report the best overall results for these problems to date.',\n",
              "  'Polishing the Right Apple: Anytime Classification Also Benefits Data Streams with Constant Arrival Times.[SEP]Classification of items taken from data streams requires algorithms that operate in time sensitive and computationally constrained environments. Often, the available time for classification is not known a priori and may change as a consequence of external circumstances. Many traditional algorithms are unable to provide satisfactory performance while supporting the highly variable response times that exemplify such applications. In such contexts, anytime algorithms, which are amenable to trading time for accuracy, have been found to be exceptionally useful and constitute an area of increasing research activity. Previous techniques for improving anytime classification have generally been concerned with optimizing the probability of correctly classifying individual objects. However, as we shall see, serially optimizing the probability of correctly classifying individual objects K times, generally gives inferior results to batch optimizing the probability of correctly classifying K objects. In this work, we show that this simple observation can be exploited to improve overall classification performance by using an anytime framework to allocate resources among a set of objects buffered from a fast arriving stream. Our ideas are independent of object arrival behavior, and, perhaps unintuitively, even in data streams with constant arrival rates our technique exhibits a marked improvement in performance. The utility of our approach is demonstrated with extensive experimental evaluations conducted on a wide range of diverse datasets.',\n",
              "  'Detecting Recurring and Novel Classes in Concept-Drifting Data Streams.[SEP]Concept-evolution is one of the major challenges in data stream classification, which occurs when a new class evolves in the stream. This problem remains unaddressed by most state-of-the-art techniques. A recurring class is a special case of concept-evolution. This special case takes place when a class appears in the stream, then disappears for a long time, and again appears. Existing data stream classification techniques that address the concept-evolution problem, wrongly detect the recurring classes as novel class. This creates two main problems. First, much resource is wasted in detecting a recurring class as novel class, because novel class detection is much more computationally- and memory-intensive, as compared to simply recognizing an existing class. Second, when a novel class is identified, human experts are involved in collecting and labeling the instances of that class for future modeling. If a recurrent class is reported as novel class, it will be only a waste of human effort to find out whether it is really a novel class. In this paper, we address the recurring issue, and propose a more realistic novel class detection technique, which remembers a class and identifies it as \"not novel\" when it reappears after a long disappearance. Our approach has shown significant reduction in classification error over state-of-the-art stream classification techniques on several benchmark data streams.'],\n",
              " '102_cartograms_map_maps_cartographic': [\"Generating Tile Maps.[SEP]Tile maps are an important tool in thematic cartography with distinct qualities (and limitations) that distinguish them from better‐known techniques such as choropleths, cartograms and symbol maps. Specifically, tile maps display geographic regions as a grid of identical tiles so large regions do not dominate the viewer's attention and small regions are easily seen. Furthermore, complex data such as time series can be shown on each tile in a consistent format, and the grid layout facilitates comparisons across tiles. Whilst a small number of handcrafted tile maps have become popular, the time‐consuming process of creating new tile maps limits their wider use. To address this issue, we present an algorithm that generates a tile map of the specified type (e.g. square, hexagon, triangle) from raw shape data. Since the ‘best’ tile map depends on the specific geography visualized and the task to be performed, the algorithm generates and ranks multiple tile maps and allows the user to choose the most appropriate. The approach is demonstrated on a range of examples using a prototype browser‐based application.\",\n",
              "  'A prototype Spatial Data Management System.[SEP]Spatial Data Management is a technique for organizing and retrieving information by positioning it in a spatial framework. Data is accessed in a Spatial Data Management System (SDMS) via pictorial representations which are arranged in space and viewed through a computer graphics system. These pictures can be created by an interactive graphical editor, allowing an SDMS to serve as a personal repository of diagrams, text, and photographs. Pictograms can also be generated from data in a symbolic database management system, allowing SDMS to be used as an interface to large, shared databases.',\n",
              "  'A fast and economic scan-to-line-conversion algorithm.[SEP]In order to generate cartographic data bases, it is necessary to digitize a large number of existing base maps. One way of replacing the error-prone and very time-consuming manual digitization by an automatic method is scanning the map and extracting the linework from the resulting binary matrix. A sufficiently fast and economic scan-to-line-conversion algorithm has to be developed for the line extraction.'],\n",
              " '103_design_clothing_clothes_designers': [\"From codes to patterns: designing interactive decoration for tableware.[SEP]We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.\",\n",
              "  \"Bod-IDE: An Augmented Reality Sandbox for eFashion Garments.[SEP]Electronic fashion (eFashion) garments use technology to augment the human body with wearable interaction. In developing ideas, eFashion designers need to prototype the role and behavior of the interactive garment in context; however, current wearable prototyping toolkits require semi-permanent construction with physical materials that cannot easily be altered. We present Bod-IDE, an augmented reality 'mirror' that allows eFashion designers to create virtual interactive garment prototypes. Designers can quickly build, refine, and test on-the-body interactions without the need to connect or program electronics. By envisioning interaction with the body in mind, eFashion designers can focus more on reimagining the relationship between bodies, clothing, and technology.\",\n",
              "  \"What if HCI Becomes a Fashion Driven Discipline?[SEP]Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers' thinking and practices throughout the design process. In this note, we draw our insights from fashion related research within HCI and interaction design, provide some observations about fashion-related design and research practices, raise questions about our field as moving forward towards fashion driven discipline.\"],\n",
              " '104_skeleton_skeletons_segmentation_mesh': ['Analytic Curve Skeletons for 3D Surface Modeling and Processing.[SEP]We present a new curve skeleton model designed for surface modeling and processing. This skeleton is defined as the geometrical integration of a piecewise harmonic parameterization defined over a disk‐cylinder surface decomposition. This decomposition is computed using a progressive Region Graph reduction based on both geometric and topological criteria which can be iteratively optimized to improve region boundaries. The skeleton has an analytical form with regularity inherited from the surface one. Such a form offers well‐defined surface‐skeleton and skeleton‐surface projections. The resulting skeleton satisfies quality criteria which are relevant for skeleton‐based modeling and processing. We propose applications that benefit from our skeleton model, including local thickness editing, inset surface creation for shell mapping, as well as a new mid‐scale feature preserving smoothing.',\n",
              "  'One-step Compact Skeletonization.[SEP]Computing a skeleton for a discretized boundary typically produces a noisy output, with a skeletal branch produced for each boundary pixel. A simplification step often follows to reduce these noisy branches. As a result, generating a clean skeleton is usually a 2-step process. In this article, we propose a skeletonization process that produces a clean skeleton in the first step, avoiding the creation of branches due to noise. The resulting skeleton compares favorably with the most common pruning methods on a large database of shapes. Our process also reduces execution time and requires only one parameter, e, that designates the desired boundary precision in the Hausdorff distance.',\n",
              "  'Skeleton computation of orthogonal polyhedra.[SEP]Skeletons are powerful geometric abstractions that provide useful representations for a number of geometric operations. The straight skeleton has a lower combinatorial complexity compared with the medial axis. Moreover, while the medial axis of a polyhedron is composed of quadric surfaces the straight skeleton just consist of planar faces. Although there exist several methods to compute the straight skeleton of a polygon, the straight skeleton of polyhedra has been paid much less attention. We require to compute the skeleton of very large datasets storing orthogonal polyhedra. Furthermore, we need to treat geometric degeneracies that usually arise when dealing with orthogonal polyhedra. We present a new approach so as to robustly compute the straight skeleton of orthogonal polyhedra. We follow a geometric technique that works directly with the boundary of an orthogonal polyhedron. Our approach is output sensitive with respect to the number of vertices of the skeleton and solves geometric degeneracies. Unlike the existing straight skeleton algorithms that shrink the object boundary to obtain the skeleton, our algorithm relies on the plane sweep paradigm. The resulting skeleton is only composed of axis‐aligned and 45° rotated planar faces and edges.'],\n",
              " '105_matrix_factorization_nonnegative_matrices': ['Unified Solution to Nonnegative Data Factorization Problems.[SEP]In this paper, we restudy the non-convex data factorization problems (regularized or not, unsupervised or supervised), where the optimization is confined in the nonnegative orthant, and provide a unified convergency provable solution based on multiplicative nonnegative update rules. This solution is general for optimization problems with block-wisely quadratic objective functions, and thus direct update rules can be derived by skipping over the tedious specific procedure deduction process and algorithmic convergence proof. By taking this unified solution as a general template, we i) re-explain several existing nonnegative data factorization algorithms, ii) develop a variant of nonnegative matrix factorization formulation for handling out-of-sample data, and Hi) propose a new nonnegative data factorization algorithm, called correlated co-decomposition (CCD), to simultaneously factorize two feature spaces by exploring the inter-correlated information. Experiments on both face recognition and multi-label image annotation tasks demonstrate the wide applicability of the unified solution as well as the effectiveness of two proposed new algorithms.',\n",
              "  'Multiplicative Algorithms for Constrained Non-negative Matrix Factorization.[SEP]Non-negative matrix factorization (NMF) provides the advantage of parts-based data representation through additive only combinations. It has been widely adopted in areas like item recommending, text mining, data clustering, speech denoising, etc. In this paper, we provide an algorithm that allows the factorization to have linear or approximately linear constraints with respect to each factor. We prove that if the constraint function is linear, algorithms within our multiplicative framework will converge. This theory supports a large variety of equality and inequality constraints, and can facilitate application of NMF to a much larger domain. Taking the recommender system as an example, we demonstrate how a specialized weighted and constrained NMF algorithm can be developed to fit exactly for the problem, and the tests justify that our constraints improve the performance for both weighted and unweighted NMF algorithms under several different metrics. In particular, on the Movie lens data with 94% of items, the Constrained NMF improves recall rate 3% compared to SVD50 and 45% compared to SVD150, which were reported as the best two in the top-N metric.',\n",
              "  'Recovering Low-Rank and Sparse Matrices via Robust Bilateral Factorization.[SEP]Recovering low-rank and sparse matrices from partial, incomplete or corrupted observations is an important problem in many areas of science and engineering. In this paper, we propose a scalable robust bilateral factorization (RBF) method to recover both structured matrices from missing and grossly corrupted data such as robust matrix completion (RMC), or incomplete and grossly corrupted measurements such as compressive principal component pursuit (CPCP). With the unified framework, we first present two robust trace norm regularized bilateral factorization models for RMC and CPCP problems, which can achieve an orthogonal dictionary and a robust data representation, simultaneously. Then, we apply the alternating direction method of multipliers to efficiently solve the RMC problems. Finally, we provide the convergence analysis of our algorithm, and extend it to address general CPCP problems. Experimental results verified both the efficiency and effectiveness of our RBF method compared with the state-of-the-art methods.'],\n",
              " '106_parallel_compiler_cache_parallelism': ['Speculative Execution and Branch Prediction on Parallel Machines.[SEP]Several recent studies on the limits of parallelism have reported that speculative execution can substantially increase the amount of exploitable parallelism in programs, especially non-numerical programs. This is true even for parallel machines models which allow multiple flows of control. However, most architectural techniques for speculation and branch prediction are geared toward conventional computers with a single flow of control, and little has been done in studying speculation models and techniques for parallel machines with multiple threads of control.',\n",
              "  'A Massively Parallel Optimizer for Expression Evaluation.[SEP]A number of “tricks” are known that trade multiplications for additions. The term “tricks” reflects the way these methods seem not to proceed from any general theory, but instead jump into existence as recipes that work. The Strassen method for 2 by 2 matrix product with 7 multiplications is a well-known example, as is the method for finding a complex number product in 3 multiplications. We have created a practical computer program for finding such tricks automatically, where massive parallelism makes the combinatorially explosive search tolerable for small problems. One result of this program is a method for computing cross products of 3-vectors using only 5 multiplications.',\n",
              "  \"Design considerations for parallel performance tools.[SEP]In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.\"],\n",
              " '107_event_events_sentinel_ranking': [\"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization.[SEP]Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.\",\n",
              "  'Life on the Line: Interacting with Temporal Event Sequence Representations.[SEP]Sequences of events are part of people’s life, their travel, hospital visits, even web browsing experiences. Analysing collections of event sequences can be challenging even for skilled computer professionals. We will review a series of visualization techniques developed at the Human-Computer Interaction lab to handle temporal data.',\n",
              "  'Evaluating Alignment Approaches in Superimposed Time-Series and Temporal Event-Sequence Visualizations.[SEP]Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using single-event alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dual-event alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness-71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness-88% vs. 36% for DualStretch- completion time-55 seconds vs. 101 seconds for DualLeft-and error-1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5'],\n",
              " '108_wavelet_wavelets_multiresolution_subdivision': ['Biorthogonal wavelet construction for hybrid quad/triangle meshes.[SEP]Ever since its introduction by Stam and Loop, the quad/triangle subdivision scheme, which is a generalization of the well-known Catmull–Clark subdivision and Loop subdivision, has attracted a great deal of interest due to its flexibility of allowing both quads and triangles in the same model. In this paper, we present a novel biorthogonal wavelet—constructed through the lifting scheme—that accommodates the quad/triangle subdivision. The introduced wavelet smoothly unifies the Catmull–Clark subdivision wavelet (for quadrilateral meshes) and the Loop subdivision wavelet (for triangular meshes) in a single framework. It can be used to flexibly and efficiently process any complicated semi-regular hybrid meshes containing both quadrilateral and triangular regions. Because the analysis and synthesis algorithms of the wavelet are composed of only local lifting operations allowing fully in-place calculations, they can be performed in linear time. The experiments demonstrate sufficient stability and fine fitting quality of the presented wavelet, which are similar to those of the Catmull–Clark subdivision wavelet and the Loop subdivision wavelet. The wavelet analysis can be used in various applications, such as shape approximation, progressive transmission, data compression and multiresolution edit of complex models.',\n",
              "  'Graph-Based Wavelet Representation of Multi-Variate Terrain Data.[SEP]Terrain data can be processed from the double perspective of computer graphics and graph theory. We propose a hybrid method that uses geometrical and vertex attribute information to construct a weighted graph reflecting the variability of the vertex data. As a planar graph, a generic terrain data set is subjected to a geometry‐sensitive vertex partitioning procedure. Through the use of a combined, thin‐plate energy and multi‐dimensional quadric metric error, feature estimation heuristic, we construct ‘even’ and ‘odd’ node subsets. Using an invertible lifting scheme, adapted from generic weighted graphs, detail vectors are extracted and used to recover or filter the node information. The design of the prediction and update filters improves the root mean squared error of the signal over general graph‐based approaches. As a key property of this design, preserving the mean of the graph signal becomes essential for decreasing the error measure and conserving the salient shape features.',\n",
              "  'Multiresolution Analysis on Irregular Surface Meshes.[SEP]Wavelet-based methods have proven their efficiency for visualization at different levels of detail, progressive transmission, and compression of large data sets. The required core of all wavelet-based methods is a hierarchy of meshes that satisfies subdivision-connectivity. This hierarchy has to be the result of a subdivision process starting from a base mesh. Examples include quadtree uniform 2D meshes, octree uniform 3D meshes, or 4-to-1 split triangular meshes. In particular, the necessity of subdivision-connectivity prevents the application of wavelet-based methods on irregular triangular meshes. In this paper, a \"wavelet-like\" decomposition is introduced that works on piecewise constant data sets over irregular triangular surface meshes. The decomposition/reconstruction algorithms are based on an extension of wavelet-theory allowing hierarchical meshes without property. Among others, this approach has the following features: it allows exact reconstruction of the data set, even for nonregular triangulations, and it extends previous results on Haar-wavelets over 4-to-1 split triangulations.'],\n",
              " '109_children_participatory_child_technologies': ['Child-personas: fact or fiction?[SEP]This paper introduces a practice-based, child-centric method of creating child-user archetypes which extends adult-based persona theory to interaction design with children. Persona construction can help interaction designers better understand real child-users and result in rich child-user archetypes which are developmentally situated and contextually valid. Key differences between adult-personas and child-personas are highlighted. A description of an online mentoring application created for CBC4Kids.ca illustrates the value of child-personas in design practice.',\n",
              "  \"Children and 'smart' technologies: can children's experiences be interpreted and coded?[SEP]This paper has a focus on young children and their emerging new technologies. It examines children's drawings as an evaluation tool for capturing their experiences of different novel interfaces.\",\n",
              "  \"Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding.[SEP]In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using these methods, while 4-year-olds were unable to use create solutions in a traditional format. How-ever, these younger children enthusiastically offered opportunities where, with methodological guidance, the research-er could have followed the child's lead and shifted the design question to one that was potentially more meaningful for the participant. We propose a future work to examine the effectiveness of giving these younger participants great-er authority in defining and scoping the problem space.\"],\n",
              " '10_motion_animation_motions_animations': ['Real time animation of dynamic processes.[SEP]Animation and simulation processes are facilitated by the use of high level graphic languages. The results of these processes are not generally available in real time, developing of microfilm delaying the screening of the process until some time after the computer run.A technique is described which overcomes this problem whilst still allowing the use of a high level graphical language.The addition of a single feature to a \"static\" graphical language has transformed it into a \"dynamic\" graphical language allowing real time illustration of time varying processes.The technique is not restricted to the language described but may well be employed by other high level graphical languages.',\n",
              "  'Real time falling animation with active and protective responses.[SEP]Combined with motion capture and dynamic simulation, characters in animation have realistic motion details and can respond to unexpected contact forces. This paper proposes a novel and real-time character motion generation approach which introduces a parallel process, and uses an approximate nearest neighbor optimization search method. Besides, we employ a support vector machine (SVM), which is trained on a set of samples and predicts a subset of our ‘return-to’ motion capture (mocap) database in order to reduce the search time. In the dynamic simulation process, we focus on designing a biomechanics based controller which detects the balance of the characters in locomotion and drives them to take several active and protective responses when they fall to the ground in order to reduce the injuries to their bodies. Finally, we show the time costs in synthesis and the visual results of our approach. The experimental results indicate that our motion generation approach is suitable for interactive games or other real-time applications.',\n",
              "  'A system for algorithm animation.[SEP]A software environment is described which provides facilities at a variety of levels for “animating” algorithms: exposing properties of programs by displaying multiple dynamic views of the program and associated data structures. The system is operational on a network of graphics-based, personal workstations and has been used successfully in several applications for teaching and research in computer science and mathematics. In this paper, we outline the conceptual framework that we have developed for animating algorithms, describe the system that we have implemented, and give several examples drawn from the host of algorithms that we have animated.'],\n",
              " '110_tabletop_collaboration_touch_groupware': [\"Evaluating the effectiveness of height visualizations for improving gestural communication at distributed tabletops.[SEP]In co-located collaboration, people use the space above the table for deictic gestures, and height is an important part of these gestures. However, when collaborators work at distributed tables, we know little about how to convey information about gesture height. A few visualizations have been proposed, but these have not been evaluated in detail. To better understand how remote embodiments can show gesture height, we developed several visualizations and evaluated them in three studies. First, we show that touch visualizations significantly improve people's accuracy in identifying the type and target of a gesture. Second, we show that visualizations of height above the table help to convey gesture qualities such as confidence, emphasis, and specificity. Third, we show that people quickly make use of height visualizations in realistic collaborative tasks, and that height-enhanced embodiments are strongly preferred. Our work illustrates several designs for effective visualization of height, and provides the first comprehensive evidence of the value of height information as a way to improve gestural communication in distributed tabletop groupware.\",\n",
              "  \"Making big gestures: effects of gesture size on observability and identification for co-located group awareness.[SEP]Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.\",\n",
              "  'Exploring the effects of group size and table size on interactions with tabletop shared-display groupware.[SEP]Interactive tabletops have been previously proposed and studied in the domain of co-located group applications. However, little fundamental research has been done to explore the issue of size. In this paper we identify a number of size considerations for tabletop design, and present an experiment to explore some of these issues, in particular the effects of group size and table size on the speed at which the task was performed, the distribution of work among group members, issues of shared resources, and user preference for table size. Our findings shed light on (1) how work strategies are affected by group size, (2) how social interaction varies with respect to table size, and (3) how the speed of task performance is influenced by group size but not by table size. In addition, our experiments revealed that for larger groups, designers might need to add additional vertical displays for shared information. This finding opens the door for extending single-display groupware to shared-display groupware settings that involve multiple, shared displays.'],\n",
              " '111_collision_collisions_deformable_rigid': ['Interactive continuous collision detection for non-convex polyhedra.[SEP]We present a highly interactive, continuous collision detection algorithm for rigid, general polyhedra. Given initial and final configurations of a moving polyhedral model, our algorithm creates a continuous motion with constant translational and angular velocities, thereby interpolating the initial and final configurations of the model. Then, our algorithm reports whether the model under the interpolated motion collides with other rigid polyhedral models in environments, and if it does, the algorithm reports its first time of contact (TOC) with the environment as well as its associated contact features at TOC.',\n",
              "  'A Collision Detection and Response Scheme for Simplified Physically Based Animation.[SEP]In this paper we describe a system for physical animation of rigid and deformable objects. These are represented as groups of particles linked by linear constraints, while a Verlet integrator is used for motion computation. Unlike traditional approaches, we accomplish physical simulation without explicitly computing orientation matrices, torques or inertia tensors. The main contribution of our work is related to the way collisions are handled by the system, which employs different approaches for deformable and rigid bodies. In particular, we show how collision detection using the GJK algorithm [9] and bounding sphere hierarchies can be combined with the projection based collision response technique described by Jakobsen [14].',\n",
              "  'Continuous collision detection for deformable objects using permissible clusters.[SEP]In this paper, we propose a new data structure to perform continuous collision detection (CCD) for deformable triangular meshes. The critical component of this data structure is permissible clusters. At the preprocessing phase, the triangular meshes are divided into permissible clusters. Then, the features of the triangular meshes are assigned to the permissible clusters. At the runtime phase, the potentially colliding feature pairs are collected and they are processed only once in the elementary processing. Our method has been integrated with a normal cone-based method and compared with other CCD methods. Experimental results show that our method improves the overall performance of CCD for deformable objects.'],\n",
              " '112_chatbot_chatbots_chat_conversation': ['Adding structured data in unstructured web chat conversation.[SEP]Web chat is becoming the primary customer contact channel in customer relationship management (CRM), and Question/Answer/Lookup (QAL) is the dominant communication pattern in CRM agent-to-customer chat. Text-based web chat for QAL has two main usability problems. Chat transcripts between agents and customers are not tightly integrated into agent-side applications, requiring customer service agents to re-enter customer typed data. Also, sensitive information posted in chat sessions in plain text raises security concerns. The addition of web form widgets to web chat not only solves both of these problems but also adds new usability benefits to QAL. Forms can be defined beforehand or, more flexibly, dynamically composed. Two preliminary user studies were conducted. An agent-side study showed that adding inline forms to web chat decreased overall QAL completion time by 47 percent and increased QAL accuracy by removing all potential human errors. A customer-side study showed that web chat with inline forms is intuitive to customers.',\n",
              "  \"Transformation through Provocation?[SEP]Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.\",\n",
              "  \"A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot.[SEP]Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.\"],\n",
              " '113_hair_hairs_cloth_hairstyles': ['3D Hair sketching for real-time dynamic  key frame animations.[SEP]Physically based simulation of human hair is a well studied and well known problem. But the “pure” physically based representation of hair (and other animation elements) is not the only concern of the animators, who want to “control” the creation and animation phases of the content. This paper describes a sketch-based tool, with which a user can both create hair models with different styling parameters and produce animations of these created hair models using physically and key frame-based techniques. The model creation and animation production tasks are all performed with direct manipulation techniques in real-time.',\n",
              "  'Hybrid fur rendering: combining volumetric fur with explicit hair strands.[SEP]Hair is typically modeled and rendered using either explicitly defined hair strand geometry or a volume texture of hair densities. Taken each on their own, these two hair representations have difficulties in the case of animal fur as it consists of very dense and thin undercoat hairs in combination with coarse guard hairs. Explicit hair strand geometry is not well-suited for the undercoat hairs, while volume textures are not well-suited for the guard hairs. To efficiently model and render both guard hairs and undercoat hairs, we present a hybrid technique that combines rasterization of explicitly defined guard hairs with ray marching of a prismatic shell volume with dynamic resolution. The latter is the key to practical combination of the two techniques, and it also enables a high degree of detail in the undercoat. We demonstrate that our hybrid technique creates a more detailed and soft fur appearance as compared with renderings that only use explicitly defined hair strands. Finally, our rasterization approach is based on order-independent transparency and renders high-quality fur images in seconds.',\n",
              "  \"Modeling Dynamic Hair as a Continuum.[SEP]In this paper we address the difficult problem of hair dynamics, particularly hair‐hair and hair‐air interactions. To model these interactions, we propose to consider hair volume as a continuum. Subsequently, we treat the interaction dynamics to be fluid dynamics. This proves to be a strong as well as viable approach for an otherwise very complex phenomenon. However, we retain the individual character of hair, which is vital to visually realistic rendering of hair animation. For that, we develop an elaborate model for stiffness and inertial dynamics of individual hair strand. Being a reduced coordinate formulation, the stiffness dynamics is numerically stable and fast. We then unify the continuum interaction dynamics and the individual hair's stiffness dynamics.\"],\n",
              " '114_watermarking_watermark_watermarks_attacks': ['Secure Authentication Watermarking for Binary Images.[SEP]Authentication watermarking is a hidden data inserted into an image, in order to detect any alterations. It seems to be almost impossible to design a really secure authentication watermarking without making use of the solid cryptography theory and techniques. In a cryptography-based authentication watermarking, a message authentication code (or digital signature) of the whole image is computed and the resulting code is inserted into the image itself. However, inserting the code alters the image and consequently its authentication code, invalidating the watermark. To avoid this problem, for gray-scale or color image, usually the least significant bits (LSBs) are cleared, the authentication code of the LSB-cleared image is computed and then the code is inserted into LSBs. Surely, one cannot perform the same procedure for binary images. We propose a quite simple solution for inserting a secure authentication watermarking in dispersed-dot halftone images. This technique can also be applied to any kind of binary images (including clustered-dot halftones), though the visual quality is not as good as when applied to dispersed-dot halftones. The proposed technique can be used with both secret-key or public-key ciphers.',\n",
              "  'A new multi-secret image sharing scheme based on DCT.[SEP]Multi-secret image sharing scheme (MSIS) is a technique to share multiple secret images over the internet. Normally, most of the secret image sharing schemes can share only a single secret image. However, due to the rapid development of internet technology, the necessity of sharing multiple images arises. An (n, n) MSIS is employed to share n images to n authorized participants. All the n participants are required to submit their respective shares to recover the original secret images. If the number of the participants is less than n, then reconstruction of the secret images is impossible. Most of the existing schemes which are in the frequency domain do not have the capability to handle multiple secret images. In this paper, a MSIS that uses the Discrete Cosine Transform is proposed to overcome the limitation present in the existing schemes. Moreover, the proposed scheme requires less computational time than the existing schemes. Security of the proposed scheme is analyzed and shows that the proposed scheme is computationally secure. Also, the proposed scheme can recover the same original secret images.',\n",
              "  'Digital Watermarking: From Concepts to Real-Time Video Applications.[SEP]Digital watermarking has been increasingly applied to hide information in digital multimedia data, thus enlisting the watermarking technology in the difficult fight against intellectual property rights infringement. The authors have developed a secure, robust watermarking algorithm and applied it in digital streaming MPEG-2 format video-the format of choice in the broadcast and video stock industry.'],\n",
              " '115_surgical_surgery_laparoscopic_minimally': ['Keynote Speaker: Virtual Reality: Current Uses in Medical Simulation and Future.[SEP]Virtual reality has gone from research to educational tool to indispensible clinical application in patient care. A brief review of the current status of the use of VR in medicine will provide the springboard for the current gaps that provide future opportunities in simulation as well as an introduction to new advanced technologies that are revolutionizing medicine and which will require VR for educational and training support and clinical applications. Some topics for discussion are virtual patients, cadavers and autopsies, surgical rehearsal, robotic surgery, suspended animation, regeneration and tissue engineering. The challenge: how creatively can VR support these incredible new technologies? The grand challenge ñ how will 3-D stereolithography revolutionize the practice of medicine? Have you bought your Makerbot yet?',\n",
              "  'Evaluation of a tool-mounted guidance display for computer-assisted surgery.[SEP]We attached a small LCD display and video camera to a surgical drill. The LCD shows the tool position with respect to a planned trajectory, overlaid on video captured by the camera. We performed a user study to determine whether such a tool-mounted guidance display yields faster and more accurate tool placement than the conventional guidance display on a separate computer monitor. Our study showed that the tool-mounted display provides better positional and angular accuracy than the conventional display but that the video camera provides no significant improvement in error.',\n",
              "  'Modelling Techniques for Enhanced Realism in an Open Surgery Simulation.[SEP]This paper is a continuation of work originating from the simulation of Inguinal Hernia Repair. Whilst the majority of research in the medical simulation field is for minimally invasive techniques, the objective of our research is to develop a general framework for open surgery simulation. We focus here on the finer details of implementing such a simulator using advanced rendering techniques, collision detection and haptic feedback.'],\n",
              " '116_subspace_clustering_clusters_subspaces': ['Subspace Selection for Clustering High-Dimensional Data.[SEP]In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (subspaces relevant for clustering) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task \"clustering\" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant sub-spaces in high dimensional, sparse data sets and produces better results than comparative methods.',\n",
              "  'Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering.[SEP]A novel approach to subspace clustering is proposed to exhaustively and efficiently mine quantitative frequent item-sets (QFIs) from massive transaction data. For the computational tractability, our approach introduces adaptive density-based and Apriori-like algorithm. Its outstanding performance is shown through numerical experiments.',\n",
              "  \"Effective and Robust Mining of Temporal Subspace Clusters.[SEP]Mining temporal multivariate data by clustering is an important research topic. In today's complex data, interesting patterns are often neither bound to the whole dimensional nor temporal extent of the data domain. This challenge is met by temporal subspace clustering methods. Their effectiveness, however, is impeded by aspects unavoidable in real world data: Misalignments between time series, for example caused by out-of-sync sensors, and measurement errors. Under these conditions, existing temporal subspace clustering approaches miss the patterns contained in the data. In this paper, we propose a novel clustering method that mines temporal subspace clusters reflected by sets of objects and relevant intervals. We enable flexible handling of misaligned time series by adaptively shifting time series in the time domain, and we achieve robustness to measurement errors by allowing certain fractions of deviating values in each relevant point in time. We show the effectiveness of our method in experiments on real and synthetic data.\"],\n",
              " '117_location_recommendation_friends_locations': [\"Towards social user profiling: unified and discriminative influence model for inferring home locations.[SEP]Users' locations are important to many applications such as targeted advertisement and news recommendation. In this paper, we focus on the problem of profiling users' home locations in the context of social network (Twitter). The problem is nontrivial, because signals, which may help to identify a user's location, are scarce and noisy. We propose a unified discriminative influence model, named as UDI, to solve the problem. To overcome the challenge of scarce signals, UDI integrates signals observed from both social network (friends) and user-centric data (tweets) in a unified probabilistic framework. To overcome the challenge of noisy signals, UDI captures how likely a user connects to a signal with respect to 1) the distance between the user and the signal, and 2) the influence scope of the signal. Based on the model, we develop local and global location prediction methods. The experiments on a large scale data set show that our methods improve the state-of-the-art methods by 13%, and achieve the best performance.\",\n",
              "  'Geo-activity recommendations by using improved feature combination.[SEP]In this paper, we propose a new model to integrate additional data, which is obtained from geospatial resources other than original data set in order to improve Location/Activity recommendations. The data set that is used in this work is a GPS trajectory of some users, which is gathered over 2 years. In order to have more accurate predictions and recommendations, we present a model that injects additional information to the main data set and we aim to apply a mathematical method on the merged data. On the merged data set, singular value decomposition technique is applied to extract latent relations. Several tests have been conducted, and the results of our proposed method are compared with a similar work for the same data set.',\n",
              "  \"Followee recommendation in asymmetrical location-based social networks.[SEP]Researches on recommending followees in social networks have attracted a lot of attentions in recent years. Existing studies on this topic mostly treat this kind of recommendation as just a type of friend recommendation. However, apart from making friends, the reason of a user to follow someone in social networks is inherently to satisfy his/her information needs in asymmetrical manner. In this paper, we propose a novel mining-based recommendation approach named Geographic-Textual-Social Based Followee Recommendation (GTS-FR), which takes into account the user movements, online texting and social properties to discover the relationship between users' information needs and provided information for followee recommendation. The core idea of our proposal is to discover users' similarity in terms of all the three properties of information which are provided by the users in a Location-Based Social Network (LBSN). To achieve this goal, we define three kinds of features to capture the key properties of users' interestingness from their provided information. In GTS-FR approach, we propose a series of novel similarity measurements to calculate similarity of each pair of users based on various properties. Based on the similarity, we make on-line recommendation for the followee a user might be interested in following. To our best knowledge, this is the first work on followee recommendation in LBSNs by exploring the geographic, textual and social properties simultaneously. Through a comprehensive evaluation using a real LBSN dataset, we show that the proposed GTS-FR approach delivers excellent performance and outperforms existing stat-of-the-art friend recommendation methods significantly.\"],\n",
              " '118_parents_parenting_child_life': ['Dealing with death in design: developing systems for the bereaved.[SEP]Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world, and materiality. We conclude with a distillation of these considerations into practical design guidelines for working in this area.',\n",
              "  \"Looking for Respite and Support: Technological Opportunities for Spousal Caregivers.[SEP]Our research aims at informing the design of technological solutions to alleviate the stress resulting from the involvement of spouses of Alzheimer's disease patients as caregivers. For so doing, we have observed and analyzed the different offline solutions that are offered by a healthcare network in the Aube region (North-East of France). We discuss the key factors that we have identified for building an effective support network and identify five perspectives for the development of an online social support platform to lower the burden of spousal caregivers.\",\n",
              "  \"Understanding technology choices and values through social class.[SEP]This ethnographic study of 22 diverse families in the San Francisco Bay Area provides a holistic account of parents' attitudes about their children's use of technology. We found that parents from different socioeconomic classes have different values and practices around technology use, and that those values and practices reflect structural differences in their everyday lives. Calling attention to class differences in technology use challenges the prevailing practice in human-computer interaction of designing for those similar to oneself, which often privileges middle-class values and practices. By discussing the differences between these two groups and the advantages of researching both, this research highlights the benefits of explicitly engaging with socioeconomic status as a category of analysis in design.\"],\n",
              " '119_location_privacy_crowdsensing_obfuscation': [\"Differential Location Privacy for Sparse Mobile Crowdsensing.[SEP]Sparse Mobile Crowdsensing (MCS) has become a compelling approach to acquire and make inference on urban-scale sensing data. However, participants risk their location privacy when reporting data with their actual sensing positions. To address this issue, we adopt e-differential-privacy in Sparse MCS to provide a theoretical guarantee for participants' location privacy regardless of an adversary's prior knowledge. Furthermore, to reduce the data quality loss caused by differential location obfuscation, we propose a privacypreserving framework with three components. First, we learn a data adjustment function to fit the original sensing data to the obfuscated location. Second, we apply a linear program to select an optimal location obfuscation function, which aims to minimize the uncertainty in data adjustment. We also propose a fast approximated variant. Third, we propose an uncertaintyaware inference algorithm to improve the inference accuracy of obfuscated data. Evaluations with real environment and traffic datasets show that our optimal method reduces the data quality loss by up to 42% compared to existing differential privacy methods.\",\n",
              "  'Secure and private proofs for location-based activity summaries in urban areas.[SEP]Activity-based social networks, where people upload and share information about their location-based activities (e.g., the routes of their activities), are increasingly popular. Such systems, however, raise privacy and security issues: The service providers know the exact locations of their users; the users can report fake location information in order to, for example, unduly brag about their performance. In this paper, we propose a secure privacy-preserving system for reporting location-based activity summaries (e.g., the total distance covered and the elevation gain). Our solution is based on a combination of cryptographic techniques and geometric algorithms, and it relies on existing Wi-Fi access-point networks deployed in urban areas. We evaluate our solution by using real data sets from the FON community networks and from the Garmin Connect activity-based social network, and we show that it can achieve tight (up to a median accuracy of 76%) verifiable lower-bounds of the distance covered and of the elevation gain, while protecting the location privacy of the users with respect to both the social network operator and the access-point network operator(s).',\n",
              "  'Active Sparse Mobile Crowd Sensing Based on Matrix Completion.[SEP]A major factor that prevents the large scale deployment of Mobile Crowd Sensing (MCS) is its sensing and communication cost. Given the spatio-temporal correlation among the environment monitoring data, matrix completion (MC) can be exploited to only monitor a small part of locations and time, and infer the remaining data. Rather than only taking random measurements following the basic MC theory, to further reduce the cost of MCS while ensuring the quality of missing data inference, we propose an Active Sparse MCS (AS-MCS) scheme which includes a bipartite-graph-based sensing scheduling scheme to actively determine the sampling positions in each upcoming time slot, and a bipartite-graph-based matrix completion algorithm to robustly and accurately recover the un-sampled data in the presence of sensing and communications errors. We also incorporate the sensing cost into the bipartite-graph to facilitate low cost sample selection and consider the incentives for MCS. We have conducted extensive performance studies using the data sets from the monitoring of PM 2.5 air condition and road traffic speed, respectively. Our results demonstrate that our AS-MCS scheme can recover the missing data at very high accuracy with the sampling ratio only around $11%$, while the peer matrix completion algorithms with similar recovery performance requires up to 4-9 times the number of samples of ours for both the data sets.'],\n",
              " '11_music_musical_voice_sound': ['Dogmas of Understanding in Western Art Music Performance.[SEP]This paper presents an exploration of the ontological shift from musical materials (i.e. melody, harmony, rhythm, texture, timbre, register) to activities in music performance analysis. The “dogmas” extend Herbert H. Clark’s conceptual framework for the study of joint activity in language use to explore music performance in the WAM tradition. A systematic analysis of London Symphony Orchestra masterclasses examines the basic mechanisms of music making in four main areas: representation, audience, interaction, and tacit knowledge. This exploration leads to a broader account of cognition and creativity in music performance, one that bridges inner and outer processes of awareness around domains of coordination in joint activities. In this view, material conceptualizations are viewed as targets of focal awareness rather than the basis for cognition in music making. This account, grounded in a rich third-person phenomenological analysis of instructional materials, paves the way for a “meaningful analytics” of musical practice.',\n",
              "  'Visualizing the Semantic Structure in Classical Music Works.[SEP]A major obstacle in the appreciation of classical music is that extensive training is required to understand musical structure and compositional techniques toward comprehending the thoughts behind the musical work. In this paper, we propose an innovative visualization solution to reveal the semantic structure in classical orchestral works such that users can gain insights into musical structure and appreciate the beauty of music. We formulate the semantic structure into macrolevel layer interactions, microlevel theme variations, and macro-micro relationships between themes and layers to abstract the complicated construction of a musical composition. The visualization has been applied with success in understanding some classical music works as supported by highly promising user study results with the general audience and very positive feedback from music students and experts, demonstrating its effectiveness in conveying the sophistication and beauty of classical music to novice users with informative and intuitive displays.',\n",
              "  'Entrain: Encouraging Social Interaction in Collective Music Making.[SEP]Entrain is an adaptive agent designed to stimulate social interaction among users in collective music making. It registers individual user behavior and provides sonic feedback to encourage users to look up from their mobiles and interact with each other. We demonstrate a use case of Entrain in Coloop, a distributed and collective musical instrument.',\n",
              "  'Short-term memory for tonal and verbal information: Comparison with absolute and non-absolute pitch possessors.[SEP]This study examined the difference in the storage of pitch and phonological information in absolute pitch (AP) and non-AP (NAP) possessors. In a recognition task using musical tones (pitch information), speech sounds (phonological information), and visual patterns, participants were asked to retain two stimulus sequences. In the same type condition, the nature of the first and second stimulus set was different (e.g., one sequence was musical tones and the other was speech sounds). In the different type condition, the nature of the two sequences was the same (e.g., both sequences were musical tones). We found that, in NAP possessors, the recognition rate of musical tones and speech sounds in the different type condition was higher than in the same type condition. In AP possessors, however, the recognition rate of musical tones revealed no difference between these two conditions. These results suggest the use of different strategy in retaining musical tones between AP and NAP possessors.',\n",
              "  'What We Move to Moves Us: Biological Rhythmicity Predicts Musical Preferences.[SEP]For at least 350 centuries, humans have invented music that offered special aesthetic appeal. Yet, the reasons for these preferences and effects are not understood. Here, we show that listeners prefer music with an underlying rhythmic structure that closely approximates our biological structure. Specifically, listeners preferred music with musical (rhythmic) structures that correspond to biological rhythmicity (motions). This finding, grounded in a straightforward biological framework, provided an intellectual advancement in the long history of thought and experimental work on the basis of musical preferences.',\n",
              "  'Embodying Theoretical Research in Music Cognition: Four Proposals for Theory-Driven Experimentation.[SEP]Research in the field of music cognition typically focuses either on low-level, technically oriented approaches or on highly abstract ontological discussions that lack direct grounding in evidence. To bridge this gap, we propose a revision of the ontology underlying such research, from a perspective restricted to the acoustic and individual aspects of music to an embodied, extended, and anti-individualist approach. We explore the application of these ideas to empirical research by discussing two experiments conducted by our group. One of them tests whether the ability to play an instrument has an influence in how a subject listens to music; the other one explores the impact of visual information in the perception of sound as music. We comment on the results obtained and its theoretical significance. Our work shows that it is possible for abstract theorizing and concrete experimentation to go hand in hand in the field of music studies.',\n",
              "  \"Using language complexity to measure cognitive load for adaptive interaction design.[SEP]An adaptive interaction system, which is aware of the users' current cognitive load, can change its response, presentation and interaction flow to improve users' experience and their task performance. In this paper, we propose a novel speech content analysis approach for measuring users' cognitive load, based on their language and dialogue complexity. We have analysed the transcribed speech of operators working in computerized incident control rooms and involved in highly complex bushfire management tasks in Australia. The resulting patterns of language complexity show significant differences between the speech from cognitively low load and high load tasks. We also discuss the value of using this approach of cognitive load measurement for user interface evaluation and interaction design improvement.\",\n",
              "  'The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives.[SEP]The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives.',\n",
              "  'Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition System.[SEP]A study was conducted to evaluate user performance and satisfaction in completion of a set of text creation tasks using three commercially available continuous speech recognition systems. The study also compared user performance on similar tasks using keyboard input. One part of the study (Initial Use) involved 24 users who enrolled, received training and carried out practice tasks, and then completed a set of transcription and composition tasks in a single session. In a parallel effort (Extended Use), four researchers used speech recognition to carry out real work tasks over 10 sessions with each of the three speech recognition software products. This paper presents results from the Initial Use phase of the study along with some preliminary results from the Extended Use phase. We present details of the kinds of usability and system design problems likely in current systems and several common patterns of error correction that we found.',\n",
              "  \"Aural Proxies and Directionally-Varying Reverberation for Interactive Sound Propagation in Virtual Environments.[SEP]We present an efficient algorithm to compute spatially-varying, direction-dependent artificial reverberation and reflection filters in large dynamic scenes for interactive sound propagation in virtual environments and video games. Our approach performs Monte Carlo integration of local visibility and depth functions to compute directionally-varying reverberation effects. The algorithm also uses a dynamically-generated rectangular aural proxy to efficiently model 2-4 orders of early reflections. These two techniques are combined to generate reflection and reverberation filters which vary with the direction of incidence at the listener. This combination leads to better sound source localization and immersion. The overall algorithm is efficient, easy to implement, and can handle moving sound sources, listeners, and dynamic scenes, with minimal storage overhead. We have integrated our approach with the audio rendering pipeline in Valve's Source game engine, and use it to generate realistic directional sound propagation effects in indoor and outdoor scenes in real-time. We demonstrate, through quantitative comparisons as well as evaluations, that our approach leads to enhanced, immersive multi-modal interaction.\",\n",
              "  'Efficient and Accurate Sound Propagation Using Adaptive Rectangular Decomposition.[SEP]Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design (Monks et al., 2000). Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the wave equation in rectangular domains, and utilizes an efficient implementation of the discrete cosine transform on graphics processors (GPU) to achieve at least a 100-fold performance gain compared to a standard finite-difference time-domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.',\n",
              "  \"Source and Listener Directivity for Interactive Wave-Based Sound Propagation.[SEP]We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source. At runtime, we perform the SH decomposition of the varying source directivity interactively and compute the total sound field at the listener position as a weighted sum of precomputed SH sound fields. We propose a novel plane-wave decomposition approach based on higher-order derivatives of the sound field that enables dynamic HRTF-based listener directivity at runtime. We provide a generic framework to incorporate our source and listener directivity in any offline or online frequency-domain wave-based sound propagation algorithm. We have integrated our sound propagation system in Valve's Source game engine and use it to demonstrate realistic acoustic effects such as sound amplification, diffraction low-passing, scattering, localization, externalization, and spatial sound, generated by wave-based propagation of directional sources and listener in complex scenarios. We also present results from our preliminary user study.\"],\n",
              " '120_dance_dancers_dancer_choreographers': ['Physical Skill and Idea Interaction in the Creation of New Dance Movements.[SEP]It has been suggested that in creative activities, cognition and physical action are related to each other. This study focuses on this relationship in breakdance, which is a creative activity of artistic and acrobatic movements. For four months, we conducted field observations of practice sessions of three expert breakdancers, and held interviews with them to investigate the creation process of new and original movements. The video records of the 34 practices and the interview data were analyzed with respect to two aspects: 1) Whether or not the dancers performed important movements appropriately; and 2) What the dancers were thinking when generating new aspects of the movements. The results show an interactive process between the development of dance movements and the generation of ideas. The dancers gradually became able to perform the movements appropriately by generating new ideas, and they generated new ideas using the somatic sensation of the new movements.',\n",
              "  \"Dance Movement: A Focus on the Technology.[SEP]Dance notation systems, like music notes, enable documentation of symbolic representations of movement as signs on paper for individual analysis and interpretation. Today, dance notation systems operate within a digital environment in dance notation applications that facilitate the process of recording movement. The author argues that a key objective in the development of these applications should be to provide the user with an unambiguous method to record and represent movement. These applications offer varying functionality in their use of technology for the representation of movement and can be broadly defined in three different categories. Dance notation applications make up the first category - they help notate or record specific forms of movement using dance notation. Notation-based applications, the second category, include applications that use dance notation as a basis for their development. The last category, dance technology, consists of applications that use emerging technologies to record and visualize movement. While each application has a defined use, it's important to consider how effective the technologies they employ are in successfully achieving their objectives. In this article, the author focuses on dance applications in these three categories. The author considers the limitations of existing technologies in their ability to effectively describe and record movement within a specific context.\",\n",
              "  'Designing Expressions of Movement Qualities.[SEP]Tango is a form of partner dancing in which two bodies sense one another, and move accordingly, in a dynamic, physical dialogue that is known for its subtle complexities, beauty and intimate experience. In MoCap Tango, we explore how we can build on our skills as designers to highlight and unravel these embedded qualities and use them as inspiration in designing interactions. In this pictorial, we invite the reader to actively participate in the designerly engagement that turns objective data into subjective expressions; highlighting the qualities embedded in the movements of professional dancers.'],\n",
              " '121_line_clipping_algorithms_polygon': ['Anti-Aliased Lines Using Run-Masks.[SEP]In recent work, a set of line digitization algorithms based on the hierarchy of runs in the digital line has unified and generalized the iterative line‐drawing algorithms used in computer graphics. In this paper, the additional structural information generated by these algorithms is leveraged to describe a run‐based approach to draw anti‐aliased line segments in which anti‐aliased run‐masks are substituted for the individual run lengths as the line is being drawn. The run‐masks are precomputed using a prefiltering technique such that one or more run‐masks are defined for each of the one or two possible run lengths that occur in the line. The run‐masks can be defined for any order or level of the hierarchy of runs in the digital line and the technique is illustrated using runs of pixels. Comparing the use of run‐masks to applying the prefiltering technique for each pixel in the line, a line of similar visual quality can be produced more efficiently. We place no restrictions on the placement of the end points of the line, which may reside anywhere on the two‐dimensional plane.',\n",
              "  'A new approach to line and line segment clipping in homogeneous coordinates.[SEP]The clipping operation is still the bottleneck of the graphics pipeline in spite of the latest developments in graphical hardware and a significant increase in performance. Algorithms for line and line segment clipping have been studied for a long time and many research papers have been published so far. This paper presents a new robust approach to line and line segment clipping using a rectangular window. A simple extension for the case of convex polygon clipping is presented as well.',\n",
              "  'A New Two Dimensional Line Clipping Algorithm for Small Windows.[SEP]A new algorithm for clipping lines against rectangular windows is described. It is suitable for computations in both object space (floating point arithmetic) and image space (integer arithmetic). The algorithm is compared with other object and image space algorithms and shown to be superior for small windows.'],\n",
              " '122_occlusion_culling_rendering_occluded': ['Towards Adaptive Occlusion Culling Using Camera Coherence.[SEP]Occlusion culling proves to be useful for the interactive visualization of environments that are not densely occluded. Those which are built up by dense geometric sets like aerospace engines composed of thousands of components and millions of polygons. In first place the convenience of using occlusion culling is studied with a simple scheme. Then improvements are analyzed. The key points to obtain frame rate speed-ups are: a convenient occlusion query scheduling provides the performance required; depth sorting is performed only when camera orientation changes more than a given threshold; coherence reduces the number of occlusion queries posted per frame. It is possible to select the percentage of occlusion queries that will be performed in each frame, from non-conservative schemes up to a conservative one. Furthermore, we propose a small addition to the GPU occlusion queries to perform faster renderings',\n",
              "  'Bent Normals and Cones in Screen-space.[SEP]Ambient occlusion (AO) is a popular technique for real-time as well as offline rendering. One of its benefits is a gain in efficiency due to the fact that occlusion and shading are decoupled which results in an average occlusion that modulates the surface shading. Its main drawback is a loss of realism due to the lack of directional occlusion and lighting. As a solution, the use of bent normals was proposed for offline rendering. This work describes how to compute bent normals and bent cones in combination with screen-space ambient occlusion. These extensions combine the speed and simplicity of AO with physically more plausible lighting.',\n",
              "  'Integrating Occlusion Culling with Levels of Detail through Hardly-Visible Sets.[SEP]Occlusion culling and level‐of‐detail rendering have become two powerful tools for accelerating the handling of very large models in real‐time visualization applications. We present a framework that combines both techniques to improve rendering times. Classical occlusion culling algorithms compute potentially visible sets (PVS), which are supersets of the sets of visible polygons. The novelty of our approach is to estimate the degree of visibility of each object of the PVS using synthesized coarse occluders. This allows to arrange the objects of each PVS into several Hardly‐Visible Sets (HVS) with similar occlusion degree. According to image accuracy and frame rate requirements, HVS provide a way to avoid sending to the graphics pipeline those objects whose pixel contribution is low due to partial occlusion. The image error can be bounded by the user at navigation time. On the other hand, as HVS offer a tighter estimation of the pixel contribution for each scene object, it can be used for a more convenient selection of the level‐of‐detail at which objects are rendered. In this paper, we describe the new framework technique, provide details of its implementation using a visibility octree as the chosen occlusion culling data structure and show some experimental results on the image quality.'],\n",
              " '123_multimodal_modality_modalities_speech': ['Usability of user interfaces: from monomodal to multimodal.[SEP]This workshop is aimed at reviewing and comparing existing Usability Evaluation Methods (UEMs) which are applicable to monomodal and multimodal applications, whether they are web-oriented or not. It addresses the problem on how to assess the usability of monomodal user interfaces according to techniques involving one or several modalities, in parallel or combined. In particular, how to synchronize results provided by different UEMs producing various types of results (e.g., audio, video, text, log files) is concerned. It also addresses the problem on how to assess the usability of multimodal user interfaces according to techniques based on multiple modalities. In particular, the question of generalizing the applicability of existing UEMs to these new types of user interfaces is concerned.',\n",
              "  'Multimodal Interaction within Ambient Environments: An Exploratory Study.[SEP]Inputs and outputs are not two independent phenomena in multimodal systems. This paper examines the relationship that exists between them. We present the results of a Wizard of Oz experiment which shows that output modalities used by the system have an influence on the users’ input modalities for a large category of users. The experiment took place in a smart room. This kind of environment does not require any particular knowledge about computers and their use and thus allowed us to study the behavior of ordinary people including subjects who are not familiar with computers. The experiment also shows that speech is a favorite modality within smart room environments for a large part of users. We think that the results presented in this paper will be useful for the design of intelligent multimodal systems.',\n",
              "  \"Designing socially acceptable multimodal interaction in cooking assistants.[SEP]Cooking assistant is an application that needs to find a trade-off between providing efficient help to the users (e.g., reminding them to stir a meal if it is about to burn) and avoiding users' annoyance. This trade-off may vary in different contexts, such as cooking alone or in a group, cooking new or known recipe etc. The results of the user study, presented in this paper, show which features of a multimodal interface users perceive as socially acceptable or unacceptable in different situations, and how this perception depends on user's age.\"],\n",
              " '124_religious_dreaming_religion_cultural': ['Immunity to error through misidentification and non-attributive self-reference.[SEP]Recent empirical literature (Jeannerod & Pacherie, 2004; Mizumoto & Ishikawa, 2005) purports to challenge the thesis that certain forms of self-awareness are immune to errors of misidentification with respect to the first-person (IEM). I argue, first, that these studies do not present a challenge to the IEM thesis, and furthermore that IEM is indicative of a fundamental distinction between two ways of being self-aware—a distinction that has real consequences for empirical studies of self-awareness. In the final section of the paper I suggest that the non-attributive self-reference (NSR) thesis better explains what is special about the distinction than IEM does by itself.',\n",
              "  'Predicting How People Feel: Ownership Matters for Preschoolers.[SEP]Ownership is central in our thinking about other people and objects. We consider ownership when deciding whether we are permitted to use an object and when predicting how owners would feel if their property was lost or broken. Recognizing and understanding ownership is not just evident in adults. Even young children appreciate ownership and its consequences. In this experiment, we show that children aged three years (N = 40) predict that an individual would be sadder when her property went missing than when someone else’s property went missing. These findings show that young children have a rich appreciation of ownership, and grasp relations between ownership and psychological states.',\n",
              "  'New Developments in the Cognitive Science of Religion. Hosted by the International Association for the Cognitive Science of Religion (IACSR).[SEP]The International Association for the Cognitive Science of Religion (IACSR) seeks to advance the naturalistic study of religion. The IACSR recognizes that the cognitive sciences encompass a wide array of disciplines and methods, including, among others, experimental research in psychology and neuroscience, computational modeling, ethnographic, historical, archaeological, and comparative studies of religious cognition, and the survey techniques of the social sciences. The main goal of the workshop is to introduce CSS members to topics that are cutting edge in the cognitive science of religion. Religion is obviously of global significance, and its study requires explanations from a variety of perspectives that involve broader issues relevant to cognitive science.'],\n",
              " '125_spreadsheet_spreadsheets_web_programming': ['Visualization Exploration and Encapsulation via a Spreadsheet-Like Interface.[SEP]Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains.',\n",
              "  'Anti-Freeze for Large and Complex Spreadsheets: Asynchronous Formula Computation.[SEP]Spreadsheet systems enable users to store and analyze data in an intuitive and flexible interface. Yet the scale of data being analyzed often leads to spreadsheets hanging and freezing on small changes. We propose a new asynchronous formula computation framework: instead of freezing the interface we return control to users quickly to ensure interactivity, while computing the formulae in the background. To ensure consistency, we indicate formulae being computed in the background via visual cues on the spreadsheet. Our asynchronous computation framework introduces two novel challenges: (a) How do we identify dependencies for a given change in a bounded time? (b) How do we schedule computation to maximize the number of spreadsheet cells available to the user over time? We bound the dependency identification time by compressing the formula dependency graph lossily, a problem we show to be NP-Hard. A compressed dependency table enables us to quickly identify the spreadsheet cells that need recomputation and indicate them as such to users. Finding an optimal computation schedule to maximize cell availability is also NP-Hard, and even merely obtaining a schedule can be expensive-we propose an on-the-fly scheduling technique to address this. We have incorporated asynchronous computation in DataSpread, a scalable spreadsheet system targeted at operating on arbitrarily large datasets on a spreadsheet frontend.',\n",
              "  'Graphical Definitions: Expanding Spreadsheet Languages Through Direct Manipulation and Gestures.[SEP]In the past, attempts to extend the spreadsheet paradigm to support graphical objects, such as colored circles or user-defined graphical types, have led to approaches featuring either a direct way of creating objects graphically or strong compatibility with the spreadsheet paradigm, but not both. This inability to conveniently go beyond numbers and strings without straying outside the spreadsheet paradigm has been a limiting factor in the applicability of spreadsheet languages. In this article we present graphical definitions, an approach that removes this limitation, allowing both simple and complex graphical objects to be programmed directly using direct manipulation and gestures, in a manner that fits seamlessly within the spreadsheet paradigm. We also describe an empirical study, in which subjects programmed such objects faster and with fewer errors using this approach than when using a traditional approach to formula specification. Because the approach is expressive enough to be used with both built-in and user-defined types, it allows the directness of demonstrational and spreadsheet techniques to be used in programming a wider range of applications than has been possible before.'],\n",
              " '126_cleaning_repairing_repair_tuples': ['Tracing data errors with view-conditioned causality.[SEP]A surprising query result is often an indication of errors in the query or the underlying data. Recent work suggests using causal reasoning to find explanations for the surprising result. In practice, however, one often has multiple queries and/or multiple answers, some of which may be considered correct and others unexpected. In this paper, we focus on determining the causes of a set of unexpected results, possibly conditioned on some prior knowledge of the correctness of another set of results. We call this problem View-Conditioned Causality. We adapt the definitions of causality and responsibility for the case of multiple answers/views and provide a non-trivial algorithm that reduces the problem of finding causes and their responsibility to a satisfiability problem that can be solved with existing tools. We evaluate both the accuracy and effectiveness of our approach on a real dataset of user-generated mobile device tracking data, and demonstrate that it can identify causes of error more effectively than static Boolean influence and alternative notions of causality.',\n",
              "  \"Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes.[SEP]Various computational procedures or constraint-based methods for data repairing have been proposed over the last decades to identify errors and, when possible, correct them. However, these approaches have several limitations including the scalability and quality of the values to be used in replacement of the errors. In this paper, we propose a new data repairing approach that is based on maximizing the likelihood of replacement data given the data distribution, which can be modeled using statistical machine learning techniques. This is a novel approach combining machine learning and likelihood methods for cleaning dirty databases by value modification. We develop a quality measure of the repairing updates based on the likelihood benefit and the amount of changes applied to the database. We propose SCARE (SCalable Automatic REpairing), a systematic scalable framework that follows our approach. SCARE relies on a robust mechanism for horizontal data partitioning and a combination of machine learning techniques to predict the set of possible updates. Due to data partitioning, several updates can be predicted for a single record based on local views on each data partition. Therefore, we propose a mechanism to combine the local predictions and obtain accurate final predictions. Finally, we experimentally demonstrate the effectiveness, efficiency, and scalability of our approach on real-world datasets in comparison to recent data cleaning approaches.\",\n",
              "  'A Perspective on Databases and Data Mining.[SEP]We discuss the use of database methods for data mining. Recently impressive results have been achieved for some data mining problems using highly specialized and clever data structures. We study how well one can manage by using general purpose database management systems. We illustrate our ideas by investigating the use of a dbms for a well-researched area: the discovery of association rules. We present a simple algorithm, consisting of only union and intersection operations, and show that it achieves quite good performance on an efficient dbms. Our method can incorporate inheritance hierarchies to the association rule algorithm easily. We also present a technique that effectively reduces the number of database operations when searching large search spaces that contain only few interesting items. Our work shows that database techniques are promising for data mining: general architectures can achieve reasonable results.'],\n",
              " '127_polygons_polygon_hull_algorithm': ['The Implementation of a 2D Convex Hull Algorithm Using Perturbation.[SEP]This paper discusses the problem of geometric degeneracies and outlines possible solutions when converting geometric algorithms into practice. It concentrates on the application of one of the suggested solutions, a perturbation technique, to a 2D convex hull program. An outline of the relevant theory and its conversion into practice is given. Experimental results are presented and discussed.',\n",
              "  'On Compatible Star Decompositions of Simple Polygons.[SEP]The authors introduce the notion of compatible star decompositions of simple polygons. In general, given two polygons with a correspondence between their vertices, two polygonal decompositions of the two polygons are said to be compatible if there exists a one-to-one mapping between them such that the corresponding pieces are defined by corresponding vertices. For compatible star decompositions, they also require correspondence between star points of the star pieces. Compatible star decompositions have applications in computer animation and shape representation and analysis. They present two algorithms for constructing compatible star decompositions of two simple polygons. The first algorithm is optimal in the number of pieces in the decomposition, providing that such a decomposition exists without adding Steiner vertices. The second algorithm constructs compatible star decompositions with Steiner vertices, which are not minimal in the number of pieces but are asymptotically worst-case optimal in this number and in the number of added Steiner vertices. They prove that some pairs of polygons require /spl Omega/(n/sup 2/) pieces, and that the decompositions computed by the second algorithm possess no more than O(n/sup 2/) pieces. In addition to the contributions regarding compatible star decompositions, the paper also corrects an error in the only previously published polynomial algorithm for constructing a minimal star decomposition of a simple polygon, an error which might lead to a nonminimal decomposition.',\n",
              "  'Reducing the Number of Points on the Convex Hull Calculation Using the Polar Space Subdivision in E2.[SEP]A convex hull of points in E 2 is used in many applications. In spite of low computational complexity O(h logn) it takes considerable time if large data processing is needed. We present a new algorithm to speed up any planar convex hull calculation. It is based on a polar space subdivision and speed up known convex hull algorithms of 3,7 times and more. The algorithm estimates the central point using 10% of the data, this point is taken as the origin for the polar subdivision. The space subdivision enables a fast and very efficient reduction of the given points, which cannot contribute to the final convex hull. The proposed algorithm iteratively approximates the convex hull, leaving only a small number of points for the final processing, which is performed using a \"standard\" algorithm. Non-eliminated points are then processed by a selected standard convex hull algorithm. The algorithm is simple and easy to implement. Experiments proved numerical robustness as well.'],\n",
              " '128_spatial_languages_across_meaning': ['Both symbolic and embodied representations contribute to spatial language processing; Evidence from younger and older adults.[SEP]Building on earlier neuropsychological work, we adopted a novel individual differences approach to examine the relationship between spatial language and a wide range of both verbal and nonverbal abilities. Three new measures were developed for the assessment of spatial language processing: spatial naming, spatial verbal memory, and verbal comprehension in spatial perspective taking. Results from a sample of young adults revealed significant correlations between performance on the spatial language tasks and performance on both the analogous (non-spatial) verbal measures as well as on the (non-verbal) visual-spatial measures. Visual-spatial abilities, however, were more predictive of spatial language processing than verbal abilities. Furthermore, results from a sample of older adults revealed impairments in visual-spatial tasks and on spatial verbal memory. The results support dual process accounts of meaning, and provide further evidence of the close connection between the language of space and non-linguistic visual-spatial cognition.',\n",
              "  '\"Natural concepts\" revisited in the spatial-topological domain: Universal tendencies in focal spatial relations.[SEP]It has long been noted that the best examples, or foci, of color categories tend to align across diverse languages (Berlin & Kay, 1969)--but there is limited documentation of such universal foci in other semantic domains. Here, we explore whether spatial topological categories, such as \"in\" and \"on\" in English, have focal members comparable to those in color. We document names and best examples of topological spatial relations in Dutch, English, French, Japanese, Korean, Mandarin Chinese, and Spanish, and find substantial consensus, both within and across languages, on the best examples of such spatial categories. Our results provide empirical evidence for focal best examples in the spatial domain and contribute further support for a theory of \"natural concepts\" in this domain.',\n",
              "  'Spatial language and visual attention: A new approach to test linguistic relativity.[SEP]It is debated how far-reaching effects of language on cognition are - if they exist at all. Using a visual search paradigm, we tested whether native Korean and German speakers are differentially sensitive to visual 3D-object composites that only the Korean, but not the German (nor the English), language semantically distinguishes as tight- versus loose-fit. We instructed our participants to search for a colour-defined target composite among distractors. However, targets were also implicitly signalled by their tight- or loose-fit composites. Only Korean speakers picked up on this implicit target-defining characteristic, reflected in attention capture by target-similar composites. As these concepts are not grammticalised in the German language, our results demonstrate that language can determine which visual features capture attention. Our research introduces a novel approach because processing of the linguistically discriminated visual characteristics was neither instructed nor necessary for the task, demonstrating a case of linguistic relativity of cognition.'],\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner': ['Addressing Mobile Phone Diversity in Ubicomp Experience Development.[SEP]Mobile phones are a widely-available class of device with supporting communications infrastructure which can be appropriated and exploited to support ubicomp experiences. However mobile phones vary hugely in their capabilities. We explore how a single dimension of phone application type embodies the critical trade-off between capability and availability, i.e. between what can be done and the fraction of potential participants’ phones that can do this. We describe four different mobile phone ubicomp experiences that illustrate different points along this continuum (SMS, WAP/Web, and J2ME, Python and native applications) and the common software platform/toolkit, EQUIP2, that has been co-developed to support them. From this we propose four development strategies for addressing mobile phone diversity: prioritise support for server development (including web integration), migrate functionality between server(s) and handset(s), support flexible communication options, and use a loosely coupled (data-driven and component-based) software approach.',\n",
              "  'Towards Deeper Understanding of User Experience with Ubiquitous Computing Systems: Systematic Literature Review and Design Framework.[SEP]Over the past decades, a plethora of innovative ubiquitous computing (ubicomp) systems have been constructed. The acceptance of the systems, however, depends on how users experience them in real contexts. While many of the ubicomp research projects include some form of user study, there is no overview of how user experience (UX) is approached in ubicomp research. To this end, we conducted a systematic literature review of ubicomp UX studies. Our findings reveal that users‘experiences with ubicomp systems have often been investigated in rather lightweight ways, for example by addressing basic usability issues, collecting ratings by simple, predetermined scales, or producing descriptions of general experiences such as fun and trust. Based on the findings we argue that a deeper and more fine-grained understanding of user experience would help developing more successful ubicomp systems. We propose a ubicomp UX framework that can help design and evaluate ubicomp systems with a desirable set of target experiences.',\n",
              "  'Rapidly Exploring Application Design Through Speed Dating.[SEP]While the user-centered design methods we bring from human-computer interaction to ubicomp help sketch ideas and refine prototypes, few tools or techniques help explore divergent design concepts, reflect on their merits, and come to a new understanding of design opportunities and ways to address them. We present Speed Dating, a design method for rapidly exploring application concepts and their interactions and contextual dimensions without requiring any technology implementation. Situated between sketching and prototyping, Speed Dating structures comparison of concepts, helping identify and understand contextual risk factors and develop approaches to address them. We illustrate how to use Speed Dating by applying it to our research on the smart home and dual-income families, and highlight our findings from using this method.'],\n",
              " '12_education_educational_teaching_classroom': ['Distinctive Approaches to Computer Graphics Education.[SEP]This paper presents the latest advances and research in Computer Graphics education in a nutshell. It is concerned with topics that were presented at the Education Track of the Eurographics Conference held in Lisbon in 2016. We describe works corresponding to approaches to Computer Graphics education that are unconventional in some way and attempt to tackle unsolved problems and challenges regarding the role of arts in computer graphics education, the role of research‐oriented activities in undergraduate education and the interaction among different areas of Computer Graphics, as well as their application to courses or extra‐curricular activities. We present related works addressing these topics and report experiences, successes and issues in implementing the approaches.',\n",
              "  'Interactive computer graphics applied to chemistry: experiences and new developments.[SEP]This paper is essentially a progress report on three years of effort in computer graphics applied to chemistry. The major technical and human problems encountered when running our facility and integrating it into a chemistry department are described. Then progress of our research project, which is developing application programs in several areas of computer graphics applied to chemical education and research, is reviewed. Recent developments in the field of the representation of dynamic processes in molecules and illustrating some basic concepts of reaction mechanisms in organic chemistry are presented, and the important role of graphics in depicting adequately 3D reaction paths is stressed. Finally, some technical problems arising when using the calligraphic system as an audio‐visual tool for teaching chemistry are discussed and some possible solutions are presented.',\n",
              "  \"Integrating User Studies into Computer Graphics-Related Courses.[SEP]This paper presents computer graphics. Computer graphics and visualization are essentially about producing images for a target audience, be it the millions watching a new CG-animated movie or the small group of researchers trying to gain insight into the large amount of numerical data resulting from a scientific experiment. To ascertain the final images' effectiveness for their intended audience or the designed visualizations' accuracy and expressiveness, formal user studies are often essential. In human-computer interaction (HCI), such user studies play a similar fundamental role in evaluating the usability and applicability of interaction methods and metaphors for the various devices and software systems we use.\",\n",
              "  \"Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent.[SEP]Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.\",\n",
              "  \"How Peripheral Data Visualisation Systems Support Secondary School Teachers during VLE-Supported Lessons.[SEP]Through the integration of technology-enhanced learning (TEL) in the classrooms, there is an increase in Virtual Learning Environment-supported classes in secondary schools, which brings unintentional complexities in terms of monitoring for teachers [25]. To support secondary school teachers during VLE-supported lessons, a peripheral data visualisation system was designed and implemented in a three-week field study. Both qualitative and quantitative data were gathered and analysed through methodological triangulation in order to get an in-depth understanding about the use of the system by teachers. The key findings from our study were that the peripheral data visualisation tool, by being a distributed, highly visible system, was well integrated in the teachers' practice. The peripheral visualisation served as a trigger for teacher interventions where the teacher could confront the student's level of concentration and provide support when a student needs it. Furthermore, by offloading the secondary tasks of checking the students' level of concentration and progress to the visualisation, most teachers experienced more peace of mind and space to manage their primary teaching practice. Lastly, approximately 95% of 89 students experienced the data visualisation as neutral or motivating, while 5.7% of the students experienced violation of privacy by this medium.\",\n",
              "  'The Design of an Authoring Interface to Make eLearning Content Accessible.[SEP]This paper presents the rationale and design process of an authoring interface that enables didactic experts to create or modify eLearning content to make it accessible by learners with special needs. The tool has been designed according to a methodological framework and a set of guidelines for eLearning accessibility previously developed by our group. A key aspect of our framework consists in helping authors to preserve the didactic quality of the eLearning experiences provided to disabled learners (in particular, visually impaired ones) beyond assuring their mere physical access to online materials. A user-centred design process has been adopted to develop a usable prototype of the authoring interface, named aLearning, that we describe below.'],\n",
              " '130_meetings_communication_informal_messaging': ['The doing of doing stuff: understanding the coordination of social group-activities.[SEP]This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.',\n",
              "  \"Accessible Online Meetings and Presentations.[SEP]In our current situation, conferences, classes, and meetings are moving online. What steps can you take to ensure that your activities are welcoming to a diverse audience, including people with disabilities? This presentation will look at proactive strategies you can take to ensure that your meetings and presentations are accessible to a wide audience. We'll talk about communication with participants, preparation, presentation materials, technology, and accommodations.\",\n",
              "  'Automated Assistance for the Telemeeting Lifecycle.[SEP]We analyse eighteen months of national and international deployment of a prototype telemeeting system supporting synchronous remote meetings which make extensive use of shared documents as well as video and audio conferencing. Logistics of a telemeeting include scheduling people and equipment, document format conversion, pre-sending documents, training, equipment and call setup, and meeting followup. The logistics burden is much larger than expected and can be a barrier to adoption of telemeeting technology. Using a process model that recognises moving between solo and group, asynchronous and synchronous work modes, the paper explores the amenability of individual logistics tasks to automated assistance, proposes a framework for such assistance, and develops a set of design principles.'],\n",
              " '131_provenance_lakes_workflows_lake': [\"C[SEP]Datasets are often derived by manipulating raw data with statistical software packages. The derivation of a dataset must be recorded in terms of both the raw input and the manipulations applied to it. Statistics packages typically provide limited help in documenting provenance for the resulting derived data. At best, the operations performed by the statistical package are described in a script. Disparate representations make these scripts hard to understand for users. To address these challenges, we created Continuous Capture of Metadata (C2Metadata), a system to capture data transformations in scripts for statistical packages and represent it as metadata in a standard format that is easy to understand. We do so by devising a Structured Data Transformation Algebra (SDTA), which uses a small set of algebraic operators to express a large fraction of data manipulation performed in practce. We then implement SDTA, inspired by relational algebra, in a data transformation specification language we call SDTL. In this demonstration, we showcase C2metadata's capture of data transformations from a pool of sample transformation scripts in at least two languages: SPSS and Stata (SAS and R are under development), for social science data in a large academic repository. We will allow the audience to explore C2Metadata using a web-based interface, visualize the intermediate steps and trace the provenance and changes of data at different levels for better understanding of the process.\",\n",
              "  \"When the Web is your Data Lake: Creating a Search Engine for Datasets on the Web.[SEP]There are thousands of data repositories on the Web, providing access to millions of datasets. National and regional governments, scientific publishers and consortia, commercial data providers, and others publish data for fields ranging from social science to life science to high-energy physics to climate science and more. Access to this data is critical to facilitating reproducibility of research results, enabling scientists to build on others' work, and providing data journalists easier access to information and its provenance. In this talk, I will discuss our work on Dataset Search, which provides search capabilities over potentially all dataset repositories on the Web. I will talk about the open ecosystem for describing and citing datasets that we hope to encourage and the technical details on how we went about building Dataset Search. Finally, I will highlight research challenges in building a vibrant, heterogeneous, and open ecosystem where data becomes a first-class citizen.\",\n",
              "  'Debugging Big Data Analytics in Spark with [SEP]To process massive quantities of data, developers leverage Data-Intensive Scalable Computing (DISC) systems such as Apache Spark. In terms of debugging, DISC systems support only post-mortem log analysis and do not provide any debugging functionality. This demonstration paper showcases BigDebug: a tool enhancing Apache Spark with a set of interactive debugging features that can help users in debug their Big Data Applications.'],\n",
              " '13_driving_vehicle_vehicles_driver': ['The SKYNIVI Experience: Evoking Startle and Frustration in Dyads and Single Drivers.[SEP]To study naturalistic in-cabin emotion we developed SKYNIVI, a modified open source driving simulator, with scenarios designed to elicit startle and frustration. We target generating these emotions because we believe that by detecting these it will be possible for autonomous vehicles to learn to drive better. We show how to use SKYNIVI to develop datasets that capture naturalistic emotions in drivers and passengers for algorithmic development. We recruited 51 participants as dyads and single drivers to participate in two different scenarios. We show that we were able to evoke hundreds of instances of our target emotions in this cohort and present an analysis of factors we found to impact emotional expression including: scenario design , demographic factors, personality and baseline affect . We find that having a second person in the vehicle impacts observed expressions of emotion even when no difference in baseline affect is reported.',\n",
              "  'Autonomous Vehicle-Cyclist Interaction: Peril and Promise.[SEP]Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.',\n",
              "  'CarNote: Reducing Misunderstanding between Drivers by Digital Augmentation.[SEP]The road environment can be seen as a social situation: Drivers need to coordinate with each other to share the infrastructure. In addition to the driving behaviour itself, lights, horn and speed are the most frequently used means to exchange information, limiting both the range and the bandwidth of the connectivity and leading to misunderstanding and conflict. With everywhere available connectivity and the broad penetration of social network services, the relationship between drivers on the road may gain more transparency, enabling social information to pass through the steel shell of the cars and giving opportunities to reduce misunderstanding and strengthen empathy. In this study, we present \"CarNote\", a concept that aims to reduce misunderstanding and conflict between drivers by showing their emergency driving status to others. This concept was prototyped and evaluated with users in a driving simulator. The results showed that CarNote enhances drivers\\' empathy, increases forgiveness and decreases anger to others on the road.',\n",
              "  \"Learning to Estimate the Travel Time.[SEP]Vehicle travel time estimation or estimated time of arrival (ETA) is one of the most important location-based services (LBS). It is becoming increasingly important and has been widely used as a basic service in navigation systems and intelligent transportation systems. This paper presents a novel machine learning solution to predict the vehicle travel time based on floating-car data. First, we formulate ETA as a pure spatial-temporal regression problem based on a large set of effective features. Second, we adapt different existing machine learning models to solve the regression problem. Furthermore, we propose a Wide-Deep-Recurrent (WDR) learning model to accurately predict the travel time along a given route at a given departure time. We then jointly train wide linear models, deep neural networks and recurrent neural networks together to take full advantages of all three models. We evaluate our solution offline with millions of historical vehicle travel data. We also deploy the proposed solution on Didi Chuxing's platform, which services billions of ETA requests and benefits millions of customers per day. Our extensive evaluations show that our proposed deep learning algorithm significantly outperforms the state-of-the-art learning algorithms, as well as the solutions provided by leading industry LBS providers.\",\n",
              "  'Exploiting Spatio-Temporal Correlations with Multiple 3D Convolutional Neural Networks for Citywide Vehicle Flow Prediction.[SEP]Predicting vehicle flows is of great importance to traffic management and public safety in smart cities, and very challenging as it is affected by many complex factors, such as spatio-temporal dependencies with external factors (e.g., holidays, events and weather). Recently, deep learning has shown remarkable performance on traditional challenging tasks, such as image classification, due to its powerful feature learning capabilities. Some works have utilized LSTMs to connect the high-level layers of 2D convolutional neural networks (CNNs) to learn the spatio-temporal features, and have shown better performance as compared to many classical methods in traffic prediction. However, these works only build temporal connections on the high-level features at the top layer while leaving the spatio-temporal correlations in the low-level layers not fully exploited. In this paper, we propose to apply 3D CNNs to learn the spatio-temporal correlation features jointly from low-level to high-level layers for traffic data. We also design an end-to-end structure, named as MST3D, especially for vehicle flow prediction. MST3D can learn spatial and multiple temporal dependencies jointly by multiple 3D CNNs, combine the learned features with external factors and assign different weights to different branches dynamically. To the best of our knowledge, it is the first framework that utilizes 3D CNNs for traffic prediction. Experiments on two vehicle flow datasets Beijing and New York City have demonstrated that the proposed framework, MST3D, outperforms the state-of-the-art methods.',\n",
              "  'Co-Prediction of Multiple Transportation Demands Based on Deep Spatio-Temporal Neural Network.[SEP]Taxi and sharing bike bring great convenience to urban transportation. A lot of efforts have been made to improve the efficiency of taxi service or bike sharing system by predicting the next-period pick-up or drop-off demand. Different from the existing research, this paper is motivated by the following two facts: 1) From a micro view, an observed spatial demand at any time slot could be decomposed as a combination of many hidden spatial demand bases; 2) From a macro view, the multiple transportation demands are strongly correlated with each other, both spatially and temporally. Definitely, the above two views have great potential to revolutionize the existing taxi or bike demand prediction methods. Along this line, this paper provides a novel Co-prediction method based on Spatio-Temporal neural Network, namely, CoST-Net. In particular, a deep convolutional neural network is constructed to decompose a spatial demand into a combination of hidden spatial demand bases. The combination weight vector is used as a representation of the decomposed spatial demand. Then, a heterogeneous Long Short-Term Memory (LSTM) is proposed to integrate the states of multiple transportation demands, and also model the dynamics of them mixedly. Last, the environmental features such as humidity and temperature are incorporated with the achieved overall hidden states to predict the multiple demands simultaneously. Experiments have been conducted on real-world taxi and sharing bike demand data, results demonstrate the superiority of the proposed method over both classical and the state-of-the-art transportation demand prediction methods.',\n",
              "  'End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks.[SEP]Despite extraordinary progress of Advanced Driver Assistance Systems (ADAS), an alarming number of over 1,2 million people are still fatally injured in traffic accidents every year 1 . Human error is mostly responsible for such casualties, as by the time the ADAS system has alarmed the driver, it is often too late. We present a vision-based system based on deep neural networks with 3D convolutions and residual learning for anticipating the future maneuver based on driver observation. While previous work focuses on hand-crafted features (e.g. head pose), our model predicts the intention directly from video in an end-to-end fashion. Our architecture consists of three components: a neural network for extraction of optical flow, a 3D residual network for maneuver classification and a Long Short-Term Memory network (LSTM) for handling temporal data of varying length. To evaluate our idea, we conduct thorough experiments on the publicly available Brain4Cars benchmark, which covers both inside and outside views for future maneuver anticipation. Our model is able to predict driver intention with an accuracy of 83,12% and 4,07s before the beginning of the maneuver, outperforming state-of-the-art approaches, while considering the inside view only.',\n",
              "  \"Learning Interaction-Aware Probabilistic Driver Behavior Models from Urban Scenarios.[SEP]Human drivers have complex and individual behavior characteristics which describe how they act in a specific situation. Accurate behavior models are essential for many applications in the field of autonomous driving, ranging from microscopic traffic simulation, intention estimation and trajectory prediction, to interactive and cooperative motion planning. Designing such models by hand is cumbersome and inaccurate, especially in urban environments, with their high variety of situations and the corresponding diversity in human behavior. Learning how humans act from recorded scenarios is a promising way to overcome these problems. However, predicting complete trajectories at once is challenging, as one needs to account for multiple hypotheses and long-term interactions between multiple agents. In contrast, we propose to learn Markovian action models with deep neural networks that are conditioned on a driver's route intention (such as turning left or right) and the situational context. Step-wise forward simulation of these models for the different possible routes of all agents allows for multi-modal and interaction-aware scene predictions at arbitrary road layouts. Learning to predict only one time step ahead given a specific route reduces learning complexity, such that simpler and faster models are obtained. This enables the integration into particle-based algorithms such as Monte Carlo tree search or particle filtering. We evaluate the learned model both on its own and integrated into our previously presented dynamic Bayesian network for intention estimation and show that it outperforms our previous hand-tuned rule-based model.\",\n",
              "  'Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning.[SEP]For highly automated driving above SAE level 3, behavior generation algorithms must reliably consider the inherent uncertainties of the traffic environment, e.g. arising from the variety of human driving styles. Such uncertainties can generate ambiguous decisions, requiring the algorithm to appropriately balance low-probability hazardous events, e.g. collisions, and high-probability beneficial events, e.g. quickly crossing the intersection. State-of-the-art behavior generation algorithms lack a distributional treatment of decision outcome. This impedes a proper risk evaluation in ambiguous situations, often encouraging either unsafe or conservative behavior. Thus, we propose a two-step approach for risk-sensitive behavior generation combining offline distribution learning with online risk assessment. Specifically, we first learn an optimal policy in an uncertain environment with Deep Distributional Reinforcement Learning. During execution, the optimal risk-sensitive action is selected by applying established risk criteria, such as the Conditional Value at Risk, to the learned state-action return distributions. In intersection crossing scenarios, we evaluate different risk criteria and demonstrate that our approach increases safety, while maintaining an active driving style. Our approach shall encourage further studies about the benefits of risk-sensitive approaches for self-driving vehicles.',\n",
              "  'Deep, spatially coherent Inverse Sensor Models with Uncertainty Incorporation using the evidential Framework.[SEP]To perform high speed tasks, sensors of autonomous cars have to provide as much information in as few time steps as possible. However, radars, one of the sensor modalities autonomous cars heavily rely on, often only provide sparse, noisy detections. These have to be accumulated over time to reach a high enough confidence about the static parts of the environment. For radars, the state is typically estimated by accumulating inverse detection models (IDMs). We employ the recently proposed evidential convolutional neural networks which, in contrast to IDMs, compute dense, spatially coherent inference of the environment state. Moreover, these networks are able to incorporate sensor noise in a principled way which we further extend to also incorporate model uncertainty. We present experimental results which show that this approach leads to a denser environment perception in only one time step while at the same time reducing the false positive and negative rates.',\n",
              "  \"Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image.[SEP]In this paper, we present a method for estimating a position, size, and orientation using a single monocular image. The proposed method makes use of an inverse perspective mapping to effectively estimate the distance from the image. The proposed method consists of two stages: 1) cancel the pitch and roll motion of the camera using inertial measurement unit and project the corrected front view image onto the bird's eye view using inverse perspective mapping. 2) detect the position, size, and orientation of the vehicle using a convolutional neural network. The camera motion cancellation process makes vanishing point to be located at the same point regardless of the ego vehicle attitude change. Through this process, the projected bird's eye view image can be parallel and linear to the x-y plane of the vehicle coordinate system. The convolutional neural network predicts not only the position and size but also the orientation of the vehicle for the 3D localization. The predicted oriented bounding box from the bird's eye view image is converted in the meter unit by the inverse projection matrix. The proposed method was evaluated on the KITTI raw dataset on the metric of the root mean square error, mean average percentage error, and average precision. Despite the conceptually simple architecture, the proposed method achieves promising performance compared to other image based approaches. The video demonstration is available online [1].\",\n",
              "  'Camera and LiDAR Fusion for On-road Vehicle Tracking with Reinforcement Learning.[SEP]We formulate camera and LiDAR fusion tracking as a sequential decision-making process. With our deep reinforcement learning framework, we try to optimize the tracking trajectory to be as accurate, smooth, and long as possible. In contrast to traditional fusion algorithms involving complex feature and strategy design and hyperparameters tuned for different scenarios, our fusion agent can learn the confidence of each input by tracking the results from raw observation in a data-driven fashion. Given the input states of different sensors, our approach chooses one input with a higher expected cumulative reward as the observation of a Kalman filter to iteratively predict the target position. The expected cumulative reward is estimated with a convolutional neural network, trained with a modified DQN algorithm, which takes inputs from both LiDAR and a camera. Through case studies and quantitative result evaluation on our dataset from the 4th Ring Road in Beijing, our algorithm is validated to achieve more accurate and robust tracking performance.',\n",
              "  \"An Integrated Path-following and Yaw Motion Control Strategy for Autonomous Distributed Drive Electric Vehicles with Differential Steering.[SEP]This paper proposes a novel control strategy integrated path-following with yaw motion control for autonomous distributed drive electric vehicles with differential steering (DS) technology. First, the path-following and vehicle dynamics model, and DS system are introduced and analyzed. Then, the control framework is proposed, where the model predictive control (MPC) is adopted for path-following and yaw motion control. Given the optimized command by MPC, the quadratic programming (QP) algorithm is applied for in-wheel motors' torque allocation optimization. Series of simulation validations are carried out, proving that the proposed strategy can effectively achieve superior path-following effect, guarantee the vehicle yaw stability, and implement the steering control in DS system, simultaneously.\",\n",
              "  \"Predictive Trajectory Planning in Situations with Hidden Road Users Using Partially Observable Markov Decision Processes.[SEP]State of the art emergency brake assistant systems solely based on sensor measurements reduced the number of traffic accidents and casualties drastically in recent years. In order to be able to react on road users who elude a vehicle's field of view because of sensor limits or occlusions, this paper presents an approach to anticipate potential hidden traffic participants in occluded areas in the decision making process of an autonomous vehicle. A Partially Observable Markov Decision Process is used to determine the vehicle's longitudinal motion. Observations are made using the vehicle's field of view. Therefore the field of view is calculated with a generic model of a sensor setup in dependence of the current or the predicted environment. In this way, the vehicle can either observe that it detects a previously hidden road user or receives information that the road is clear. In total, that allows the vehicle to better anticipate future developments. Therefore, assumptions about vehicles that may be located in hidden areas need to be made. We demonstrate the approach in two scenarios. Firstly in a scenario, where the vehicle has to move cautiously into the intersection with a minimum number of actions and secondly in a typical scenario for urban traffic. Evaluation shows, that the approach is able to anticipate hidden road users correctly and act accordingly.\",\n",
              "  'Semi-Active Suspension Control on Bicycles: Anti-Dive during Road Excitation.[SEP]Suspension systems on bicycles have a tendency to severe brake-induced dive-in, caused by the small wheelbase in combination with a high center of gravity. Semi-active dampers allow the implementation of anti-dive functionality, preventing this behavior. Experimental analysis has shown that this yields significant advantages during brake control on level surfaces. In the presence of additional road excitation, however, a strong conflict arises. A specific test case is a bump occurring while braking, when the damping is set to the hardest value in order to mitigate dive-in. A simulative analysis illustrates that especially the dynamic wheel load is affected, which during braking is safety critical. By simulation and experimental implementation it is shown that using a simple semi-active control rule a decent trade-off can be found. Finally, the influence of the actuator response time is evaluated.'],\n",
              " '14_gesture_gestures_touch_finger': ['Preschoolers understand the representational and communicative nature of iconic gestures.[SEP]Twenty 3.5- to 4-year-olds participated in a study to investigate children’s understanding of the representative and communicative nature of iconic gestures. Two toys, one of them with a sticker attached, were presented to the child. It was not possible to request the toy with the sticker by asking (experimenter wore headphones) or pointing (toys were too close together), but they could show the experimenter which toy they wanted by performing the correct gesture. Children had to generate the correct iconic gestures themselves as the gestures were not modeled during test trials. On 70% of the trials children performed a correct gesture (p = .045), instead of only producing other response types (no response, verbal request, wrong gesture, pointing). This study shows that children understand that iconic gestures can represent objects, and also that they can use iconic gestures to communicate.',\n",
              "  'Gesture structure affects syntactic structure in speech.[SEP]Different functions have been proposed for the hand gestures speakers spontaneously produce while speaking. The Information Packaging Hypothesis (Kita, 2000) states that gestures can structure rich spatio-motoric information into packages suitable for speaking. It therefore predicts that how information is divided over different gestures affects how it is divided over different processing units in speech: clauses. We indeed found that if participants were asked to express the manner and path of a motion in one gesture, they were also more likely to conflate this information into one clause in speech, whereas if they were asked to produce separate gestures, they were more likely to express manner and path in separate clauses too. These results support the view that there are speaker-internal motivations for gesture production. They confirm predictions made by the Information Packaging Hypothesis, which the Lexical Retrieval Hypothesis and the Image Activation Hypothesis do not make.',\n",
              "  'Sign processes in emergence of communication.[SEP]Communication depends on the production and interpretation of representations, but the study of representational processes underlying communication finds little discussion in computational experiments. Here we present an experiment on the emergence of both interpretation and production of multiple representations, with multiple referents, where referential processes can be tracked. Results show the dynamics of semiotic processes during the evolution of artificial creatures and the emergence of a variety of semiotic processes, such as sign production, sign interpretation, and sign-object-interpretant relations.',\n",
              "  \"Understanding users' preferences for surface gestures.[SEP]We compare two gesture sets for interactive surfaces---a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures' authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.\",\n",
              "  'Designer Led Computational Approach to Generate Mappings for Devices with Low Gestural Resolution.[SEP]We present an approach for the semi-automatic generation of gesture mappings for devices with low gestural resolution such as the Myo Armband, an off-the-shelf EMG capture device. As an exemplar interactive task, we use text-entry: a pervasive and highly complex interaction. We quantify data related to interaction combining systematic studies (i.e., error, speed, accuracy) and semi-structured workshops with experts (e.g., cognitive load, heuristics). We then formalize these factors in a mathematical model and use optimization algorithms (i.e. simulated annealing) to find an optimum gesture mapping. We demonstrated our method in a text-entry application (i.e., complex interactive dialogue) comparing our approach with other computationally determined mappings using naive cost functions. Our results showed that the designers mapping (with all factors weighted by designers) presented a good balance on performance in all factors involved (speed, accuracy, comfort, memorability, etc.), consistently performing better than purely computational mappings. The results indicate that our hybrid approach can yield better results than either pure user-driven methodologies or pure data-driven approaches, for our application context featuring a large solution space and complex high-level factors.',\n",
              "  'Designing Mid-Air TV Gestures for Blind People Using User- and Choice-Based Elicitation Approaches.[SEP]Mid-air gestures enable intuitive and natural interactions. However, few studies have investigated the use of mid-air gestures for blind people. TV interactions are one promising use of mid-air gestures for blind people, as \"listening\"\\' to TV is one of their most common activities. Thus, we investigated mid-air TV gestures for blind people through two studies. Study 1 used a user-elicitation approach where blind people were asked to define gestures given a set of commands. Then, we present a classification of gesture types and the frequency of body parts usage. Nevertheless, our participants had difficulty imagining gestures for some commands. Thus, we conducted Study 2 that used a choice-based elicitation approach where the participants selected their favorite gesture from a predefined list of choices. We found that providing choices help guide users to discover suitable gestures for unfamiliar commands. We discuss concrete design guidelines for mid-air TV gestures for blind people.',\n",
              "  'CyclopsRing: Enabling Whole-Hand and Context-Aware Interactions Through a Fisheye Ring.[SEP]This paper presents CyclopsRing, a ring-style fisheye imaging wearable device that can be worn on hand webbings to en- able whole-hand and context-aware interactions. Observing from a central position of the hand through a fisheye perspective, CyclopsRing sees not only the operating hand, but also the environmental contexts that involve with the hand-based interactions. Since CyclopsRing is a finger-worn device, it also allows users to fully preserve skin feedback of the hands. This paper demonstrates a proof-of-concept device, reports the performance in hand-gesture recognition using random decision forest (RDF) method, and, upon the gesture recognizer, presents a set of interaction techniques including on-finger pinch-and-slide input, in-air pinch-and-motion input, palm-writing input, and their interactions with the environ- mental contexts. The experiment obtained an 84.75% recognition rate of hand gesture input from a database of seven hand gestures collected from 15 participants. To our knowledge, CyclopsRing is the first ring-wearable device that supports whole-hand and context-aware interactions.',\n",
              "  \"Small gestures go a long way: how many bits per gesture do recognizers actually need?[SEP]We investigate in this work the effect of bit depth on the performance of today's commonly used nearest-neighbor gesture recognizers. As current bit representations are typically an artifact of today's hardware and file formats, they are not reflective of the true cardinality of gesture data. We show that as few as 4-5 bits per gesture channel (x/y) are enough in order to attain peak recognition for Euclidean, Cosine, DTW, and Hausdorff distances. We also show how reduction in bit depth can lead to 85 times less memory for storing the training set without ruining recognition performance. The results will benefit practitioners of the next age of gesture sensing gadgets and devices that need to optimize speed, memory, and bit depth representation in their software and hardware designs.\",\n",
              "  'Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.[SEP]We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.'],\n",
              " '15_classification_class_feature_kernel': ['Regularized discriminant analysis for high dimensional, low sample size data.[SEP]Linear and Quadratic Discriminant Analysis have been used widely in many areas of data mining, machine learning, and bioinformatics. Friedman proposed a compromise between Linear and Quadratic Discriminant Analysis, called Regularized Discriminant Analysis (RDA), which has been shown to be more flexible in dealing with various class distributions. RDA applies the regularization techniques by employing two regularization parameters, which are chosen to jointly maximize the classification performance. The optimal pair of parameters is commonly estimated via cross-validation from a set of candidate pairs. It is computationally prohibitive for high dimensional data, especially when the candidate set is large, which limits the applications of RDA to low dimensional data.In this paper, a novel algorithm for RDA is presented for high dimensional data. It can estimate the optimal regularization parameters from a large set of parameter candidates efficiently. Experiments on a variety of datasets confirm the claimed theoretical estimate of the efficiency, and also show that, for a properly chosen pair of regularization parameters, RDA performs favorably in classification, in comparison with other existing classification methods.',\n",
              "  'Binary Classifier Calibration Using an Ensemble of Near Isotonic Regression Models.[SEP]Learning accurate probabilistic models from data is crucial in many practical tasks in data mining. In this paper we present a new non-parametric calibration method called Ensemble of Near Isotonic Regression (ENIR). The method can be considered as an extension of BBQ, a recently proposed calibration method, as well as the commonly used calibration method based on isotonic regression (IsoRegC). ENIR is designed to address the key limitation of IsoRegC which is the monotonicity assumption of the predictions. Similar to BBQ, the method post-processes the output of a binary classifier to obtain calibrated probabilities. Thus it can be used with many existing classification models to generate accurate probabilistic predictions. We demonstrate the performance of ENIR on synthetic and real datasets for commonly applied binary classification models. Experimental results show that the method outperforms several common binary classifier calibration methods. In particular on the real data, ENIR commonly performs statistically significantly better than the other methods, and never worse. It is able to improve the calibration power of classifiers, while retaining their discrimination power. The method is also computationally tractable for large scale datasets, as it is O(N log N) time, where N is the number of samples.',\n",
              "  'Transductive Component Analysis.[SEP]In this paper, we study semisupervised linear dimensionality reduction. Beyond conventional supervised methods which merely consider labeled instances, the semisupervised scheme allows to leverage abundant and ample unlabeled instances into learning so as to achieve better generalization performance. Under semisupervised settings, our objective is to learn a smooth as well as discriminative subspace and linear dimensionality reduction is thus achieved by mapping all samples into the subspace. Specifically, we present the transductive component analysis (TCA) algorithm to generate such a subspace founded on a graph-theoretic framework. Considering TCA is nonorthogonal, we further present the orthogonal transductive component analysis (OTCA) algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better discriminating power than TCA. Experiments carried out on synthetic and real-world datasets by OTCA show a clear improvement over the results of representative dimensionality reduction algorithms.',\n",
              "  'Extracting key-substring-group features for text classification.[SEP]In many text classification applications, it is appealing to take every document as a string of characters rather than a bag of words. Previous research studies in this area mostly focused on different variants of generative Markov chain models. Although discriminative machine learning methods like Support Vector Machine (SVM) have been quite successful in text classification with word features, it is neither effective nor efficient to apply them straightforwardly taking all substrings in the corpus as features. In this paper, we propose to partition all substrings into statistical equivalence groups, and then pick those groups which are important (in the statistical sense) as features (named key-substring-group features) for text classification. In particular, we propose a suffix tree based algorithm that can extract such features in linear time (with respect to the total number of characters in the corpus). Our experiments on English, Chinese and Greek datasets show that SVM with key-substring-group features can achieve outstanding performance for various text classification tasks.',\n",
              "  'A parallel learning algorithm for text classification.[SEP]Text classification is the process of classifying documents into predefined categories based on their content. Existing supervised learning algorithms to automatically classify text need sufficient labeled documents to learn accurately. Applying the Expectation-Maximization (EM) algorithm to this problem is an alternative approach that utilizes a large pool of unlabeled documents to augment the available labeled documents. Unfortunately, the time needed to learn with these large unlabeled documents is too high. This paper introduces a novel parallel learning algorithm for text classification task. The parallel algorithm is based on the combination of the EM algorithm and the naive Bayes classifier. Our goal is to improve the computational time in learning and classifying process. We studied the performance of our parallel algorithm on a large Linux PC cluster called PIRUN Cluster. We report both timing and accuracy results. These results indicate that the proposed parallel algorithm is capable of handling large document collections.',\n",
              "  \"A Bayesian Hierarchical Model for Comparing Average F1 Scores.[SEP]In multi-class text classification, the performance (effectiveness) of a classifier is usually measured by micro-averaged and macro-averaged F1 scores. However, the scores themselves do not tell us how reliable they are in terms of forecasting the classifier's future performance on unseen data. In this paper, we propose a novel approach to explicitly modelling the uncertainty of average F1 scores through Bayesian reasoning, and demonstrate that it can provide much more comprehensive performance comparison between text classifiers than the traditional frequentist null hypothesis significance testing (NHST).\"],\n",
              " '16_gaze_eye_attention_head': [\"Detecting eye contact using wearable eye-tracking glasses.[SEP]We describe a system for detecting moments of eye contact between an adult and a child, based on a single pair of gaze-tracking glasses which are worn by the adult. Our method utilizes commercial gaze tracking technology to determine the adult's point of gaze, and combines this with computer vision analysis of video of the child's face to determine their gaze direction. Eye contact is then detected as the event of simultaneous, mutual looking at faces by the dyad. We report encouraging findings from an initial implementation and evaluation of this approach.\",\n",
              "  'VRpursuits: interaction in virtual reality using smooth pursuit eye movements.[SEP]Gaze-based interaction using smooth pursuit eye movements (Pursuits) is attractive given that it is intuitive and overcomes the Midas touch problem. At the same time, eye tracking is becoming increasingly popular for VR applications. While Pursuits was shown to be effective in several interaction contexts, it was never explored in-depth for VR before. In a user study (N=26), we investigated how parameters that are specific to VR settings influence the performance of Pursuits. For example, we found that Pursuits is robust against different sizes of virtual 3D targets. However performance improves when the trajectory size (e.g., radius) is larger, particularly if the user is walking while interacting. While walking, selecting moving targets via Pursuits is generally feasible albeit less accurate than when stationary. Finally, we discuss the implications of these findings and the potential of smooth pursuits for interaction in VR by demonstrating two sample use cases: 1) gaze-based authentication in VR, and 2) a space meteors shooting game.',\n",
              "  'Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets.[SEP]Although gaze is an attractive modality for pervasive interactions, the real-world implementation of eye-based interfaces poses significant challenges, such as calibration. We present Pursuits, an innovative interaction technique that enables truly spontaneous interaction with eye-based interfaces. A user can simply walk up to the screen and readily interact with moving targets. Instead of being based on gaze location, Pursuits correlates eye pursuit movements with objects dynamically moving on the interface. We evaluate the influence of target speed, number and trajectory and develop guidelines for designing Pursuits-based interfaces. We then describe six realistic usage scenarios and implement three of them to evaluate the method in a usability study and a field study. Our results show that Pursuits is a versatile and robust technique and that users can interact with Pursuits-based interfaces without prior knowledge or preparation phase.'],\n",
              " '17_haptic_tactile_force_virtual': [\"Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation.[SEP]We present Haptic Links, electro-mechanically actuated physical connections capable of rendering variable stiffness between two commodity handheld virtual reality (VR) controllers. When attached, Haptic Links can dynamically alter the forces perceived between the user's hands to support the haptic rendering of a variety of two-handed objects and interactions. They can rigidly lock controllers in an arbitrary configuration, constrain specific degrees of freedom or directions of motion, and dynamically set stiffness along a continuous range. We demonstrate and compare three prototype Haptic Links: Chain, Layer-Hinge, and Ratchet-Hinge. We then describe interaction techniques and scenarios leveraging the capabilities of each. Our user evaluation results confirm that users can perceive many two-handed objects or interactions as more realistic with Haptic Links than with typical unlinked VR controllers.\",\n",
              "  \"Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality.[SEP]Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.\",\n",
              "  'Haptic Device Control - Will it Fit Standardized Input Models?[SEP]Over recent years a wide variety of interaction devices involving haptic feedback have been brought to the market, but they vary widely in terms of input measures recorded. These range from one dimensional input on a haptic feedback steering wheel to a six degree of freedom position and orientation device and further, to assemblies of such devices. On the surface most of the variations can be accommodated logically with standardized input models combining existing logical input devices and haptic feedback processes as acknowledgement/echos. However it is very uncertain whether such a model can adequately model the system requirements for effective haptic feedback.'],\n",
              " '18_rendering_graphics_gpu_splatting': ['Graphics processing on a graphics supercomputer.[SEP]A description is given of the Titan Graphics Supercomputer. The primary design philosophy was to have as little redundant hardware as possible and to make as much of the hardware available to compiled application code as possible. This led to a design with multiple parallel processors, each with an integer unit and a vector floating-point unit. The system provides 3D graphics and image processing, using the main processors for most computations. The graphics subsystem consists of only a frame buffer with rasterization (vector and triangle pixel drawing) support. The Titan architecture provides a very good balance of computation and graphics but to make it more competitive in graphics or imaging-intensive applications, a special-purpose accelerator also fits into the architecture.< >',\n",
              "  'A display system for the Stellar graphics supercomputer model GS1000.[SEP]This paper describes a high performance display system that has been incorporated into the overall architecture of the Stellar Graphics Supercomputer Model GS1000. The display system is tightly coupled to the CPU, memory system and vector processing unit of this supercomputer, and is capable of rendering 150,000 shaded triangles/sec, and 600,000 short vectors/sec. The goal of the architecture is to share hardware resources between the CPU and display system and achieve a high bandwidth connection between them. This coupling of the display system and the processor, the architecture of the rendering processor, and the two ASICs that are used to implement the rendering processor are described.In addition, the display system architecture is contrasted to other approaches to high performance graphics, and design trade-offs and possible extensions are described. The implementation of popular display algorithms on the architecture is discussed, and their performance specified. The reader is advised that Stellar Computer Inc. is seeking patent protection for work described in this paper.',\n",
              "  'The Truga001: A Scalable Rendering Processor.[SEP]To support the increasing interest in virtual reality systems, computer graphics must now be extremely powerful to obtain realistic images. VR systems are based on two technical tools: graphics accelerators and pixel renderers. The paper discusses the Truga001 single-chip rendering processor for virtual reality and multimedia systems. It embeds 12 graphics processors and 7 special modules in a single chip.',\n",
              "  'An efficient multi-resolution framework for high quality interactive rendering of massive point clouds using multi-way kd-trees.[SEP]We present an efficient technique for out-of-core multi-resolution construction and high quality interactive visualization of massive point clouds. Our approach introduces a novel hierarchical level of detail (LOD) organization based on multi-way kd-trees, which simplifies memory management and allows control over the LOD-tree height. The LOD tree, constructed bottom up using a fast high-quality point simplification method, is fully balanced and contains all uniformly sized nodes. To this end, we introduce and analyze three efficient point simplification approaches that yield a desired number of high-quality output points. For constant rendering performance, we propose an efficient rendering-on-a-budget method with asynchronous data loading, which delivers fully continuous high quality rendering through LOD geo-morphing and deferred blending. Our algorithm is incorporated in a full end-to-end rendering system, which supports both local rendering and cluster-parallel distributed rendering. The method is evaluated on complex models made of hundreds of millions of point samples.',\n",
              "  \"Optimized Pattern-Based Adaptive Mesh Refinement Using GPU.[SEP]The high performance of GPUs and the increasing use of their programming mechanisms have fostered the development of graphics applications that better exploit the raw power of these devices to achieve higher levels of realism. Silhouette refinement, as one of the techniques that help to improve realism, has profited from GPUs' advances in recent years. In this paper, we present a method for triangular mesh refinement which alleviates the problem of rugged silhouettes. We demonstrate that, through a clever indexing scheme, our method is able to use adaptive patterns in an optimized way, taking full advantage of the GPU's parallelism. The ideas we used were adapted from distinct previous works, but our method presents astounding performance gains. Also, our method works very well with existing meshes, therefore, it can improve the visual appearance of existing models without mesh redesign.\",\n",
              "  'Optimized View-Dependent Rendering for Large Polygonal Datasets.[SEP]In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.',\n",
              "  'Volume Rendering on a Distributed Memory Parallel Computer.[SEP]A prototype implementation of a splatting volume renderer (SVR) on a commercially available distributed memory MIMD (multiple instruction stream, multiple data stream) parallel processor, the nCUBE2, is described. Some relatively good rendering times can be achieved with the nCUBE SVR. Message-passing bottlenecks occur when large numbers of floating-point values have to be collected from every processor for every picture. For large images this is a severe limitation. An initial implementation of a SVR on a distributed memory parallel computer demonstrates the need for parallel computers with high-bandwidth connections between processors, and also for new parallelizable volume rendering algorithms.< >',\n",
              "  'Algorithms for rendering realistic terrain image sequences and their parallel implementation.[SEP]We present algorithms for rendering realistic images of large terrains and their implementation on a parallel computer for rapid production of terrain-animation sequences. “Large” means datasets too large for RAM. A hybrid ray-casting and projection technique incorporates quadtree subdivision techniques and filtering using precomputed bit masks. Hilbert space-filling curves determine the imagepixel rendering order. A parallel version of the algorithm is based on a Meiko parallel computer architecture, designed to relieve dataflow bottlenecks and exploit temporal image coherence. Our parallel system, incorporating 26 processors, can generate a full color-terrain image at video resolution (without noticable aliasing artifacts) every 2 s, including I/O and communication overheads.',\n",
              "  'A sorting classification of parallel rendering.[SEP]We describe a classification scheme that we believe provides a more structured framework for reasoning about parallel rendering. The scheme is based on where the sort from object coordinates to screen coordinates occurs, which we believe is fundamental whenever both geometry processing and rasterization are performed in parallel. This classification scheme supports the analysis of computational and communication costs, and encompasses the bulk of current and proposed highly parallel renderers - both hardware and software. We begin by reviewing the standard feed-forward rendering pipeline, showing how different ways of parallelizing it lead to three classes of rendering algorithms. Next, we consider each of these classes in detail, analyzing their aggregate processing and communication costs, possible variations, and constraints they may impose on rendering applications. Finally, we use these analyses to compare the classes and identify when each is likely to be preferable.< >'],\n",
              " '19_mining_frequent_itemsets_rules': ['Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking.[SEP]Mining for frequent item sets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficient mining of frequent item sets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.',\n",
              "  'Optimizing Constraint-Based Mining by Automatically Relaxing Constraints.[SEP]In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.',\n",
              "  'DualMiner: a dual-pruning algorithm for itemsets with constraints.[SEP]Constraint-based mining of itemsets for questions such as \"find all frequent itemsets where the total price is at least $50\" has received much attention recently. Two classes of constraints, monotone and antimonotone, have been identified as very useful. There are algorithms that efficiently take advantage of either one of these two classes, but no previous algorithms can efficiently handle both types of constraints simultaneously. In this paper, we present the first algorithm (called DualMiner) that uses both monotone and antimonotone constraints to prune its search space. We complement a theoretical analysis and proof of correctness of DualMiner with an experimental study that shows the efficacy of DualMiner compared to previous work.',\n",
              "  'CoLe: A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection.[SEP]We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.',\n",
              "  'MMAC: A New Multi-Class, Multi-Label Associative Classification Approach.[SEP]Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.',\n",
              "  'Brute-Force Mining of High-Confidence Classification Rules.[SEP]This paper investigates a brute-force technique for mining classification rules from large data sets. We employ an association rule miner enhanced with new pruning strategies to control combinatorial explosion in the number of candidates counted with each database pass. The approach effectively and efficiently extracts high confidence classification rules that apply to most if not all of the data in several classification benchmarks.'],\n",
              " '1_language_word_linguistic_lexical': ['The role of word-word co-occurrence in word learning.[SEP]A growing body of research on early word learning suggests that learners gather word-object co-occurrence statistics across learning situations. Here we test a new mechanism whereby learners are also sensitive to word-word co-occurrence statistics. Indeed, we find that participants can infer the likely referent of a novel word based on its co-occurrence with other words, in a way that mimics a machine learning algorithm dubbed ‘zero-shot learning’. We suggest that the interaction between referential and distributional regularities can bring robustness to the process of word acquisition',\n",
              "  'Interlocutors preserve complexity in language.[SEP]Why do languages change? One possibility is they evolve in response to two competing pressures: (1) to be easily learned, and (2) to be effective for communication. In a number of domains, variation in the world’s natural languages appears to be accounted for by different but near-optimal tradeoffs between these pressures. Models of these evolutionary processes have used transmission chain paradigms in which errors of learning by one agent become the input for the subsequent generation. However, a critical feature of human language is that children do not learn in isolation. Rather, they learn in communicative interactions with caregivers who draw inferences from their errorful productions to their intended interests. In a set of iterated reproduction experiments, we show that this supportive context can have a powerful stabilizing role in the development of artificial patterned systems, allowing them to achieve higher levels of complexity than they would by vertical transmission alone while retaining equivalent transmission accuracies.',\n",
              "  'Linguistic Structure Evolves to Match Meaning Structure.[SEP]Quantitative analysis has usually highlighted the random nature of linguistic forms (Zipf, 1949). We zoom in on three structured samples of language (numerals; playing cards; and a corpus of artificial languages from Kirby, Cornish & Smith 2008) to quantitative explore and illustrate the idea that linguistic forms are nonrandom in that their structure reflects the structure of the meanings they convey. A novel methodology returns frequency spectra showing the distribution of character n-gram frequencies in our language samples. These spectra, purely derived from linguistic form, clearly reflect the quantitative structure of the underlying meaning spaces, as verified with a new information theoretical metric of compositionality. Moreover, analyses of a diachronic corpus of languages show that linguistic structure gradually adapts to match the structure of meanings over cultural transmission.',\n",
              "  'Eye-tracking situated language comprehension: Immediate actor gaze versus recent action events.[SEP]Visual-world eye-tracking findings suggest visual cues rapidly affect spoken sentence comprehension. When participants saw an actor perform an action and then listened to a related sentence (NP1-VERB-ADV-NP2), they preferentially inspected the “recent” over another “future” event target, and this even when future events were much more frequent. The current studies assessed to which extent this recent-event preference is modulated by another situation-immediate cue to the future event target (an actor’s gaze). Half of the sentences referenced a future event, and the experimenter performed one “recent” action before and one “future” action after the sentence. On 50% of the trials, he gazed at the future target object during the verb (Experiment 1) or at verb onset (Experiment 2). Results showed that gaze and future tense together cued attention to the future target; however gaze did not completely override the recent event preference.',\n",
              "  'Response direction and sentence-tense compatibility effects: An eye tracking study.[SEP]Recent evidence shows tense-response compatibility effects only when the task relates to sentence tense (Ulrich & Maienborn, 2010). In two eye-tracking experiments, we investigated tense-response compatibility effects. In our first experiment (E1, where sentence tense was relevant to the task) we found compatibility effects at the beginning of the sentence (e.g., Yesterday versus Tomorrow), which shifted to interference effects by sentence end. Overall, we also found compatibility effects in response times, replicating Ulrich and Maienborn. Both compatibility effects in Experiment 1 (E1) were stronger for low- compared to high-WM readers. In Experiment 2 (E2, where tense was irrelevant), we found compatibility effects for high-WM readers, but only in early reading measures. These results suggest that compatibility effects are weaker depending on the task, but not eliminated; an implication which may help refine a strict view of embodied cognition.',\n",
              "  \"Visual attention during spatial language comprehension: Reference alone isn't enough.[SEP]When people listen to sentences referring to objects and events in visual context, their visual attention to objects is closely time-locked to words in the unfolding utterance. How precisely people deploy attention during situated language understanding and in verifying (spatial) utterances is, however, unclear. A ‘visual world’ hypothesis suggests that we look at what is mentioned (Tanenhaus et al., 1995) and anticipate likely referents based on linguistic cues (Altmann & Kamide, 1999). In spatial language research, in contrast, the Attention Vector Sum model (Regier & Carlson, 2001) predicts that in order to process a sentence such as “The plant is above the clock”, attention must shift from the clock to the plant. An eye-tracking study examined whether gaze pattern during comprehension of spatial descriptions support the visual world or the Attention Vector Sum account. Analyses of eye movements indicate that we need both accounts to accommodate the findings.\",\n",
              "  \"Monsieur, azonnal k[SEP]Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems. This paper proposes a new way to compensate for such resource-scarce languages, based on the fact that most languages share a common vocabulary. Concretely, our approach leverages a family of languages closely related to the speaker's native language to construct translations in a coherent mix of these languages. Experimental results indicate that these translations can be easily understood, being also a useful aid for users who are not proficient in foreign languages. Therefore this work significantly contributes to HCI in two ways: it establishes a language that can improve how applications communicate to their users, and it reports insights on the user acceptance towards the method.\",\n",
              "  'Effects of machine translation on collaborative work.[SEP]Even though multilingual communities that use machine translation to overcome language barriers are increasing, we still lack a complete understanding of how machine translation affects communication. In this study, eight pairs from three different language communities--China, Korea, and Japan--worked on referential tasks in their shared second language (English) and in their native languages using a machine translation embedded chat system. Drawing upon prior research, we predicted differences in conversational efficiency and content, and in the shortening of referring expressions over trials. Quantitative results combined with interview data show that lexical entrainment was disrupted in machine translation-mediated communication because echoing is disrupted by asymmetries in machine translations. In addition, the process of shortening referring expressions is also disrupted because the translations do not translate the same terms consistently throughout the conversation. To support natural referring behavior in machine translation-mediated communication, we need to resolve asymmetries and inconsistencies caused by machine translations.',\n",
              "  \"Machine translation vs. common language: effects on idea exchange in cross-lingual groups.[SEP]Diversity among members of international teams can be a valuable source of novel ideas. However, to reap these benefits, groups need to overcome communication barriers that stem from differences in members' native languages. We compare two strategies for overcoming these barriers: the use of English as a common language, and the use of machine translation (MT) tools that allow each person to communicate in his or her own native language. Dyads consisting of one English-speaking American and one native Mandarin-speaking Chinese participant exchanged ideas to perform brainstorming tasks, either through English or using MT. We found that MT helped the non-native English speakers produce ideas but that both native and non-native English speakers viewed MT-mediated messages as less comprehensible than English messages. The findings suggest it can be effective to support cross-lingual communication with asymmetric design, using MT technology to help people produce messages in their native languages, while leaving incoming messages untranslated and leveraging people's second language proficiency for comprehension.\"],\n",
              " '20_image_images_retrieval_recognition': ['A Strategy for Boundary Detection Combining Region and Edge Information.[SEP]A method to detect boundaries in in natural color images is here proposed, combining edge information and region information. This unsupervised fully automatic process uses edge map information to eliminate false boundaries in the image region map, and region map information to remove noise in the image edge map. Thus, it integrates these two maps into a single one to get the final result. This proposal is extensively compared to the multi-label graph cut approach, since both approaches are unsupervised and fully automatic, as well as receive the same two inputs, although performing different processing. Experiments performed on a large set of natural color images were the base for such comparison. The results show that the approach here proposed is promising, besides allowing interesting interpretations about boundary detection.',\n",
              "  'How to Complete Any Segmentation Process Interactively via Image Foresting Transform.[SEP]The segmentation of poorly defined structures in medical imaging and heterogeneous objects in natural images usually call for considerable user assistance. Consequently, automatic results are often far from desirable and interactive repairs become an essential feature to consider. However, how to import automatic results obtained from external processes and complete their segmentation interactively is an issue, since different tools are based on different optimization criteria. Another simpler related problem concerns how to continue a previous segmentation obtained by the same interactive tool. This ability to stop and later resume interactive segmentation sessions is specially important for tridimensional images and video. However, very often crucial data (e.g., the history of user input) are no longer available; or are no longer reliable, as consequence of some post-processing. How to offer a comprehensive recovery and resume capability, comprising all these different scenarios, under the framework of the \"Image Foresting Transform\" (IFT) is the central focus of this paper.',\n",
              "  'Interactive Segmentation by Image Foresting Transform on Superpixel Graphs.[SEP]There are many scenarios in which user interaction is essential for effective image segmentation. In this paper, we present a new interactive segmentation method based on the Image Foresting Transform (IFT). The method over segments the input image, creates a graph based on these segments (super pixels), receives markers (labels) drawn by the user on some super pixels and organizes a competition to label every pixel in the image. Our method has several interesting properties: it is effective, efficient, capable of segmenting multiple objects in almost linear time on the number of super pixels, readily extendable through previously published techniques, and benefits from domain-specific feature extraction. We also present a comparison with another technique based on the IFT, which can be seen as its pixel-based counterpart. Another contribution of this paper is the description of automatic (robot) users. Given a ground truth image, these robots simulate interactive segmentation by trained and untrained users, reducing the costs and biases involved in comparing segmentation techniques.',\n",
              "  'Spatio-Temporal Frames in a Bag-of-Visual-Features Approach for Human Actions Recognition.[SEP]The recognition of human actions from videos has several interesting and important applications, and a vast amount of different approaches has been proposed for this task in different settings. Such approaches can be broadly categorized in model-based and model-free. Typically, model-based approaches work only in very constrained settings, and because of that, a number of model-free approaches appeared in the last years. Among them, those based in bag-of-visual-features (BoVF) have been proving to be the most consistently successful, being used by several independent authors. For videos to be represented by BoVFs, though, an important issue that arises is how to represent dynamic information. Most existing proposals consider the video as a spatio-temporal volume and then describe \"volumetric patches\" around 3D interest points. In this work, we propose to build a BoVF representation for videos by collecting 2D interest points directly. The basic idea is to gather such points not only from the traditional frames (xy planes), but also from those planes along the time axis, which we call the spatio-temporal frames. Our assumption is that such features are able to capture dynamic information from the videos, and are therefore well-suited to recognize human actions from them, without the need of 3D extentions for the descriptors. In our experiments, this approach achieved state-of-the-art recognition rates on a well-known human actions database, even when compared to more sophisticated schemes.',\n",
              "  'A survey on activity recognition and behavior understanding in video surveillance.[SEP]This paper provides a comprehensive survey for activity recognition in video surveillance. It starts with a description of simple and complex human activity, and various applications. The applications of activity recognition are manifold, ranging from visual surveillance through content based retrieval to human computer interaction. The organization of this paper covers all aspects of the general framework of human activity recognition. Then it summarizes and categorizes recent-published research progresses under a general framework. Finally, this paper also provides an overview of benchmark databases for activity recognition, the market analysis of video surveillance, and future directions to work on for this application.',\n",
              "  'Online robust action recognition based on a hierarchical model.[SEP]Action recognition solely based on video data has known to be very sensitive to background activity, and also lacks the ability to discriminate complex 3D motion. With the development of commercial depth cameras, skeleton-based action recognition is becoming more and more popular. However, the skeleton-based approach is still very challenging because of the large variation in human actions and temporal dynamics. In this paper, we propose a hierarchical model for action recognition. To handle confusing motions, a motion-based grouping method is proposed, which can efficiently assign each video a group label, and then for each group, a pre-trained classifier is used for frame-labeling. Unlike previous methods, we adopt a bottom-up approach that first performs action recognition for each frame. The final action label is obtained by fusing the classification to its frames, with the effect of each frame being adaptively adjusted based on its local properties. To achieve online real-time performance and suppressing noise, bag-of-words is used to represent the classification features. The proposed method is evaluated using two challenge datasets captured by a Kinect. Experiments show that our method can robustly recognize actions in real-time.',\n",
              "  'A co-boost framework for learning object categories from Google Images with 1st and 2nd order features.[SEP]Conventional object recognition techniques rely heavily on manually annotated image datasets to achieve good performances. However, collecting high quality datasets is really laborious. The image search engines such as Google Images seem to provide quantities of object images. Unfortunately, a large portion of the search images are irrelevant. In this paper, we propose a semi-supervised framework for learning visual categories from Google Images. We exploit a co-training algorithm, the CoBoost algorithm, and integrate it with two kinds of features, the 1st and 2nd order features, which define bag of words representation and spatial relationship between local features, respectively. We create two boosting classifiers based on the 1st and 2nd order features in the training, during which one classifier provides labels for the other. The 2nd order features are generated dynamically rather than extracted exhaustively to avoid high computation. An active learning technique is also introduced to further improve the performance. Experimental results show that the object models learned from Google Images by our method are competitive with the state-of-the-art unsupervised approaches and some supervised techniques on the standard benchmark datasets.',\n",
              "  'Fast Feature-Oriented Visual Connection for Large Image Collections.[SEP]Deriving the visual connectivity across large image collections is a computationally expensive task. Different from current image‐oriented match graph construction methods which build on pairwise image matching, we present a novel and scalable feature‐oriented image matching algorithm for large collections. Our method improves the match graph construction procedure in three ways. First, instead of building trees repeatedly, we put the feature points of the input image collection into a single kd‐tree and select the leaves as our anchor points. Then we construct an anchor graph from which each feature can intelligently find a small portion of related candidates to match. Finally, we design a new form of adjacency matrix for fast feature similarity measuring, and return all the matches in different photos across the whole dataset directly. Experiments show that our feature‐oriented correspondence algorithm can explore visual connectivity between images with significant improvement in speed.',\n",
              "  'Delimitation of Regions of Interest in Similarity Queries Visualization.[SEP]In Content Based Image Retrieval (CBIR) systems, the visualization of queries allows to add the human visual perception in the analysis process and facilitate the discovery of knowledge. Content-based queries can be performed comparing features extracted from images, such as color, texture, and shape. In this paper we propose ways to delimit the region of interest to be visualized in the execution of queries by similarity in complex datasets. Limiting the amount of data to be visualized allows keeping the distribution of mapped data closer to the real distribution, besides allowing the application of more expensive computational methods for multidimensional projection. The proposed techniques were implemented in a prototype that allows visualizing only the region in which the query is being performed, mapping the data in three-dimensional spaces and allowing users to interact with them, being favored by human perception to improve the analysis and understanding of the data.',\n",
              "  'Computer-Aided Diagnosis in Brain Computed Tomography Screening.[SEP]Currently, interpretation of medical images is almost exclusively made by specialized physicians. Although, the next decades will most certainly be of change and computer-aided diagnosis systems will play an important role in the reading process. Assisted interpretation of medical images has become one of the major research subjects in medical imaging and diagnostic radiology. From a methodological point of view, the main attraction for the resolution of this kind of problem arises from the combination of the image reading made by the radiologists, with the results obtained from using Artificial Intelligence based applications that will contribute to the reduction and eventually the elimination of perception errors. This article describes how machine learning algorithms can help distinguish normal readings in brain Computed Tomography from all its variations. The goal is to have a system that is able to detect normal appearing structures, thus identifying normal studies, making the reading by the radiologist unnecessary for a large proportion of the brain Computed Tomography scans.',\n",
              "  'Effect of layer-wise fine-tuning in magnification-dependent classification of breast cancer histopathological image.[SEP]A large and balanced training data are the foremost requirement in proper convergence of a deep convolutional neural network (CNN). Medical data always suffer from the problem of unbalancing and inadequacy that makes it difficult to train CNN from scratch. It is known that the transfer learning approach provides great potential to deal with inadequate dataset besides the benefit of faster training. The efficient transfer of knowledge from natural images to histopathological images has yet to be achieved. In view of the foregoing, an attempt has been made toward the classification of BreakHis dataset using pre-trained ‘AlexNet’ model with a suitable fine-tuning approach. The effective depth of fine-tuning is also determined at different levels of magnification (40×, 100×, 200× and 400 ×). The experimental trials conform that the moderate level of fine-tuning is an optimum choice for the classification of magnification-dependent histology images in contrast to the shallow and deep tuning of the pre-trained network which in turn depends on the size and relative distribution of a dataset. Additionally, the layer-wise fine-tuning approach provides a neck-to-neck performance with the latest state-of-the-art developments.',\n",
              "  'Semi-supervised Tissue Segmentation of 3D Brain MR Images.[SEP]Clustering algorithms have been popularly applied in tissue segmentation in MRI. However, traditional clustering algorithms could not take advantage of some prior knowledge of data even when it does exist. In this paper, we propose a new approach to tissue segmentation of 3D brain MRI using semi-supervised spectral clustering. Spectral clustering algorithm is more powerful than traditional clustering algorithms since it models the voxel-to-voxel relationship as opposed to voxel-to-cluster relationships. In the semi-supervised spectral clustering, two types of instance-level constraints: must-link and cannot-link as background prior knowledge are incorporated into spectral clustering, and the self-tuning parameter is applied to avoid the selection of the scaling parameter of spectral clustering. The semi-supervised spectral clustering is an effective tissue segmentation method because of its advantages in (1) better discovery of real data structure since there is no cluster shape restriction, (2) high quality segmentation results as it can obtain the global optimal solutions in the relaxed continuous domain by eigen-decomposition and combines the pairwise constraints information. Experimental results on simulated and real MRI data demonstrate its effectiveness.',\n",
              "  'Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring.[SEP]Locality-Sensitive Hashing (LSH) is one of the most popular methods for c-Approximate Nearest Neighbor Search (c-ANNS) in high-dimensional spaces. In this paper, we propose a novel LSH scheme based on the Longest Circular Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee. We introduce a novel concept of LCCS and a new data structure named Circular Shift Array (CSA) for k-LCCS search. The insight of LCCS search framework is that close data objects will have a longer LCCS than the far-apart ones with high probability. LCCS-LSH is LSH-family-independent, and it supports c-ANNS with different kinds of distance metrics. We also introduce a multi-probe version of LCCS-LSH and conduct extensive experiments over five real-life datasets. The experimental results demonstrate that LCCS-LSH outperforms state-of-the-art LSH schemes.',\n",
              "  'PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension.[SEP]Similarity search has been widely used in various fields, particularly in the Alibaba ecosystem. The open-source solutions to a similarity search of vectors can only support a query with a single vector, whereas real-life scenarios generally require a processing of compound queries. Moreover, existing open-source implementations only provide runtime libraries, which have difficulty meeting the requirements of industrial applications. To address these issues, we designed a novel scheme for extending the index-type of PostgreSQL (PG), which enables a similar vector search and achieves a high-performance level and strong reliability of PG. Two representative types of nearest neighbor search (NNS) algorithms are presented herein. These algorithms achieve a high performance, and afford advantages such as the support of composite queries and seamless integration of existing business data. The other NNS algorithms can be easily implemented under the proposed framework. Experiments were conducted on large datasets to illustrate the efficiency of the proposed retrieval mechanism.',\n",
              "  'A General and Efficient Querying Method for Learning to Hash.[SEP]As an effective solution to the approximate nearest neighbors (ANN) search problem, learning to hash (L2H) is able to learn similarity-preserving hash functions tailored for a given dataset. However, existing L2H research mainly focuses on improving query performance by learning good hash functions, while Hamming ranking (HR) is used as the default querying method. We show by analysis and experiments that Hamming distance, the similarity indicator used in HR, is too coarse-grained and thus limits the performance of query processing. We propose a new fine-grained similarity indicator, quantization distance (QD), which provides more information about the similarity between a query and the items in a bucket. We then develop two efficient querying methods based on QD, which achieve significantly better query performance than HR. Our methods are general and can work with various L2H algorithms. Our experiments demonstrate that a simple and elegant querying method can produce performance gain equivalent to advanced and complicated learning algorithms.'],\n",
              " '21_software_programmers_collaboration_developers': ['Variolite: Supporting Exploratory Programming by Data Scientists.[SEP]How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.',\n",
              "  'Consistency maintenance in real-time collaborative graphics editing systems.[SEP]Real-time collaborative graphics editing systems allow a group of users to view and edit the same graphics document at the same time from geographically dispersed sites connected by communication networks. Consistency maintenance in the face of concurrent accesses to shared objects is one of the core issues in the design of these types of systems. In this article, we propose an object-level multiversioning approach to consistency maintenance in real-time collaborative graphic editors. This approach is novel in achieving intention preservation and convergence, in preserving the work concurrently produced by multiple users in the face of conflict, and in minimizing the number of object versions for conflict resolution. Major technical contributions of this work include a formal specification of a unique combined effect for an arbitrary group of conflict and compatible operations, a distributed algorithm for incremental creation of multiple object versions, a consistent object identification scheme for multiple object versions, and a convergent layering scheme for overlapping objects. All algorithms and schemes presented in this article have been implemented in an Internet-based GRACE (graphics collaborative editing) system.',\n",
              "  'DistEdit: A Distributed Toolkit for Supporting Multiple Group Editors.[SEP]The purpose of our project is to provide toolkits for building applications that support collaboration between people in distributed environments. In this paper, we describe one such toolkit, called DistEdit, that can be used to build interactive group editors for distributed environments. This toolkit has the ability to support different editors simultaneously and provides a high degree of fault-tolerance against machine crashes. To evaluate the toolkit, we modified two editors to make use of the toolkit. The resulting editors allow users to take turns at making changes while other users observe the changes as they occur. We give an evaluation of the toolkit based on the development and use of these editors.',\n",
              "  'Elucidate: employing information visualisation to aid pedagogy for students.[SEP]Understanding the intricacies behind concurrency within object-oriented programming languages has always been a challenge for undergraduate students. While the lecture is a relatively passive learning experience for the student, the use of software visualisation offers the chance to examine the concepts covered in the lecture in an interactive, visual environment. Students can add further dimensions and greater depth to their understanding previously hindered by the pedagogy of this passive environment. Elucidate makes use of the JDI architecture in the Java language to create its own environment that allows students to execute any program within it. Elucidate utilises several information workspaces, each presenting a different perspective about the information, thus facilitating a students ability to employ it in a manner that best allows them to construct their own understanding. Students are able to navigate around multiple views, and through various levels of abstraction, revealing the inner workings and sequence of events in what would otherwise be a black-box program.',\n",
              "  'Viewing Object-Oriented Software with MetricAttitude: An Empirical Evaluation.[SEP]MetricAttitude is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In this paper, we present a preliminary empirical investigation based on a questionnaire-based survey to assess Metric Attitude with respect to source code comprehension tasks. Participants involved in this study were Computer Science students and software professionals. The results suggest that Metric Attitude is a viable means to comprehend source code and that both kinds of participants in the empirical investigation considered it to be appropriate in source code comprehension.',\n",
              "  'Enhancing Software Visualization with Information Retrieval.[SEP]I have enhanced Metric Attitude. It is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In particular, we have integrated an Information Retrieval engine and named this new version of visualization tool as Metric Attitude++. It allows the user to formulate a textual query and to show on the visual representation of the subject software the elements that are more similar to that query. This could be useful in all those cases in which a user needs to identify (or to localize) features implemented in the source code. Several filters are also available to hide possibly irrelevant details and to ease the browsing and then the comprehension of a software system. Finally, we have applied Metric Attitude++ on a number of object-oriented software systems. In this paper, we report preliminary results of a quantitative study on a widely studied open-source software, namely JEdit. On the basis of our results it seems that Metric Attitude++ can be effectively applied to different kinds of source code comprehension tasks and to concept location in source code, in particular.'],\n",
              " '22_brain_cognitive_attention_visual': ['Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation.[SEP]The rich literature on multiple object tracking (MOT) conclusively demonstrates that humans are able to visually track a small number of objects (Pylyshyn & Storm 1988, Alvarez & Franconeri 2007). There is considerably less agreement on what perceptual and cognitive processes are involved. While it is clear that MOT is attentionally demanding, various accounts of MOT performance centrally involve pre-attentional mechanisms as well. In this paper we present an account of object tracking in the ARCADIA framework (Bridewell & Bello 2015) that treats MOT as dependent upon both pre-attentive and attention-bound processes. We show that with minimal addition this model replicates a variety of core phenomena in the MOT literature and provides an algorithmic explanation of human performance limitations.',\n",
              "  'A Bayesian Model of the Effect of Object Context on Visual Attention.[SEP]Research in visual cognition has demonstrated that scene understanding is influenced by the contextual properties of objects, and a number of computational models have been proposed that capture specific context effects. However, a general model that predicts the fit of an arbitrary object with the context established by the rest of the scene is until now lacking. In this paper, we explain the contextual fit of objects in visual scenes using Bayesian topic models, which we induce from a database of annotated images. We evaluate our models firstly on synthetic object intrusion data, and then on eye-tracking data from a spot-the-difference task and from an object naming experiment. For the synthetic data, we find that our models are able to detect object intrusions accurately. For the eye-tracking data, we show that context scores derived from our models are associated with fixation latencies on target objects.',\n",
              "  'Inattentional Blindness in Visual Search.[SEP]Models of visual salience normally belong to one of two camps: models such as Experience Guided Search (E-GS), which emphasize top-down guidance based on task features, and models such as Attention as Information Maximisation (AIM), which emphasize the role of bottom-up saliency. In this paper, we show that E-GS and AIM are structurally similar and can be unified to create a general model of visual search with includes a generic prior over potential non-task related objects. We demonstrate that this model displays inattentional blindness, and that blindness can be modulated by adjusting the relative precisions of several terms within the model. At the same time, our model correctly accounts for a series of classical visual search results.',\n",
              "  'Learning and Variability in Spiking Neural Networks.[SEP]Neural networks exhibit ongoing, spatio-temporal patterns of spiking activity. Evidence shows that these patterns are metastable, i.e. temporary, transient, and non-stationary. Metastability is theorized to be adaptive for neural and cognitive function, but learning must somehow remain stable in the context of highly variable spike dynamics. In the present study, a neural network learning algorithm is developed to co-exist with intrinsic variability that arises from regulating spike propagation to stay near its critical branching point. The learning algorithm is based on reinforcement traces stored at synapses that change much more slowly than synaptic switches triggered to maintain critical branching. As a result, learning establishes a stable synaptic space within which variability and metastability can arise from critical branching. Model efficacy is demonstrated using time-delayed XOR learning, and spike dynamics are compared with evidence of metastability in hippocampal recordings.',\n",
              "  'Improving with Practice: A Neural Model of Mathematical Development.[SEP]The ability to improve in speed and accuracy as a result of repeating some task is an important hallmark of intelligent biological systems. We model the progression from a counting-based strategy for addition to a recall-based strategy. The model consists of two networks working in parallel: a slower basal ganglia loop, and a faster cortical network. The slow network methodically computes the count from one digit given another, corresponding to the addition of two digits, while the fast network gradually \"memorizes\" the output from the slow network. The faster network eventually learns how to add the same digits that initially drove the behaviour of the slower network. Performance of this model is demonstrated by simulating a fully spiking neural network that includes basal ganglia, thalamus and various cortical areas.',\n",
              "  'Thermodynamics and Cognition: Towards a Lawful Explanation of the Mind.[SEP]An argument is developed to show that the theoretical methods of description for biological and physical systems can be corroborated by appealing to the second law of thermodynamics. The separation dates back to Modern western philosophy, but we show that the second law’s influence on the evolutionary history of life at the scale of the global Earth system—a system that has demonstrated an exponential increase of entropy production over time— justifies rescinding this separation. From this perspective it appears that the necessity of ever increasing entropy in nature may constrain the organization and behavior of living organisms and cognitive processes. We suggest a new framework for understanding cognition by explaining memory at the scale of the brain-body-environment system with respect to its role in increasing entropy in nature. This framework, if developed further, may lead to a fruitful understanding of cognition by appealing to the necessity of physical laws.',\n",
              "  'This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.[SEP]This project represents a first step towards bridging the gap between HCI and cognition research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.',\n",
              "  'Visualizing and manipulating brain dynamics.[SEP]Brain is not a mere input-output information transformation system, but a dynamical system that generates spontaneous spatiotemporal patterns even without sensory inputs, executed movements, or cognitive tasks. These spontaneously generated patterns by brain dynamics are called spontaneous brain activities for experimental animals, and resting state brain activities for humans. The resting state brain activity of an individual contains much information about age, cognitive capability, mental disorder etc. By combining information decoding from brain activity and its neurofeedback in reinforcement learning paradigms, we can unconsciously control brain activity patterns corresponding to specific information. This leads to therapies of psychiatric disorders, unconscious manipulation of facial preferences, color qualia, confidence in decision making, increase of cognitive capability, etc. Ubicomp community can expect this technology will soon be available in much cheaper and lighter devices such as EEG and near infrared spectroscopy instead of heavy and expensive fMRI or MEG.',\n",
              "  'Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks.[SEP]Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential value for brain sensing in HCI user studies. Research has shown that, although large head movement significantly affects fNIRS data, typical keyboard use, mouse movement, and non-task-related verbalisations do not affect measurements during Verbal tasks. This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings, and 2) significantly extending our understanding of how artefacts affect recordings during Spatial tasks, since much of user interfaces and interaction is inherently spatial. Our results show that artefacts have a significantly different impact during Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool within HCI user studies.',\n",
              "  \"Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze.[SEP]We introduce an image annotation approach for the analysis of volumetric electron microscopic imagery of brain tissue. The core task is to identify and link tubular objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain tissue. In our approach an individual 'flies' through the 3D data at a high speed and maintains eye gaze focus on a single neuronal fiber, aided by navigation with a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing). In a participant experiment we validate the approach by demonstrating a tracing accuracy of about the respective radiuses of the traced fibers with browsing speeds of up to 40 brain sections per second.\",\n",
              "  'NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity.[SEP]We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.',\n",
              "  \"The Neuron Navigator: Exploring the information pathway through the neural maze.[SEP]Recent advances in microscopic imaging technology have enabled neuroscientists to obtain unprecedentedly clear images of neurons. To extract additional knowledge from the tangled neurons, for example, their connective relationships, is key to understanding how information is processed and transmitted within the brain. In this paper, we will introduce our recent endeavor, the Neuron Navigator (NNG), which integrates a 3D neuron image database into an easy-to-use visual interface. Via a flexible and user-friendly interface, NNG is designed to help researchers analyze and observe the connectivity within the neural maze and discover possible pathways. With NNG's 3D neuron image database, researchers can perform volumetric searches using the location of neural terminals, or the occupation of neuron volumes within the 3D brain space. Also, the presence of the neurons under a combination of spatial restrictions can be shown as well. NNG is a result of a multi-discipline collaboration between neuroscientists and computer scientists, and NNG has now been implemented on a coordinated brain space, that being, the Drosophila (fruit fly) brain. NNG is accessible through: http://211.73.64.34/NNG.\"],\n",
              " '23_trajectory_trajectories_mobility_urban': ['Visual Exploration of Sparse Traffic Trajectory Data.[SEP]In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.',\n",
              "  'Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit.[SEP]The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.',\n",
              "  'Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats.[SEP]We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.',\n",
              "  'Mining large-scale, sparse GPS traces for map inference: comparison of approaches.[SEP]We address the problem of inferring road maps from large-scale GPS traces that have relatively low resolution and sampling frequency. Unlike past published work that requires high-resolution traces with dense sampling, we focus on situations with coarse granularity data, such as that obtained from thousands of taxis in Shanghai, which transmit their location as seldom as once per minute. Such data sources can be made available inexpensively as byproducts of existing processes, rather than having to drive every road with high-quality GPS instrumentation just for map building - and having to re-drive roads for periodic updates. Although the challenges in using opportunistic probe data are significant, successful mining algorithms could potentially enable the creation of continuously updated maps at very low cost.',\n",
              "  'Traveling Salesman in Reverse: Conditional Markov Entropy for Trajectory Segmentation.[SEP]We are interested in inferring the set of waypoints (or intermediate destinations) of a mobility trajectory in the absence of timing information. We find that, by mining a dataset of real mobility traces, computing the entropy of conditional Markov trajectory enables us to uncover waypoints, even though no timing information nor absolute geographic location is provided. We build on this observation and design an efficient algorithm for trajectory segmentation. Our empirical evaluation demonstrates that the entropy-based heuristic used by our segmentation algorithm outperforms alternative approaches as it is 43% more accurate than a geometric approach and 20% more accurate than path-stretch based approach. We further explore the link between trajectory entropy, mobility predictability and the nature of intermediate locations using a route choice model on real city maps.',\n",
              "  \"CityMomentum: an online approach for crowd behavior prediction at a citywide level.[SEP]Human movements are difficult to predict, especially, when we consider rare behaviors that deviate from normal daily routines. By tracing the behavior of a person over a long period, we can model their daily routines and predict periodical behaviors, whereas rare behaviors, such as participating in the New Year's Eve countdown, can hardly be predicted readily and thus they have usually been treated as outliers of the daily routines in most existing studies. However, for scenarios such as emergency management or intelligent traffic regulation, we are more interested in rare behaviors than daily routines. Using human mobility Big Data, the rare behavior of each individual in a social crowd is no longer rare and thus it may be predicted when we analyze the crowd behavior at a citywide level. Therefore in this study, instead of predicting movement based on daily routines, we make short-term predictions based on the recent movement observations. We propose a novel model called CityMomentum as a predicting-by-clustering framework for sampling future movement using a mixture of multiple random Markov chains, each of which is a Naive Movement Predictive model trained with the movements of the subjects that belong to each cluster. We apply our approach to a big mobile phone GPS log dataset and predict the short-term future movements, especially during the Comiket 80 and New Year's Eve celebration. We evaluate our prediction by a Earth Mover Distance (EMD) based metric, and show our approach accurately predicts the crowd behavior during the rare crowd events, which makes an early crowd event warning and regulation possible in the emergent situations.\"],\n",
              " '24_graphics_graphic_standards_phigs': ['Object-Oriented Data Modelling for Graphics Databases: a Declarative Approach.[SEP]This paper presents a new scheme to integrate the declarative approach to graphics and object‐oriented data modelling techniques to form a fruitful symbiosis for constraint‐based graphics database systems. It has rich modelling constructs to describe graphics data and allows sharing of representation. It also provides useful mechanisms for management of integrity constraints. We have also identified important classes of constraints in the context of object‐oriented graphics database systems. Examples are given for maintenance of constraints at the time of insertion, deletion and modification.',\n",
              "  'GKS-9x: The Design Output Primitive, an Approach to a Specification.[SEP]This paper describes an approach to the formal definition of the design primitive introduced in the revision of the ISO/IEC computer graphics standard, GKS. The paper starts with a general description of the design primitive and then describes the specification (which is given in the Z notation) and the motivation for the approach taken in some detail. The paper concludes with a reflection on the contribution of this work, and the descriptive style adopted an the GKS revision, to the role of formal description in the presentation of graphics standards.',\n",
              "  'The Effectiveness of High-level Graphical Languages in Dealing with Various Graphical Domains.[SEP]There are many domains in which graphical programming languages can be applied. Use of a particular graphical programing language will be limited if the domains in which it can be applied are restricted. High-level graphical languages provide simply expressed constructs for the definition, manipulation, inquiry, and external representation of graphical data. These capabilities permit the application to various domains of high-level graphical languages. Five specific domains are discussed; an example of an application of the graphical language LIG is presented in each domain.',\n",
              "  'Preface.[SEP]In this issue, we have four additional papers from 35th Computer Graphics International conference (CGI 2018) held on 11–14 June, 2018 in Bintan, Indonesia. Moreover, three papers from Euro VA 2017 held on 12–13 June 2017 in Barcelona, Spain and three papers from Cyberworlds 2017 held on 20–22 September 2017 in Chester, UK are included.',\n",
              "  'A Breezy Summer Read.[SEP]Editor in Chief Torsten Möller discusses the articles in the July/August 2018 issue of IEEE Computer Graphics and Applications.',\n",
              "  'Steps to Effective Business Graphics.[SEP]Europe is becoming aware that a political determination to collaborate is required, if it wants to attain the position it could claim on the basis of its research achievements. This is especially true in the field of Computer Graphics. The program ESPRIT is hopefully a decisive step in this direction.'],\n",
              " '25_series_time_patterns_mining': ['Dual-Domain Hierarchical Classification of Phonetic Time Series.[SEP]Phonemes are the smallest units of sound produced by a human being. Automatic classification of phonemes is a well-researched topic in linguistics due to its potential for robust speech recognition. With the recent advancement of phonetic segmentation algorithms, it is now possible to generate datasets of millions of phonemes automatically. Phoneme classification on such datasets is a challenging data mining task because of the large number of classes (over a hundred) and complexities of the existing methods. In this paper, we introduce the phoneme classification problem as a data mining task. We propose a dual-domain (time and frequency) hierarchical classification algorithm. Our method uses a Dynamic Time Warping (DTW) based classifier in the top layers and time-frequency features in the lower layer. We cross-validate our method on phonemes from three online dictionaries and achieved up to 35% improvement in classification compared to existing techniques. We provide case studies on classifying accented phonemes and speaker invariant phoneme classification.',\n",
              "  \"Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels.[SEP]Unsupervised semantic segmentation in the time series domain is a much-studied problem due to its potential to detect unexpected regularities and regimes in poorly understood data. However, the current techniques have several shortcomings, which have limited the adoption of time series semantic segmentation beyond academic settings for three primary reasons. First, most methods require setting/learning many parameters and thus may have problems generalizing to novel situations. Second, most methods implicitly assume that all the data is segmentable, and have difficulty when that assumption is unwarranted. Finally, most research efforts have been confined to the batch case, but online segmentation is clearly more useful and actionable. To address these issues, we present an algorithm which is domain agnostic, has only one easily determined parameter, and can handle data streaming at a high rate. In this context, we test our algorithm on the largest and most diverse collection of time series datasets ever considered, and demonstrate our algorithm's superiority over current solutions. Furthermore, we are the first to show that semantic segmentation may be possible at superhuman performance levels.\",\n",
              "  'On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis.[SEP]Multivariate time series (MTS) data sets are common in-various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as principal component analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficients concisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.',\n",
              "  \"Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations.[SEP]We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs - a space-efficient time series visualization technique - across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception.\",\n",
              "  'Visual-Interactive Preprocessing of Multivariate Time Series Data.[SEP]Pre‐processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre‐processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre‐processing pipelines, human‐in‐the‐loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in‐depth research in visual analytics. We present a visual‐interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre‐processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty‐aware pre‐processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre‐processing in general and for uncertainty‐aware pre‐processing of multivariate time series in particular.',\n",
              "  'Qualizon graphs: space-efficient time-series visualization with qualitative abstractions.[SEP]In several application fields, the joint visualization of quantitative data and qualitative abstractions can help analysts make sense of complex time series data by associating precise numeric values with corresponding domain-specific interpretations, such as good, bad, high, low, normal. At the same time, the need to analyse large multivariate time-oriented datasets often calls for keeping visualizations as compact as possible. In this paper, we introduce Qualizon Graphs, a compact visualization that combines quantitative data and qualitative abstractions. It is based on the well known Horizon Graphs, but instead of a predefined number of equally sized bands, it uses as many bands as qualitative categories with corresponding different sizes. In this way, Qualizon Graphs increase the data density of visualized quantitative values and inherently integrate qualitative abstractions. A user study shows that Qualizon Graphs are as fast and accurate as Horizon Graphs for quantitative data, and are an alternative to state-of-the-art visualizations for both quantitative and qualitative data, enabling a trade-off between speed and accuracy.'],\n",
              " '26_fabrication_printing_print_manufacturing': ['Stress-Constrained Thickness Optimization for Shell Object Fabrication.[SEP]We present an approach to fabricate shell objects with thickness parameters, which are computed to maintain the user‐specified structural stability. Given a boundary surface and user‐specified external forces, we optimize the thickness parameters according to stress constraints to extrude the surface. Our approach mainly consists of two technical components: First, we develop a patch‐based shell simulation technique to efficiently support the static simulation of extruded shell objects using finite element methods. Second, we analytically compute the derivative of stress required in the sensitivity analysis technique to turn the optimization into a sequential linear programming problem. Experimental results demonstrate that our approach can optimize the thickness parameters for arbitrary surfaces in a few minutes and well predict the physical properties, such as the deformation and stress of the fabricated object.',\n",
              "  'Computational Design and Fabrication.[SEP]Computer graphics research is increasingly interested in the high-level analysis and processing of geometric objects. By acquiring a structural or functional understanding of 3D shapes, researchers are able to tackle mid- to high-level design problems for which machine computations can replace or at least relieve human efforts. In parallel, with the rapid advances in 3D printing technologies, many design solutions explored by researchers and practitioners are focusing on the needs and constraints arising from physical fabrication. The contributions in this special issue are cross-disciplinary, connecting physical fabrication with design and processing tasks in new domains including circuit design, geospatial visualization, and 3D scanning, leading to never-before-seen 3D printing applications.',\n",
              "  'Cost-effective printing of 3D objects with self-supporting property.[SEP]The fused deposition modeling (FDM) printer is a simple, affordable and widely used device in the 3D printing society. However, the high price of printing materials is one of major restrictive factors for its further application. Based on the self-supporting property of printing materials, we present an optimization method to reduce the total material consumption of 3D printed objects themselves and their support structures for FDM printers in this paper. We first develop an orientation optimization scheme to reduce the outer support volume of a printed model. The volume is evaluated according to the depths of 3D model fragments obtained by the depth peeling technique in an optimization process. We then build a self-supporting frame with a set of scale-adaptive parallelepiped grids to replace the solid interior of the printed model for further reducing the material consumption. In our orientation optimization scheme, the overhanging area detecting function can detect the self-supporting regions of a 3D model in terms of the depths stored in the graphical processing unit memory. The self-supporting frame with grid structures inside printed models does not need to add additional support structures during the printing process. Experimental results indicate that our method is faster and consumes less printing materials than the state-of-the-art algorithms.',\n",
              "  'TuVe: A Shape-changeable Display using Fluids in a Tube.[SEP]We propose TuVe, a novel shape-changing display consisting of a flexible tube and fluids, in which the droplets flowing through the tube compose the display medium that represents information. In this system, every colored droplet is flowed by controlling valves and a pump connected to the tube. The display part employs a flexible tube that can be shaped to any structure (e.g., wrapped around a specific object), which is achieved by a calibration made to capture the tube structure using image processing with a camera. A performance evaluation reveals that our prototype succeeds in controlling each droplet with a positional error of 2 mm or less, which is small enough to show such simple characters as alphabetic characters using a 7 × 7-pixel resolution display. We also discuss example applications, such as large public displays and flow-direction visualization, that illustrate the characteristics of the TuVe display.',\n",
              "  'Happy Moves, Sad Grooves: Using Theories of Biological Motion and Affect to Design Shape-Changing Interfaces.[SEP]The design of shape-changing interfaces to show emotions relies on craft skill with few clear guidelines. Through two experiments, we explore how to design such interfaces using theories of the relation between biological motion and affect. In the first experiment, 19 participants viewed six shape-changing behaviors that varied the velocity, fluidity, direction, and orientation of the movement of an extrusion from a small box in accordance with existing theories of affective motion. Participants were able to recognize four of the six intended basic Ekman emotions (sadness, fear, happiness, surprise) with above-chance probability. The second experiment used 36 shape-changing behaviors that systematically varied speed, regularity of motion, and direction. For each behavior, 23 participants rated valence, arousal, and dominance. Speed, direction, and orientation impacted emotion ratings significantly and in the predicted directions. These results offer an initial basis for the systematic design of emotions in shape-changing interfaces.',\n",
              "  'Understanding the Benefits and Drawbacks of Shape Change in Contrast or Addition to other Modalities.[SEP]Shape changing interfaces enable exciting new ways to interact with devices, to communicate information, meaning and affect, and provide dynamic affordance. Such interfaces are often complex and more expensive to fabricate compared to tangible, screen-based and voice interfaces. The research field has yet to explore the advantages and drawbacks of shape change in contrast to other modalities. The research outlined in this paper aims to evaluate shape changing interfaces for different purposes in contrast to interfaces that rely on tangible, screen-based or voice interaction. Shape change will be explored in the context of explainable AI to examine how it affects aspects like usability, user experience, user engagement and trust. The aim of this research is to generate an understanding about the conditions under which shape changing interfaces are beneficial and when traditional or multimodal interfaces are more appropriate.',\n",
              "  'Instrumenting and Analyzing Fabrication Activities, Users, and Expertise.[SEP]The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces.',\n",
              "  \"Automatics: Dynamically Generating Fabrication Tasks to Adapt to Varying Contexts.[SEP]When fabricating, it is common to follow a prescribed set of steps in a tutorial or how-to. While popular, such explicit knowledge resources have many inconsistencies and omissions, use static illustrations, and cannot adapt to drop-in makers or a maker's mistakes. To overcome many of these issues, this work presents Automatics, a novel explicit knowledge resource system that dynamically generates fabrication activities for one or more makers based on their current environmental and fabrication context. Automatics assigns tasks to makers based on the past tools and components the maker was working with, enables makers to recover from mistakes through model regeneration, suggests alternative tools if a needed tool is unavailable or in use, and allows multiple makers to drop-in throughout a fabrication activity. Initial usage and feedback from novice makers showed that Automatics increases the number of tasks that can be completed compared to paper instructions, decreases frustration, and improves one's understanding of the global context of assigned tasks during fabrication activities.\",\n",
              "  \"Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures.[SEP]Digital fabrication tools have transformed how people work in micro- and small-scale manufacturing settings. While increasing efficiency and precision, these tools raise concerns around user agency and control. This paper describes an exploratory study investigating the felt work experience and desired futures of professionals who use fabrication tools. We conducted co-design workshops with 23 professionals who use 3D printers, laser cutters, and CNC routers. We probed about current practices; machine awareness and autonomy; and user agency. Our findings reveal that current tools are not very professional. They are unreliable and untrustworthy. Participants desired smarter tools that can actively prevent errors and perform self-calibration and self-maintenance. They had few concerns that more intelligence would impact agency. They desired tools that could negotiate trade-offs between time, cost, and quality; and that can operate as super-human shop assistants. We discuss the implications of these findings as opportunities for research that can improve professionals' work experience.\"],\n",
              " '27_smart_activities_context_interfaces': [\"Mixed-initiative conflict resolution for context-aware applications.[SEP]A number of technologies have contributed to automatically resolving resource conflicts between multiple users in a smart space. However, such systems eliminate the users' ability to perform this conflict resolution by themselves, which they actually prefer to do in certain circumstances. Since both resolution approaches have their merits, we propose a mixed-initiative conflict resolution system, which combines automatic conflict resolution with mediated, or user-driven, resolution by exploiting contextual information in context-aware applications. An evaluation of our system found that users prefer to use a mediated resolution approach when their preferences about outcome are very different from others', but have no preferred method when their preferences about outcome are similar to others'.\",\n",
              "  \"A user's perspective of design for context-awareness.[SEP]Along with the development of microchip and sensing technologies, more and more Context-Aware applications have been introduced to our daily life to engage us in information-rich environments. Unlike many desktop applications, Context-Aware applications have usually been used to support users in dynamic situations by utilizing many resources available through physical environments. This research takes a user's perspective on Context-Aware activities, to focus on user's motivation and perception among dynamic surroundings, and aims to demonstrate the role and importance of user involvement for Context-Aware services.\",\n",
              "  'A goal-oriented interface to consumer electronics using planning and commonsense reasoning.[SEP]We are reaching a crisis with design of user interfaces for consumer electronics. Flashing 12:00 time indicators, push-and-hold buttons, and interminable modes and menus are all symptoms of trying to maintain a one-to-one correspondence between functions and physical controls, which becomes hopeless as the number of capabilities of devices grows. We propose instead to orient interfaces around the goals that users have for the use of devices.We present Roadie, a user interface agent that provides intelligent context-sensitive help and assistance for a network of consumer devices. Roadie uses a Commonsense knowledge base to map between user goals and functions of the devices, and an AI partial-order planner to provide mixed-initiative assistance with executing multi-step procedures and debugging help when things go wrong.',\n",
              "  'Modelling internet based applications for designing multi-device adaptive interfaces.[SEP]The wide spread of mobile devices in the consumer market has posed a number of new issues in the design of internet applications and their user interfaces. In particular, applications need to adapt their interaction modalities to different portable devices. In this paper we address the problem of defining models and techniques for designing internet based applications that automatically adapt to different mobile devices. First, we define a formal model that allows for specifying the interaction in a way that is abstract enough to be decoupled from the presentation layer, which is to be adapted to different contexts. The model is mainly based on the idea of describing the user interaction in terms of elementary actions. Then, we provide a formal device characterization showing how to effectively implements the AIUs in a multidevice context.',\n",
              "  'Robust Annotation of Mobile Application Interfaces in Methods for Accessibility Repair and Enhancement.[SEP]Accessibility issues in mobile apps make those apps difficult or impossible to access for many people. Examples include elements that fail to provide alternative text for a screen reader, navigation orders that are difficult, or custom widgets that leave key functionality inaccessible. Social annotation techniques have demonstrated compelling approaches to such accessibility concerns in the web, but have been difficult to apply in mobile apps because of the challenges of robustly annotating interfaces. This research develops methods for robust annotation of mobile app interface elements. Designed for use in runtime interface modification, our methods are based in screen identifiers, element identifiers, and screen equivalence heuristics. We implement initial developer tools for annotating mobile app accessibility metadata, evaluate our current screen equivalence heuristics in a dataset of 2038 screens collected from 50 mobile apps, present three case studies implementing runtime repair of common accessibility issues, and examine repair of real-world accessibility issues in 26 apps. These contributions overall demonstrate strong opportunities for social annotation in mobile accessibility.',\n",
              "  'Workshop W2: multi-user and ubiquitous user interfaces (MU3I 2006).[SEP]The main objective of the third workshop on Multi-User and Ubiquitous User Interfaces (MU3I 2006) is to bring people with relevant backgrounds (e.g. interface design, CSCW, ubiquitous computing) together to discuss two key questions in this field: How can we build interfaces, which span multiple devices so that the user knows that they can be used to control a specific application? How can we build interfaces for public displays? Therefore, the main outcome of the workshop is expected to consists of further insights into those problems, potential solutions and a research agenda to investigate these further.',\n",
              "  \"The Upcycled Home: Removing Barriers to Lightweight Modification of the Home's Everyday Objects.[SEP]The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home.\",\n",
              "  'Alternative Avenues for IoT: Designing with Non-Stereotypical Homes.[SEP]We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen.',\n",
              "  \"Making place for clutter and other ideas of home.[SEP]In this article, we examine the containment of clutter in family homes and, from this, outline considerations for design. Selected materials from an ethnographically informed study of home life are used to detail the ways in which families contain their clutter in bowls and drawers. Clutter, within these containers, is found to be made up of a heterogeneous collection of things that, for all manner of reasons, hold an ambiguous status in the home. It is shown that bowls and drawers provide a “safe” site of containment for clutter, giving the miscellany of content the “space” to be properly dealt with and classified, or to be left unresolved. The shared but idiosyncratic practices families use to contain their clutter are seen to be one of the ways in which the home, or at least the idea of home, is collectively produced. It is also part of the means by which families come to make their homes distinct and unique. These findings are used to consider what it might mean to design for the home, and to do so in ways that are sensitive to the idiosyncratic systems of household organization. In conclusion, thought is given to how we design for people's ideas of home, and how we might build sites of uncertainty into homes, where physical as well as digital things might coalesce.\",\n",
              "  'Applications of mobile activity recognition.[SEP]Activity Recognition (AR), which identifies the activity that a user performs, is attracting a tremendous amount of attention, especially with the recent explosion of smart mobile devices. These ubiquitous mobile devices, most notably but not exclusively smartphones, provide the sensors, processing, and communication capabilities that enable the development of diverse and innovative activity recognition-based applications. However, although there has been a great deal of research into activity recognition, surprisingly little practical work has been done in the area of applications in mobile devices. In this paper we describe and categorize a variety of activity recognition-based applications. Our hope is that this work will encourage the development of such applications and also influence the direction of activity recognition research.',\n",
              "  'Learning from less for better: semi-supervised activity recognition via shared structure discovery.[SEP]Despite the active research into, and the development of, human activity recognition over the decades, existing techniques still have several limitations, in particular, poor performance due to insufficient ground-truth data and little support of intra-class variability of activities (i.e., the same activity may be performed in different ways by different individuals, or even by the same individuals with different time frames). Aiming to tackle these two issues, in this paper, we present a robust activity recognition approach by extracting the intrinsic shared structures from activities to handle intra-class variability, and the approach is embedded into a semi-supervised learning framework by utilizing the learned correlations from both labeled and easily-obtained unlabeled data simultaneously. We use l2,1 minimization on both loss function and regularizations to effectively resist outliers in noisy sensor data and improve recognition accuracy by discerning underlying commonalities from activities. Extensive experimental evaluations on four community-contributed public datasets indicate that with little training samples, our proposed approach outperforms a set of classical supervised learning methods as well as those recently proposed semi-supervised approaches.',\n",
              "  \"Supporting activity recognition by visual analytics.[SEP]Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.\"],\n",
              " '28_vessel_imaging_ultrasound_clinical': ['HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments.[SEP]High Intensity Focused Ultrasound (HIFU) is a non invasive therapeutic method, which has been a subject of interest for the treatment of various kinds of tumors. Despite the numerous advantages, HIFU techniques do not reach the high delivery precision like other therapies (e.g., radiotherapy). For this reason, a correct therapy planning and monitoring in HIFU treatments remains a challenge. We propose HIFUpm, a visual analytics approach which enables the visualization of the HIFU simulation results, while guiding the user in the evaluation of the procedure. We illustrate the use of HIFUpm for an ablative treatment of an osteoid osteoma. This use case demonstrates that HIFUpm provides a flexible visual environment to plan and monitor HIFU procedures.',\n",
              "  '3D heart-vessel reconstruction from biplane angiograms.[SEP]Biplane angiography generates just two time equivalent X-ray images. These X-ray systems can be rotated independently from each other (restricted by possible collisions only). The article explains how highly accurate 3D models of vessel systems can be reconstructed, visualized, and quantitatively evaluated from these X-ray images.',\n",
              "  \"Automatic Transfer Function Specification for Visual Emphasis of Coronary Artery Plaque.[SEP]Cardiovascular imaging with current multislice spiral computed tomography (MSCT) technology enables a non‐invasive evaluation of the coronary arteries. Contrast‐enhanced MSCT angiography with high spatial resolution allows for a segmentation of the coronary artery tree. We present an automatically adapted transfer function (TF) specification to highlight pathologic changes of the vessel wall based on the segmentation result of the coronary artery tree. The TFs are combined with common visualization techniques, such as multiplanar reformation and direct volume rendering for the evaluation of coronary arteries in MSCT image data. The presented TF‐based mapping of CT values in Hounsfield Units (HU) to color and opacity leads to a different color coding for different plaque types. To account for varying HU values of the vessel lumen caused by the contrast medium, the TFs are adapted to each dataset by local histogram analysis. We describe an informal evaluation with three board‐certified radiologists which indicates that the represented visualizations guide the user's attention to pathologic changes of the vessel wall as well as provide an overview about spatial variations.\",\n",
              "  'Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms.[SEP]Blood flow simulations play an important role for the understanding of vascular diseases, such as aneurysms. However, analysis of the resulting flow patterns, especially comparisons across patient groups, are challenging. Typically, the hemodynamic analysis relies on trial and error inspection of the flow data based on pathline visualizations and surface renderings. Visualizing too many pathlines at once may obstruct interesting features, e.g., embedded vortices, whereas with too little pathlines, particularities such as flow characteristics in aneurysm blebs might be missed. While filtering and clustering techniques support this task, they require the pre-computation of pathlines densely sampled in the space-time domain. Not only does this become prohibitively expensive for large patient groups, but the results often suffer from undersampling artifacts. In this work, we propose the usage of evolutionary algorithms to reduce the overhead of computing pathlines that do not contribute to the analysis, while simultaneously reducing the undersampling artifacts. Integrated in an interactive framework, it efficiently supports the evaluation of hemodynamics for clinical research and treatment planning in case of cerebral aneurysms. The specification of general optimization criteria for entire patient groups allows the blood flow data to be batch-processed. We present clinical cases to demonstrate the benefits of our approach especially in presence of aneurysm blebs. Furthermore, we conducted an evaluation with four expert neuroradiologists. As a result, we report advantages of our method for treatment planning to underpin its clinical potential.',\n",
              "  'Illustration-Inspired Visualization of Blood Flow Dynamics.[SEP]Image-based computational fluid dynamics (CFD) is a central tool in the evaluation of hemodynamic factors in cardiovascular disease development and treatment, to the point where major vendors are now seeking to deploy CFD solvers on their medical imaging platforms. Detailed hemodynamic data available from CFD generate large data sets due to complex flow, which are difficult to render clearly - and thus communicate to clinical stakeholders - using conventional engineering flow visualization techniques. This is especially challenging considering the four-dimensional nature of the flow patterns (i.e., Rapidly varying in space and time), as well as the clinical need for generating static reports rather than cumbersome digital animations. Taking a cue from the rich history of biomedical illustration, our goal is to use this opportunity for developing new data-driven paradigms for visualizing blood flow based on the principles of illustration, sequential art, and the visual vocabularies and conventions of radiology and vascular surgery.',\n",
              "  'Occlusion-free Blood Flow Animation with Wall Thickness Visualization.[SEP]We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.'],\n",
              " '29_texture_textures_synthesis_image': ['Texture Synthesis for Mobile Data Communications.[SEP]This paper presents an approach to image coding that first paints a regularly arranged dotted pattern, using colors picked from a texture sample with features corresponding to the embedded data. It then camouflages the dotted pattern using the same texture sample while preserving quality comparable to that of existing synthesis techniques.',\n",
              "  'Deterministic Texture Analysis and Synthesis Using Tree Structure Vector Quantization.[SEP]Texture analysis and synthesis is very important for computer graphics, vision, and image processing. This paper describes an algorithm which can produce new textures with a matching visual appearance from a given example image. Our algorithm is based on a model that characterizes textures using a nonlinear deterministic function. During analysis, an example texture is summarized into this function using tree structure vector quantization. An output texture, initially random noise, is then synthesized from this estimated function. Compared to existing approaches, our algorithm can efficiently generate a wide variety of textures. The effectiveness of our approach is demonstrated using standard test images from the Brodatz texture album.',\n",
              "  'Hidden message in a deformation-based texture.[SEP]We present stego-texture, a unique texture synthesis method that allows users to deliver personalized messages with beautiful, decorative textures. Our approach was inspired by the success of recent work generating marbling textures using mathematical functions. We were able to transform an input image or a text message into an intricate texture by combining the seven basic, reversible functions provided in the system. Later, the input image or message could be recovered by reversing the process of these functions. During the design process, the parameters of operations were automatically recorded, encrypted and invisibly embedded into the final pattern to create a stego-texture. In this way, the receiver could extract the hidden message from the stego-texture without the need for extra information from the sender. To ensure that the delivered message is unnoticeably covered by the texture, we propose a new technique for automatically creating a background that is harmonious with the message based on a set of visual perception cues.',\n",
              "  'Application-Specific Tone Mapping Via Genetic Programming.[SEP]High dynamic range (HDR) imagery permits the manipulation of real‐world data distinct from the limitations of the traditional, low dynamic range (LDR), content. The process of retargeting HDR content to traditional LDR imagery via tone mapping operators (TMOs) is useful for visualizing HDR content on traditional displays, supporting backwards‐compatible HDR compression and, more recently, is being frequently used for input into a wide variety of computer vision applications. This work presents the automatic generation of TMOs for specific applications via the evolutionary computing method of genetic programming (GP). A straightforward, generic GP method that generates TMOs for a given fitness function and HDR content is presented. Its efficacy is demonstrated in the context of three applications: Visualization of HDR content on LDR displays, feature mapping and compression. For these applications, results show good performance for the generated TMOs when compared to traditional methods. Furthermore, they demonstrate that the method is generalizable and could be used across various applications that require TMOs but for which dedicated successful TMOs have not yet been discovered.',\n",
              "  'A Tone Reproduction Operator for All Luminance Ranges Considering Human Color Perception.[SEP]In this paper, we present a novel tone reproduction operator that is able to handle the color shift that occurs in photopic, mesopic, and scotopic vision, using a model based on a two-stage model of human color vision and psychophysical data obtained from measurements of human color perception. Since conventional methods are limited to generating images under a certain visual condition, it is difficult to apply just one operator to deal with scenes with continuous change within a wide luminance range, such as various scenes in movies. To overcome this problem, we have developed a model based on psychophysical data involving wavelength discrimination within a wide luminance range, which provides us with clues about the change of color perception. That is, the spectral sensitivity shifts toward the short wavelengths and decreases according to the adaptation light levels. By integrating the wavelength discrimination into our model, the proposed operator enables us to compute the transition of color perception under a wide range of viewing conditions.',\n",
              "  'Style Aware Tone Expansion for HDR Displays.[SEP]The vast majority of video content existing today is in Standard Dynamic Range (SDR) format and there is a strong interest in upscaling this content for upcoming High Dynamic Range (HDR) displays. Tone expansion or inverse tone mapping converts SDR content into HDR format using Expansion Operators (EO). In this paper, we show that current EO’s do not perform as well when dealing with content of various lighting style aesthetics. In addition to this, we present a series of perceptual user studies evaluating user preference for lighting style in HDR content. This study shows that tone expansion of stylized content takes the form of gamma correction and we propose a method that adapts the gamma value to the style of the video. We validate our method through a subjective evaluation against state-of-the-art methods. Furthermore, our work has been oriented for 1000 nits HDR displays and we present a framework positioning our method in conformance with existing SDR standards and upcoming HDR TV standards.'],\n",
              " '2_visualization_topic_visual_visualizations': ['Patterns for visualization evaluation.[SEP]We propose a patterns-based approach to evaluating data visualization: a set of general and reusable solutions to commonly occurring problems in evaluating tools, techniques, and systems for visual sensemaking. Patterns have had significant impact in a wide array of disciplines, particularly software engineering, and we believe that they provide a powerful lens for looking at visualization evaluation by offering practical, tried-and-tested tips and tricks that can be adopted immediately. The 12 patterns presented here have also been added to a freely editable Wiki repository. The motivation for creating this evaluation pattern language is to (a) disseminate hard-won experience on visualization evaluation to researchers and practitioners alike; to (b) provide a standardized vocabulary for designing visualization evaluation; and to (c) invite the community to add new evaluation patterns to a growing repository of patterns.',\n",
              "  \"Metrics for measuring human interaction with interactive visualizations for information analysis.[SEP]There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.\",\n",
              "  'Learning-based evaluation of visual analytic systems.[SEP]Evaluation in visualization remains a difficult problem because of the unique constraints and opportunities inherent to visualization use. While many potentially useful methodologies have been proposed, there remain significant gaps in assessing the value of the open-ended exploration and complex task-solving that the visualization community holds up as an ideal. In this paper, we propose a methodology to quantitatively evaluate a visual analytics (VA) system based on measuring what is learned by its users as the users reapply the knowledge to a different problem or domain. The motivation for this methodology is based on the observation that the ultimate goal of a user of a VA system is to gain knowledge of and expertise with the dataset, task, or tool itself. We propose a framework for describing and measuring knowledge gain in the analytical process based on these three types of knowledge and discuss considerations for evaluating each. We propose that through careful design of tests that examine how well participants can reapply knowledge learned from using a VA system, the utility of the visualization can be more directly assessed.',\n",
              "  'Text visualization techniques: Taxonomy, visual survey, and community insights.[SEP]Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.',\n",
              "  'Visualizing the Performance of Computational Linguistics Algorithms.[SEP]We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components',\n",
              "  'Quantity estimation in visualizations of tagged text.[SEP]A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.',\n",
              "  'MetaLDA: A Topic Model that Efficiently Incorporates Meta Information.[SEP]Besides the text content, documents and their associated words usually come with rich sets of meta information, such as categories of documents and semantic/syntactic features of words, like those encoded in word embeddings. Incorporating such meta information directly into the generative process of topic models can improve modelling accuracy and topic quality, especially in the case where the word-occurrence information in the training data is insufficient. In this paper, we present a topic model, called MetaLDA, which is able to leverage either document or word meta information, or both of them jointly. With two data argumentation techniques, we can derive an efficient Gibbs sampling algorithm, which benefits from the fully local conjugacy of the model. Moreover, the algorithm is favoured by the sparsity of the meta information. Extensive experiments on several real world datasets demonstrate that our model achieves comparable or improved performance in terms of both perplexity and topic quality, particularly in handling sparse texts. In addition, compared with other models using meta information, our model runs significantly faster.',\n",
              "  'Discriminatively Enhanced Topic Models.[SEP]This paper proposes a space-efficient, discriminatively enhanced topic model: a V structured topic model with an embedded log-linear component. The discriminative log-linear component reduces the number of parameters to be learnt while outperforming baseline generative models. At the same time, the explanatory power of the generative component is not compromised. We establish its superiority over a purely generative model by applying it to two different ranking tasks: (a) In the first task, we look at the problem of proposing alternative citations given textual and bibliographic evidence. We solve it as a ranking problem in itself and as a platform for further qualitative analysis of convergence of scientific phenomenon. (b) In the second task we address the problem of ranking potential email recipients based on email content and sender information.',\n",
              "  'Stochastic collapsed variational Bayesian inference for latent Dirichlet allocation.[SEP]There has been an explosion in the amount of digital text information available in recent years, leading to challenges of scale for traditional inference algorithms for topic models. Recent advances in stochastic variational inference algorithms for latent Dirichlet allocation (LDA) have made it feasible to learn topic models on very large-scale corpora, but these methods do not currently take full advantage of the collapsed representation of the model. We propose a stochastic algorithm for collapsed variational Bayesian inference for LDA, which is simpler and more efficient than the state of the art method. In experiments on large-scale text corpora, the algorithm was found to converge faster and often to a better solution than previous methods. Human-subject experiments also demonstrated that the method can learn coherent topics in seconds on small corpora, facilitating the use of topic models in interactive document analysis software.'],\n",
              " '30_decision_choice_risk_risky': ['Bar-Gain Boxes: An Informative Illustration of the Pairing Problem.[SEP]A practical problem in command and control is to assign assets (e.g., bomber planes) to targets (e.g., hostile sites), one-on-one, in order to optimize an overall operation. The asset-target pairing must be completed quickly (before targets act), and the expected effectiveness of an asset against a target depends on a number of factual and judgmental factors. Here I present a diagram called ”Bar-Gain Boxes” designed to help people solve the problem. The diagram uses a matrix of boxes to illustrate the possible pairings, along with color-coded bars (in each box) to illustrate the gain associated with each individual asset-target pair. The diagram is informative because it displays algorithmic results and underlying reasons, for normative and alternative solutions.',\n",
              "  'Context effects and risk amplification: Why more is risky.[SEP]Research on risky choice has been dominantly based on studies of choice between two alternatives, with the findings often generalized to environments with more than two alternatives. One prominent claim of this research is that choices differ with respect to risk when alternatives are described (the description paradigm) as opposed to experienced (the experience paradigm): Individuals appear to make decisions as if they over-weight small probabilities in the description paradigm, but under-weight the same probabilities in the experience paradigm. Here, we show that the under-weighting in the experience paradigm is sensitive to the choice set size in the gain domain. Two experiments show that as set sizes increase, choices systematically favour risky alternatives in the experience paradigm. Using simulations of three choice models, we further demonstrate that this risk-amplification is independent of choice and search strategies and is predicted by the statistical structure of pay-offs. The results suggest caution in generalising findings from two-choice environments to many-choice environments and further indicate a robust and systematic problem with increasing choice set sizes.',\n",
              "  \"How Does Prospect Theory Reflect Heuristics' Probability Sensitivity in Risky Choice?[SEP]Two prominent approaches to describing how people make decisions between risky options are algebraic models and heuristics. The two approaches are based on fundamentally different algorithms and are thus usually treated as antithetical, suggesting that they may be incommensurable. Using cumulative prospect theory (CPT; Tversky & Kahneman, 1992) as an illustrative case of an algebraic model, we demonstrate how algebraic models and heuristics can mutually inform each other. Specifically, we highlight that CPT describes decisions in terms of psychophysical characteristics, such as diminishing sensitivity to probabilities, and we show that this holds even when the underlying process is heuristic in nature. Our results suggest that algebraic models and heuristics might offer complementary rather than rival modeling frameworks and highlight the potential role of heuristic principles in information processing for prominent descriptive constructs in risky choice.\"],\n",
              " '31_weather_visualization_climate_ocean': ['User-defined feature comparison for vector field ensembles.[SEP]Most of the existing approaches to visualize vector field ensembles are to reveal the uncertainty of individual variables, for example, statistics, variability, etc. However, a user-defined derived feature like vortex or air mass is also quite significant, since they make more sense to domain scientists. In this paper, we present a new framework to extract user-defined derived features from different simulation runs. Specially, we use a detail-to-overview searching scheme to help extract vortex with a user-defined shape. We further compute the geometry information including the size, the geo-spatial location of the extracted vortexes. We also design some linked views to compare them between different runs. At last, the temporal information such as the occurrence time of the feature is further estimated and compared. Results show that our method is capable of extracting the features across different runs and comparing them spatially and temporally.',\n",
              "  \"Analysis of Decadal Climate Predictions with User-guided Hierarchical Ensemble Clustering.[SEP]In order to gain probabilistic results, ensemble simulation techniques are increasingly applied in the weather and climate sciences (as well as in various other scientific disciplines). In many cases, however, only mean results or other abstracted quantities such as percentiles are used for further analyses and dissemination of the data. In this work, we aim at a more detailed visualization of the temporal development of the whole ensemble that takes the variability of all single members into account. We propose a visual analytics tool that allows an effective analysis process based on a hierarchical clustering of the time‐dependent scalar fields. The system includes a flow chart that shows the ensemble members' cluster affiliation over time, reflecting the whole cluster hierarchy. The latter one can be dynamically explored using a visualization derived from a dendrogram. As an aid in linking the different views, we have developed an adaptive coloring scheme that takes into account cluster similarity and the containment relationships. Finally, standard visualizations of the involved field data (cluster means, ground truth data, etc.) are also incorporated. We include results of our work on real‐world datasets to showcase the utility of our approach.\",\n",
              "  'Extraction and Visual Analysis of Potential Vorticity Banners around the Alps.[SEP]Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.',\n",
              "  'Exploratory Hierarchical Clustering for Management Zone Delineation in Precision Agriculture.[SEP]Precision Agriculture has become an emerging topic over the last ten years. It is concerned with the integration of information technology into agricultural processes. This is especially true for the ongoing and growing data collection in agriculture. Novel ground-based sensors, aerial and satellite imagery as well as soil sampling provide large georeferenced data sets with high spatial resolution. However, these data lead to the data mining problem of finding novel and useful information in these data sets.',\n",
              "  'Gaussian multiple instance learning approach for mapping the slums of the world using very high resolution imagery.[SEP]In this paper, we present a computationally efficient algorithm based on multiple instance learning for mapping informal settlements (slums) using very high-resolution remote sensing imagery. From remote sensing perspective, informal settlements share unique spatial characteristics that distinguish them from other urban structures like industrial, commercial, and formal residential settlements. However, regular pattern recognition and machine learning methods, which are predominantly single-instance or per-pixel classifiers, often fail to accurately map the informal settlements as they do not capture the complex spatial patterns. To overcome these limitations we employed a multiple instance based machine learning approach, where groups of contiguous pixels (image patches) are modeled as generated by a Gaussian distribution. We have conducted several experiments on very high-resolution satellite imagery, representing four unique geographic regions across the world. Our method showed consistent improvement in accurately identifying informal settlements.',\n",
              "  'Regression Models for Spatial Data: An Example from Precision Agriculture.[SEP]The term precision agriculture refers to the application of state-of-the-art GPS technology in connection with small-scale, sensor-based treatment of the crop. This data-driven approach to agriculture poses a number of data mining problems. One of those is also an obviously important task in agriculture: yield prediction. Given a precise, geographically annotated data set for a certain field, can a season’s yield be predicted?'],\n",
              " '32_ray_rays_traversal_rendering': ['Adaptive Ray Tracing of Subdivision Surfaces.[SEP]Subdivision Surfaces as well as (interactive) ray tracing have become an important issue in computer graphics.But ray tracing of subdivision surfaces has received only little attention. We present a new approach for raytracing of subdivision surfaces. The algorithm uses a projection of the ray onto the surface and works mainly intwo dimensions along this projection. While proceeding from patch to patch, we examine the bounding volume oftheir borders: the lower the distance between ray and subdivision surface, the more refinement steps are adaptivelyapplied to the surface but only along the projection of the ray. The adaptive refinement of a patch is controlled bycurvature, size, its membership to the silhouette, and its potential contribution to the light transport. The algorithmis simple and mainly consists of elementary geometric computations. Hence it is fast and easy to implementwithout the need for elaborate preprocessing. The algorithm is robust in the sense that it deals with all features ofsubdivision surfaces like creases and corners.',\n",
              "  'Octree-R: An Adaptive Octree for Efficient Ray Tracing.[SEP]Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves.',\n",
              "  'Improved techniques for ray tracing parametric surfaces.[SEP]Several techniques for acceleration of ray tracing parametric surfaces are presented. Some of these are entirely new to ray tracing, while others are improvements of previously known techniques. First a uniform spatial subdivision scheme is adapted to parametric surfaces. A new space- and time-efficient algorithm for finding raysurface intersections is introduced. It combines numerical and subdivision techniques, thus allowing utilization of ray coherence and greatly reducing the average ray-surface intersection time. Non-scanline sampling orders of the image plane are proposed that facilitate utilization of coherence. Finally, a method to handle reflected, refracted, and shadow rays in a more efficient manner is described. Results of timing tests indicating the efficiency of these techniques for various environments are presented.'],\n",
              " '33_twitter_tweets_media_sentiment': ['#Indigenous: Tracking the Connective Actions of Native American Advocates on Twitter.[SEP]With fewer than 66% of eligible voters registered and voter turnout rates 5-14 percentage points lower than any other ethnic group, Native Americans comprise the least participatory ethnic group in U.S. political elections [42, 57, 49, 25]. While discourse surrounding Native American issues and interests has increasingly moved to social media [55, 56], there is a lack of data about Native American political discourse on these platforms. Given the heterogeneity of Native American peoples in the U.S., one way to begin approaching a holistic understanding of Native American political discourse on social media is to characterize how Native American advocates utilize social media platforms for connective action. Using a post-structural, interdisciplinary, mixed methods approach, we use theories of connective action [5] and media richness [14] to analyze a Twitter data set culled from influential Native American advocates and their followers during the 2016 primary presidential election season. Our study sheds light on how Native American advocates use social media to propagate political information and identifies which issues are central to the political discourse of Native American advocates. Furthermore, we demonstrate how the bandwidth characteristics of content impact its propagation and we discuss this in the context of pernicious digital divide effects present in Indian Country.',\n",
              "  'Thanks and tweets: comparing two public displays.[SEP]Two public display systems, with different methods of posting, were deployed over several years. One, the Thank You Board, was designed to give people an outlet specifically for publicly thanking and acknowledging others in the community. The other, SI Display, showed any Twitter post directed to the display and did not have explicit usage guidelines. People preferred the flexibility of the latter, but ambiguity about its purpose and norms of usage persisted even six months after deployment and made some people hesitant to post. Also, using Twitter as the posting mechanism facilitated participation for some but also created barriers for those not using Twitter and for Twitter users who were wary of mixing their professional and non-professional contexts.',\n",
              "  '(How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian uprising.[SEP]This paper examines microblogging information diffusion activity during the 2011 Egyptian political uprisings. Specifically, we examine the use of the retweet mechanism on Twitter, using empirical evidence of information propagation to reveal aspects of work that the crowd conducts. Analysis of the widespread contagion of a popular meme reveals interaction between those who were \"on the ground\" in Cairo and those who were not. However, differences between information that appeals to the larger crowd and those who were doing on-the-ground work reveal important interplay between the two realms. Through both qualitative and statistical description, we show how the crowd expresses solidarity and does the work of information processing through recommendation and filtering. We discuss how these aspects of work mutually sustain crowd interaction in a politically sensitive context. In addition, we show how features of this retweet-recommendation behavior could be used in combination with other indicators to identify information that is new and likely coming from the ground.',\n",
              "  \"ScatterBlogs: Geo-spatial document analysis.[SEP]We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system's combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.\",\n",
              "  'TimeSets: Temporal Sensemaking in Intelligence Analysis.[SEP]TimeSets is a temporal data visualization technique designed to reveal insights into event sets, such as all the events linked to one person or organization. In this article, we describe two TimeSets-based visual analytics tools for intelligence analysis. In the first case, TimeSets is integrated with other visual analytics tools to support open-source intelligence analysis with Twitter data, particularly the challenge of finding the right questions to ask. The second case uses TimeSets in a participatory design process with analysts that aims to meet their requirements of uncertainty analysis involving fake news. Lessons learned are potentially beneficial to other application domains.',\n",
              "  \"Can Twitter Save Lives? A Broad-Scale Study on Visual Social Media Analytics for Public Safety.[SEP]The use of social media monitoring for public safety is on the brink of commercialization and practical adoption. To close the gap between research and application, this paper presents results of a two-phase study on visual analytics of social media for public safety. For the first phase, we conducted a large field study, in which 29 practitioners from disaster response and critical infrastructure management were asked to investigate crisis intelligence tasks based on Twitter data recorded during the 2013 German Flood. To this end, the ScatterBlogs visual analytics system, a platform that provides reference implementations of tools and techniques popular in research, was given to them as an integrated toolbox. We reviewed the domain experts' individual performances with the system as well as their comments about the usefulness of techniques. In the second phase, we built on this feedback about ScatterBlogs in order to sketch out a system and create additional tools specifically adapted to the collected requirements. The performance of the old lab prototype is finally compared against the re-design in a controlled user study.\"],\n",
              " '34_creativity_painting_art_creative': ['Systematic Integration of Solution Elements: How Does Digital Creativity Support Change Group Dynamics?[SEP]In practice, most creativity techniques are still performed with traditional tools, such as pen and paper, whiteboards, and flipcharts. When transforming these techniques into a digital environment, the reduction of organizational overhead is the main goal to foster accessibility. Still, we do not know if overhead reduction fosters creativity or if it eliminates an important part of the creative process. To get a deeper understanding of these effects, we compare the performance of the creativity technique SIS (Systematic Integration of Solution Elements) in a traditional setting with a setup based on multiple interactive surfaces. By using a mix of diverse evaluation methods, we show how the use of a digital interactive creativity room can really foster creativity and produce better results.',\n",
              "  'Understanding Creativity Methods in Design.[SEP]This paper contributes an analytical framework to improve understanding of the composition of recognized creativity methods used in design. Based on an extensive literature review, our framework synthesizes key concepts from design and particularly creativity research, and is further supported by significant experience with creativity methods in design. We propose that nine concepts are relevant for analyzing creativity methods in design: process structure, materials, tools, combination, metaphor, analogy, framing, divergence, and convergence. To test their relevance as components of an analytical framework, we use these key concepts to analyze three recognized creativity methods that we have often used ourselves: Inspiration Card Workshops, Fictional Inquiry, and Extreme Characters. Our analytical framework expands current categorizations of methods and offers new insight into how creativity methods are composed, how and why they work, and how they potentially may be tweaked or refined for enhanced deployment in design.',\n",
              "  'What You See Is What You Get: The Impact of Visual Perceived Finishedness (PF) on Collaboration Comments during Electronic Idea Generation.[SEP]Micro-level visual phenomena significantly impact visually-supported interactions, and require further exploration. This study uses a laboratory experiment with managerial participants to examine the impact of typeface appearance on number of comments concerning collaboration process during use of an electronic ideation platform. The typefaces verifiably differed on perceived finishedness (PF) level. Low typeface PF was expected to lead to freer, more frequent interaction on the collaboration process. Contrary to expectations, this study found that participant familiarity with the high PF typeface led to a significant increase in the amount of collaboration process comments. This study examines the complementary new ideation metric of collaboration comment number in light of the benefits social metacognition can bring to the structuring of group creativity processes.',\n",
              "  'The Best of Both Realities.[SEP]This paper looks at the work of Dan Turner, who creates art based on digital imagery.',\n",
              "  'Her Work Is All the Buzz.[SEP]This installment looks at the work of Lita Albuquerque, who creates art based on digital imagery.',\n",
              "  \"A Space to Dream.[SEP]Dolores Kaufmann's work is a cross between photo manipulation and computer-generated imagery. She creates her works using Kai Power Tools' Hyper Tiling plug in.\",\n",
              "  'Image-Based Color Ink Diffusion Rendering.[SEP]This paper proposes an image-based painterly rendering algorithm for automatically synthesizing an image with color ink diffusion. We suggest a mathematical model with a physical base to simulate the phenomenon of color colloidal ink diffusing into absorbent paper. Our algorithm contains three main parts: a feature extraction phase, a Kubelka-Munk (KM) color mixing phase, and a color ink diffusion synthesis phase. In the feature extraction phase, the information of the reference image is simplified by luminance division and color segmentation. In the color mixing phase, the KM theory is employed to approximate the result when one pigment is painted upon another pigment layer. Then, in the color ink diffusion synthesis phase, the physically-based model that we propose is employed to simulate the result of color ink diffusion in absorbent paper using a texture synthesis technique. Our image-based ink diffusing rendering (IBCIDR) algorithm eliminates the drawback of conventional Chinese ink simulations, which are limited to the black ink domain, and our approach demonstrates that, without using any strokes, a color image can be automatically converted to the diffused ink style with a visually pleasing appearance',\n",
              "  'Pixel Art with Refracted Light by Rearrangeable Sticks.[SEP]Pixel art is a kind of digital art that through per‐pixel manipulation enables production of a diverse array of artistic images. In this paper, we present a new way for people to experience and express pixel art. Our digital art consists of a set of sticks made of acrylate resin, each of which refracts light from a parallel light source, in certain directions. Artistic users are able to easily rearrange these sticks and view their digital art through the refracted light projection on any planar surface. As we demonstrate in this paper, a user can generate various artistic images using only a single set of sticks. We additionally envision that our pixel art with rearrangeable sticks would have great entertainment appeal, e.g., as an art puzzle.',\n",
              "  'Artistic relighting of paintings and drawings.[SEP]We present a practical solution to the problem of subject relighting in paintings and drawings. Our interactive technique uses 3-D shading proxies and can be applied to objects with arbitrary geometries. Given a user-provided guess for the shading of an object in a painting/drawing and its corresponding target shading, we refine them using shading-color correlation and a multi-scale scheme. These refined shadings are then used to create a multi-channel shading-ratio image to perform relighting, while taking into account the colors used by the artists to convey shading information. We demonstrate the effectiveness of our solution on a variety of artistic styles, including paintings with strong brush strokes and unconventional shading encodings, drawings, and other types of artwork. Our method is the first to perform relighting of paintings and drawings and, in addition to relighting, can transfer smooth normal and depth maps from 3-D proxies to images.'],\n",
              " '35_causal_beliefs_evidence_belief': ['Stable Causal Relationships are Better Causal Relationships.[SEP]We report two experiments investigating whether people’s judgments about causal relationships are sensitive to the robustness or stability of such relationships across a wide range of background circumstances. We demonstrate that people prefer stable causal relationships even when overall causal strength is held constant, and show that this effect is unlikely to be driven by a causal generalization’s actual scope of application. This documents a previously unacknowledged factor that shapes people’s causal reasoning.',\n",
              "  'Informative Transitions: A Heuristic for Conditionalized Causal Strength Learning.[SEP]Controlling for alternative causes is essential for learning the strength of any one cause on an effect. Several processes have been proposed for how people control for alternative causes, including probabilistic contrasts within focal sets and associative processes. We investigated another mechanism called the informative transitions heuristic; people selectively attend to temporally adjacent observations (informative transitions; IT) in which the state of the target cause changes but the alternative causes remain the same. Within ITs, whether the effect also changes in the same direction, does not change, or changes in the opposite direction implies that the target cause has a positive, neutral, or negative influence on the effect. Participants judged the strength of the relationship between two drugs and a side effect in a trial-by-trial learning task. Causes with more positive as opposed to neutral ITs were judged to have stronger causal relations, consistent with the IT heuristic.',\n",
              "  'Causal Reasoning with Continuous Outcomes.[SEP]We describe an attempt to understand causal reasoning in situations where a binary cause produces a change on a continuous magnitude dimension. We consider established theories of binary probabilistic causal inference – ΔP and Power PC – and adapt them to continuous non-probabilistic outcomes. While ΔP describes causal strength as the difference of effect occurrence between the presence and absence of the cause, Power PC normalizes this difference with the effect base-rate to obtain a proportional measure of causal power, relative to the maximum possible strength. Two experiments compared the applicability of each approach by creating scenarios where binary probabilistic scenarios were directly mapped onto inference problems involving continuous magnitude dimensions. Results from counterfactual judgments tentatively indicate that people reason about causal relations with continuous outcomes by adopting a proportional approach when evaluation preventive causal powers, and a difference approach in generative scenarios.'],\n",
              " '36_privacy_security_private_protection': ['Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security Practices.[SEP]A primary goal of research in usable security and privacy is to understand the differences and similarities between users. While past researchers have clustered users into different groups, past categories of users have proven to be poor predictors of end-user behaviors. In this paper, we perform an alternative clustering of users based on their behaviors. Through the analysis of data from surveys and interviews of participants, we identify five user clusters that emerge from end-user behaviors-Fundamentalists, Lazy Experts, Technicians, Amateurs and the Marginally Concerned. We examine the stability of our clusters through a survey-based study of an alternative sample, showing that clustering remains consistent. We conduct a small-scale design study to demonstrate the utility of our clusters in design. Finally, we argue that our clusters complement past work in understanding privacy choices, and that our categorization technique can aid in the design of new computer security technologies.',\n",
              "  \"Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps.[SEP]Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone apps may help people make more informed privacy-related decisions. To investigate this question, we designed and prototyped a new class of privacy indicators, called Data Controller Indicators (DCIs), that expose previously hidden information flows out of the apps. Our lab study of DCIs suggests that such indicators do support people in making more confident and consistent choices, informed by a more diverse range of factors, including the number and nature of third-party companies that access users' data. Furthermore, personalised DCIs, which are contextualised against the other apps an individual already uses, enable them to reason effectively about the differential impacts on their overall information exposure.\",\n",
              "  'Privacy as part of the app decision-making process.[SEP]Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts\\' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.',\n",
              "  'Maximum Likelihood Postprocessing for Differential Privacy under Consistency Constraints.[SEP]When analyzing data that has been perturbed for privacy reasons, one is often concerned about its usefulness. Recent research on differential privacy has shown that the accuracy of many data queries can be improved by post-processing the perturbed data to ensure consistency constraints that are known to hold for the original data. Most prior work converted this post-processing step into a least squares minimization problem with customized efficient solutions. While improving accuracy, this approach ignored the noise distribution in the perturbed data.',\n",
              "  'Inference Analysis in Privacy-Preserving Data Re-publishing.[SEP]Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.',\n",
              "  'Concentrated Differentially Private Gradient Descent with Adaptive per-Iteration Privacy Budget.[SEP]Iterative algorithms, like gradient descent, are common tools for solving a variety of problems, such as model fitting. For this reason, there is interest in creating differentially private versions of them. However, their conversion to differentially private algorithms is often naive. For instance, a fixed number of iterations are chosen, the privacy budget is split evenly among them, and at each iteration, parameters are updated with a noisy gradient.'],\n",
              " '37_urban_city_building_buildings': ['Staging Urban Interactions with Media Fa[SEP]Using media façades as a subcategory of urban computing, this paper contributes to the understanding of spatial interaction, sense-making, and social mediation as part of identifying key characteristics of interaction with media façades. Our research addresses in particular the open-ended but framed nature of interaction, which in conjunction with varying interpretations enables individual sense-making. Moreover, we contribute to the understanding of flexible social interaction by addressing urban interaction in relation to distributed attention, shared focus, dialogue and collective action. Finally we address challenges for interaction designers encountered in a complex spatial setting calling for a need to take into account multiple viewing and action positions. Our research-through-design approach has included a real-life design intervention in terms of the design, implementation, and reflective evaluation of a 180 m2 (1937 square feet) interactive media façade in operation 24/7 for more than 50 days.',\n",
              "  'Immersive Street-level Social Media in the 3D Virtual City: Anticipated User Experience and Conceptual Development.[SEP]In this paper we explore immersive street-level integration of social media content into collaborative virtual 3D city environments on two levels: i) public, where the virtual environment is populated with relevant social media content (e.g. Twitter and Facebook feeds of shops, non-governmetal organizations, the City organization); and ii) personal, where the virtual user, through his/her avatar, is able to access his/her personal social media feeds while immersed in the virtual city. We conducted a qualitative anticipated user experience study with 14 participants in four focus groups, who were asked to create designs of how they imagined social networking services could be integrated into virtual city environments. Further, participants were asked to comment on two visual concepts created by researchers. Results show that people appreciate the concept of having virtual cities populated with up-to-date content from social media services, but linking their own social media accounts is a more complex issue.',\n",
              "  'Projected Realities: Conceptual Design for Cultural Effect.[SEP]As a part of a European Union sponsored project, we have proposed a system which aggregates peoples expressions over a widening network of public electronic displays in a massive Dutch housing development. Reflecting ideas from contemporary arts as well as from research on media spaces, this is an example of a conceptual design intended to produce meaningful effects on a local culture. In this paper, we describe the methods and ideas that led to this proposal, as an example of research on technologies from the traditions of artist-designers.',\n",
              "  'A Survey of Urban Reconstruction.[SEP]This paper provides a comprehensive overview of urban reconstruction. While there exists a considerable body of literature, this topic is still under very active research. The work reviewed in this survey stems from the following three research communities: computer graphics, computer vision, and photogrammetry and remote sensing. Our goal is to provide a survey that will help researchers to better position their own work in the context of existing solutions, and to help newcomers and practitioners in computer graphics to quickly gain an overview of this vast field. Further, we would like to bring the mentioned research communities to even more interdisciplinary work, since the reconstruction problem itself is by far not solved.',\n",
              "  'Generating 3D Building Models from Architectural Drawings: A Survey.[SEP]Automatically generating 3D building models from 2D architectural drawings has many useful applications in the architecture engineering and construction community. This survey of model generation from paper and CAD-based architectural drawings covers the common pipeline and compares various algorithms for each step of the process.',\n",
              "  \"Automatic Integration of Facade Textures into 3D Building Models with a Projective Geometry Based Line Clustering.[SEP]Visualization of city scenes is important for many applications including entertainment and urban mission planning. Models covering wide areas can be efficiently constructed from aerial images. However, only roof details are visible from aerial views; ground views are needed to provide details of the building facades for high quality 'fly‐through' visualization or simulation applications. We present an automatic method of integrating facade textures from ground view images into 3D building models for urban site modeling. We first segment the input image into building facade regions using a hybrid feature extraction method, which combines global feature extraction with Hough transform on an adaptively tessellated Gaussian Sphere and local region segmentation. We estimate the external camera parameters by using the corner points of the extracted facade regions to integrate the facade textures into the 3D building models. We validate our approach with a set of experiments on some urban sites.\"],\n",
              " '38_transaction_transactions_concurrency_distributed': ['Efficient Concurrency Control for Broadcast Environments.[SEP]A crucial consideration in environments where data is broadcast to clients is the low bandwidth available for clients to communicate with servers. Advanced applications in such environments do need to read data that is mutually consistent as well as current. However, given the asymmetric communication capabilities and the needs of clients in mobile environments, traditional serializability-based approaches are too restrictive, unnecessary, and impractical. We thus propose the use of a weaker correctness criterion called update consistency and outline mechanisms based on this criterion that ensure (1) the mutual consistency of data maintained by the server and read by clients, and (2) the currency of data read by clients. Using these mechanisms, clients can obtain data that is current and mutually consistent “off the air”, i.e., without contacting the server to, say, obtain locks. Experimental results show a substantial reduction in response times as compared to existing (serializability-based) approaches. A further attractive feature of the approach is that if caching is possible at a client, weaker forms of currency can be obtained while still satisfying the mutual consistency of data.',\n",
              "  \"Concepts for Transaction Recovery in Nested Transactions.[SEP]The concept of nested transactions offers more decomposable execution units and finer grained control over recovery and concurrency as compared to 'flat' transactions. To exploit these advantages, especially transaction recovery has to be refined and adjusted to the requirements of the control structure.\",\n",
              "  'Implementing Recoverable Requests Using Queues.[SEP]Transactions have been rigorously defined and extensively studied in the database and transaction processing literature, but little has been said about the handling of the requests for transaction execution in commercial TP systems, especially distributed ones, managing the flow of requests is often as important as executing the transactions themselves.'],\n",
              " '39_displays_display_navigation_lenses': [\"360° panoramic overviews for location-based services.[SEP]We investigate 360° panoramas as overviews to support users in the task of locating objects in the surrounding environment. Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment. In this paper, we conduct a series of studies with three different shapes: Frontal, Top-Down and Bird's Eye; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment. Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role. This paper is the first to provide understanding on how users exploit 360° panoramic over-views to locate objects in the surrounding environment and how different design factors can affect user performance.\",\n",
              "  'Effects of display size and navigation type on a classification task.[SEP]The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.',\n",
              "  'Wedge: clutter-free visualization of off-screen locations.[SEP]To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge, a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.',\n",
              "  \"Elastic windows: improved spatial layout and rapid multiple window operations.[SEP]Most windowing systems follow the independent overlapping windows approach, which emerged as an answer to the needs of the 80s' application and technology. Advances in computers, display technology, and the applications demand more functionality from window management systems. Based on these changes and the problems of current windowing appraoches, we have updated the requirements for multiwindow systems to guide new methods of window management. We propose elastic windows with improved spatial layout and rapid multi-window operations. Multi-window operations are achieved by issuing operations on window groups hierachically organized in a space-filling tiled layout. Sophisticated multi-window operations and spatial layout dynamics helps users to handle fast task-switching and to structure thier work environment to their rapidly changing needs. We claim that these multi-window operations and the improved spatial layout decrease the cognitive load on users. Users found our prototype system to be comprehensible and enjoyable as they playfully explored the way multiple windows are reshaped.\",\n",
              "  'Copy-and-paste between overlapping windows.[SEP]Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.',\n",
              "  'A window system with leafing through mode: BookWindow.[SEP]This paper describes “Book Window” that we implemented, a window system based on the “book” metaphor, that displays information not by scrolling but by using the animation of paging through. The BookWindow system equips some bookmarks, tabs, etc., by which we can access to an expected page through our requirements. BookWindow can support our work environment which navigates us through information space flexibly, because human beings are quite familiar with “books”.',\n",
              "  \"ThinVR: Heterogeneous microlens arrays for compact, 180 degree FOV VR near-eye displays.[SEP]Today's Virtual Reality (VR) displays are dramatically better than the head-worn displays offered 30 years ago, but today's displays remain nearly as bulky as their predecessors in the 1980's. Also, almost all consumer VR displays today provide 90-110 degrees field of view (FOV), which is much smaller than the human visual system's FOV which extends beyond 180 degrees horizontally. In this paper, we propose ThinVR as a new approach to simultaneously address the bulk and limited FOV of head-worn VR displays. ThinVR enables a head-worn VR display to provide 180 degrees horizontal FOV in a thin, compact form factor. Our approach is to replace traditional large optics with a curved microlens array of custom-designed heterogeneous lenslets and place these in front of a curved display. We found that heterogeneous optics were crucial to make this approach work, since over a wide FOV, many lenslets are viewed off the central axis. We developed a custom optimizer for designing custom heterogeneous lenslets to ensure a sufficient eyebox while reducing distortions. The contribution includes an analysis of the design space for curved microlens arrays, implementation of physical prototypes, and an assessment of the image quality, eyebox, FOV, reduction in volume and pupil swim distortion. To our knowledge, this is the first work to demonstrate and analyze the potential for curved, heterogeneous microlens arrays to enable compact, wide FOV head-worn VR displays.\",\n",
              "  \"Gaussian Light Field: Estimation of Viewpoint-Dependent Blur for Optical See-Through Head-Mounted Displays.[SEP]We propose a method to calibrate viewpoint-dependent, channel-wise image blur of near-eye displays, especially of Optical See-Through Head-Mounted Displays (OST-HMDs). Imperfections in HMD optics cause channel-wise image shift and blur that degrade the image quality of the display at a user's viewpoint. If we can estimate such characteristics perfectly, we could mitigate the effect by applying correction techniques from the computational photography in computer vision as analogous to cameras. Unfortunately, directly applying existing calibration techniques of cameras to OST-HMDs is not a straightforward task. Unlike ordinary imaging systems, image blur in OST-HMDs is viewpoint-dependent, i.e., the optical characteristic of a display dynamically changes depending on the current viewpoint of the user. This constraint makes the problem challenging since we must measure image blur of an HMD, ideally, over the entire 3D eyebox in which a user can see an image. To overcome this problem, we model the viewpoint-dependent blur as a Gaussian Light Field (GLF) that stores spatial information of the display screen as a (4D) light field with depth information and the blur as point-spread functions in the form of Gaussian kernels, respectively. We first describe both our GLF model and a calibration procedure to learn a GLF for a given OST-HMD. We then apply our calibration method to two HMDs that use different optics: a cubic prism or holographic gratings. The results show that our method achieves significantly better accuracy in Point-Spread Function (PSF) estimations with an accuracy about 2 to 7 dB in Peak SNR.\",\n",
              "  \"A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays.[SEP]Optical see-through head-mounted displays (OST HMDs) are a major output medium for Augmented Reality, which have seen significant growth in popularity and usage among the general public due to the growing release of consumer-oriented models, such as the Microsoft Hololens. Unlike Virtual Reality headsets, OST HMDs inherently support the addition of computer-generated graphics directly into the light path between a user's eyes and their view of the physical world. As with most Augmented and Virtual Reality systems, the physical position of an OST HMD is typically determined by an external or embedded 6-Degree-of-Freedom tracking system. However, in order to properly render virtual objects, which are perceived as spatially aligned with the physical environment, it is also necessary to accurately measure the position of the user's eyes within the tracking system's coordinate frame. For over 20 years, researchers have proposed various calibration methods to determine this needed eye position. However, to date, there has not been a comprehensive overview of these procedures and their requirements. Hence, this paper surveys the field of calibration methods for OST HMDs. Specifically, it provides insights into the fundamentals of calibration techniques, and presents an overview of both manual and automatic approaches, as well as evaluation methods and metrics. Finally, it also identifies opportunities for future research.\",\n",
              "  \"The Immersive Visualization Probe for Exploring n-Dimensional Spaces.[SEP]A new tool uses two types of dimensional navigation to display continuous 4D subsets of n-dimensional data. Thanks to the tool's embedded coordinate systems, researchers can better understand a model's underlying physical or mathematical process. Here, we describe a new method for visualizing data structure or models defined in higher-dimensional spaces. This technique is suitable for applications in which a scalar function, defined mathematically or procedurally, depends on n variables or parameters. The function's values essentially describe a set of points in n-dimensional space. To visualize these sets, we fix all but three of the parameters and then sample the resulting 4D set (the three parameters and the function's resulting value) on several discrete grids located on planes in the 3D space. We compose the image by using color to represent the fourth dimension (the function's value) at discrete locations on these grids. Interactive control over the way the parameters are fixed results in a highly dynamic system that researchers can easily use to explore the n-dimensional space's structure.\",\n",
              "  'Multidimensional virtual reality-MVR method: a new method of visualization of multidimensional worlds.[SEP]The paper presents a new, original method of multidimensional worlds’ visualization. It allows to present views of any dimension objects out of which it is possible to construct even the most complicated multidimensional virtual world on a computer screen. Due to this, it is possible to observe multidimensional worlds modeled in this way, analyze mutual relations between multidimensional objects, move between them and, most importantly, verify whether human brain is able to adapt to the perception of more than three-dimensional space. This paper presents example interior views of four-dimensional and five-dimensional labyrinths. It also presents results of the research performed on 97 IT students at the AGH University of Science and Technology. Students in total made 357 attempts to leave virtual four-dimensional and five-dimensional labyrinths, each having three difficulty levels. The method presented in this paper is sufficiently general to allow observation of objects in an n-dimensional space for any 𝑛≥3n≥3. Simultaneously, it is the natural extension of our reality perception because using this method for 𝑛=3n=3 we obtain views known to us from our human experience from the three-dimensional space.',\n",
              "  'ImAxes: Immersive Axes as Embodied Affordances for Interactive Multivariate Data Visualisation.[SEP]We introduce ImAxes immersive system for exploring multivariate data using fluid, modeless interaction. The basic interface element is an embodied data axis. The user can manipulate these axes like physical objects in the immersive environment and combine them into sophisticated visualisations. The type of visualisation that appears depends on the proximity and relative orientation of the axes with respect to one another, which we describe with a formal grammar. This straight-forward composability leads to a number of emergent visualisations and interactions, which we review, and then demonstrate with a detailed multivariate data analysis use case.'],\n",
              " '3_recommendation_recommender_recommendations_users': ['Smart Pacing for Effective Online Ad Campaign Optimization.[SEP]In targeted online advertising, advertisers look for maximizing campaign performance under delivery constraint within budget schedule. Most of the advertisers typically prefer to impose the delivery constraint to spend budget smoothly over the time in order to reach a wider range of audiences and have a sustainable impact. Since lots of impressions are traded through public auctions for online advertising today, the liquidity makes price elasticity and bid landscape between demand and supply change quite dynamically. Therefore, it is challenging to perform smooth pacing control and maximize campaign performance simultaneously. In this paper, we propose a smart pacing approach in which the delivery pace of each campaign is learned from both offline and online data to achieve smooth delivery and optimal performance goals. The implementation of the proposed approach in a real DSP system is also presented. Experimental evaluations on both real online ad campaigns and offline simulations show that our approach can effectively improve campaign performance and achieve delivery goals.',\n",
              "  'From 0.5 Million to 2.5 Million: Efficiently Scaling up Real-Time Bidding.[SEP]Real-Time Bidding allows an advertiser to purchase media inventory through an auction system that unfolds in the order of milliseconds. Media providers are increasingly being integrated into such programmatic buying platforms. It is typical for a contemporary Real-Time Bidding system to receive millions of bid requests per second at peak time, and have a large portion of these to be irrelevant to any advertiser. Meanwhile, given a valuable bid request, tens of thousands of advertisements might be qualified for scoring. We present our efforts in building selection models for both bid requests and advertisements to handle this scalability challenge. Our bid request model treats the system load as a hierarchical resource allocation problem and directs traffic based on the estimated quality of bid requests. Next, our exploration/exploitation advertisement model selects a limited number of qualified advertisements for thorough scoring based on the expected value of a bid request to the advertiser given its features. Our combined bid request and advertisement model is able to win more auctions and bring more value to clients by stabilizing the bidding pipeline. We empirically show that our deployed system is capable of handling 5x more bid requests.',\n",
              "  \"An Engagement-Based Customer Lifetime Value System for E-commerce.[SEP]A comprehensive understanding of individual customer value is crucial to any successful customer relationship management strategy. It is also the key to building products for long-term value returns. Modeling customer lifetime value (CLTV) can be fraught with technical difficulties, however, due to both the noisy nature of user-level behavior and the potentially large customer base. Here we describe a new CLTV system that solves these problems. This was built at Groupon, a large global e-commerce company, where confronting the unique challenges of local commerce means quickly iterating on new products and the optimal inventory to appeal to a wide and diverse audience. Given current purchaser frequency we need a faster way to determine the health of individual customers, and given finite resources we need to know where to focus our energy. Our CLTV system predicts future value on an individual user basis with a random forest model which includes features that account for nearly all aspects of each customer's relationship with our platform. This feature set includes those quantifying engagement via email and our mobile app, which give us the ability to predict changes in value far more quickly than models based solely on purchase behavior. We further model different customer types, such as one-time buyers and power users, separately so as to allow for different feature weights and to enhance the interpretability of our results. Additionally, we developed an economical scoring framework wherein we re-score a user when any trigger events occur and apply a decay function otherwise, to enable frequent scoring of a large customer base with a complex model. This system is deployed, predicting the value of hundreds of millions of users on a daily cadence, and is actively being used across our products and business initiatives.\"],\n",
              " '40_search_web_information_pages': [\"Internet Search Roles of Adults in their Homes.[SEP]Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews and observations of search task performance with 40 adult participants, we identify and describe characteristics of 9 search roles. By comparing these roles with those of youths, we explain how previously identified roles, such as Power Searcher and Social Searcher, have evolved in adult populations, and how new roles, such as Efficient Searcher and Interest-driven Searcher, have emerged. We also review the challenges and benefits associated with search roles and their potential impacts on search performance. The findings of this study provide a better understanding of how contextual factors influence search roles in relation to ELIS, what can be learned from search roles, and opportunities to support different search roles.\",\n",
              "  'Designing the Search Experience.[SEP]This half-day tutorial provides a practical introduction to Human-Centred Design for information search, access and discovery. We present a concise overview of the fundamental concepts and principles of human information-seeking behaviour and show how to apply these in the design of search user experiences. A key element of the tutorial is the opportunity to practice these skills in a group exercise.',\n",
              "  'Adaptive information search: age-dependent interactions between cognitive profiles and strategies.[SEP]Previous research has shown that older adults performed worse in web search tasks, and attributed poorer performance to a decline in their cognitive abilities. We conducted a study involving younger and older adults to compare their web search behavior and performance in ill-defined and well-defined information tasks using a health information website. In ill-defined tasks, only a general description about information needs was given, while in well-defined tasks, information needs as well as the specific target information were given. We found that older adults performed worse than younger adults in well-defined tasks, but the reverse was true in ill-defined tasks. Older adults compensated for their lower cognitive abilities by adopting a top-down knowledge-driven strategy to achieve the same level of performance in the ill-defined tasks. Indeed, path models showed that cognitive abilities, health literacy, and knowledge influenced search strategies adopted by older and younger adults. Design implications are also discussed.',\n",
              "  \"Exploring multi-session web tasks.[SEP]Users are now performing more sophisticated web tasks. In this work, we explore web tasks that require multiple web sessions to complete (multi-session tasks) to satisfy a goal. We conducted a web-based diary study and a field study that used a customized version of Firefox which logged the participants' interactions for multi-session tasks and all their web activity. We found that multi-session tasks occur frequently and that users utilize a variety of browser tools and actions to help complete these tasks.\",\n",
              "  'Interest-Determining Web Browser.[SEP]This paper investigates the application of data-mining techniques on a user’s browsing history for the purpose of determining the user’s interests. More specifically, a system is outlined that attempts to determine certain keywords that a user may or may not be interested in. This is done by first applying a term-frequency/inverse-document frequency filter to extract keywords from webpages in the user’s history, after which a Self-Organizing Map (SOM) neural network is utilized to determine if these keywords are of interest to the user. Such a system could enable web-browsers to highlight areas of web pages that may be of higher interest to the user. It is found that while the system is indeed successful in identifying many keywords of user-interest, it also mis-classifies many uninteresting words boasting only a 62% accuracy rate.',\n",
              "  \"How do people find information on a familiar website?[SEP]Previous research has investigated how people either navigate the web as a whole, or find information on websites of which they have little previous knowledge. However, it is now common for people to make frequent use of one site (e.g., their employer's intranet). This paper reports how participants recalled and navigated a familiar website they had used for 8--20 months. Sketch maps showed that participants' memory for the site's content and structure was very limited in extent, but generally accurate. Navigation data showed that participants had much more difficulty finding the region of the site that contained a piece of information, than then finding the information itself. These data highlight the need for directly accessed pages to be given greater prominence in browser history mechanisms and designers to make information regions memorable. Finally, two navigational path metrics (stratum and percentage of revisit actions) that correlated with participants' performance were identified.\",\n",
              "  'Freebase: a collaboratively created graph database for structuring human knowledge.[SEP]Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.',\n",
              "  'Hybrid in-database inference for declarative information extraction.[SEP]In the database community, work on information extraction (IE) has centered on two themes: how to effectively manage IE tasks, and how to manage the uncertainties that arise in the IE process in a scalable manner. Recent work has proposed a probabilistic database (PDB) based declarative IE system that supports a leading statistical IE model, and an associated inference algorithm to answer top-k-style queries over the probabilistic IE outcome. Still, the broader problem of effectively supporting general probabilistic inference inside a PDB-based declarative IE system remains open. In this paper, we explore the in-database implementations of a wide variety of inference algorithms suited to IE, including two Markov chain Monte Carlo algorithms, the Viterbi and the sum-product algorithms. We describe the rules for choosing appropriate inference algorithms based on the model, the query and the text, considering the trade-off between accuracy and runtime. Based on these rules, we describe a hybrid approach to optimize the execution of a single probabilistic IE query to employ different inference algorithms appropriate for different records. We show that our techniques can achieve up to 10-fold speedups compared to the non-hybrid solutions proposed in the literature.',\n",
              "  'ONDUX: on-demand unsupervised learning for information extraction.[SEP]Information extraction by text segmentation (IETS) applies to cases in which data values of interest are organized in implicit semi-structured records available in textual sources (e.g. postal addresses, bibliographic information, ads). It is an important practical problem that has been frequently addressed in the recent literature. In this paper we introduce ONDUX (On Demand Unsupervised Information Extraction), a new unsupervised probabilistic approach for IETS. As other unsupervised IETS approaches, ONDUX relies on information available on pre-existing data to associate segments in the input string with attributes of a given domain. Unlike other approaches, we rely on very effective matching strategies instead of explicit learning strategies. The effectiveness of this matching strategy is also exploited to disambiguate the extraction of certain attributes through a reinforcement step that explores sequencing and positioning of attribute values directly learned on-demand from test data, with no previous human-driven training, a feature unique to ONDUX. This assigns to ONDUX a high degree of flexibility and results in superior effectiveness, as demonstrated by the experimental evaluation we report with textual sources from different domains, in which ONDUX is compared with a state-of-art IETS approach.'],\n",
              " '41_category_categories_categorization_similarity': ['Similarity-based Ordering of Instances for Efficient Concept Learning.[SEP]Theories in concept learning predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning low-similarity concept structures. This suggests that the performance in concept learning tasks can be improved by grouping the instances of given concepts based on their similarity. To explore this hypothesis, we use Physical Bongard Problems, a rich categorization task with an open feature space, to analyze the combined effects of comparing dissimilar and similar instances within and across categories. We manipulate the within- and between-category similarity of instances presented close to each other in blocked, interleaved and simultaneous presentation schedules. The results show that grouping instances to promote dissimilar within- and similar between-category comparisons improves the learning results, to a degree depending on the strategy used by the learner.',\n",
              "  'Models of Human Category Learning: Do they Generalize?[SEP]Generalization to new examples is an essential aspect of categorization. However, recent category learning research has not focused on how people generalize their category knowledge. Taking generalization to be a critical basis for evaluating formal models of category learning, we employed a ‘minimal case’ approach to begin a systematic investigation of generalization. Human participants received supervised training on a two-way artificial classification task based on two dimensions that were each perfect predictors. Learners were then asked to classify new examples sampled from the stimulus space. Most participants based their judgments on one or the other dimension. Varying the relative levels of dimension salience influenced generalization outcomes, but varying category size (2, 4, or 8 items) did not. We fit two theoretically distinct similarity-based models (ALCOVE and DIVA) to aggregate learning data and tested on the generalization set. Both models could explain important aspects of human performance, but DIVA produced a superior overall account.',\n",
              "  'Perceptual Learning in Correlation Estimation: The Role of Learning Category Organization.[SEP]Research has shown that estimation of correlation from scatter plots is done poorly by both novices and experts. We tested whether proficiency in correlation estimation could be improved by perceptual learning interventions, in the form of perceptual-adaptive learning modules (PALMs). We also tested learning effects of alternative category structures in perceptual learning. We organized the same set of 252 scatter plot displays either into a PALM that implemented spacing in learning by shape categories or one in which the categories were ranges of correlation strength. Both PALMs produced markedly reduced errors, and both led trained participants to classify near transfer items as accurately as trained items. Differences in category organization produced modest effects on learning; there was some indication of more consistent reduction of absolute error when learning categories were organized by shape, whereas average bias of judgments was best reduced by categories organized by different numerical ranges of correlation.'],\n",
              " '42_crowdsourcing_workers_crowd_worker': ['Demonstration of Qurk: a query processor for humanoperators.[SEP]Crowdsourcing technologies such as Amazon\\'s Mechanical Turk (\"MTurk\") service have exploded in popularity in recent years. These services are increasingly used for complex human-reliant data processing tasks, such as labelling a collection of images, combining two sets of images to identify people that appear in both, or extracting sentiment from a corpus of text snippets. There are several challenges in designing a workflow that filters, aggregates, sorts and joins human-generated data sources. Currently, crowdsourcing-based workflows are hand-built, resulting in increasingly complex programs. Additionally, developers must hand-optimize tradeoffs among monetary cost, accuracy, and time to completion of results. These challenges are well-suited to a declarative query interface that allows developers to describe their worflow at a high level and automatically optimizes workflow and tuning parameters. In this demonstration, we will present Qurk, a novel query system that allows human-based processing for relational databases. The audience will interact with the system to build queries and monitor their progress. The audience will also see Qurk from an MTurk user\\'s perspective, and complete several tasks to better understand how a query is processed.',\n",
              "  \"CrowdFill: collecting structured data from the crowd.[SEP]We present CrowdFill, a system for collecting structured data from the crowd. While a typical microtask-based approach would pose specific questions to each worker and assemble the answers, CrowdFill shows a partially-filled table to all participating workers. Workers contribute by filling in empty cells, as well as upvoting and downvoting data entered by other workers. The system's synchronization scheme, based on a careful model of primitive operations, enables workers to collaboratively complete the table without latency overhead. CrowdFill allows the specification of constraints on the collected data, and has mechanisms for resolving inconsistencies. Its compensation scheme takes into account each worker's contribution to the final table, and the varying difficulty of data entry tasks. The paper includes some preliminary experimental results.\",\n",
              "  'CrowdDQS: Dynamic Question Selection in Crowdsourcing Systems.[SEP]In this paper, we present CrowdDQS, a system that uses the most recent set of crowdsourced voting evidence to dynamically issue questions to workers on Amazon Mechanical Turk (AMT). CrowdDQS posts all questions to AMT in a single batch, but delays the decision of the exact question to issue a worker until the last moment, concentrating votes on uncertain questions to maximize accuracy. Unlike previous works, CrowdDQS also (1) optionally can decide when it is more beneficial to issue gold standard questions with known answers than to solicit new votes (both can help us estimate worker accuracy, but gold standard questions provide a less noisy estimate of worker accuracy at the expense of not obtaining new votes), (2) estimates worker accuracies in real-time even with limited evidence (with or without gold standard questions), and (3) infers the distribution of worker skill levels to actively block poor workers. We deploy our system live on AMT to over 1000 crowdworkers, and find that CrowdDQS can accurately answer questions using up to 6x fewer votes than standard approaches. We also find there are many non-obvious practical challenges involved in deploying such a system seamlessly to crowdworkers, and discuss techniques to overcome these challenges.'],\n",
              " '43_patient_patients_care_clinical': ['Local-universality: designing EMR to support localized informal documentation practices.[SEP]In this paper, we describe a practice that is common across multiple heterogeneous contexts but enacted differently depending on the unique constellation of resources and demands present in each local context. Using the case of informal documentation practices in two departments of a single hospital, Emergency and Labor & Delivery, we describe how clinicians in each department develop contextualized informal documentation practices after deployment of a new EMR system. We describe three underlying functions of informal documentation that are inherent to the practice of medical personnel: \"memory work,\" abstraction work,\" and \"future work.\" We then find that the newly deployed EMR technology does not support these kinds of work. We argue that hospital documentation work systems should be designed with an eye to such universal work practices, while keeping in mind that the effectiveness of informal documentation practices is rooted in its adaptive and flexible deployment in heterogeneous work settings.',\n",
              "  \"Accountability in an alarming environment.[SEP]This paper considers how adjustable alarms support collaborative monitoring work within the intensive care unit. Drawing on examples from an observational study, it hopes to stimulate new ways of thinking about the role that alarms play in supporting awareness of not only changes in the environment but also awareness of colleagues' actions. Adjustable alarms allow nurses to fit the alarm limits to both the patient state and the nurse's level of experience. The setting of alarm limits is an accountable activity, being visible to and observed by colleagues.\",\n",
              "  \"Documenting transitional information in EMR.[SEP]An observational study was conducted to examine EMR-based documentation in an Emergency Department (ED), with an emphasis on computerized documentation activities in the complex flow of clinical processes. This study revealed a gap between the formal EMR documentation and the actual clinical workflow, which leads ED staff to rely on intermediate - transitional artifacts to facilitate their work. The analysis of these transitional artifacts in four different clinical workflows shows that the EMR system's inability to document procedural information, capture key information, and present information according to the actual clinical workflow are accountable for leading to the use of transitional artifacts. The findings of this study call for designing EMR system not only for keeping patients' formal records, but also for documenting transitional information in the chart-writing process.\",\n",
              "  'Patient Subtyping via Time-Aware LSTM Networks.[SEP]In the study of various diseases, heterogeneity among patients usually leads to different progression patterns and may require different types of therapeutic intervention. Therefore, it is important to study patient subtyping, which is grouping of patients into disease characterizing subtypes. Subtyping from complex patient data is challenging because of the information heterogeneity and temporal dynamics. Long-Short Term Memory (LSTM) has been successfully used in many domains for processing sequential data, and recently applied for analyzing longitudinal patient records. The LSTM units are designed to handle data with constant elapsed times between consecutive elements of a sequence. Given that time lapse between successive elements in patient records can vary from days to months, the design of traditional LSTM may lead to suboptimal performance. In this paper, we propose a novel LSTM unit called Time-Aware LSTM (T-LSTM) to handle irregular time intervals in longitudinal patient records. We learn a subspace decomposition of the cell memory which enables time decay to discount the memory content according to the elapsed time. We propose a patient subtyping model that leverages the proposed T-LSTM in an auto-encoder to learn a powerful single representation for sequential records of patients, which are then used to cluster patients into clinical subtypes. Experiments on synthetic and real world datasets show that the proposed T-LSTM architecture captures the underlying structures in the sequences with time irregularities.',\n",
              "  'Dynamic Illness Severity Prediction via Multi-task RNNs for Intensive Care Unit.[SEP]Most of the existing analytics on ICU data mainly focus on mortality risk prediction and phenotyping analysis. However, they have limitations in providing sufficient evidence for decision making in a dynamically changing clinical environment. In this paper, we propose a novel approach that simultaneously analyses different organ systems to predict the illness severity of patients in an ICU, which can intuitively reflect the condition of the patients in a timely fashion. Specifically, we develop a novel deep learning model, namely MTRNN-ATT, which is based on multi-task recurrent neural networks. The physiological features of each organ system in time-series representations are learned by a single long short-term memory unit as a specific task. To utilize the relationships between organ systems, we use a shared LSTM unit to exploit the correlations between different tasks for further performance improvement. Also, we apply an attention mechanism in our deep model to learn the selective features at each stage to achieve better prediction results. We conduct extensive experiments on a real-world clinical dataset (MIMIC-III) to compare our method with many state-of-the-art methods. The experiment results demonstrate that the proposed approach performs better on the prediction tasks of illness severity scores.',\n",
              "  'Multi-layer Representation Learning for Medical Concepts.[SEP]Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.'],\n",
              " '44_diagrams_diagrammatic_diagram_logic': ['Aristotelian and Duality Relations Beyond the Square of Opposition.[SEP]Nearly all squares of opposition found in the literature represent both the Aristotelian relations and the duality relations, and exhibit a very close correspondence between both types of logical relations. This paper investigates the interplay between Aristotelian and duality relations in diagrams beyond the square. In particular, we study a Buridan octagon, a Lenzen octagon, a Keynes-Johnson octagon and a Moretti octagon. Each of these octagons is a natural extension of the square, both from an Aristotelian perspective and from a duality perspective. The results of our comparative analysis turn out to be highly nuanced.',\n",
              "  'A Semiotic-Conceptual Analysis of Euler and Hasse Diagrams.[SEP]Semiotic-Conceptual Analysis (SCA) considers diagrams (and in general any signs) as consisting of representamens, denotations and interpretations which supports investigating these three components individually and jointly. A core notion for diagram research is “observability” which refers to logically valid statements that can be visually extracted from diagrams. This notion is included into the SCA vocabulary and discussed with respect to Euler and Hasse diagrams.',\n",
              "  'Euler Diagrams for Defeasible Reasoning.[SEP]We investigate Euler diagrammatic systems for defeasible reasoning by extending the usual systems for Euler and Venn diagrams corresponding to standard classical logic. To achieve this, we use the generalized quantifier “most” to formalize defeasible reasoning, as proposed by Schlechta (1995), where defeasible knowledge is represented as “Most A are B” and axioms for “most” are defined. We introduce an Euler diagrammatic system for defeasible reasoning by introducing circle mA that represents “most A” for each circle A. We show that our Euler diagrammatic system is a diagrammatic representation of the symbolic system of the generalized quantifier “most”. Furthermore, we investigate skeptical and credulous strategies in defeasible reasoning with our Euler diagrams.',\n",
              "  'The Diagram of Flow: Its Departure from Software Engineering and Its Return.[SEP]The first diagrammatic notation used in software engineering represented the concept of flow. This paper considers the factors that affected the apparent departure of the flowchart from software engineering practice during the 1970s and 1980s and its subsequent return in the 1990s. A new emphasis on hierarchy (as level of abstraction) and on data structure meant that the general concept of flow was completely superseded, only to re-emerge later as a new duality of control flow and data flow. This reappearance took a variety of forms with varying semantics until its stabilisation in the latest version of the Unified Modeling Language. Flow is there re-instated as a fundamental concept in software engineering although its importance, and that of the activity diagram used to represent it, diminished as a consequence of its becoming just one among a wider set of paradigms for software systems development, each associated with its own diagrams.',\n",
              "  'Notations for Software Engineering Class Structures.[SEP]This builds on previous work in which we have developed diagramming principles based on theories of structural object perception. We call these geon diagrams. We have previously shown that such diagrams are easy to remember and to analyze. To evaluate our hypothesis that geon diagrams should also be easy to understand we carried out an empirical study to evaluate the learnability of geon diagram semantics in comparison with the well-established UML convention. The results support our theory of learnability. Both ”novices” and ”experts” found the geon diagram syntax easier to apply in a diagram-to-textual description matching task than the equivalent UML syntax.',\n",
              "  'Enhancing State-Space Tree Diagrams for Collaborative Problem Solving.[SEP]State-space search methods in problem solving have often been illustrated using tree diagrams. We explore a set of issues related to coordination in collaborative problem solving and design, and we present a variety of interactive features for state-space search trees intended to facilitate such activity. Issues include how to show provenance of decisions, how to combine work and views produced separately, and how to represent work performed by computer agents. Some of the features have been implemented in a kit “TStar” and a design tool “PRIME Designer.”'],\n",
              " '45_color_colors_palette_palettes': ['Color, Change and Control for Quantitative Data Display.[SEP]Calico, a dynamic tool for the creation and manipulation of color mappings for the exploration of multivariate, quantitative data, was used to study the effects of user control and smooth change on user preference, accuracy, and confidence. The results of the study, as well as other user experiences with Calico, support the hypothesis that dynamic manipulation of color mappings is a useful feature of systems for the exploration of quantitative data using color. The main effect observed is a clear user preference for representations providing control over the mapping, a small but significant increase in accuracy, and greater confidence in information gleaned from manipulable displays. A smaller and less consistent effect showed greater user preference for an confidence in representations which provided smooth change between images.< >',\n",
              "  \"Examining Implicit Discretization in Spectral Schemes.[SEP]Two of the primary reasons rainbow color maps are considered ineffective trace back to the idea that they implicitly discretize encoded data into hue‐based bands, yet no research addresses what this discretization looks like or how consistent it is across individuals. This paper presents an exploratory study designed to empirically investigate the implicit discretization of common spectral schemes and explore whether the phenomenon can be modeled by variations in lightness, chroma, and hue. Our results suggest that three commonly used rainbow color maps are implicitly discretized with consistency across individuals. The results also indicate, however, that this implicit discretization varies across different datasets, in a way that suggests the visualization community's understanding of both rainbow color maps, and more generally effective color usage, remains incomplete.\",\n",
              "  \"Modeling Color Difference for Visualization Design.[SEP]Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.\"],\n",
              " '46_hci_design_research_practice': ['Metaprobes, Metaphysical Workshops and Sketchy Philosophy.[SEP]The intersection of philosophy and HCI is a longstanding site of interest for the field that has been attracting special attention in recent years. In this paper, we present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry. A Metaprobe is a design artifact used to study a metaphysical idea without concealing the philosophical tools mobilized by the designers or the designerly knowledge attained after deployment. We introduce the concept of a Metaphysical Workshop. This is the set of sketchy philosophical notions that a designer mobilizes in order to research a philosophical idea through design. We then present a case study that comprises: the philosophical issue under examination, the Metaprobes designed to study it, the metaphysical workshop used and the designerly insight produced. We conclude with a discussion of the potentials and weaknesses of Metaprobes in relation to other critical and speculative research-through-design practices. We aim to provide one way to make philosophies already present in design more explicit and make other philosophical concepts relevant to HCI more accessible and workable for designers.',\n",
              "  'From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product.[SEP]As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact.',\n",
              "  'Design Justice and User Interface Design.[SEP]In this keynote talk, Dr. Costanza-Chock will explore the theory and practice of design justice, discuss how design affordances, disaffordances, and dysaffordances distribute benefits and burdens unequally according to users? location within the matrix of domination (white supremacy, heteropatriarchy, ableism, capitalism, and settler colonialism), and invite us to consider how user interface designers can intentionally contribute to building ?a better world?, a world where many worlds fit; linked worlds of collective liberation and ecological sustainability.'],\n",
              " '47_robot_robots_robotic_robotics': ['Museum guide robot based on sociological interaction analysis.[SEP]We are currently working on a museum guide robot with an emphasis on \"friendly\" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.',\n",
              "  \"A Survey of Users' Expectations Towards On-body Companion Robots.[SEP]Being as a robotic companion is an extensive application of on-body robots; yet, as an emerging type of robots, few previous works focus on the design of on-body companion robots from the users' perspective, remaining users' expectations towards this type of robots unclear. To assist designers in the design process of on-body companion robots, we surveyed users' expectations towards on-body companion robots (n=215) by a questionnaire constituting of questions on factors that may affect robot acceptance, including robot functionality, robot appearance, and robot social ability. Based on the survey results, we stated design guidelines for the design of on-body companion robots supporting designers with insights into users. To demonstrate how to design on-body companion robots based on our findings, we organized a workshop with experienced designers to develop a conceptual on-body companion robot, and they proposed Bubo, an example prototype of on-body companion robot.\",\n",
              "  \"Authoring and Verifying Human-Robot Interactions.[SEP]As social agents, robots designed for human interaction must adhere to human social norms. How can we enable designers, engineers, and roboticists to design robot behaviors that adhere to human social norms and do not result in interaction breakdowns? In this paper, we use automated formal-verification methods to facilitate the encoding of appropriate social norms into the interaction design of social robots and the detection of breakdowns and norm violations in order to prevent them. We have developed an authoring environment that utilizes these methods to provide developers of social-robot applications with feedback at design time and evaluated the benefits of their use in reducing such breakdowns and violations in human-robot interactions. Our evaluation with application developers (N=9) shows that the use of formal-verification methods increases designers' ability to identify and contextualize social-norm violations. We discuss the implications of our approach for the future development of tools for effective design of social-robot applications.\"],\n",
              " '48_label_labels_unlabeled_classification': ['Active Learning from Multiple Noisy Labelers with Varied Costs.[SEP]In active learning, where a learning algorithm has to purchase the labels of its training examples, it is often assumed that there is only one labeler available to label examples, and that this labeler is noise-free. In reality, it is possible that there are multiple labelers available (such as human labelers in the online annotation tool Amazon Mechanical Turk) and that each such labeler has a different cost and accuracy. We address the active learning problem with multiple labelers where each labeler has a different (known) cost and a different (unknown) accuracy. Our approach uses the idea of adjusted cost, which allows labelers with different costs and accuracies to be directly compared. This allows our algorithm to find low-cost combinations of labelers that result in high-accuracy labelings of instances. Our algorithm further reduces costs by pruning under-performing labelers from the set under consideration, and by halting the process of estimating the accuracy of the labelers as early as it can. We found that our algorithm often outperforms, and is always competitive with, other algorithms in the literature.',\n",
              "  'Neural Conditional Energy Models for Multi-label Classification.[SEP]Multi-label classification (MLC) is a type of structured output prediction problems where a given instance can be associated to more than one labels at a time. From the probabilistic point of view, a model predicts a set of labels y given an input vector v by learning a conditional distribution p(y|v). This paper presents a powerful model called a Neural Conditional Energy Model (NCEM) to solve MLC. The model can be viewed as a hybrid deterministic-stochastic network of which we use a deterministic neural network to transform the input data, before contributing to the energy landscape of v, y, and a single stochastic hidden layer h. Non-linear transformation given by the neural network makes our model more expressive and more capable of capturing complex relations between input and output, and using deterministic neurons facilitates exact inference. We present an efficient learning algorithm that is simple to implement. We conduct extensive experiments on 15 real-world datasets from wide variety of domains with various evaluation metrics to confirm that NCEM is significantly superior to current state-of-the-art models most of the time based on pair-wise t-test at 5% significance level. The MATLAB source code to replicate our experiments are available at https://github.com/Kublai-Jing/NCEM.',\n",
              "  'Inductive Semi-supervised Multi-Label Learning with Co-Training.[SEP]In multi-label learning, each training example is associated with multiple class labels and the task is to learn a mapping from the feature space to the power set of label space. It is generally demanding and time-consuming to obtain labels for training examples, especially for multi-label learning task where a number of class labels need to be annotated for the instance. To circumvent this difficulty, semi-supervised multi-label learning aims to exploit the readily-available unlabeled data to help build multi-label predictive model. Nonetheless, most semi-supervised solutions to multi-label learning work under transductive setting, which only focus on making predictions on existing unlabeled data and cannot generalize to unseen instances. In this paper, a novel approach named COINS is proposed to learning from labeled and unlabeled data by adapting the well-known co-training strategy which naturally works under inductive setting. In each co-training round, a dichotomy over the feature space is learned by maximizing the diversity between the two classifiers induced on either dichotomized feature subset. After that, pairwise ranking predictions on unlabeled data are communicated between either classifier for model refinement. Extensive experiments on a number of benchmark data sets show that COINS performs favorably against state-of-the-art multi-label learning approaches.'],\n",
              " '49_keyboard_keyboards_touch_finger': ['Alphabetically constrained keypad designs for text entry on mobile devices.[SEP]The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.',\n",
              "  'DualKey: Miniature Screen Text Entry via Finger Identification.[SEP]Fast and accurate access to keys for text entry remains an open question for miniature screens. Existing works typically use a cumbersome two-step selection process, first to zero-in on a particular zone and second to make the key selection. We introduce DualKey, a miniature screen text entry technique with a single selection step that relies on finger identification. We report on the results of a 10 day longitudinal study with 10 participants that evaluated speed, accuracy, and learning. DualKey outperformed the existing techniques on long-term performance with a speed of 19.6 WPM. We then optimized the keyboard layout for reducing finger switching time based on the study data. A second 10 day study with eight participants showed that the new sweqty layout improved upon DualKey even further to 21.59 WPM for long-term speed, was comparable to existing techniques on novice speed and outperformed existing techniques on novice accuracy rate.',\n",
              "  'Language modeling for soft keyboards.[SEP]Language models predict the probability of letter sequences. Soft keyboards are images of keyboards on a touch screen for input on Personal Digital Assistants. When a soft keyboard user hits a key near the boundary of a key position, the language model and key press model are combined to select the most probable key sequence. This leads to an overall error rate reduction by a factor of 1.67 to 1.87. An extended version of this paper [4] is available.'],\n",
              " '4_graph_graphs_network_networks': [\"Discrete Overlapping Community Detection with Pseudo Supervision.[SEP]Community detection is of significant importance in understanding the structures and functions of networks. Recently, overlapping community detection has drawn much attention due to the ubiquity of overlapping community structures in real-world networks. Nonnegative matrix factorization (NMF), as an emerging standard framework, has been widely employed for overlapping community detection, which obtains nodes' soft community memberships by factorizing the adjacency matrix into low-rank factor matrices. However, in order to determine the ultimate community memberships, we have to post-process the real-valued factor matrix by manually specifying a threshold on it, which is undoubtedly a difficult task. Even worse, a unified threshold may not be suitable for all nodes. To circumvent the cumbersome post-processing step, we propose a novel discrete overlapping community detection approach, i.e., Discrete Nonnegative Matrix Factorization (DNMF), which seeks for a discrete (binary) community membership matrix directly. Thus DNMF is able to assign explicit community memberships to nodes without post-processing. Moreover, DNMF incorporates a pseudo supervision module into it to exploit the discriminative information in an unsupervised manner, which further enhances its robustness. We thoroughly evaluate DNMF using both synthetic and real-world networks. Experiments show that DNMF has the ability to outperform state-of-the-art baseline approaches.\",\n",
              "  'Communities in Preference Networks: Refined Axioms and Beyond.[SEP]Borgs et al. [2016] investigated essential requirements for communities in preference networks. They defined six axioms on community functions, i.e., community detection rules. Though having elegant properties, the practicality of this axiomsystem is compromised by the intractability of checking twocritical axioms, so no nontrivial consistent community functionwas reported in [Borgs et al., 2016]. By adapting the two axioms in a natural way, we propose two new axioms that are efficiently-checkable. We show that most of the desirable properties of the original axiom system are preserved. More importantly, the new axioms provide a general approach to constructing consistent community functions. We further find a natural consistent community function that is also enumerable and samplable, answering an open problem in the literature.',\n",
              "  'Joint Community and Structural Hole Spanner Detection via Harmonic Modularity.[SEP]Detecting communities (or modular structures) and structural hole spanners, the nodes bridging different communities in a network, are two essential tasks in the realm of network analytics. Due to the topological nature of communities and structural hole spanners, these two tasks are naturally tangled with each other, while there has been little synergy between them. In this paper, we propose a novel harmonic modularity method to tackle both tasks simultaneously. Specifically, we apply a harmonic function to measure the smoothness of community structure and to obtain the community indicator. We then investigate the sparsity level of the interactions between communities, with particular emphasis on the nodes connecting to multiple communities, to discriminate the indicator of SH spanners and assist the community guidance. Extensive experiments on real-world networks demonstrate that our proposed method outperforms several state-of-the-art methods in the community detection task and also in the SH spanner identification task (even the methods that require the supervised community information). Furthermore, by removing the SH spanners spotted by our method, we show that the quality of other community detection methods can be further improved.',\n",
              "  \"Gragnostics: Fast, Interpretable Features for Comparing Graphs.[SEP]Many analytical tasks, such as social network analysis, depend on comparing graphs. Existing methods are slow, or can be difficult to understand. To address these challenges, this paper proposes gragnostics, a set of 10 fast, layperson-understandable graph-level features. Each can be computed in linear time. To evaluate the ability of these features to discriminate different topologies and types of graphs, this paper compares a machine learning classifier using gragnostics to alternative classifiers, and the evaluation finds that the gragnostics classifier achieves higher performance. To evaluate gragnostics' utility in interactive visualization tools, this paper presents Chiron, a graph visualization tool that enables users to explore the subgraphs of a larger graph. Example usage scenarios of Chiron demonstrate that using gragnostics in a rank-by-feature framework can be effective for finding interesting subgraphs.\",\n",
              "  'Interactively Uncluttering Node Overlaps for Network Visualization.[SEP]Visual interaction with networks have been promising in the sense that we can successfully elucidate underlying relationships hidden behind complicated mutual relationships such as co-authorship networks, product co purchasing networks, and scale-free social networks. However, it is still burdensome to alleviate visual clutter arising from overlaps among node labels especially in such interactive environments as the networks become dense in terms of the topological connectivity. This paper presents a novel approach for dynamically rearranging the network layouts by incorporating centroidal Voronoi tessellation for better readability of node labels. Our idea is to smoothly transform the network layouts obtained through the conventional force-directed algorithm to that produced by the centroidal Voronoi tessellation to seek a plausible compromise between them. We also incorporated the Chebyshev distance metric into the centroidal Voronoi tessellation while adaptively adjusting the aspect ratios of the Voronoi cells so that we can place rectangular labels compactly over the network nodes. Finally, we applied the proposed approach to relatively large networks to demonstrate the feasibility of our formulation especially in interactive environments.',\n",
              "  'Multilayer graph edge bundling.[SEP]Many real world information can be represented by a graph with a set of nodes interconnected with each other by multiple type of relations called edge layers (e.g., social network, biological data). Edge bundling techniques have been proposed to solve cluttering issue for standard graphs while few efforts were done to deal with the similar issue for multilayer graphs. In multilayer graphs scenario, not only the clutter induced by large amount of edges is a problem but also the fact that different type of edges can overlap each other making useless the final visualization. In this paper we introduce a new multilayer graph edge bundling technique that firstly produces a preliminary edge bundling independently of the different edge layers and then deals with the specificity of multilayer graphs where more than one type of edges can be routed on the same bundle. The proposed visualization is tested on a real world case study and the outcomes point out the ability of our proposal to discover patterns present in the data.',\n",
              "  \"Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks.[SEP]We introduce MultiPiles, a visualization to explore time‐series of dense, weighted networks. MultiPiles is based on the physical analogy of piling adjacency matrices, each one representing a single temporal snapshot. Common interfaces for visualizing dynamic networks use techniques such as: flipping/animation; small multiples; or summary views in isolation. Our proposed ‘piling’ metaphor presents a hybrid of these techniques, leveraging each one's advantages, as well as offering the ability to scale to networks with hundreds of temporal snapshots. While the MultiPiles technique is applicable to many domains, our prototype was initially designed to help neuroscientists investigate changes in brain connectivity networks over several hundred snapshots. The piling metaphor and associated interaction and visual encodings allowed neuroscientists to explore their data, prior to a statistical analysis. They detected high‐level temporal patterns in individual networks and this helped them to formulate and reject several hypotheses.\",\n",
              "  'Edge-stacked Timelines for Visualizing Dynamic Weighted Digraphs.[SEP]We investigate the problem of visually encoding time-varying weighted digraphs to provide an overview about dynamic graphs. Starting from a rough overview of dynamic relational data an analyst can subsequently explore the data in more detail to gain further insights. To reach this goal we first map the graph vertices in the graph sequence to a common horizontal axis. Edges between vertices are represented as stacked horizontal and color-coded links starting and ending at their corresponding start and end vertex positions. The direction of each edge is indicated by placing it either above or below the horizontal vertex line. We attach a vertically aligned timeline to each link to show the weight evolution for those links. The order of the vertices and stacked edges is important for the readability of the visualization. We support interactive reordering and sorting in the vertex, edge, and timeline representations. The usefulness of our edge-stacked timelines is illustrated in a case st',\n",
              "  'Interactive Time-Series of Measures for Exploring Dynamic Networks.[SEP]We present MeasureFlow, an interface to visually and interactively explore dynamic networks through time-series of network measures such as link number, graph density, or node activation. When networks contain many time steps, become large and more dense, or contain high frequencies of change, traditional visualizations that focus on network topology, such as animations or small multiples, fail to provide adequate overviews and thus fail to guide the analyst towards interesting time points and periods. MeasureFlow presents a complementary approach that relies on visualizing time-series of common network measures to provide a detailed yet comprehensive overview of when changes are happening and which network measures they involve. As dynamic networks undergo changes of varying rates and characteristics, network measures provide important hints on the pace and nature of their evolution and can guide an analysts in their exploration; based on a set of interactive and signal-processing methods, MeasureFlow allows an analyst to select and navigate periods of interest in the network. We demonstrate MeasureFlow through case studies with real-world data.',\n",
              "  'Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees.[SEP]Finding dense subgraphs is an important graph-mining task with many applications. Given that the direct optimization of edge density is not meaningful, as even a single edge achieves maximum density, research has focused on optimizing alternative density functions. A very popular among such functions is the average degree, whose maximization leads to the well-known densest-subgraph notion. Surprisingly enough, however, densest subgraphs are typically large graphs, with small edge density and large diameter.',\n",
              "  'Graph-Structured Sparse Optimization for Connected Subgraph Detection.[SEP]Structured sparse optimization is an important and challenging problem for analyzing high-dimensional data in a variety of applications such as bioinformatics, medical imaging, social networks, and astronomy. Although a number of structured sparsity models have been explored, such as trees, groups, clusters, and paths, connected subgraphs have been rarely explored in the current literature. One of the main technical challenges is that there is no structured sparsity-inducing norm that can directly model the space of connected subgraphs, and there is no exact implementation of a projection oracle for connected subgraphs due to its NP-hardness. In this paper, we explore efficient approximate projection oracles for connected subgraphs, and propose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to optimize a generic nonlinear objective function subject to connectivity constraint on the support of the variables. Our proposed algorithms enjoy strong guarantees analogous to several current methods for sparsity-constrained optimization, such as Projected Gradient Descent (PGD), Approximate Model Iterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit (GHTP) with respect to convergence rate and approximation accuracy. We apply our proposed algorithms to optimize several well-known graph scan statistics in several applications of connected subgraph detection as a case study, and the experimental results demonstrate that our proposed algorithms outperform state-of-the-art methods.',\n",
              "  'Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling.[SEP]This paper studies the problem of efficiently computing a maximum independent set from a large graph, a fundamental problem in graph analysis. Due to the hardness results of computing an exact maximum independent set or an approximate maximum independent set with accuracy guarantee, the existing algorithms resort to heuristic techniques for approximately computing a maximum independent set with good performance in practice but no accuracy guarantee theoretically. Observing that the existing techniques have various limits, in this paper, we aim to develop efficient algorithms (with linear or near-linear time complexity) that can generate a high-quality (large-size) independent set from a graph in practice. In particular, firstly we develop a Reducing-Peeling framework which iteratively reduces the graph size by applying reduction rules on vertices with very low degrees (Reducing) and temporarily removing the vertex with the highest degree (Peeling) if the reduction rules cannot be applied. Secondly, based on our framework we design two baseline algorithms, BDOne and BDTwo, by utilizing the existing reduction rules for handling degree-one and degree-two vertices, respectively. Both algorithms can generate higher-quality (larger-size) independent sets than the existing algorithms. Thirdly, we propose a linear-time algorithm, LinearTime, and a near-linear time algorithm, NearLinear, by designing new reduction rules and developing techniques for efficiently and incrementally applying reduction rules. In practice, LinearTime takes similar time and space to BDOne but computes a higher quality independent set, similar in size to that of an independent set generated by BDTwo. Moreover, in practice NearLinear has a good chance to generate a maximum independent set and it often generates near-maximum independent sets. Fourthly, we extend our techniques to accelerate the existing iterated local search algorithms. Extensive empirical studies show that all our algorithms output much larger independent sets than the existing linear-time algorithms while having a similar running time, as well as achieve significant speedup against the existing iterated local search algorithms.',\n",
              "  \"Quegel: A General-Purpose System for Querying Big Graphs.[SEP]Inspired by Google's Pregel, many distributed graph processing systems have been developed recently to process big graphs. These systems expose a vertex-centric programming interface to users, where a programmer thinks like a vertex when designing parallel graph algorithms. However, existing systems are designed for tasks where most vertices in a graph participate in the computation, and they are not suitable for processing light-workload graph queries which only access a small portion of vertices. This is because their programming model can seriously under-utilize the resources in a cluster for processing graph queries. In this demonstration, we introduce a general-purpose system for querying big graphs, called Quegel, which treats queries as first-class citizens in the design of its computing model. Quegel adopts a novel superstep-sharing execution model to overcome the weaknesses of existing systems. We demonstrate it is user-friendly to write parallel graph-querying programs with Quegel's interface; and we also show that Quegel is able to achieve real-time response time in various applications, including the two applications that we plan to demonstrate: point-to-point shortest-path queries and XML keyword search.\",\n",
              "  'DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine.[SEP]Subgraph enumeration is important for many applications such as subgraph frequencies, network motif discovery, graphlet kernel computation, and studying the evolution of social networks. Most earlier work on subgraph enumeration assumes that graphs are resident in memory, which results in serious scalability problems. Recently, efforts to enumerate all subgraphs in a large-scale graph have seemed to enjoy some success by partitioning the data graph and exploiting the distributed frameworks such as MapReduce and distributed graph engines. However, we notice that all existing distributed approaches have serious performance problems for subgraph enumeration due to the explosive number of partial results. In this paper, we design and implement a disk-based, single machine parallel subgraph enumeration solution called DualSim that can handle massive graphs without maintaining exponential numbers of partial results. Specifically, we propose a novel concept of the dual approach for subgraph enumeration. The dual approach swaps the roles of the data graph and the query graph. Specifically, instead of fixing the matching order in the query and then matching data vertices, it fixes the data vertices by fixing a set of disk pages and then finds all subgraph matchings in these pages. This enables us to significantly reduce the number of disk reads. We conduct extensive experiments with various real-world graphs to systematically demonstrate the superiority of DualSim over state-of-the-art distributed subgraph enumeration methods. DualSim outperforms the state-of-the-art methods by up to orders of magnitude, while they fail for many queries due to explosive intermediate results.',\n",
              "  'GTS: A Fast and Scalable Graph Processing Method based on Streaming Topology to GPUs.[SEP]A fast and scalable graph processing method becomes increasingly important as graphs become popular in a wide range of applications and their sizes are growing rapidly. Most of distributed graph processing methods require a lot of machines equipped with a total of thousands of CPU cores and a few terabyte main memory for handling billion-scale graphs. Meanwhile, GPUs could be a promising direction toward fast processing of large-scale graphs by exploiting thousands of GPU cores. All of the existing methods using GPUs, however, fail to process large-scale graphs that do not fit in main memory of a single machine. Here, we propose a fast and scalable graph processing method GTS that handles even RMAT32 (64 billion edges) very efficiently only by using a single machine. The proposed method stores graphs in PCI-E SSDs and executes a graph algorithm using thousands of GPU cores while streaming topology data of graphs to GPUs via PCI-E interface. GTS is fast due to no communication overhead and scalable due to no data duplication from graph partitioning among machines. Through extensive experiments, we show that GTS consistently and significantly outperforms the major distributed graph processing methods, GraphX, Giraph, and PowerGraph, and the state-of-the-art GPU-based method TOTEM.',\n",
              "  'Unsupervised Differentiable Multi-aspect Network Embedding.[SEP]Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end differentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.',\n",
              "  \"DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph Classification.[SEP]Graph data widely exist in many high-impact applications. Inspired by the success of deep learning in grid-structured data, graph neural network models have been proposed to learn powerful node-level or graph-level representation. However, most of the existing graph neural networks suffer from the following limitations: (1) there is limited analysis regarding the graph convolution properties, such as seed-oriented, degree-aware and order-free; (2) the node's degreespecific graph structure is not explicitly expressed in graph convolution for distinguishing structure-aware node neighborhoods; (3) the theoretical explanation regarding the graph-level pooling schemes is unclear.\",\n",
              "  'AM-GCN: Adaptive Multi-channel Graph Convolutional Networks.[SEP]Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytics tasks on graph and network data. However, some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph with rich information. In this paper, we first present an experimental investigation. Surprisingly, our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks, since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an adaptive multi-channel graph convolutional networks for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features, topological structures, and their combinations simultaneously, and use the attention mechanism to learn adaptive importance weights of the embeddings. Our extensive experiments on benchmark data sets clearly show that AM-GCN extracts the most correlated information from both node features and topological structures substantially, and improves the classification accuracy with a clear margin.',\n",
              "  'Consistency Meets Inconsistency: A Unified Graph Learning Framework for Multi-view Clustering.[SEP]Graph Learning has emerged as a promising technique for multi-view clustering, and has recently attracted lots of attention due to its capability of adaptively learning a unified and probably better graph from multiple views. However, the existing multi-view graph learning methods mostly focus on the multi-view consistency, but neglect the potential multi-view inconsistency (which may be incurred by noise, corruptions, or view-specific characteristics). To address this, this paper presents a new graph learning-based multi-view clustering approach, which for the first time, to our knowledge, simultaneously and explicitly formulates the multi-view consistency and the multi-view inconsistency in a unified optimization model. To solve this model, a new alternating optimization scheme is designed, where the consistent and inconsistent parts of each single-view graph as well as the unified graph that fuses the consistent parts of all views can be iteratively learned. It is noteworthy that our multi-view graph learning model is applicable to both similarity graphs and dissimilarity graphs, leading to two graph fusion-based variants, namely, distance (dissimilarity) graph fusion and similarity graph fusion. Experiments on various multi-view datasets demonstrate the superiority of our approach. The MATLAB source code is available at https://github.com/youweiliang/ConsistentGraphLearning.',\n",
              "  'Dual active feature and sample selection for graph classification.[SEP]Graph classification has become an important and active research topic in the last decade. Current research on graph classification focuses on mining discriminative subgraph features under supervised settings. The basic assumption is that a large number of labeled graphs are available. However, labeling graph data is quite expensive and time consuming for many real-world applications. In order to reduce the labeling cost for graph data, we address the problem of how to select the most important graph to query for the label. This problem is challenging and different from conventional active learning problems because there is no predefined feature vector. Moreover, the subgraph enumeration problem is NP-hard. The active sample selection problem and the feature selection problem are correlated for graph data. Before we can solve the active sample selection problem, we need to find a set of optimal subgraph features. To address this challenge, we demonstrate how one can simultaneously estimate the usefulness of a query graph and a set of subgraph features. The idea is to maximize the dependency between subgraph features and graph labels using an active learning framework. We propose a branch-and-bound algorithm to search for the optimal query graph and optimal features simultaneously. Empirical studies on nine real-world tasks demonstrate that the proposed method can obtain better accuracy on graph data than alternative approaches.',\n",
              "  'Shortest-Path Kernels on Graphs.[SEP]Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels.'],\n",
              " '50_sketching_sketches_drawing_design': ['nuSketch battlespace: a demonstration.[SEP]Sketching provides a natural means of interaction for many spatially-oriented tasks. One task where sketching is used extensively is when military planners are formulating battle plans, called Courses of Action (COAs). This paper describes a system we have built, nuSketch Battlespace (nSB), which provides a sketching interface for creating COAs. The system is described in the paper \"Sketching for Military Courses of Action\" in these proceedings. The demonstration will highlight:',\n",
              "  'Getting Started with Sketch Tools.[SEP]Diagrams are an important, if not pivotal, part in both education and design. In an effort to understand abstract concepts, students play an active role in their education by specifying visual and abstract concepts in hand-sketched diagrams. While students are understanding abstract concepts through hand-drawn diagrams, designers are creating those abstract concepts. Just as the act of hand-drawing a diagram (as opposed to using a mouse-and-palette CAD tool) better engages the student in the learning process, the act of hand-drawing a diagram also improves the design process by freeing the designer of constraints that may otherwise impede creativity and innovation.',\n",
              "  'Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals.[SEP]Sketching is a practical and useful skill that can benefit communication and problem solving. However, it remains a difficult skill to learn because of low confidence and motivation among students and limited availability for instruction and personalized feedback among teachers. There is an need to improve the educational experience for both groups, and we hypothesized that integrating technology could provide a variety of benefits. We designed and developed an intelligent tutoring system for sketching fundamentals called Sketchtivity, and deployed it in to six existing courses at the high school and university level during the 2017-2018 school year. 268 students used the tool and produced more than 116,000 sketches of basic primitives. We conducted semi-structured interviews with the six teachers who implemented the software, as well as nine students from a course where the tool was used extensively. Using grounded theory, we found ten categories which unveiled the benefits and limitations of integrating an intelligent tutoring system for sketching fundamentals in to existing pedagogy.'],\n",
              " '51_facial_face_animation_faces': ['Bilinear interpolation for facial expression and metamorphosis in real-time animation.[SEP]This paper describes a new method for generating facial animation in which facial expression and shape can be changed simultaneously in real time. A 2D parameter space independent of facial shape is defined, on which facial expressions are superimposed so that the expressions can be applied to various facial shapes. A facial model is transformed by a bilinear interpolation, which enables a rapid change in facial expression with metamorphosis. The practical efficiency of this method has been demonstrated by a real-time animation system based on this method in live theater.',\n",
              "  'Transferring of Speech Movements from Video to 3D Face Space.[SEP]We present a novel method for transferring speech animation recorded in low quality videos to high resolution 3D face models. The basic idea is to synthesize the animated faces by an interpolation based on a small set of 3D key face shapes which span a 3D face space. The 3D key shapes are extracted by an unsupervised learning process in 2D video space to form a set of 2D visemes which are then mapped to the 3D face space. The learning process consists of two main phases: 1) isomap-based nonlinear dimensionality reduction to embed the video speech movements into a low-dimensional manifold and 2) k-means clustering in the low-dimensional space to extract 2D key viseme frames. Our main contribution is that we use the isomap-based learning method to extract intrinsic geometry of the speech video space and thus to make it possible to define the 3D key viseme shapes. To do so, we need only to capture a limited number of 3D key face models by using a general 3D scanner. Moreover, we also develop a skull movement recovery method based on simple anatomical structures to enhance 3D realism in local mouth movements. Experimental results show that our method can achieve realistic 3D animation effects with a small number of 3D key face models',\n",
              "  'Design, transformation and animation of human faces.[SEP]Creation of new human faces for synthetic actors is a tedious and painful task. The situation may be improved by introducing tools for the creation. Two approaches are discussed in this paper: modification and edition of an existing synthetic actor using local transformations; generation of new synthetic actors obtained by interpolation between two existing actors; creation of a synthetic actor by composition of different parts. This paper also describes the methods used in the facial animation of synthetic actors who change their personalities from one person to another. This means that our purpose is to transform one character into another, and also to transform the animation at the same time. The interpolation must be at several levels: the shape level, the parameter level, the expression level and the script level. For the animation, we introduce three levels of inbetweens: inbetween parameters, inbetween expressions and inbetween scripts. The method has been completely implemented and integrated into the Human Factory software.',\n",
              "  'Spatial pyramid face feature representation and weighted dissimilarity matching for improved face recognition.[SEP]In this paper, we present a novel face recognition (FR) algorithm based on multiresolution spatial pyramid. In our method, a face is subdivided into increasingly finer subregions (local regions) and represented at multiple levels of histogram representations. To address image misalignment problem, overlapped patch-based local descriptor extraction has been also developed in an effective way. To preserve multiple levels of detail in facial local characteristics and to encode holistic spatial configuration, face features obtained for concatenated histograms (coming from all levels of spatial pyramid) are integrated into a combined feature set, termed spatial pyramid face feature representation (SPFR). In addition, to perform recognition by matching between the pair of probe and gallery SPFR sets, we propose the use of a weighted sum of the dissimilarity scores computed at all spatial pyramid levels. For this purpose, we develop a novel weight determination solution based on class-wise discriminant power estimation for face feature at a specific pyramid level. We incorporate our proposed algorithm into general FR pipeline and achieve encouraging identification results on the CMU-PIE, FERET, and LFW datasets, compared to previously developed methods. In addition, the feasibility of our method has been successfully demonstrated by making comparisons with other state-of-the-art FR methods (including deep CNN based method) under the FERET and FRGC 2.0 evaluation protocols. Based on results, our method is advantageous in terms of high recognition accuracy and low complexity, as well as straightforward implementation.',\n",
              "  'On the Learning of Deep Local Features for Robust Face Spoofing Detection.[SEP]Biometrics emerged as a robust solution for security systems. However, given the dissemination of biometric applications, criminals are developing techniques to circumvent them by simulating physical or behavioral traits of legal users (spoofing attacks). Despite face being a promising characteristic due to its universality, acceptability and presence of cameras almost everywhere, face recognition systems are extremely vulnerable to such frauds since they can be easily fooled with common printed facial photographs. State-of-the-art approaches, based on Convolutional Neural Networks (CNNs), present good results in face spoofing detection. However, these methods do not consider the importance of learning deep local features from each facial region, even though it is known from face recognition that each facial region presents different visual aspects, which can also be exploited for face spoofing detection. In this work we propose a novel CNN architecture trained in two steps for such task. Initially, each part of the neural network learns features from a given facial region. Afterwards, the whole model is fine-tuned on the whole facial images. Results show that such pre-training step allows the CNN to learn different local spoofing cues, improving the performance and the convergence speed of the final model, outperforming the state-of-the-art approaches.',\n",
              "  'Analysis of the Eyes on Face Images for Compliance with ISO/ICAO Requirements.[SEP]The face has been used in identity documents and represents the ideal biometric characteristic in many applications. The International Civil Aviation Organization endorsed the use of face as the globally interoperable biometric characteristic. Successively, the International Standard Organization proposed the ISO/IEC 19794-5 standard for face usage in travel documents. The purpose of this work is to evaluate the quality of face images for identification documents and check if the face images satisfy the requirements defined by the ISO/IEC 19794-5. This work presents approaches for the evaluation of the following ISO/ICAO requirements: eyes state, red eyes and looking away. In addition, an approach to estimate the location of the center of the eyes is proposed. The proposed methods to check ISO/ICAO requirements were evaluated using the BioLab-ICAO Framework. The results achieved by the proposed methods were satisfactory, overcoming almost all the works in the literature for this purpose.'],\n",
              " '52_machine_fairness_deep_explanations': ['Chainer: A Deep Learning Framework for Accelerating the Research Cycle.[SEP]Software frameworks for neural networks play a key role in the development and application of deep learning methods. In this paper, we introduce the Chainer framework, which intends to provide a flexible, intuitive, and high performance means of implementing the full range of deep learning models needed by researchers and practitioners. Chainer provides acceleration using Graphics Processing Units with a familiar NumPy-like API through CuPy, supports general and dynamic models in Python through Define-by-Run, and also provides add-on packages for state-of-the-art computer vision models as well as distributed training.',\n",
              "  'The business impact of deep learning.[SEP]In the last year deep learning has gone from being a special purpose machine learning technique used mainly for image and speech recognition, to becoming a general purpose machine learning tool. This has broad implications for all organizations that rely on data analysis. It represents the latest development in a general trend towards more automated algorithms, and away from domain specific knowledge. For organizations that rely on domain expertise for their competitive advantage, this trend could be extremely disruptive. For start-ups interested in entering established markets, this trend could be a major opportunity. This talk will be a non-technical introduction to general-purpose deep learning, and its potential business impact.',\n",
              "  \"Principles of Explanatory Debugging to Personalize Interactive Machine Learning.[SEP]How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.\"],\n",
              " '53_papers_conference_issue_editorial': ['ScreenCrayons: annotating anything.[SEP]ScreenCrayons is a system for collecting annotations on any type of document or visual information from any application. The basis for the system is a screen capture upon which the user can highlight the relevant portions of the image. The user can define any number of topics for organizing notes. Each topic is associated with a highlighting \"crayon.\" In addition the user can supply annotations in digital ink or text. Algorithms are described that summarize captured images based on the highlight strokes so as to provide overviews of many annotations as well as being able to \"zoom in\" on particular information about a given note and the context of that note.',\n",
              "  'Reflowing digital ink annotations.[SEP]Annotating paper documents with a pen is a familiar and indispensable activity across a wide variety of work and educational settings. Recent developments in pen-based computing promise to bring this experience to digital documents. However, digital documents are more flexible than their paper counterparts. When a digital document is edited, or displayed on different devices, its layout adapts to the new situation. Freeform digital ink annotations made on such a document must likewise adapt, or \"reflow.\" But their unconstrained nature yields only vague guidelines for how these annotations should be transformed. Few systems have considered this issue, and still fewer have addressed it from a user\\'s point of view. This paper reports the results of a study of user expectations for reflowing digital ink annotations. We explore user reaction to reflow in common cases, how sensitive users are to reflow errors, and how important it is that personal style survive reflow. Our findings can help designers and system builders support freeform annotation more effectively.',\n",
              "  'The Breadth and Depth of E-reading and Paper-reading.[SEP]The present study investigated the differences between e-reading and paper-reading in their breadth and depth. Our results showed that (1) breadth and depth of reading were both greater in e-reading than in paper-reading; (2) possession of a tablet tended to facilitate breadth of e-reading; (3) breadth of e-reading was greater than breadth of paper-reading for news, magazines, and others, but not for novels; (4) depth of e-reading was greater than depth of paper-reading for novels, but the reverse was true for news and magazines; (5) people tended to read research articles, books and magazines on paper, but news and others on digital devices; (6) people tended to read longer on paper than on digital devices, but the percentage of contents they could remember was no different between e-reading and paper-reading. We conclude that modern readers have become accustomed to e-reading and can do it more efficiently than paper-reading.',\n",
              "  'Preface.[SEP]In this issue, we have fourteen regular papers and two corrections for previously published papers:',\n",
              "  'VIS capstone address.[SEP]Useful as each of them can be, a large body of tips and tricks is impossible to remember, at least in a practical, usable way, unless it is structured into a balanced, meaningful hierarchy. This talk proposes and illustrates three simple yet solid ideas that lead to more effective communication and that underpin every other guideline: easy to remember, readily applicable, and always relevant—in short, valuable for the rest of your life.',\n",
              "  'Preface.[SEP]In this issue, we have ten regular papers and one erratum:',\n",
              "  'A Survey of Topology-based Methods in Visualization.[SEP]This paper presents the state of the art in the area of topology‐based visualization. It describes the process and results of an extensive annotation for generating a definition and terminology for the field. The terminology enabled a typology for topological models which is used to organize research results and the state of the art. Our report discusses relations among topological models and for each model describes research results for the computation, simplification, visualization, and application. The paper identifies themes common to subfields, current frontiers, and unexplored territory in this research area.',\n",
              "  'Editor\\'s Note [2013 Best Associate Editor Award  2013 Best Reviewer Award].[SEP]The success of a journal relies heavily on the quality of submissions and of their reviews. The latter is primarily the work and efforts of the associate editors and the anonymous reviewers. The dedication of associate editors and of external reviewers is essential to the continuing growth of the journal. To continue recognizing these \"unsung heroes\" who drive the scientific peer review process for IEEE Transactions on Visualization and Computer Graphics (TVCG), it is my pleasure to announce the 2013 Best Associate Editor Award and the 2013 Best Reviewer Award. Three associate editors (AEs) for are recognized their dedication and hard work in 2013: Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi. They handled a large number of submissions efficiently with the quickest turnaround (averaging less than 50 days) and provided consistently high-quality, thoughtful AE summary to the authors. In recognizing their distinguished service to the IEEE TVCG, the 2013 TVCG Best Associate Editor Award goes to Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi.',\n",
              "  \"Guest Editors' Introduction: Special Section on the IEEE Pacific Visualization Symposium 2012.[SEP]The papers in this special section are extended versions of three selected papers from the IEEE Pacific Visualization Symposium 2012 (PacificVis) which took place in Songdo, Korea from 28 February to 2 March 2012.\"],\n",
              " '54_heritage_museum_visitors_museums': ['Web3D representation and cultural heritage: from annotations to narrations.[SEP]Storytelling is a powerful means for teaching, often used for engaging pupils while educating them. This paper describes an innovative web tool for creating engaging narrations for educational purposes that can be shared on the web. The tool is integrated with ToBoA-3D, a web platform for annotating 3D environments and taking advantage of the crowdsourced effort of its users for creating linear stories that can be shared on the web. An example focused on an educational narration about Renaissance architecture will be shown.',\n",
              "  'Unearthing Virtual History: Using Diverse Interfaces to Reveal Hidden Virtual Worlds.[SEP]We describe an application in which museum visitors hunt for virtual history outdoors, capture it, and bring it back indoors for detailed inspection. This application provides visitors with ubiquitous access to a parallel virtual world as they move through an extended physical space. Diverse devices, including mobile wireless interfaces for locating hotspots of virtual activity outdoors, provide radically different experiences of the virtual depending upon location, task, and available equipment. Initial reflections suggest that the physical design of such devices needs careful attention so as to encourage an appropriate style of use. We also consider the extension of our experience to support enacted scenes. Finally, we discuss potential benefits of using diverse devices to make a shared underlying virtual world ubiquitously available throughout physical space.',\n",
              "  'Making Place: Designing and Building an Engaging, Interactive and Pedagogical Historical World.[SEP]Digital visualisation technologies have transformed the field of heritage. The digital re-creation of a place demands much more than architectural modeling. Designers of virtual heritage places can learn from commercial computer games which can be very successful at creating a sense of place. The Virtual Sydney Rocks is designed to undertake research into the role that user preference for interaction strategy has on engagement in a Virtual Heritage Environment. Users can explore an experiential model of Sydney Cove between 1788 and 2008 in three different ways; by self directed exploration, by playing a game or by taking a tour. Users set the date and time to determine the position of the sun, the weather, the sounds that are heard and the buildings that are displayed. Users can also alter the speed of time. Additional information is accessed via the interlinked Virtual Sydney Rocks Guidebook.',\n",
              "  \"Visitors' Evaluations of ICTs Used in Cultural Heritage.[SEP]Technology that serves to enhance the visitors experience is gradually becoming more commonplace at Cultural Heritage (CH) sites. However ICT is not usually the CH professional s area of expertise and they have to make choices from a bewildering array of technology, often without fully understanding their visitors ICT needs. This research aims to alleviate the situation by gathering visitors evaluations of technologies that are frequently used at CH sites along with advanced applications, to identify which technologies visitors use and what they need. The research took place in five CH attractions in the UK and incorporates the results of one hundred and sixty four interviews with visitors. Both CH professionals and technology developers can use this research to gain insights into the use of ICT applications at sites and to identify emerging needs in the marketplace. The findings of this research indicate that ICTs in use at the CH sites involved were underutilised. Despite this, respondents strongly supported the advanced applications which included: Augmented Reality; an Interactive Museum Installation; a Mobile Media Guide and an Avatar Application. This is because they could see how they would benefit. This paper concludes that the use of ICT was supported by visitors to some degree. However in order to encourage use, the benefits must be clearly communicated to visitors.\",\n",
              "  \"Digital Exhibit Labels in Museums: Promoting Visitor Engagement with Cultural Artifacts.[SEP]How can we use interactive displays in museums to help visitors appreciate authentic objects and artifacts that they can't otherwise touch or manipulate? This paper shares results from a design-based research study on the use of interactive displays to help visitors learn about artifacts in an exhibit on the history and culture of China. To explore the potential afforded by these displays, we unobtrusively video recorded 834 museum visitor groups who stopped in front of one collection of objects. Drawing on cognitive models of curiosity, we tested three redesigns of this display, each focusing on a different strategy to spark visitor curiosity, interest, and engagement. To understand the relative effectiveness of these designs, we analyzed visitor interaction and conversation. Our results uncovered significant differences across the conditions suggesting implications for the use of such technology in museums.\",\n",
              "  'Articulating Co-Design in Museums: Reflections on Two Participatory Processes.[SEP]In this paper we reflect on the process of co-design by detailing and comparing two strategies for the participatory development of interaction concepts and prototypes in the context of technologically-enhanced museum visiting experiences. While much work in CSCW, HCI and related disciplines has examined different role configurations in co-design, more research is needed on examining how collaborative design processes can unfold in different ways. Here we present two instances of co-design of museum visiting aids, one stemming from an open brief, another from an initial working prototype; we discuss the process in each case and discuss how these alternative strategies presented the team with different possibilities as well as constraints, and led to different patterns of collaboration within the design team. Finally, we draw a set of themes for discussion and reflection to inform and aid researchers and practitioners participating in similar co-design processes, particularly in the domain of cultural heritage.',\n",
              "  'Innovative Digital Heuristic Approaches in Architectural Historical Research.[SEP]In recent years a great debate has aroused concerning the deep transformations triggered by the so-called \"digital revolution\" in all research fields. Architecture has been highly affected by this phenomenon but, while it is commonplace to measure these changes in terms of \"science\", much less popular are those aspects connected with the Humanities integrated in any architectural work. History of Architecture represents from this standpoint a perfect example of how new digital tools and approaches can help to disclose novel research opportunities. The paper presents two projects regarding the Vatican Basilica (the Sangallo\\'s wooden model for the New St. Peter and the reconstruction of St. Peter\\'s square \"the day before\" the moving of the Vatican Obelisk led by Domenico Fontana) as paradigmatic showcases.',\n",
              "  'Managing the real with the virtual: A role for digital media recording in archaeological fieldwork.[SEP]Recent innovations in digital media have allowed for a surge of new techniques to be applied to an old problem - how to record and archive the archaeological record and the process of archaeological fieldwork. Like many new technologies, digital recording is rife with limitations and challenges - low resolution when compared to traditional film, a lack of standards for both media types and archiving methods, expensive entry costs and a relatively high technical skill level required for implementing a complete digital recording methodology, to name a few. However, the benefits of embracing digital recording techniques range from the practical to the profound, for once the initial investment has been made, digital media is relatively inexpensive and allows for a more rich and finer grain of recording, including exciting innovations in GIS-information systems and visualization tools. While the benefits may outweigh the costs, there is within the field of archaeology a strong \"Resistance To Change\" and a feeling that digital media recording, while novel and promising, is nonessential when compared to traditional photography and illustration.',\n",
              "  'A Repository for Heterogeneous and Complex Digital Cultural Objects.[SEP]The paper proposes a solution for a repository of digital cultural objects, which can manage complex data as 3D objects, videos and more, together with the related metadata. The repository is built with open source components and may be easily installed and managed. Basing on an example, interfaces are shown for the most common operations. The system allows for text searches, semantic searches as well as facet refinements. The proposed system can support a full-featured digital library for its modularity and easy personalization.'],\n",
              " '55_number_symbolic_magnitude_numbers': ['Magnitude Comparisons of Improper Fractions.[SEP]Previous studies examining the mental representations of fractions have focused on fractions with magnitudes less than one (e.g., 2/3). In the current study, we examine the mental representations of fractions with magnitudes greater than one, specifically those of improper fractions. Participants were asked to make magnitude comparisons of these improper fractions to a reference that was in an improper fraction, a mixed fraction, or a decimal format. Results show that magnitudes of improper fractions were more accurately accessed when they were compared to mixed fractions and decimals. This suggests that the reinterpretation of these improper fractions benefited magnitude processing. Distance effects on error rate and response time were observed for all three reference formats and more consistently took the form of a Welford function, which predicts worse performance above rather than below the reference. Possible explanations of these results are discussed.',\n",
              "  'Mathematical Model of Developmental Changes in Number Cognition.[SEP]Numerical discrimination is a primary measure of the acuity of children’s approximate number system (ANS). ANS acuity is associated with key developmental outcomes such as symbolic number skill, standardized test scores and even employment outcomes. The current study examines the factors that contribute to children’s performance on non-symbolic numerical discrimination tasks. The current study evaluates the contribution of absolute value in children’s numerical discrimination, and how that contribution may change during development. We use a combination of behavioral and computational results to illustrate a U-shaped developmental change in the factors that predict numerical discriminability. Computational modeling based on the neural coding of numerical perception demonstrates why the reported behavioral data is expected. The novel inclusion of absolute value as a predictive factor in children’s numerical discrimination suggests reevaluation of connections between numerical acuity and educational outcomes.',\n",
              "  'Are Fractions Natural Numbers, Too?[SEP]This study presents evidence in favor of a cognitive primitives hypothesis for processing fraction magnitudes. This account holds that humans have perceptual access to fractional magnitudes and that this may be used to support symbolic fraction knowledge. In speeded cross-format comparisons, participants picked the larger of two stimuli, which were either symbolic fractions or nonsymbolic ratios composed of pairs of dot arrays or pairs of circles. Participants demonstrated distance effects across formats, demonstrating that they could compare analog fractional magnitudes independently of the particular formats in which they were presented. These results pose a challenge to innate constraints accounts that argue that human cortical structures are ill-suited for processing fractions. These results may have important implications both for theorizing about the nature of human number sense and for optimizing instruction of fractional concepts.'],\n",
              " '56_facebook_social_privacy_friends': ['\"Is it Weird to Still Be a Virgin\": Anonymous, Locally Targeted Questions on Facebook Confession Boards.[SEP]People have long sought answers to questions online, typically using either anonymous or pseudonymous forums or social network platforms that primarily use real names. Systems that allow anonymous communication afford freedom to explore identity and discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying. Identifiable communication systems allows one to reach a known audience and avoid negative disinhibition, but can constrain behavior with concerns about privacy and reputation. One persistent design issue is understanding how to leverage the benefits of anonymity without suffering its drawbacks. This paper presents a case study analysis of question asking on Facebook confession boards (FCBs), a tool popular on some college campuses. FCBs present a unique configuration in which members of an offline community (e.g., a university) anonymously submit content to a moderator who posts it to a Facebook page where others in the community can view it and respond. Response is via identifiable Facebook comments and likes. Our results show users asking about taboo and stigmatized topics with local others, and receiving relevant responses with little cyberbullying or negativity.',\n",
              "  \"The post that wasn't: exploring self-censorship on facebook.[SEP]Social networking site users must decide what content to share and with whom. Many social networks, including Facebook, provide tools that allow users to selectively share content or block people from viewing content. However, sometimes instead of targeting a particular audience, users will self-censor, or choose not to share. We report the results from an 18-participant user study designed to explore self-censorship behavior as well as the subset of unshared content participants would have potentially shared if they could have specifically targeted desired audiences. We asked participants to report all content they thought about sharing but decided not to share on Facebook and interviewed participants about why they made sharing decisions and with whom they would have liked to have shared or not shared. Participants reported that they would have shared approximately half the unshared content if they had been able to exactly target their desired audiences.\",\n",
              "  'Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content.[SEP]Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale.'],\n",
              " '57_influence_social_networks_network': ['Influence maximization: near-optimal time complexity meets practical efficiency.[SEP]Given a social network G and a constant $k$, the influence maximization problem asks for k nodes in G that (directly and indirectly) influence the largest number of nodes under a pre-defined diffusion model. This problem finds important applications in viral marketing, and has been extensively studied in the literature. Existing algorithms for influence maximization, however, either trade approximation guarantees for practical efficiency, or vice versa. In particular, among the algorithms that achieve constant factor approximations under the prominent independent cascade (IC) model or linear threshold (LT) model, none can handle a million-node graph without incurring prohibitive overheads.',\n",
              "  'Minimizing seed set selection with probabilistic coverage guarantee in a social network.[SEP]A topic propagating in a social network reaches its tipping point if the number of users discussing it in the network exceeds a critical threshold such that a wide cascade on the topic is likely to occur. In this paper, we consider the task of selecting initial seed users of a topic with minimum size so that {\\\\em with a guaranteed probability} the number of users discussing the topic would reach a given threshold. We formulate the task as an optimization problem called {\\\\em seed minimization with probabilistic coverage guarantee (SM-PCG)}. This problem departs from the previous studies on social influence maximization or seed minimization because it considers influence coverage with {\\\\em probabilistic} guarantees instead of guarantees on {\\\\em expected} influence coverage. We show that the problem is not submodular, and thus is harder than previously studied problems based on submodular function optimization. We provide an approximation algorithm and show that it approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplicative ratio is tight while the additive error would be small if influence coverage distributions of certain seed sets are well concentrated. For one-way bipartite graphs we analytically prove the concentration condition and obtain an approximation algorithm with an $O(\\\\log n)$ multiplicative ratio and an $O(\\\\sqrt{n})$ additive error, where $n$ is the total number of nodes in the social graph. Moreover, we empirically verify the concentration condition in real-world networks and experimentally demonstrate the effectiveness of our proposed algorithm comparing to commonly adopted benchmark algorithms.',\n",
              "  'Effective Large-Scale Online Influence Maximization.[SEP]In this paper, we study a highly generic version of influence maximization (IM), one of optimizing influence campaigns by sequentially selecting \"spread seeds\" from a set of candidates, a small subset of the node population, under the hypothesis that, in a given campaign, previously activated nodes remain \"persistently\" active throughout and thus do not yield further rewards. We call this problem online influence maximization with persistence. We introduce an estimator on the candidates\\' missing mass - the expected number of nodes that can still be reached from a given seed candidate - and justify its strength to rapidly estimate the desired value. We then describe a novel algorithm, GT-UCB, relying on upper confidence bounds on the missing mass. We show that our approach leads to high-quality spreads on classic IM datasets, even though it makes almost no assumptions on the diffusion medium. Importantly, it is orders of magnitude faster than state-of-the-art IM methods.'],\n",
              " '58_walking_virtual_locomotion_reality': ['Velocity-Dependent Dynamic Curvature Gain for Redirected Walking.[SEP]Redirected walking techniques allow people to walk in a larger virtual space than the physical extents of the laboratory. We describe two experiments conducted to investigate human sensitivity to walking on a curved path and to validate a new redirected walking technique. In a psychophysical experiment, we found that sensitivity to walking on a curved path was significantly lower for slower walking speeds (radius of 10 m versus 22 m). In an applied study, we investigated the influence of a velocity-dependent dynamic gain controller and an avatar controller on the average distance that participants were able to freely walk before needing to be reoriented. The mean walked distance was significantly greater in the dynamic gain controller condition, as compared to the static controller (22 m versus 15 m). Our results demonstrate that perceptually motivated dynamic redirected walking techniques, in combination with reorientation techniques, allow for unaided exploration of a large virtual city model.',\n",
              "  \"Virtual locomotion system for human-scale virtual environments.[SEP]This paper presents a new virtual locomotion interface based on step-in-place action and a smart-turntable system. The interface provides a turntable as walking platform, on top of which users will stand at its center, and facing a large screen, to perform life-like walking actions that steer their navigation through the virtual environment. Steering actions are tracked seamlessly without attachment to the body through a set of pressure sensors embedded within the turntable and a computer vision system. For instance, in place stepping is treated as a gesture indicating the intention to move forward. Rotation about the body's vertical axis is treated as a gesture changing the walking direction. However, as large screens are usually limited in size and do not allow a surrounding projection, a large turning action may put users in a visual-less situation, which hamper considerably the effectiveness of the walking experience. To avoid such case and keep users always provided with sufficient visual feedback, the turntable will passively and smoothly rotate in opposite direction of users' turning. Rotation speed and acceleration of the turntable are well optimized to keep users well balanced and easily withstand the passive rotation. The interface is shown to be easy and simple to use in virtual environments equipped with large screen.\",\n",
              "  '15 Years of Research on Redirected Walking in Immersive Virtual Environments.[SEP]Virtual reality users wearing head-mounted displays can experience the illusion of walking in any direction for infinite distance while, in reality, they are walking a curvilinear path in physical space. This is accomplished by introducing unnoticeable rotations to the virtual environment-a technique called redirected walking. This paper gives an overview of the research that has been performed since redirected walking was first practically demonstrated 15 years ago.'],\n",
              " '59_reality_augmented_virtual_interaction': ['Development of Adaptive Information Visualization Systems with Augmented Reality.[SEP]Augmented Reality combined with adaptive hypermedia plays an important role on providing effective information visualization systems. In this paper, we propose a comprehensive architecture model in order to provide adaptive information visualization systems with augmented reality. We also provide a novel visual metaphor for real-valued, low-dimensional data with optimal values for each feature inspired on the pseudo-flower metaphor.',\n",
              "  'Situated Visualization in The Decision Process Through Augmented Reality.[SEP]The decision-making process and the development of decision support systems (DSS) have been enhanced by a variety of methods originated from information science, cognitive psychology and artificial intelligence over the past years. Situated visualization (SV) is a method to present data representations in context. Its main characteristic is to display data representations near the data referent. As augmented reality (AR) is becoming more mature, affordable and widespread, using it as a tool for SV becomes feasible in several situations. In addition, it may provide a positive contribution to more effective and efficient decision-making, as the users have contextual, relevant and appropriate information to endorse their choices. As new challenges and opportunities arise, it is important to understand the relevance of intertwining these fields. Based on a literature analysis, this paper addresses and discusses current areas of application, benefits, challenges and opportunities of using SV through AR to visualize data in context and to support a decision-making process and its importance in future DSS.',\n",
              "  'Temporal Coherence Strategies for Augmented Reality Labeling.[SEP]Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.',\n",
              "  'Message from the Paper Chairs and Guest Editors.[SEP]The articles in this special issue contain the full paper proceedings of the IEEE Virtual Reality Conference 2012 (IEEE VR 2012), held March 4-8, 2012 in Orange County, California.',\n",
              "  \"Guest Editors' Introduction: Virtual Reality.[SEP]Presents the guest editorial for this issue of the publication.\",\n",
              "  'Future scenarios of mixed reality: the INTUITION roadmap scenarios.[SEP]INTUITION is a Network of Excellence that aims to integrate the European research efforts on the scientific and technological field of Virtual and Mixed Reality. To perform that, a series of activities have taken place in order to gather knowledge regarding actors and research profiles, projects and research results, products and patents. Having a clear view of research needs and technology trends the Network has envisioned the research goals that need to be pursued within the years to come. The starting point is a set of visionary scenarios which set out the picture for the technological and scientific advances that need to take place. Within this paper a set of indicative scenarios on a higher and descriptive level are provided and the way they contribute to the roadmap definition is explained. With this report we want to share these scenarios and our initial thoughts to stimulate a broader discussion and invite people from all relevant backgrounds to enter the knowledge creation process. The paper is a collective production of the INTUITION Consortium.'],\n",
              " '5_shape_mesh_meshes_subdivision': ['Spectral compression of mesh geometry.[SEP]We show how spectral methods may be applied to 3D mesh data to obtain compact representations. This is achieved by projecting the mesh geometry onto an orthonormal basis derived from the mesh topology. To reduce complexity, the mesh is partitioned into a number of balanced submeshes with minimal interaction, each of which are compressed independently. Our methods may be used for compression and progressive transmission of 3D content, and are shown to be vastly superior to existing methods using spatial techniques, if slight loss can be tolerated.',\n",
              "  'Compressing Polygon Mesh Geometry with Parallelogram Prediction.[SEP]We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.',\n",
              "  'Connectivity Compression for Three-Dimensional Planar Triangle Meshes.[SEP]We describe a new algorithm for coding the connectivity information of three-dimensional planar triangle meshes. Vertices of a mesh are placed on a two-dimensional grid. The connectivity pattern of the grid is implicit and hence the only information that needs to be encoded is the diagonal links. We present experimental results that show that the new method has a low connectivity cost of 2.1 bits per vertex on average.',\n",
              "  'A Unified Interpolatory and Approximation sqrt-3 Subdivision Scheme.[SEP]We have found that there is a relationship between the cubic B-spline and four-point curve subdivision method. In the paper it is used to deduce interpolatory subdivision schemes from cubic B-spline based approximation subdivision schemes directly and construct unified schemes for compositing approximation and interpolatory subdivision. A new interpolatory p3 subdivision scheme and a interpolatory and approximation blended p3 subdivision scheme are created by this straightforward method. The former produces C1 limit surface and avoids the problem in the exsiting interpolatory p3 subdivision mask where the weight coefficients on extraordinary vertices can not be described by explicit formulation. The latter can be used to solve the \"popping effect\" problem when switching between meshes at different levels of resolution, provide the possibility to locally choose an interpolating variant of the conventionally approximating subdivision scheme, and give more flexibility for feature modeling. These are realized by only changing the value of a parameter. The method is thoroughly simple without needs of constructing and solving equations.',\n",
              "  'Quad/Triangle Subdivision.[SEP]In this paper we introduce a new subdivision operator that unifies triangular and quadrilateral subdivision schemes. Designers often want the added flexibility of having both quads and triangles in their models. It is also well known that triangle meshes generate poor limit surfaces when using a quad scheme, while quad‐only meshes behave poorly with triangular schemes. Our new scheme is a generalization of the well known Catmull‐Clark and Loop subdivision algorithms. We show that our surfaces are C 1 everywhere and provide a proof that it is impossible to construct such a C 2 scheme at the quad/triangle boundary. However, we provide rules that produce surfaces with bounded curvature at the regular quad/triangle boundary and provide optimal masks that minimize the curvature divergence elsewhere. We demonstrate the visual quality of our surfaces with several examples.',\n",
              "  'A New Interpolatory Subdivision for Quadrilateral Meshes.[SEP]This paper presents a new interpolatory subdivision scheme for quadrilateral meshes based on a 1–4 splitting operator. The scheme generates surfaces coincident with those of the Kobbelt interpolatory subdivision scheme for regular meshes. A new group of rules are designed for computing newly inserted vertices around extraordinary vertices. As an extension of the regular masks,the new rules are derived based on a reinterpretation of the regular masks. Eigen‐structure analysis demonstrates that subdivision surfaces generated using the new scheme are C1 continuous and, in addition, have bounded curvature.',\n",
              "  'Planar Shape Interpolation Based On Teichm[SEP]Shape interpolation is a classical problem in computer graphics and has been widely investigated in the past two decades. Ideal shape interpolation should be natural and smooth which have good properties such as affine and conformal reproduction, bounded distortion, no fold‐overs, etc. In this paper, we present a new approach for planar shape interpolation based on Teichmüller maps ‐ a special type of maps in the class of quasi‐conformal maps. The algorithm consists of two steps. In the first step, a Teichmüller map is computed from the source shape to the target shape, and then the Beltrami coefficient is interpolated such that the conformal distortion is linear with respect to the time variable. In the second step, the intermediate shape is reconstructed by solving the Beltrami equation locally over each triangle and then stitching the mapped triangles by conformal transformations. The new approach preserves all the good properties mentioned above and produces more natural and more uniform intermediate shapes than the start‐of‐the‐art methods. Especially, the conformal distortion changes linearly with respect to the time variable. Experiment results show that our method can produce appealing results regardless of interpolating between the same or different objects.',\n",
              "  'Locally Injective Mappings.[SEP]Mappings and deformations are ubiquitous in geometry processing, shape modeling, and animation. Numerous deformation energies have been proposed to tackle problems like mesh parameterization and volumetric deformations. We present an algorithm that modifies any deformation energy to guarantee a locally injective mapping, i.e., without inverted elements. Our formulation can be used to compute continuous planar or volumetric piecewise‐linear maps and it uses a barrier term to prevent inverted elements. Differently from previous methods, we carefully design both the barrier term and the associated numerical techniques to be able to provide immediate feedback to the user, enabling interactive manipulation of inversion‐free mappings. Stress tests show that our method robustly handles extreme deformations where previous techniques converge very slowly or even fail. We demonstrate that enforcing local injectivity increases fidelity of the results in applications such as shape deformation and parameterization.',\n",
              "  'As-Rigid-As\\ue4f8Possible Distance Field Metamorphosis.[SEP]Widely used for morphing between objects with arbitrary topology, distance field interpolation (DFI) handles topological transition naturally without the need for correspondence or remeshing, unlike surface‐based interpolation approaches. However, lack of correspondence in DFI also leads to ineffective control over the morphing process. In particular, unless the user specifies a dense set of landmarks, it is not even possible to measure the distortion of intermediate shapes during interpolation, let alone control it. To remedy such issues, we introduce an approach for establishing correspondence between the interior of two arbitrary objects, formulated as an optimal mass transport problem with a sparse set of landmarks. This correspondence enables us to compute non‐rigid warping functions that better align the source and target objects as well as to incorporate local rigidity constraints to perform as‐rigid‐as\\ue4f8possible DFI. We demonstrate how our approach helps achieve flexible morphing results with a small number of landmarks.',\n",
              "  'Vega: Non-Linear FEM Deformable Object Simulator.[SEP]This practice and experience paper describes a robust C++ implementation of several non‐linear solid three‐dimensional deformable object strategies commonly employed in computer graphics, named the Vega finite element method (FEM) simulation library. Deformable models supported include co‐rotational linear FEM elasticity, Saint–Venant Kirchhoff FEM model, mass–spring system and invertible FEM models: neo‐Hookean, Saint–Venant Kirchhoff and Mooney–Rivlin. We provide several timestepping schemes, including implicit Newmark and backward Euler integrators, and explicit central differences. The implementation of material models is separated from integration, which makes it possible to employ our code not only for simulation, but also for deformable object control and shape modelling. We extensively compare the different material models and timestepping schemes. We provide practical experience and insight gained while using our code in several computer animation and simulation research projects.',\n",
              "  \"Modal Warping: Real-Time Simulation of Large Rotational Deformation and Manipulation.[SEP]This work proposes a real-time simulation technique for large deformations. Green's nonlinear strain tensor accurately models large deformations; however, time stepping of the resulting nonlinear system can be computationally expensive. Modal analysis based on a linear strain tensor has been shown to be suitable for real-time simulation, but is accurate only for moderately small deformations. In the present work, we identify the rotational component of an infinitesimal deformation and extend traditional linear modal analysis to track that component. We then develop a procedure to integrate the small rotations occurring at the nodal points. An interesting feature of our formulation is that it can implement both position and orientation constraints in a straightforward manner. These constraints can be used to interactively manipulate the shape of a deformable solid by dragging/twisting a set of nodes. Experiments show that the proposed technique runs in real-time, even for a complex model, and that it can simulate large bending and/or twisting deformations with acceptable realism.\",\n",
              "  'Geometric Stiffness for Real-time Constrained Multibody Dynamics.[SEP]This paper focuses on the stable and efficient simulation of articulated rigid body systems for real‐time applications. Specifically, we focus on the use of geometric stiffness which can dramatically increase simulation stability. We examine several numerical problems with the inclusion of geometric stiffness in the equations of motion, as proposed by previous work, and address these issues by introducing a novel method for efficiently building the linear system. This offers improved tractability and numerical efficiency. Furthermore, geometric stiffness tends to significantly dissipate kinetic energy. We propose an adaptive damping scheme, inspired by the geometric stiffness, that uses a stability criterion based on the numerical integrator to determine the amount of non‐constitutive damping required to stabilize the simulation. With this approach, not only is the dynamical behavior better preserved, but the simulation remains stable for mass ratios of 1,000,000‐to‐1 at time steps up to 0.1 s. We present a number of challenging scenarios to demonstrate that our method improves efficiency, and that it increases stability by orders of magnitude compared to previous work.',\n",
              "  'Simplifying surfaces with color and texture using quadric error metrics.[SEP]There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.',\n",
              "  'Locally Toleranced Surface Simplification.[SEP]We present a technique for simplifying a triangulated surface. Simplifying consists of approximating the surface with another surface of lower triangle count. Our algorithm can preserve the volume of a solid to within machine accuracy; it favors the creation of near-equilateral triangles. We develop novel methods for reporting and representing a bound to the approximation error between a simplified surface and the original, and respecting a variable tolerance across the surface. A different positive error value is reported at each vertex. By linearly blending the error values in between vertices, we define a volume of space, called the error volume, as the union of balls of linearly varying radii. The error volume is built dynamically as the simplification progresses, on top of preexisting error volumes that it contains. We also build a tolerance volume to forbid simplification errors exceeding a local tolerance. The information necessary to compute error values is local to the star of a vertex; accordingly, the complexity of the algorithm is either linear or in O(n log n) in the original number of surface edges, depending on the variant. We extend the mechanisms of error and tolerance volumes to preserve during simplification scalar and vector attributes associated with surface vertices. Assuming a linear variation across triangles, error and tolerance volumes are defined in the same fashion as for positional error. For normals, a corrective term is applied to the error measured at the vertices to compensate for nonlinearities.',\n",
              "  'Coarse-to-fine surface simplification with geometric guarantees.[SEP]Let PC be a 3D point cloud and ε be a positive value called tolerance. We aim at constructing a triangulated surface S based on a subset PCU of PC such that all the points in PCL=PC∖PCU are at distance at most ε from a facet of S. (PCU and PCL respectively stand for Point Cloud Used and Point Cloud Left.) We call this problem simplification with geometric guarantees.',\n",
              "  'Crest Lines for Surface Segmentation and Flattening.[SEP]We present a method for extracting feature curves called crest lines from a triangulated surface. Then, we calculate the geodesic Voronoi diagram of crest lines to segment the surface into several regions. Afterward, barycentric surface flattening using theory from graph embeddings is implemented and, using the geodesic Voronoi diagram, we develop a faster surface flattening algorithm.',\n",
              "  'On stochastic methods for surface reconstruction.[SEP]In this article, we present and discuss three statistical methods for surface reconstruction. A typical input to a surface reconstruction technique consists of a large set of points that has been sampled from a smooth surface and contains uncertain data in the form of noise and outliers. We first present a method that filters out uncertain and redundant information yielding a more accurate and economical surface representation. Then we present two methods, each of which converts the input point data to a standard shape representation; the first produces an implicit representation while the second yields a triangle mesh.',\n",
              "  'Applied Geometry: Discrete Differential Calculus for Graphics.[SEP]Geometry has been extensively studied for centuries, almost exclusively from a differential point of view. However, with the advent of the digital age, the interest directed to smooth surfaces has now partially shifted due to the growing importance of discrete geometry. From 3D surfaces in graphics to higher dimensional manifolds in mechanics, computational sciences must deal with sampled geometric data on a daily basis‐hence our interest in Applied Geometry.',\n",
              "  'One Point Isometric Matching with the Heat Kernel.[SEP]A common operation in many geometry processing algorithms consists of finding correspondences between pairs of shapes by finding structure‐preserving maps between them. A particularly useful case of such maps is isometries, which preserve geodesic distances between points on each shape. Although several algorithms have been proposed to find approximately isometric maps between a pair of shapes, the structure of the space of isometries is not well understood. In this paper, we show that under mild genericity conditions, a single correspondence can be used to recover an isometry defined on entire shapes, and thus the space of all isometries can be parameterized by one correspondence between a pair of points. Perhaps surprisingly, this result is general, and does not depend on the dimensionality or the genus, and is valid for compact manifolds in any dimension. Moreover, we show that both the initial correspondence and the isometry can be recovered efficiently in practice. This allows us to devise an algorithm to find intrinsic symmetries of shapes, match shapes undergoing isometric deformations, as well as match partial and incomplete models efficiently.',\n",
              "  'Computing Teichm[SEP]Shape indexing, classification, and retrieval are fundamental problems in computer graphics. This work introduces a novel method for surface indexing and classification based on Teichmuller theory. The Teichmuller space for surfaces with the same topology is a finite dimensional manifold, where each point represents a conformal equivalence class, a curve represents a deformation process from one class to the other. We apply Teichmuller space coordinates as shape descriptors, which are succinct, discriminating and intrinsic; invariant under the rigid motions and scalings, insensitive to resolutions. Furthermore, the method has solid theoretic foundation, and the computation of Teichmuller coordinates is practical, stable and efficient. This work focuses on the surfaces with negative Euler numbers, which have a unique conformal Riemannian metric with -1 Gaussian curvature. The coordinates which we will compute are the lengths of a special set of geodesics under this special metric. The metric can be obtained by the curvature flow algorithm, the geodesics can be calculated using algebraic topological method. We tested our method extensively for indexing and comparison of about one hundred of surfaces with various topologies, geometries and resolutions. The experimental results show the efficacy and efficiency of the length coordinate of the Teichmuller space.',\n",
              "  'Bilateral Maps for Partial Matching.[SEP]Feature‐driven analysis forms the basis of many shape processing tasks, where detected feature points are characterized by local shape descriptors. Such descriptors have so far been defined to capture regions of interest centred at individual points. Using such regions to compare feature points can be problematic when performing partial shape matching, because the region of interest is typically defined as an isotropic neighbourhood around a point, which does not adapt to the geometry of the shape parts. We introduce the bilateral map, a local shape descriptor whose region of interest is defined by two feature points. Compared to the classical descriptor definition using a single point, the bilateral approach exploits the use of a second point to place more constraints on the selection of the spatial context for feature analysis. This leads to a descriptor where the shape of the region of interest adapts to the context of the two points, making it more refined for shape matching. In particular, we show that our new descriptor is more effective for partial matching, because potentially extraneous regions of the models are selectively ignored owing to the adaptive nature of the bilateral map. This property also renders the bilateral map partially insensitive to topological changes. We demonstrate the effectiveness of the bilateral map for partial matching via several correspondence and retrieval experiments and evaluate the results both qualitatively and quantitatively.'],\n",
              " '60_molecules_atoms_molecule_halos': [\"Protein Tunnel Reprojection for Physico-Chemical Property Analysis.[SEP]Cavities are crucial for interactions of proteins with other molecules. While a variety of different cavity types exists, tunnels in particular play an important role, as they enable a ligand to deeply enter the active site of a protein where chemical reactions can undergo. Consequently, domain scientists are interested in understanding properties relevant for binding interactions inside molecular tunnels. Unfortunately, when inspecting a 3D representation of the molecule under investigation, tunnels are difficult to analyze due to occlusion issues. Therefore, within this paper we propose a novel reprojection technique that transforms the 3D structure of a molecule to obtain a 2D representation of the tunnel interior. The reprojection has been designed with respect to application-oriented design guidelines, we have identified together with our domain partners. To comply with these guidelines, the transformation preserves individual residues, while the result is capable of showing binding properties inside the tunnel without suffering from occlusions. Thus the reprojected tunnel interior can be used to display physico-chemical properties, e.g., hydrophobicity or amino acid orientation, of residues near a tunnel's surface. As these properties are essential for the interaction between protein and ligand, they can thus hint angles of attack for protein engineers. To demonstrate the benefits of the developed visualization, the obtained results are discussed with respect to domain expert feedback.\",\n",
              "  'Comparative Visualization of Molecular Surfaces Using Deformable Models.[SEP]The comparison of molecular surface attributes is of interest for computer aided drug design and the analysis of biochemical simulations. Due to the non‐rigid nature of molecular surfaces, partial shape matching is feasible for mapping two surfaces onto each other. We present a novel technique to obtain a mapping relation between two surfaces using a deformable model approach. This relation is used for pair‐wise comparison of local surface attributes (e.g. electrostatic potential). We combine the difference value as well as the comparability as derived from the local matching quality in a 3D molecular visualization by mapping them to color. A 2D matrix shows the global dissimilarity in an overview of different data sets in an ensemble. We apply our visualizations to simulation results provided by collaborators from the field of biochemistry to evaluate the effectiveness of our results.',\n",
              "  'CAVER Viewer - the explorer of behaviour of tunnels in proteins.[SEP]Protein exploration in order to discover new medication has been the principal aim of biochemists. In combination with informatics the solution of this task can be faster, more accurate and also more intuitive and straightforward in comparison with traditional methods. Our CAVER Viewer application allows the exploration of protein structures and the visualization of results. It enables to find certain paths from the outer space around the molecule to the specific site inside the protein called the active site. The existence of these important paths (also called tunnels or channels) is crucial in the process of transferring some small molecule of substrate into this active site. Namely, the substrate enters the active site via these precomputed tunnels. There the chemical reaction between the substrate and protein can undergo. The product of this reaction can form the basis of a new medication. This poster describes the key aim of our research in the field of protein visualization, when we have to visualize the protein dynamics - movements of the molecule as well as the behaviour of its tunnels in time space.'],\n",
              " '61_memory_insight_solving_task': ['Constraints on Theories of Serial Order Memory Revisited: The Cases of the Fill-In and Protrusion Effects.[SEP]In his seminal dissertation, Henson (1996) identified a number of constraints on theories of serial order memory. Two constraints, the fill-in constraint, in which an item that is erroneously recalled early is likely to be followed by its predecessor rather than its successor (recall of ACB is more likely than ACD), and the protrusion constraint, in which prior list intrusions are likely to be recalled in the same output position as their previous serial position, were considered evidence against chaining theories. We present results from two experiments which investigate the extent to which these effects are dependent on experimental methodology. When participants are given an open set of items, an equal ratio of fill-in and in-fill errors was observed and a protrusion effect was obtained. However, when a reconstruction of order task was used, a fill-in effect was observed. Implications for theories of serial order memory are discussed.',\n",
              "  \"The Primary and Convergent Retrieval Model of Recall.[SEP]Memory models typically assume that recall is a two-stage process with learning affecting both processes to the same degree. This equal learning assumption is difficult to reconcile with studies of the 'testing effect', which reveal different forgetting rates following learning from test practice versus learning from restudy. Here we present a new memory model, termed Primary and Convergent Retrieval (PCR) that assumes successful recall leads to a selective enhancement for the second stage of recall (Convergent Retrieval). We applied this model to existing testing effect data. In two new experiments, we confirmed novel predictions of the PCR model for transfer between retrieval cues and for recall latencies. This is the first formally specified model of the testing effect and it has broad implications for the nature of learning and retrieval.\",\n",
              "  \"Now I like it, now I don't: Delay effects and retrospective judgment.[SEP]The present paper tests the widely accepted hypothesis that on-line judgment implies functional independence between memory for, and judgment of, verbal stimuli (e.g., Anderson, 1989; Hastie & Park, 1986). In the present study, participants recalled lists of words, after having assessed each for its pleasantness. Presentation position of a negative item within the lists was manipulated. Also, items memorability was manipulated after their presentation – by inserting a filled delay between presentation and the judgment task; in this way, on-line judgment formation was spared. The memory manipulation reduced recall rates for negative items presented in the last position – and their negative influence on pleasantness ratings accordingly. These results contradict the predictions of pure on-line approaches to judgment formation (e.g., Betsch, Plessner, Schwieren, & Gütig, 2001) and suggest that even in on-line judgment tasks, memory plays a role.\",\n",
              "  'Evaluating the Relationship Between Neuropsychological Function and Cognitive Performance.[SEP]The last 2 decades have produced a vast literature describing relationships between cognitive performance and neuropsychological data. This literature has provided the foundation for countless theories about the neural correlates of cognitive processing and specific theories regarding the role of different cortical areas in human cognition. In this paper, we examine a particular theory – the error likelihood model (Brown & Braver, 2005) – that attempts to account for the function of a particular brain area (the anterior cingulate cortex). A careful evaluation of behavioral data from humans raises questions about the error likelihood model and the implications of neuropsychological data for understanding cognitive performance.',\n",
              "  'Using a Cognitive Model for an In-Depth Analysis of the Tower of London.[SEP]The Tower of London (ToL) is a transformation task extensively used and well-established as a neuropsychological diagnostic tool for assessing human planning ability in clinical and research contexts. Behavioral experiments have recently shown that planning in the ToL is substantially influenced by structural task parameters. This work presents an ACT-R model of the ToL that explains structural influences by using different strategies, whereby, strategy selection depends on visually observable characteristics. Model evaluation was based on a problem selection that accounted for systematic variations of task demands. Based on comparisons with empirically observed planning latencies from previously published data, we argue that task-specific structural characteristics are necessary to explain human planning strategies.',\n",
              "  'A Mechanistic Account of Constraints on Control-Dependent Processing: Shared Representation, Conflict and Persistence.[SEP]One of the most fundamental and striking limitations of human cognitive function is the constraint on the number of control-dependent processes that can be executed simultaneously. However, the sources of this capacity constraint remain largely unexplored. Previous work has attributed the constraints on control-dependent processing to the sharing of representations between tasks in neural systems. Here, we examine how shared representations interact with two other factors in producing constraints on control-dependent processing. We first demonstrate that the detrimental effects of shared representations on multitasking performance are contingent on the amount of conflict that is induced by the tasks that share representations. We then examine how the persistence of shared representations between tasks affects processing interference during serial task execution. Finally, we discuss how this set of mechanisms can account for various phenomena in neural architectures, including the psychological refractory period, task switch costs, as well as constraints on cognitive control.'],\n",
              " '62_spline_splines_curves_cubic': ['Surface approximation to scanned data.[SEP]A method to approximate scanned data points with a B-spline surface is presented. The data are assumed to be organized in the form of Q i,j, i=0,…,n; j=0,…,m i, i.e., in a row-wise fashion. The method produces a C (p-1, q-1) continuous surface (p and q are the required degrees) that does not deviate from the data by more than a user-specified tolerance. The parametrization of the surface is not affected negatively by the distribution of the points in each row, and it can be influenced by a user-supplied knot vector.',\n",
              "  \"A recursive evaluation algorithm for a class of Catmull-Rom splines.[SEP]It is known that certain Catmull-Rom splines [7] interpolate their control vertices and share many properties such as affine invariance, global smoothness, and local control with B-spline curves; they are therefore of possible interest to computer aided design. It is shown here that another property a class of Catmull-Rom splines shares with B-spline curves is that both schemes possess a simple recursive evaluation algorithm. The Catmull-Rom evaluation algorithm is constructed by combining the de Boor algorithm for evaluating B-spline curves with Neville's algorithm for evaluating Lagrange polynomials. The recursive evaluation algorithm for Catmull-Rom curves allows rapid evaluation of these curves by pipelining with specially designed hardware. Furthermore it facilitates the development of new, related curve schemes which may have useful shape parameters for altering the shape of the curve without moving the control vertices. It may also be used for constructing transformations to B&eacute;zier and B-spline form.\",\n",
              "  'B-spline surfaces for ship hull design.[SEP]The use of true sculptured surface descriptions for design applications has been proposed by numerous authors. The actual implementation and use of interactive sculptured surface description techniques for design and production has been limited. The use of such techniques for ship hull design has been even more limited. The present paper describes a preliminary implementation of such a system for the design of ship hulls and for the production of towing tank models using numerical control techniques. The present implementation is based on a Cartesian product B-spline surface description. Implementation is on an Evans and Sutherland Picture System supported by a PDP-11/45 minicomputer.'],\n",
              " '63_clustering_clusters_cluster_clusterings': ['A robust and scalable clustering algorithm for mixed type attributes in large database environment.[SEP]Clustering is a widely used technique in data mining applications to discover patterns in the underlying data. Most traditional clustering algorithms are limited to handling datasets that contain either continuous or categorical attributes. However, datasets with mixed types of attributes are common in real life data mining problems. In this paper, we propose a distance measure that enables clustering data with both continuous and categorical attributes. This distance measure is derived from a probabilistic model that the distance between two clusters is equivalent to the decrease in log-likelihood function as a result of merging. Calculation of this measure is memory efficient as it depends only on the merging cluster pair and not on all the other clusters. Zhang et al [8] proposed a clustering method named BIRCH that is especially suitable for very large datasets. We develop a clustering algorithm using our distance measure based on the framework of BIRCH. Similar to BIRCH, our algorithm first performs a pre-clustering step by scanning the entire dataset and storing the dense regions of data records in terms of summary statistics. A hierarchical clustering algorithm is then applied to cluster the dense regions. Apart from the ability of handling mixed type of attributes, our algorithm differs from BIRCH in that we add a procedure that enables the algorithm to automatically determine the appropriate number of clusters and a new strategy of assigning cluster membership to noisy data. For data with mixed type of attributes, our experimental results confirm that the algorithm not only generates better quality clusters than the traditional k-means algorithms, but also exhibits good scalability properties and is able to identify the underlying number of clusters in the data correctly. The algorithm is implemented in the commercial data mining tool Clementine 6.0 which supports the PMML standard of data mining model deployment.',\n",
              "  'Foundations of Perturbation Robust Clustering.[SEP]Clustering is a fundamental data mining tool that aims to divide data into groups of similar items. Intuition about clustering reflects the ideal case - exact data sets endowed with flawless dissimilarity between individual instances. In practice however, these cases are in the minority, and clustering applications are typically characterized by noisy data sets with approximate pairwise dissimilarities. As such, the efficacy of clustering methods necessitates robustness to perturbations. In this paper, we address foundational questions on perturbation robustness, studying to what extent can clustering techniques exhibit this desirable characteristic. Our results also demonstrate the type of cluster structures required for robustness of popular clustering paradigms.',\n",
              "  'Scalable k -Means Clustering via Lightweight Coresets.[SEP]\\\\emphCoresets are compact representations of data sets such that models trained on a coreset are provably competitive with models trained on the full data set. As such, they have been successfully used to scale up clustering models to massive data sets. While existing approaches generally only allow for multiplicative approximation errors, we propose a novel notion of lightweight coresets that allows for both multiplicative and additive errors. We provide a single algorithm to construct lightweight coresets for k -means clustering as well as soft and hard Bregman clustering. The algorithm is substantially faster than existing constructions, embarrassingly parallel, and the resulting coresets are smaller. We further show that the proposed approach naturally generalizes to statistical k -means clustering and that, compared to existing results, it can be used to compute smaller summaries for empirical risk minimization. In extensive experiments, we demonstrate that the proposed algorithm outperforms existing data summarization strategies in practice.'],\n",
              " '64_impaired_visually_tactile_impairments': [\"Design and user evaluation of a joystick-operated full-screen magnifier.[SEP]The paper reports on two development cycles of a joystick-operated full-screen magnifier for visually impaired users. In the first cycle of evaluation, seven visually impaired computer users evaluated the system in comprehension-based sessions using text documents. After considering feedback from these evaluators, a second version of the system was produced and evaluated by a further six visually impaired users. The second evaluation was conducted using information-seeking tasks using Web pages. In both evaluations, the 'thinking aloud protocol' was used. This study makes several contributions to the field. First, it is perhaps the first published study investigating the use of a joystick as an absolute and relative pointing device to control a screen magnifier. Second, the present study revealed that for most of the visually impaired users who participated in the study the joystick had good spatial, cognitive and ergonomic attributes, even for those who had never before used a joystick.\",\n",
              "  'Molder: An Accessible Design Tool for Tactile Maps.[SEP]Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.',\n",
              "  'Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: a Participatory Design Approach.[SEP]Current low-tech Orientation & Mobility (O&M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.'],\n",
              " '65_distributed_parallel_scientific_convergence': ['Distributed computing: new power for scientific visualization.[SEP]Distributed computing provides unique benefits for scientific visualization in this system (Discover) that supports interactive visualization and cooperative work for nonprogrammers. Discover (Distributed Interactive Scientific Computing and Visualization Environment), is suitable for many areas, but we have concentrated on medical image analysis and generation-one of the the most rapidly growing applications for scientific visualization. In its present form, Discover acts as a framework for clinical applications. True to its name, it allows a variety of users to discover the relevant information in a vast body of scientific data. Nonprogrammers, such as physicians and radiologists, interactively display and manipulate the two and three dimensional medical objects, visualize the results, control system computation, and generally drive the image analysis process. The emphasis is on the distributed nature of the software architecture and its functions. We also describe a unique load balancing algorithm designed to maximize workstation performance.',\n",
              "  \"Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations.[SEP]The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.\",\n",
              "  'A Concurrent Architecture Proposal for Information Visualization Pipeline.[SEP]This paper identifies an opportunity to reduce the latency in information visualization (InfoVis) systems, exploring the parallelization of the visualization pipeline architecture. We propose a concurrent architecture where the visualization pipeline stages are modified to execute as producers and consumers threads. The threads synchronization is done by memory barriers and the data flow pass the pipeline through a unique data structure, called ring buffer, which reuses a contiguous space preallocated in memory. Two InfoVis prototypes were developed in java, the first one using sequential pipeline and the other using concurrent pipeline. The results obtained with concurrent architecture in comparison with sequential pipeline presented less execution time and memory allocation for data visualization renderization.',\n",
              "  'A Weighted Aggregating SGD for Scalable Parallelization in Deep Learning.[SEP]We investigate the stochastic optimization problem and develop a scalable parallel computing algorithm for deep learning tasks. The key of our study involves a reformation of the objective function for the stochastic optimization in neural network models. We propose a novel update rule, named weighted aggregating stochastic gradient decent, after theoretically analyzing the characteristics of the newly formalized objective function. The new rule introduces a weighted aggregation scheme based on the performance of local workers and does not require a center variable. It assesses the relative importance of local workers and accepts them according to their contributions. Our new rule also allows the implementation of both synchronous and asynchronous parallelization and can result in varying convergence rates. For method evaluation, we benchmark our schemes against the mainstream algorithms, including the elastic averaging SGD in training deep neural networks for classification tasks. We conduct extensive experiments on several classic datasets, and the results confirm the strength of our scheme in accelerating the training of deep architecture and scalable parallelization.',\n",
              "  'Large-scale distributed non-negative sparse coding and sparse dictionary learning.[SEP]We consider the problem of building compact, unsupervised representations of large, high-dimensional, non-negative data using sparse coding and dictionary learning schemes, with an emphasis on executing the algorithm in a Map-Reduce environment. The proposed algorithms may be seen as parallel optimization procedures for constructing sparse non-negative factorizations of large, sparse matrices. Our approach alternates between a parallel sparse coding phase implemented using greedy or convex (l1) regularized risk minimization procedures, and a sequential dictionary learning phase where we solve a set of l0 optimization problems exactly. These two-fold sparsity constraints lead to better statistical performance on text analysis tasks and at the same time make it possible to implement each iteration in a single Map-Reduce job. We detail our implementations and optimizations that lead to the ability to factor matrices with more than 100 million rows and billions of non-zero entries in just a few hours on a small commodity cluster.',\n",
              "  'Parallelization with Multiplicative Algorithms for Big Data Mining.[SEP]We propose a nontrivial strategy to parallelize a series of data mining and machine learning problems, including 1-class and 2-class support vector machines, nonnegative least square problems, and \\\\ell_1 regularized regression (LASSO) problems. Our strategy fortunately leads to extremely simple multiplicative algorithms which can be straightforwardly implemented in parallel computational environments, such as Map Reduce, or CUDA. We provide rigorous analysis of the correctness and convergence of the algorithm. We demonstrate the scalability and accuracy of our algorithms in comparison with other current leading algorithms.'],\n",
              " '66_wikipedia_communities_community_newcomers': [\"Impression formation in online peer production: activity traces and personal profiles in github.[SEP]In this paper we describe a qualitative investigation of impression formation in an online distributed software development community with social media functionality. We find that users in this setting seek out additional information about each other to explore the project space, inform future interactions, and understand the potential future value of a new person. They form impressions around other users' expertise based on history of activity across projects, and successful collaborations with key high status projects in the community. These impressions influence their receptivity to strangers' work contributions.\",\n",
              "  'Community insights: helping community leaders enhance the value of enterprise online communities.[SEP]Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.',\n",
              "  \"SuggestBot: using intelligent task routing to help people find work in wikipedia.[SEP]Member-maintained communities ask their users to perform tasks the community needs. From Slashdot, to IMDb, to Wikipedia, groups with diverse interests create community-maintained artifacts of lasting value (CALV) that support the group's main purpose and provide value to others. Said communities don't help members find work to do, or do so without regard to individual preferences, such as Slashdot assigning meta-moderation randomly. Yet social science theory suggests that reducing the cost and increasing the personal value of contribution would motivate members to participate more.We present SuggestBot, software that performs intelligent task routing (matching people with tasks) in Wikipedia. SuggestBot uses broadly applicable strategies of text analysis, collaborative filtering, and hyperlink following to recommend tasks. SuggestBot's intelligent task routing increases the number of edits by roughly four times compared to suggesting random articles. Our contributions are: 1) demonstrating the value of intelligent task routing in a real deployment; 2) showing how to do intelligent task routing; and 3) sharing our experience of deploying a tool in Wikipedia, which offered both challenges and opportunities for research.\"],\n",
              " '67_metaphors_metaphor_analogical_analogy': ['Spontaneous Analogy by Piggybacking on a Perceptual System.[SEP]Most computational models of analogy assume they are given a delineated source domain and often a specified target domain. These systems do not address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory, a process we call spontaneous analogy. We present a system that represents relational structures as feature bags. Using this representation, our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long-term memory. We provide a demonstration of our approach that takes a set of unsegmented stories, constructs an ontology of analogical schemas (corresponding to plot devices), and uses this ontology to efficiently find analogs within new stories, yielding significant time-savings over linear analog retrieval at a small accuracy cost.',\n",
              "  'Generalizing relations during analogical problem solving in preschool children: does blocked or interleaved training improve performance?[SEP]Analogical reasoning, the mapping of structured relations across conceptual domains, is commonly recognized as essential to human cognition, but young children often perform poorly in the classical A:B::C:? analogical reasoning task. Particularly, young children have trouble when the objects in the task are not strongly associated with each other, and/or when there are strong associative lures among the potential answers. Here, we examine whether successive trials that repeat the same relation needed to solve the analogy can help overcome some of the challenges with weakly associated items. In the first of two experiments, our results were mixed. In the second, we simplified the design, and were able to more clearly show a benefit of repeating relations across consecutively solved problems.',\n",
              "  'Analogy and Arithmetics: An HDTP-Based Model of the Calculation Circular Staircase.[SEP]Analogical reasoning and its applications are gaining attention not only in cognitive science but also in the context of education and teaching. In this paper we provide a short analysis and a detailed formal model (based on the Heuristic-Driven Theory Projection framework for computational analogy-making) of the Calculation Circular Staircase, a tool for teaching basic arithmetic and insights based on the ordinal number conception of the natural numbers to children in their first years of primary school. We argue that such formal methods and computational accounts of analogy-making can be used to gain additional insights in the inner workings of analogy-based educational methods and tools.',\n",
              "  'An Eye For Figurative Meaning: The Effects of Familiarity on Metaphor Comprehension.[SEP]The career of metaphor hypothesis suggests that processing preference is a result of conventionality whereby conventional metaphors are processed through categorization, and novel ones processed through comparison. Alternatively, the categorization model predicts that apt metaphors are processed as categorizations whether or not they are conventional. However, research has largely ignored another known factor to influence metaphor processing, namely familiarity. The categorization model predicts familiarity to play no role in deciding on processing strategy. On the other hand, the career of metaphor hypothesis predicts that familiarity to play a facilitating role in metaphor comprehension. In this experiment, we used the eye tracking paradigm and controlled for aptness and conventionality, and manipulated familiarity in order to test these predictions. Our initial results support the career of metaphor hypothesis suggesting that familiarity facilitates metaphor processing. We discuss the implications these results have on the psycholinguistic models and briefly speculate on their philosophical consequences.',\n",
              "  \"Formalizing the Pragmatics of Metaphor Understanding.[SEP]While the ubiquity and importance of nonliteral language are clear, people's ability to use and understand it remains a mystery. Metaphor in particular has been studied extensively across many disciplines in cognitive science. One approach focuses on the pragmatic principles that listeners utilize to infer meaning from metaphorical utterances. While this approach has generated a number of insights about how people understand metaphor, to our knowledge there is no formal model showing that effects in metaphor understanding can arise from basic principles of communication. Building upon recent advances in formal models of pragmatics, we describe a computational model that uses pragmatic reasoning to interpret metaphorical utterances. We conduct behavioral experiments to evaluate the model's performance and show that our model produces metaphorical interpretations that closely fit behavioral data. We discuss implications of the model for metaphor understanding, principles of communication, and formal models of language understanding.\",\n",
              "  'Computing Humorous Metaphors.[SEP]It was experimentally showed that humorous texts can be explained using approaches applied to metaphors, such as the salience-imbalance or the domain-interaction approach. It was also demonstrated that humorous metaphors often include a switch between positive and negative emotions. We propose to construct a computer system able to understand and generate such metaphors. Currently we are constructing a metaphor conceptual network, in which links between concepts are calculated accordingly to their roles in metaphor understanding. This will allow the computer to process metaphors. Next, we will adjust the links distance calculation to match the humorous metaphors (to increase the salience-imbalance, as demonstrated in existing research). We will also use an emotiveness-recognition-system to detect emotive associations towards particular phrases, in order to choose pairs with the emotional switch. The system will be evaluated in user-oriented experiments. Acknowledgements: This work was supported by KAKENHI (Project Number: 23-01348)'],\n",
              " '68_crowd_crowds_simulation_pedestrians': ['Improved Obstacle Relevancy, Distance, and Angle for Crowds Constrained to Arbitrary Manifolds in 3D Space.[SEP]Recent work has proposed crowd simulation algorithms on arbitrary manifolds in 3D space. These algorithms simulate crowds on far more realistic surfaces than previously possible, including multi-story structures, science fiction scenarios, and habitats for insects and other animals that can walk on walls. However, current implementations can have distinct artifacts, including collision false positives and false negatives. Also, current implementations fail to account for the cylindrical shape of the characters being simulated. The resulting crowds move unnaturally and have obvious collisions. After identifying the cause of these artifacts, we propose an algorithm that does not struggle from these false positives or false negatives and correctly accounts for the non-spherical shape of agents. The resulting crowds move on large surfaces (over 100k triangles) running with a thousand agents in real-time.',\n",
              "  \"A Graphical Simulator for Modeling Complex Crowd Behaviors.[SEP]Abnormal crowd behaviors of varied real-world settings could represent or pose serious threat to public safety. The video data required for relevant analysis are often difficult to acquire due to security, privacy and data protection issues. Without large amounts of realistic crowd data, it is difficult to develop and verify crowd behavioral models, event detection techniques, and corresponding test and evaluations. This paper presented a synthetic method for generating crowd movements and tendency based on existing social and behavioral studies. Graph and tree searching algorithms as well as game engine-enabled techniques have been adopted in the study. The main outcomes of this research include a categorization model for entity-based behaviors following a linear aggregation approach; and the construction of an innovative agent-based pipeline for the synthesis of A-Star path-finding algorithm and an enhanced Social Force Model. A Spatial-Temporal Texture (STT) technique has been adopted for the evaluation of the model's effectiveness. Tests have highlighted the visual similarities between STTs extracted from the simulations and their counterparts - video recordings - from the real-world.\",\n",
              "  'Perceptual evaluation of maneuvering motion illusion for virtual pedestrians.[SEP]Crowd simulations span a wide spectrum of application domains, most notably video games, evacuation scenarios, and the movie industry. However, it is not obligatory that all virtual populace applications have the primary objective of realistic simulation. In most instances, it is necessary and sufficient that viewers perceive the crowd as plausible. Even for a crowd consisting of agents navigating on linear trajectories without any maneuvers, visual motion illusion elicited by these trajectories might appear to be a natural consequence, causing them to be perceived as wriggling rather than straight. In this respect, we evaluate in this study whether simulated 3D human agents walking with constant, collision-free velocities, induce such a maneuvering motion illusion, aiming toward an efficient real-time crowd simulation. For this purpose, we recorded videos of virtual human crowds with different parameter combinations, such as the agent walking speed, crowd density, camera tilt angle, and camera distance. These videos were watched by human subjects who were instructed to mark the virtual agents who they thought had changed their gait directions. The analyzed results revealed that participants claimed the presence of maneuvering virtual agents in the videos, even though there were none in any of them. Spatial grouping of the markings highlighted that the participants mainly focused on the central area of the simulation environment, and spatiotemporal analysis of the click data also showed stronger evidence to such an illusion (see accompanying video). Furthermore, we found that all of the referred parameters have statistically significant main effects on the number of marked agents per watched video.'],\n",
              " '69_conversational_dialogue_agent_conversation': [\"Whose turn is it anyway? Same- and cross-person compound contributions in dialogue.[SEP]In natural conversation people sometimes build larger grammatical, semantic and pragmatic units out of multiple turns or installments. The incremental and collaborative character of these `compound contributions' presents challenges for theories of natural language processing. Compounds produced over successive turns by one person have often been analysed in essentially the same way as compounds produced by multiple people. In some recent accounts this putative equivalence has been taken as evidence for the claim that within- and cross-person language processing are fundamentally interchangeable. However, in this paper we present an analysis of compound contributions in a corpus of ordinary dialogues which shows that same- and cross-person compound contributions are constructed in different ways and have different semantic and pragmatic effects on the organisation of dialogue. In particular, we show that they differ in the pragmatic environments in which they occur and that they have different consequences for subsequent turn-taking and interpretation. This asymmetry highlights the need for models of dialogue that account for not just the inherent incrementality of dialogue, but the different status of each contributor towards a turn-in-progress.\",\n",
              "  'The Role of Feedback in Aligning Perspectives in Referential Communication.[SEP]Successful dialogue frequently requires that interlocutors construct and align their conceptualizations of referents. This study presents data from a referential communication experiment the manipulates contextual factors such as the availability of feedback and role constancy in order to investigate how conversational partners reconcile their perspectives in the face of mutual uncertainty about what constitutes common ground. The results show that speakers tend to incorporate information about the addressee’s perspective, and that this information tends to come through direct feedback rather than through indirect channels such as turn-taking.',\n",
              "  'Temporal Dynamics of Scan Patterns in Comprehension and Production.[SEP]Speakers and listeners in a dialogue establish mutual understanding by coordinating their linguistic responses. When a visual scene is present, scan patterns on that scene are also coordinated. However, it is an open question which linguistic and scene factors affect coordination. In this paper, we investigate the coordination of scan patterns during the comprehension and generation of scene descriptions. We manipulate the animacy of the subject and the number of visual referents associated with it. By using Cross Recurrence Analysis, we demonstrate that coordination emerges only during linguistic processing, and that it is especially pronounced for inanimate unambiguous subjects. When the subject is referentially ambiguous (more than one visual object associated with it), scan pattern variability increases to the extent that the animacy effect is neutralized.',\n",
              "  \"An Intelligent Assistant for High-Level Task Understanding.[SEP]People are able to interact with domain-specific intelligent assistants (IAs) and get help with tasks. But sometimes user goals are complex and may require interactions with multiple applications. However current IAs are limited to specific applications and users have to directly manage execution spanning multiple applications in order to engage in more complex activities. An ideal personal agent would be able to learn, over time, about tasks that span different resources. This paper addresses the problem of cross-domain task assistance in the context of spoken dialogue systems. We propose approaches to discover users' high-level intentions and using this information to assist users in their task. We collected real-life smartphone usage data from 14 participants and investigated how to extract high-level intents from users' descriptions of their activities. Our experiments show that understanding high-level tasks allows the agent to actively suggest apps relevant to pursuing particular user goals and reduce the cost of users' self-management.\",\n",
              "  '\"Do Animals Have Accents?\": Talking with Agents in Multi-Party Conversation.[SEP]In this paper we unpack the use of conversational agents, or so-called intelligent personal assistants (IPAs), in multi-party conversation amongst a group of friends while they are socialising in a café. IPAs such as Siri or Google Now can be found on a large proportion of personal smartphones and tablets, and are promoted as \\'natural language\\' interfaces. The question we pursue here is how they are actually drawn upon in conversational practice? In our work we examine the use of these IPAs in a mundane and common-place setting and employ an ethnomethodological perspective to draw out the character of the IPA-use in conversation. Additionally, we highlight a number of nuanced practicalities of their use in multi-party settings. By providing a depiction of the nature and methodical practice of their use, we are able to contribute our findings to the design of IPAs.',\n",
              "  'Iris: A Conversational Agent for Complex Tasks.[SEP]Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data scientists completed a modeling task 2.6 times faster with Iris than with Jupyter Notebook.'],\n",
              " '6_game_games_sports_play': [\"Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games.[SEP]Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses to recent events like #gamergate implies that the gender of the participant is not paramount to experience, but that their beliefs about gender roles are. To explore the role of sexist beliefs on experience in sexist games, we created three versions of a game that were identical except for the presence of sexist imagery and/or dialogue. We show that enjoyment of sexist games is not predicted by player gender, but by the player's pre-existing beliefs about gender. Furthermore, avatar identification is the pathway through which enjoyment is facilitated. Finally, sexist dialogue does not improve the play experience for anyone rather it harms experience for players of all genders who do not hold sexist beliefs.\",\n",
              "  \"Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience.[SEP]Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.\",\n",
              "  \"Negative Emotion, Positive Experience?: Emotionally Moving Moments in Digital Games.[SEP]Emotions are key to the player experience (PX) and interest in the potential of games to provide unique emotional, sometimes uncomfortable experiences is growing. Yet there has been little empirical investigation of what game experiences players consider emotionally moving, their causes and effects, and whether players find these experiences rewarding at all. We analyzed 121 players' accounts of emotionally moving game experiences in terms of the feelings and thoughts they evoked, different PX constructs, as well as game-related and personal factors contributing to these. We found that most players enjoyed and appreciated experiencing negatively valenced emotions, such as sadness. Emotions were evoked by a variety of interactive and non-interactive game aspects, such as in-game loss, character attachment and (lack of) agency, but also personal memories, and were often accompanied by (self-)reflection. Our findings highlight the potential of games to provide emotionally rewarding and thought-provoking experiences, as well as outline opportunities for future research and design of such experiences. They also showcase that negative affect may contribute to enjoyment, thereby extending our notion of positive player experience.\",\n",
              "  'Exergame Training of Executive Function in Preschool Children: Generalizability and Long-term Effects.[SEP]Studies with older children and adults have found that physically engaging video games (i.e., Exergames) that promote both cognitive control and physical activity improve executive function (EF) skills; yet, children below school age remain understudied with regard to the impact of Exergames on EF. Additionally, research on the extent of the impact of Exergames resulting in prolonged changes, and whether training generalizes to EF-related behaviors in a real-world context remains scarce. This study examined the short- and long-term changes in EF of 4- to 5-year-olds after participation in two 20-minute Exergame sessions. Results indicate that Exergame training improved performance on EF tasks and resulted in higher teacher ratings of EF in the classroom compared to a sex-/classroom-/age-matched control group. The improvements in EF persisted over a one-month period. This study provides novel insights into the short-term and long-term effects of Exergame training on executive function in preschool-aged children.',\n",
              "  'Exploring  designing tools to enhance falls rehabilitation in the home.[SEP]Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.',\n",
              "  'Fitmersive Games: Fitness Gamification through Immersive VR.[SEP]The decreasing hardware cost makes it affordable to pair Immersive Virtual Environments (IVR) visors with treadmills and exercise bikes. In this paper, we discuss the application of different gamification techniques in IVR for supporting physical exercise. We describe both the hardware setting and the design of Rift-a-bike, a cycling fitmersive game (immersive games for fitness). We evaluate the effectiveness of such techniques through a user study, which provides different insights on their effectiveness in designing such applications.',\n",
              "  'Chalkboarding: A New Spatiotemporal Query Paradigm for Sports Play Retrieval.[SEP]The recent explosion of sports tracking data has dramatically increased the interest in effective data processing and access of sports plays (i.e., short trajectory sequences of players and the ball). And while there exist systems that offer improved categorizations of sports plays (e.g., into relatively coarse clusters), to the best of our knowledge there does not exist any retrieval system that can effectively search for the most relevant plays given a specific input query. One significant design challenge is how best to phrase queries for multi-agent spatiotemporal trajectories such as sports plays.We have developed a novel query paradigm and retrieval system, which we call Chalkboarding, that allows the user to issue queries by drawing a play of interest (similar to how coaches draw up plays). Our system utilizes effective alignment, templating, and hashing techniques tailored to multi-agent trajectories, and achieves accurate play retrieval at interactive speeds.We showcase the efficacy of our approach in a user study, where we demonstrate orders-of-magnitude improvements in search quality compared to baseline systems.',\n",
              "  'Baseball Timeline: Summarizing Baseball Plays Into a Static Visualization.[SEP]In sports, Play Diagrams are the standard way to represent and convey information. They are widely used by coaches, managers, journalists and fans in general. There are situations where diagrams may be hard to understand, for example, when several actions are packed in a certain region of the field or there are just too many actions to be transformed in a clear depiction of the play. The representation of how actions develop through time, in particular, may be hardly achieved on such diagrams. The time, and the relationship among the actions of the players through time, is critical on the depiction of complex plays. In this context, we present a study on how player actions may be clearly depicted on 2D diagrams. The study is focused on Baseball plays, a sport where diagrams are heavily used to summarize the actions of the players. We propose a new and simple approach to represent spatiotemporal information in the form of a timeline. We designed our visualization with a requirement driven approach, conducting interviews and fulfilling the needs of baseball experts and expert‐fans. We validate our approach by presenting a detailed analysis of baseball plays and conducting interviews with four domain experts.',\n",
              "  'Sports Tournament Predictions Using Direct Manipulation.[SEP]An advanced interface for sports tournament predictions uses direct manipulation to allow users to make nonlinear predictions. Unlike previous interface designs, the interface helps users focus on their prediction tasks by enabling them to first choose a winner and then fill out the rest of the bracket. In real-world tests of the proposed interface (for the 2014 FIFA World Cup tournament and 2015/2016 UEFA Champions League), the authors validated the use of direct manipulation as an alternative to widgets. Using visitor interaction logs, they were able to determine the strategies people use to perform predictions and identify potential areas of improvement for further prediction interfaces.',\n",
              "  'Usability Planner: A Tool to Support the Process of Selecting Usability Methods.[SEP]There is increasing pressure on developers to produce usable systems, which requires the use of appropriate methods to support user centred design during development. There is currently no consistent advice on which methods are appropriate in which circumstances, so the selection of methods relies on individual experience and expertise. Considerable effort is required to collate information from various sources and to understand the applicability of each method in a particular situation. Usability Planner is a tool aimed to support the selection of the most appropriate methods depending on project and organizational constraints. Many of the rules employed are derived from ISO standards, complemented with rules from the authors’ experience.',\n",
              "  'Usability Evaluation in a Digitally Emerging Country: A Survey Study.[SEP]Several emerging countries experience increasing software development activities. With the purpose of provide useful feedback on possible courses of action for increasing application of usability evaluation in such countries, this paper explores the status of usability evaluation in a digitally emerging country. Our aim is to identifying common characteristics or behavioral patterns that could be compared with digitally advanced countries. We used an online survey answered by 26 software development organizations, which gave a snapshot of the application of usability evaluation in these organizations. We found many similarities with advanced countries, several completely new obstacles more connected with software development matters and a relatively positive improvement in the lack of “usability culture”. These findings suggest good conditions to improve conduction of usability evaluations in digitally emerging countries.',\n",
              "  'Usability testing: what have we overlooked?[SEP]For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.'],\n",
              " '70_tracking_camera_tracker_pose': ['Projection Distortion-based Object Tracking in Shader Lamp Scenarios.[SEP]Shader lamp systems augment the real environment by projecting new textures on known target geometries. In dynamic scenes, object tracking maintains the illusion if the physical and virtual objects are well aligned. However, traditional trackers based on texture or contour information are often distracted by the projected content and tend to fail. In this paper, we present a model-based tracking strategy, which directly takes advantage from the projected content for pose estimation in a projector-camera system. An iterative pose estimation algorithm captures and exploits visible distortions caused by object movements. In a closed-loop, the corrected pose allows the update of the projection for the subsequent frame. Synthetic frames simulating the projection on the model are rendered and an optical flow-based method minimizes the difference between edges of the rendered and the camera image. Since the thresholds automatically adapt to the synthetic image, a complicated radiometric calibration can be avoided. The pixel-wise linear optimization is designed to be easily implemented on the GPU. Our approach can be combined with a regular contour-based tracker and is transferable to other problems, like the estimation of the extrinsic pose between projector and camera. We evaluate our procedure with real and synthetic images and obtain very precise registration results.',\n",
              "  \"Spatio-Temporal Point Path Analysis and Optimization of a Galvanoscopic Scanning Laser Projector.[SEP]Galvanoscopic scanning laser projectors are powerful vector graphic devices offering a tremendous local brightness advantage compared to standard video projection systems. However, such devices have inherent problems, such as temporal flicker and spatially inaccurate rendering. We propose a method to generate an accurate point-based projection with such devices. To overcome the mentioned problems, we present a camera-based method to automatically analyze the laser projector's motion behavior. With this information, a model database is generated that is used to optimize the scanning path of projected point sequences. The optimization considers the overall path length, its angular shape, acceleration behavior, and the spatio-temporal point neighborhood. The method minimizes perceived visual flickering while guaranteeing an accurate spatial point projection at the same time. Comparisons and timing measurements prove the effectiveness of our method. An informal user evaluation shows substantial visual quality improvement as well.\",\n",
              "  'Robust upright adjustment of 360 spherical panoramas.[SEP]With the recent advent of 360 cameras, spherical panorama images are becoming more popular and widely available. In a spherical panorama, alignment of the scene orientation to the image axes is important for providing comfortable and pleasant viewing experiences using VR headsets and traditional displays. This paper presents an automatic method for upright adjustment of 360 spherical panorama images without any prior information, such as depths and gyro sensor data. We take the Atlanta world assumption and use the horizontal and vertical lines in the scene to formulate a cost function for upright adjustment. In addition to fast optimization of the cost function, our method includes outlier handling to improve the robustness and accuracy of upright adjustment. Our method produces visually pleasing results for a variety of real-world spherical panoramas in less than a second, and the accuracy is verified using ground-truth data.',\n",
              "  'Coupled-layer based visual tracking via adaptive kernelized correlation filters.[SEP]Part-based visual model is particularly useful when the target appearance undergoes partial occlusion or deformation. The existing reliable patches tracking (RPT) method has achieved better result by identifying and exploiting the reliable patches that can be tracked correctly, yet it tends to fail in some challenging scenes since it ignores the holistic information of target completely, while, in fact, the target’s holistic appearance provides more discriminative features than local patches with low resolution. Based on the existing RPT and kernelized correlation filters tracking method, in this paper, we propose a coupled-layer visual model based tracker by combining the target’s global and local appearance in a coupled way. The global layer provides the holistic information and is treated as an approximation of the target. The local layer is composed of multiple small patches that are randomly initialized in the first frame. During tracking, the global tracker detects the target itself; its detection result is employed in the local layer to exploit the reliable patches and to estimate the target position corresponding to each patch. The exploited reliable patches are employed to estimate the target scale and to vote the current target location. Finally, both global and local models are updated with carefully designed updating mechanisms. Experiments conducted on 80 challenging benchmark sequences clearly show that our tracker improves the RPT tracker significantly both in overall and individual performance yet without obvious speed cost. Also, our tracker outperforms all the state-of-the-art trackers in overall datasets and eight independent datasets.',\n",
              "  'Object tracking by color distribution fields with adaptive hierarchical structure.[SEP]The essence of visual tracking is to distinguish the target from background, so how to describe the difference between target and background is a key problem. In this paper, tracking algorithm by color distribution fields with adaptive hierarchical structure is presented to solve this problem. First, multichannel color distribution fields are presented for appearance modeling, which represents color distinction between the target and background. Second, in order to adapt to the individuality of each target, the hierarchical structure of its color distribution fields are generated via k-means cluster. Third, weighted multichannel 𝐿1L1 distance is used to measure the similarity between the candidate region and the template; the weight of each channel is adjusted online according to its discrimination. Finally, a search strategy based on simulated annealing is proposed to improve the search efficiency and reduce the probability of falling into the local optimum. Experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art tracking algorithms.',\n",
              "  'An improved correlation filter tracking method with occlusion and drift handling.[SEP]Despite remarkable progress, visual object tracking is still a challenging task as objects usually suffer from significant appearance changes, fast motion, and serious occlusion. In this paper, we propose a correlation filter-based tracking method with reliability evaluation and re-detection mechanism (CF-RERM) to deal with drift and occlusion problems. We first propose a criterion that uses the fluctuation trend of the response values, the displacement difference of the object, and the peak-to-sidelobe ratio to comprehensively evaluate the reliability of the tracking process. Then, a re-detection mechanism with a two-stage screening strategy is proposed for implementing the re-detection task when the criterion is triggered. Experimental results show that our method has achieved considerable performance in terms of accuracy and success rate on widely used OTB-50, OTB-100 and Temple-Color-128 tracking benchmark dataset. In addition, CF-RERM is able to achieve real-time tracking speed.',\n",
              "  'A Backmapping Approach for Graph-Based Object Tracking.[SEP]Model-based methods play a central role to solve different problems in computer vision. A particular important class of such methods rely on graph models where an object is decomposed into a number of parts, each one being represented by a graph vertex. A graph model-based tracking algorithm has been recently introduced in which a model is generated for a given frame (reference frame) and used to track a target object in the subsequent ones. Because the view of an object changes along the video sequence, the solution updated the model using affine transformations. This paper proposes a different approach and improves the previous one in several ways. Firstly, instead of updating the model, each analyzed frame is backmapped to the model space, thus providing more robustness to the method because model parameters do not have to be modified. A different method for model generation based on user traces has also been implemented and used. This model generation approach is much simpler and user-friendly. Finally, a graph-matching algorithm that has been recently proposed is used for object tracking. This new algorithm is more efficient and leads to better matching results. Experimental results using synthetic and real sequences from the CAVIAR project are shown and discussed.',\n",
              "  'Automatic Detection of 2D Human Postures Based on Single Images.[SEP]Estimating human pose in static images is a challenging task due to the high dimensional state space, presence of image clutter and ambiguities of image observations. In this paper we propose a method to automatically detect human poses in a single image, based on a 2D model combined with anthropometric data. Furthermore, we use artificial neural networks to detect high level information about the human posture. Experimental results showed that the proposed technique performs well in non trivial images.',\n",
              "  'Robust motion flow for mesh tracking of freely moving actors.[SEP]4D multi-view reconstruction of moving actors has many applications in the entertainment industry and although studios providing such services become more accessible, efforts have to be done in order to improve the underlying technology to produce high-quality 4D contents. In this paper, we present a method to derive a time-evolving surface representation from a sequence of binary volumetric data representing an arbitrary motion in order to introduce coherence in the data. The context is provided by an indoor multi-camera system which performs synchronized video captures from multiple viewpoints in a chroma-key studio. Our input is given by a volumetric silhouette-based reconstruction algorithm that generates a visual hull at each frame of the video sequence. These 3D volumetric models lack temporal coherence, in terms of structure and topology, as each frame is generated independently. This prevents an easy post-production editing with 3D animation tools. Our goal is to transform this input sequence of independent 3D volumes into a single dynamic structure, directly usable in post-production. Our approach is based on a motion estimation procedure. An unsigned distance function on the volumes is used as the main shape descriptor and a 3D surface matching algorithm minimizes the interference between unrelated surface regions. Experimental results, tested on our multi-view datasets, show that our method outperforms other approaches based on optical flow when considering robustness over several frames.'],\n",
              " '71_shadow_shadows_light_rendering': ['ShadowPix: Multiple Images from Self Shadowing.[SEP]ShadowPixare white surfaces that display several prescribed images formed by the self‐shadowing of the surface when lit from certain directions. The effect is surprising and not commonly seen in the real world. We present algorithms for constructing ShadowPixthat allow up to four images to be embedded in a single surface. ShadowPixcan produce a variety of unusual effects depending on the embedded images: moving the light can animate or relight the object in the image, or three colored lights may be used to produce a single colored image. ShadowPixare easy to manufacture using a 3D printer and we present photographs, videos, and renderings demonstrating these effects.',\n",
              "  'Exponential shadow maps.[SEP]Rendering high-quality shadows in real-time is a challenging problem. Shadow mapping has proved to be an efficient solution, as it scales well for complex scenes. However, it suffers from aliasing problems. Filtering the shadow map alleviates aliasing, but unfortunately, native hardware-accelerated filtering cannot be applied, as the shadow test has to take place beforehand.',\n",
              "  \"Generating soft shadows with a depth buffer algorithm.[SEP]A pragmatic approach is taken to develop an algorithm that combines an existing shadowing method with a popular visible surface rendering technique, called a depth buffer, to generate soft shadows resulting from light sources of finite extent. The method extends F. Crow's shadow volume algorithm (1977) to produce multiple shadows overlapped to yield the characteristic soft edges of a shadow penumbra.\"],\n",
              " '72_narrative_story_stories_storytelling': ['SceneSkim: Searching and Browsing Movies Using Synchronized Captions, Scripts and Plot Summaries.[SEP]Searching for scenes in movies is a time-consuming but crucial task for film studies scholars, film professionals, and new media artists. In pilot interviews we have found that such users search for a wide variety of clips---e.g., actions, props, dialogue phrases, character performances, locations---and they return to particular scenes they have seen in the past. Today, these users find relevant clips by watching the entire movie, scrubbing the video timeline, or navigating via DVD chapter menus. Increasingly, users can also index films through transcripts---however, dialogue often lacks visual context, character names, and high level event descriptions. We introduce SceneSkim, a tool for searching and browsing movies using synchronized captions, scripts and plot summaries. Our interface integrates information from such sources to allow expressive search at several levels of granularity: Captions provide access to accurate dialogue, scripts describe shot-by-shot actions and settings, and plot summaries contain high-level event descriptions. We propose new algorithms for finding word-level caption to script alignments, parsing text scripts, and aligning plot summaries to scripts. Film studies graduate students evaluating SceneSkim expressed enthusiasm about the usability of the proposed system for their research and teaching.',\n",
              "  'CSIUI 2009: story understanding and generation for aware and interactive interface design.[SEP]In order to be helpful to people, the intelligent interfaces of the future will have to acquire, represent, and infer simple knowledge about everyday life and activities. While much work in AI has represented this knowledge at the word, sentence, and logical assertion level, we see a growing need to understand it at a larger granularity, that of stories.',\n",
              "  \"Declarative Optimization-Based Drama Management in Interactive Fiction.[SEP]Our work relates to automatically guiding experiences in large, open-world interactive dramas and story-based experiences where a player interacts with and influences a story. A drama manager (DM) is a system that watches a story as it progresses, reconfiguring the world to fulfill the author's goals. A DM might notice a player doing something that fits poorly with the current story and attempt to dissuade him or her. This is accomplished using soft actions such as having a nonplayer character start a conversation with a player to lure him or her to something else, or by more direct actions such as locking doors. We present work applying search-based drama management (SBDM) to the interactive fiction piece Anchorhead, to further investigate the algorithmic and authorship issues involved. Declarative optimization-based drama management (DODM) guides the player by projecting possible future stories and reconfiguring the story world based on those projections. This approach models stories as a set of possible plot points, and an author-specified evaluation function rates the quality of a particular plot-point sequence\",\n",
              "  'More Than Telling a Story: Transforming Data into Visually Shared Stories.[SEP]The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.',\n",
              "  'Formalizing Analytical Discourse in Visual Analytics.[SEP]This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse.',\n",
              "  \"A Deeper Understanding of Sequence in Narrative Visualization.[SEP]Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.\"],\n",
              " '73_authentication_passwords_password_security': [\"Do Users' Perceptions of Password Security Match Reality?[SEP]Although many users create predictable passwords, the extent to which users realize these passwords are predictable is not well understood. We investigate the relationship between users' perceptions of the strength of specific passwords and their actual strength. In this 165-participant online study, we ask participants to rate the comparative security of carefully juxtaposed pairs of passwords, as well as the security and memorability of both existing passwords and common password-creation strategies. Participants had serious misconceptions about the impact of basing passwords on common phrases and including digits and keyboard patterns in passwords. However, in most other cases, participants' perceptions of what characteristics make a password secure were consistent with the performance of current password-cracking tools. We find large variance in participants' understanding of how passwords may be attacked, potentially explaining why users nonetheless make predictable passwords. We conclude with design directions for helping users make better passwords.\",\n",
              "  'Age-related performance issues for PIN and face-based authentication systems.[SEP]Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population. We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period. We use this paradigm with two user populations, comparing the performance of younger and older adults. We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components. As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.',\n",
              "  'EpisoDAS: DAS-based password generation using episodic memories.[SEP]We introduce a simple and powerful visual interaction technique for managing strong passwords. Passwords have been used for authentication for decades, but appropriate handling of passwords is difficult because people can easily forget passwords and they can be easily attacked. Better authentication methods have been investigated, and various visual interaction methods have been proposed, including the DAS (draw-a-secret) method. Using DAS, users can log into a service just by drawing a secret pattern on the screen, but remembering complex secret patterns is as difficult as remembering passwords. We developed EpisoDAS, with which users can generate strong passwords based on their secret episodic memories with a simple DAS interface. A user can draw a secret pattern and generate a password, based on their secret episodic memories that they cannot easily forget.'],\n",
              " '74_students_math_solving_achievement': ['Patterns of anxiety in algebraic problem solving in Australian adolescents: A three-step latent variable analysis.[SEP]Adolescents’ math anxiety is commonly assessed using questionnaires that identified the anxiety experienced solving arithmetic problems. A more nuanced understanding of math anxiety would be gained by investigating anxiety associated with math problems encountered in school at the time they are encountered. To this end, we investigated the anxiety associated with algebraic problem solving ability relationships in 129 14-year-olds. We varied problem difficulty and the time allowed to solve problems, and assessed students’ anxiety concurrently as they solved problems. Latent variable mixture modelling revealed meaningfully different patterns of algebra ability and anxiety relationships that changed as a function of problem difficulty and time pressure. A second study, examining 257 13- to 15-year-olds, successfully replicated the Study 1 findings. The results highlight the value of using latent variable analysis to identify subgroup patterns of abilities and caution against making overly general claims about the role of anxiety in math problem solving.',\n",
              "  'Problem-Solving Strategy Selection in Relation to Formal Schooling.[SEP]A study of the literacy-generated cognitive cultural gap was carried out on subjects of different literacy background ranging from illiterate individuals to university students in different majors. The characteristics that aid literate and illiterate people in solving mathematical problems efficiently were identified and analyzed. A field research was carried out in the field of algorithmic problem solving and in the reasoning domain, followed by constructing a software cognitive model to represent the findings. Findings showed that in both domains cognitive ability did not improve with level of literacy, rather the formality of the problem solving strategy selected demonstrating a link between these two domains.',\n",
              "  \"Study on Facilitation of Problem Posing by Learning Examples through Reproduction.[SEP]In general education, learning of production tasks is important but difficult due to it requires heavy cognitive activities such as generation of ideas and synthesis of structures. We proposed a method to facilitate a production task of mathematical problem posing through learning by reproducing examples. In the proposed method, learners learn essential ideas by reproducing examples based on process information indicating how to compose them. We then conducted an experimental investigation where undergraduate students posed their own problems after learning an example by reproducing or solving it. Our previous study had confirmed that undergraduate students without learning of any examples posed many problems that had simple and inappropriate solution structures. In this study, undergraduate students who learned by reproducing the example posed many complex problems, whereas those who learned by solving it didn't do. This proved that learning of ideas for a production task is more effective when it's done through a productive activity.\",\n",
              "  'Improving First-Year Writing Using Argument Diagramming.[SEP]There is substantial evidence from many domains that visual representations aid various forms of cognition. We aimed to determine whether learning to construct visual representations of argument structure enhanced the acquisition and development of argumentative writing skills within the context of first-year college writing course. We found a significant effect of the use of argument diagrams, and this effect was stable even when multiple plausible correlates were controlled for. These results suggest that natural⎯and relatively minor⎯modifications to standard first-year composition courses could provide substantial increases in student writing ability.',\n",
              "  \"Are Teachers Aware of Students' Lack of Spontaneity in Diagram Use? Suggestions from a Mathematical Model-Based Analysis of Teachers' Predictions.[SEP]Although many studies have shown that diagrams are effective tools for problem solving, research evidence shows that students do not always use diagrams effectively. One of the most serious problems is their lack of spontaneity in diagram use. However, no previous studies have examined whether teachers are adequately aware of this problem. In this investigation, data were gathered on students’ mathematics performance (including their spontaneous use of diagrams) and teachers’ predictions of the students’ performance. Using a mathematical model (Uesaka & Nakagawa, 2010) to analyze the data, it was found that the parameter representing the accuracy of teachers’ prediction was lower for their assessment of spontaneous diagram use compared to other mathematical tasks. This suggests that spontaneity in diagram use is an overlooked aspect in teachers’ view of student performance.\",\n",
              "  'The Effect of Graphical Format and Instruction on the Interpretation of Three-Variable Bar and Line Graphs.[SEP]We present a study that investigates how graph format and training can affect undergraduate psychology students’ ability to interpret three-variable bar and line graphs. A pre and post-test design was employed to assess 76 students’ conceptual understanding of three-variable graphs prior to and after a training intervention. The study revealed that significant differences in interpretation are produced by graph format prior to training; bar graph users outperform line graph users. Training also resulted in a statistically significant improvement in interpretation of both graph formats with effect sizes confirming the intervention resulted in substantial learning gains in graph interpretation. This resulted in bar graph users outperforming line graph users pre and post training making it the superior format even when training has occurred. The effect of graph format and training differed depending on task demands. Based on the results of this experiment, it is argued that undergraduate students’ interpretations of such three-variable data are more accurate when using the bar form. Findings also demonstrate how a brief tutorial can result in large gains in graph comprehension scores. We provide a test which can be used to assess students understanding of three-variable graphs and the tutorial developed for the study for educators to use.'],\n",
              " '75_health_patients_self_online': ['Data, Data Everywhere, and Still Too Hard to Link: Insights from User Interactions with Diabetes Apps.[SEP]For those with chronic conditions, such as Type 1 diabetes, smartphone apps offer the promise of an affordable, convenient, and personalized disease management tool. However, despite significant academic research and commercial development in this area, diabetes apps still show low adoption rates and underwhelming clinical outcomes. Through user-interaction sessions with 16 people with Type 1 diabetes, we provide evidence that commonly used interfaces for diabetes self-management apps, while providing certain benefits, can fail to explicitly address the cognitive and emotional requirements of users. From analysis of these sessions with eight such user interface designs, we report on user requirements, as well as interface benefits, limitations, and then discuss the implications of these findings. Finally, with the goal of improving these apps, we identify 3 questions for designers, and review for each in turn: current shortcomings, relevant approaches, exposed challenges, and potential solutions.',\n",
              "  \"Designing Self-tracking Devices for Vulnerable Chronic Ill.[SEP]In my thesis, I take departure in a view on illness perception in design as found in the biopsychosocial (BPS) model. I expect that an equal focus on biological, psychological and social dimensions of illness will successfully assist the design of self-tracking devices. My thesis focusses on vulnerable patients with diabetes or prostate cancer. The objective is to improve patient wellbeing by making self-reflection accessible through the use of personal devices for self-tracking. The self-tracking devices and its surrounding system will be collaboratively developed with the participating patients. This collaboration is done to make sure that the patients lived experiences inform the design of the devices. The system will support communication in treatment between the patient, professional and relatives. Key challenges are in designing for vulnerable. How to create devices that respect patient's everyday life and how to bring the patient in control of self-tracked data, that is shared to others.\",\n",
              "  \"Findings of e-ESAS: a mobile based symptom monitoring system for breast cancer patients in rural Bangladesh.[SEP]Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how 'motivation' and 'automation' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.\",\n",
              "  'A Sociotechnical Mechanism for Online Support Provision.[SEP]Social support can significantly improve health outcomes for individuals living with disease, and online forums have emerged as an important vehicle for social support. Whereas research has focused on the delivery and use of social support, little is known about how these communities are sustained. We describe one sociotechnical mechanism that enables sustainable communities to provide social support to a large number of people. We focus upon thirteen disease-specific discussion forums hosted by the WebMD online health community. In these forums, small, densely connected cores of members who maintain strong relationships generate the majority of support for others. Through content analysis we find they provide informational support to a large number of more itinerant members, but provide one another with community support. Based on these observations, we describe a sociotechnical mechanism of online support that is distinct from non-support oriented communities, and has implications for the design of self-sustaining online support systems.',\n",
              "  \"Forum77: An Analysis of an Online Health Forum Dedicated to Addiction Recovery.[SEP]Prescription drug abuse is a pressing public health issue, and people who misuse prescription drugs are turning to online forums for help. Are such forums effective? We analyze the process of opioid withdrawal, recovery and relapse on Forum77, MedHelp.org's online health forum for substance abuse recovery. Applying Prochashka's Transtheoretical Model for behavior change, we develop a taxonomy describing phases of addiction expressed by Forum77 members. We examine activity and linguistic features across the phases USING, WITHDRAWING and RECOVERING. We train statistical classifiers to identify addiction phase, relapse and whether a user was RECOVERING at the time of her last post. Applying our classifiers to 2,848 users, we find that while almost 50% relapse, the prognosis for ending in RECOVERING is favorable. Supplementing our results with users' own accounts of their experiences, we discuss Forum77's efficacy and shortcomings, and implications for future technologies.\",\n",
              "  'HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers.[SEP]To address the needs of cancer patients and their caregivers, Microsoft Research and the Fred Hutchinson Cancer Research Center developed HutchWorld, an online community environment, to provide computer-mediated social and informational support. In a controlled clinical study, we deployed HutchWorld to bone marrow transplant patients and their caregivers and assessed the impact of Internet access and HutchWorld on their quality of life. We found that Internet access and the use of HutchWorld helped to buffer study participants against reductions in life satisfaction and social support following the transplant procedure. In particular, participants used the Internet to seek out support from family and friends'],\n",
              " '76_route_map_navigation_wayfinding': ['How Spatial Ability and Stress Impact Escape Path.[SEP]Individual differences and situational factors can both affect how and how well one navigates. This study examined the effects of stress and spatial ability, measured as mental rotation ability, on navigation during an emergency situation. Participants learned a virtual mall environment and were subsequently either told to meet a friend at the far exit (control) or to use the far exit to escape a fire. In an emergency, participants made an initial movement faster, made more errors during navigation, and overestimated the amount of time they took to exit relative to controls. Relative to controls, emergency low spatial participants more often reversed a learned path to exit the mall, whereas high spatial participants more often directly used a previously learned path. The results illustrate that stress from an emergency situation negatively impacts navigation, and that the behavioral consequences of this are in part dependent upon one’s spatial abilities.',\n",
              "  'Constraints, Inferences, and the Shortest Path: Which paths do we prefer?[SEP]How do we reason about incomplete spatio-temporal descriptions? How might a map influence formerly constructed preferred mental models? Little research so far focused on a combination of two central fields important for successful route planning: the way humans deal with constraint based reasoning (especially with some sort of spatio-temporal constraints) and the way in which humans plan with a given map (especially with problems inspired by typical Traveling Salesman Problems). This, however, becomes even more interesting in cases in which the spatio-temporal constraints allow for several solutions. Do the predictions of the preferred mental model theory still hold true in such situations? This article investigates the influence of maps on the generation of preferred models. The goal is to bring together the theory of (preferred) mental models and route planning.',\n",
              "  'The influence of structural salience and verbalisation on finding the return path.[SEP]Are some landmark positions at intersections better for finding a return path than others? This study investigated whether there is a variation in the influence of a landmark on performance and decision times when finding a return path depending on its position at an intersection. A variation of this influence is expected depending on the type of verbalisation of spatial directions used. First, participants learned a path either with direction specific (turn left at or turn right at) or direction unspecific material (turn into direction of or turn in the opposite direction of). In this path the positions of the landmarks were varied systematically. Secondly, participants had to find the return path of the learned route and their third task was to write down verbal route descriptions. An effect of the landmark position on finding the return path can be suggested, although it was barely insignificant, for direction specific and direction unspecific material. A significant influence on the accuracy of the information in the route descriptions depending on the position of a landmark and on the specificity of the spatial directions could be shown. The results are discussed in the context of current wayfinding and landmark research.',\n",
              "  'COPERNICUS: Context-Preserving Engine for Route Navigation with Interactive User-modifiable Scaling.[SEP]In this paper, we present an automated system for generating context‐preserving route maps that depict navigation routes as a path between nodes and edges inside a topographic network. Our application identifies relevant context information to support navigation and orientation, and generates customizable route maps according to design principles that communicate all relevant context information clearly visible on one single page. Interactive scaling allows seamless transition between the original undistorted map and our new map design, and supports user‐specified scaling of regions of interest to create personalized driving directions according to the drivers needs.',\n",
              "  'Drawing Road Networks with Focus Regions.[SEP]Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.',\n",
              "  'Designing and Annotating Metro Maps with Loop Lines.[SEP]Schematic metro maps provide an effective means of simplifying the geographical configuration of public rapid transportation systems. Nonetheless, travelers still find it difficult to identify routes of a specific topology on the maps because it is usually hidden behind the conventional octilinear layout of the entire map. In this paper, we present an approach to designing schematic maps with loop lines, which are drawn as circles together with annotation labels for guiding different traveling purposes. Our idea here is to formulate the aesthetic criteria as mathematical constraints in the mixed-integer programming model, which allows us to either align stations on the loop line at a grid if they are interchange stations or noninterchange stations on a circle otherwise. We then distribute the annotation labels associated with stations on the loop line evenly to the four side boundary of the map domain in order to make full use of the annotation space, while maximally avoiding intersections between leader lines and the metro network by employing a flow network algorithm. Finally, we present several experimental results generated by our prototype system to demonstrate the feasibility of the proposed approach.'],\n",
              " '77_gene_genome_genomic_visualization': ['Visualizing virus population variability from next generation sequencing data.[SEP]Advances in genomic sequencing techniques allow for larger scale generation and usage of sequence data. While these techniques afford new types of analysis, they also generate new concerns with regards to data quality and data scale. We present a tool designed to assist in the exploration of the genetic variability of the population of viruses at multiple time points and in multiple individuals, a task that necessitates considering large amounts of sequence data and the quality issues inherent in obtaining such data in a practical manner. Our design affords the examination of the amount of variability and mutation at each position in the genome for many populations of viruses. Our design contains novel visualization techniques that support this specific class of analysis while addressing the issues of data aggregation, confidence visualization, and interaction support that arise when making use of large amounts of sequence data with variable uncertainty. These techniques generalize to a wide class of visualization problems where confidence is not known a priori, and aggregation in multiple directions is necessary.',\n",
              "  'Interactive visual support for metagenomic contig binning.[SEP]Within metagenomics, \"Contig Binning\" is an important step in the process of reconstructing genomes of species in mixed cultures and environmental samples. We present an interactive visual environment which enables a biologist to statistically analyze the multiple dimensions of data that are typically used during binning, and integrate and compare the results of various binning methods. Our system features a web-based parallel coordinate visualization at the front end and a R server back end for analysis and semi-supervised clustering of contig data.',\n",
              "  'Visual analysis of next-generation sequencing data to detect overlapping genes in bacterial genomes.[SEP]Next generation sequencing (NGS) technologies are about to revolutionize biological research. Being able to sequence large amounts of DNA or, indirectly, RNA sequences in a short time period opens numerous new possibilities. However, analyzing the large amounts of data generated in NGS is a serious challenge, which requires novel data analysis and visualization methods to allow the biological experimenter to understand the results. In this paper, we describe a novel system to deal with the flood of data generated by transcriptome sequencing (RNA-seq) using NGS. Our system allows the analyzer to get a quick overview of the data and interactively explore interesting regions based on the three important parameters coverage, transcription, and fit. In particular, our system supports the NGS analysis in the following respects: (1) Representation of the coverage sequence in a way that no artifacts are introduced. (2) Easy determination of a fit of an open reading frame (ORF) to a transcript by mapping the coverage sequence directly into the ORF representation. (3) Providing automatic support for finding interesting regions to address the problems that the overwhelming volume of data comes with. (4) Providing an overview representation that allows parameter tuning and enables quick access to interesting areas of the genome. We show the usefulness of our system by a case study in the area of overlapping gene detection in a bacterial genome.'],\n",
              " '78_image_smoothing_denoising_inpainting': ['Two-level joint local laplacian texture filtering.[SEP]Extracting the structure component from an image with textures is a challenging problem. This paper presents a novel structure-preserving texture-filtering approach based on the two-level local Laplacian filter. The new texture-filtering method is developed by introducing local Laplacian filters into the joint filtering. Our study shows that local Laplacian filters can also be used for texture smoothing by defining a special remapping function, which is closely related to joint bilateral filtering. This finding leads to a variant of the joint bilateral filter, which produces smooth edges while preserving color variations. Our filter shares similar advantages with the joint bilateral filter, such as being simple to implement and easy to understand. Experiments demonstrate that the new filter can produce satisfactory filtering results with the properties of texture smoothing, smooth edges, and edge shape preserving. We compare our method with the state-of-the-art methods to demonstrate its improvements, and apply this filter to a variety of image-editing applications.',\n",
              "  'Non-blind deblurring of structured images with geometric deformation.[SEP]Non-blind deconvolution, which is to restore a sharp version of a given blurred image when the blur kernel is known, is a fundamental step in image deblurring. While the problem has been extensively studied, existing methods have conveniently ignored an important fact that deformation can significantly affect the statistical characteristics of an image and introduce additional blurring effect. In this paper, we show how to enhance non-blind deconvolution by recovering and undoing the deformation while deconvolving a given blurred image. We show that this is the case for almost all popular regularizers that have been proposed for image deblurring such as total variation and its variants. We conduct extensive simulations and experiments on real images and verify that the incorporation of geometric deformation in deconvolution can significantly improve the final deblurring results. Combined with existing blur kernel estimation techniques, our method can also be used to enhance blind image deblurring.',\n",
              "  'Fast high-quality non-blind deconvolution using sparse adaptive priors.[SEP]We present an efficient approach for high-quality non-blind deconvolution based on the use of sparse adaptive priors. Its regularization term enforces preservation of strong edges while removing noise. We model the image-prior deconvolution problem as a linear system, which is solved in the frequency domain. This clean formulation lends to a simple and efficient implementation. We demonstrate its effectiveness by performing an extensive comparison with existing non-blind deconvolution methods, and by using it to deblur photographs degraded by camera shake. Our experiments show that our solution is faster and its results tend to have higher peak signal-to-noise ratio than the state-of-the-art techniques. Thus, it provides an attractive alternative to perform high-quality non-blind deconvolution of large images, as well as to be used as the final step of blind-deconvolution algorithms.'],\n",
              " '79_construction_visualisation_building_heritage': ['Visual analysis method for cultural heritage site risk assessment.[SEP]Many significant cultural heritage sites are at risk caused by natural environment. A unique type of natural risk to heritage sites is deterioration risk. Conservators and managers of heritage sites are attempting to develop a risk management approach to reduce this type of risk. Risk assessment is the essential component part of risk management process. However, it is hindered by several challenges resulting from the complexity of deterioration risk. We propose the use of visual analysis method for deterioration risk assessment focusing on matching the major needs and objectives of deterioration risk analysis. Our purpose is to facilitate risk analysis which consists of perceiving risk as basis, risk level estimate, and risk cause analysis. A spatial view of deterioration risk is designed for the discovery of distribution patterns. Based on clustering technique, we propose a visual analytics method for risk level analysis. Lastly, the proposed multidimensional data analysis technique is used to detect the causes of deterioration risks.',\n",
              "  \"Applying 3D Dynamic Visualisation to (Palaeo) Geomorphic Reconstruction: Modelling a Tenth Century J[SEP]At Sólheimajökull glacier in southern Iceland, field evidence has been collected of a Tenth Century jökulhlaup (or glacial outburst flood). It was an exceptional event in terms of generation, scale, magnitude and geomorphic impact. Although now fragmented and piecemeal, many of its direct (and indirect) geomorphological and sedimentary markers have been identified, mapped and dated to unravel the sequence of events played out during this significant episode in the glacial history. 'VolcVis', an innovative, customised visualisation platform using computer gaming technology is developed and applied for the first time in coalescing and displaying field results from Sólheimajökull, creating an interactive, multi-perspective, three-dimensional (3D) prototype model. A visual simulation of Sólheimajökull's Tenth Century physical environment places the flood into geomorphic and topographic context. This ability to dynamically display and interpret field data presents new possibilities for testing hypotheses, and for data sharing with Icelandic hazard mitigation authorities and the general public.\",\n",
              "  'Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations.[SEP]For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.'],\n",
              " '7_light_illumination_rendering_lighting': ['Unified Mathematical Model for Multilayer-Multiframe Compressive Light Field Displays Using LCDs.[SEP]We propose a unified mathematical model for multilayer-multiframe compressive light field displays that supports both attenuation-based and polarization-based architectures. We show that the light field decomposition of such a display can be cast as a bound constrained nonlinear matrix optimization problem. Efficient light field decomposition algorithms are developed using the limited-memory BFGS (L-BFGS) method for automultiscopic displays with high resolution and high image fidelity. In addition, this framework is the first to support multilayer polarization-based compressive light field displays with time multiplexing. This new architecture significantly reduces artifacts compared with attenuation-based multilayer-multiframe displays; thus, it can allow the requirements regarding the number of layers or the refresh rate to be relaxed. We verify the proposed methods by constructing two 3-layer prototypes using high-speed LCDs, one based on the attenuation architecture and one based on the polarization architecture. Moreover, an efficient CUDA-based program is implemented. Our displays can produce images with higher spatial resolution with thinner form factors compared with traditional automultiscopic displays in both simulations and experiments.',\n",
              "  'Polarization Demosaicking for Monochrome and Color Polarization Focal Plane Arrays.[SEP]Division-of-focal-plane (DoFP) polarization image sensors allow for snapshot imaging of linear polarization effects with inexpensive and straightforward setups. However, conventional interpolation based image reconstruction methods for such sensors produce unreliable and noisy estimates of quantities such as degree of linear polarization (DoLP) or angle of linear polarization (AoLP). In this paper, we propose a polarization demosaicking algorithm by inverting the polarization image formation model for both monochrome and color DoFP cameras. Compared to previous interpolation methods, our approach can significantly reduce noise induced artifacts and drastically increase the accuracy in estimating polarization states. We evaluate and demonstrate the performance of the methods on a new high-resolution color polarization dataset. Simulation and experimental results show that the proposed reconstruction and analysis tools offer an effective solution to polarization imaging.',\n",
              "  'Depth of Field in Plenoptic Cameras.[SEP]Certain new algorithms used by plenoptic cameras require focused microlens images. The range of applicability of these algorithms therefore depends on the depth of field of the relay system comprising the plenoptic camera. We analyze the relationships and tradeoffs between camera parameters and depth of field and characterize conditions for optimal refocusing, stereo, and 3D imaging.',\n",
              "  'A Composite BRDF Model for Hazy Gloss.[SEP]We introduce a bidirectional reflectance distribution function (BRDF) model for the rendering of materials that exhibit hazy reflections, whereby the specular reflections appear to be flanked by a surrounding halo. The focus of this work is on artistic control and ease of implementation for real‐time and off‐line rendering. We propose relying on a composite material based on a pair of arbitrary BRDF models; however, instead of controlling their physical parameters, we expose perceptual parameters inspired by visual experiments [VBF17]. Our main contribution then consists in a mapping from perceptual to physical parameters that ensures the resulting composite BRDF is valid in terms of reciprocity, positivity and energy conservation. The immediate benefit of our approach is to provide direct artistic control over both the intensity and extent of the haze effect, which is not only necessary for editing purposes, but also essential to vary haziness spatially over an object surface. Our solution is also simple to implement as it requires no new importance sampling strategy and relies on existing BRDF models. Such a simplicity is key to approximating the method for the editing of hazy gloss in real‐time and for compositing.',\n",
              "  'Improving the Selection of Bases of BRDFs for Appearance Preservation.[SEP]An important step in the appearance preservation of real materials is the analysis of how they interact with light. Since this phenomena happens at a microscopic level, heuristics with different complexity have been developed to capture and reproduce it. In order to minimize sampling efforts, one of these approaches consists in representing the reflectance of a material as a linear combination of a basis of known reflectance functions. To accomplish realistic and efficient representations, this basis must be expressive and contain a reduced number of elements. This work presents three approaches to select such basis. The first one performs an empirical leave-one-out optimization procedure. The other two are based on classical and evolutionary clustering algorithms. To improve clustering results, a new BRDF-oriented fitness function is designed. These approaches are evaluated using NNLS algorithm to estimate sampled materials and a comparison based on numerical precision is performed.',\n",
              "  'Accurate fitting of measured reflectances using a Shifted Gamma micro-facet distribution.[SEP]Material models are essential to the production of photo‐realistic images. Measured BRDFs provide accurate representation with complex visual appearance, but have larger storage cost. Analytical BRDFs such as Cook‐Torrance provide a compact representation but fail to represent the effects we observe with measured appearance. Accurately fitting an analytical BRDF to measured data remains a challenging problem. In this paper we introduce the SGD micro‐facet distribution for Cook‐Torrance BRDF. This distribution accurately models the behavior of most materials. As a consequence, we accurately represent all measured BRDFs using a single lobe. Our fitting procedure is stable and robust, and does not require manual tweaking of the parameters.'],\n",
              " '80_solid_solids_boundary_polyhedral': ['Set models and Boolean operations for solids and assemblies.[SEP]Applications of solid modeling in computer-aided design, computer-aided manufacturing, and robotics, which often involve aggregates or assemblies of disconnected pieces, are addressed. Models for such assemblies must be subjected to some of the same operations as models for single parts. The mathematical basis of constructive solid geometry (CSG), the usual formalism in solid modelers, leads to difficulties in dealing with assemblies. An alternative CSG-like formalism based on open sets, in which both assemblies and connected pieces are modeled as point sets is presented. Consequently the same Boolean operations apply uniformly to connected pieces and assemblies.< >',\n",
              "  'Volume-Preserving Free-Form Solids.[SEP]Some important trends in geometric modeling are the reliance on solid models rather than surface-based models and the enhancement of the expressive power of models, by using free-form objects in addition to the usual geometric primitives and by incorporating physical principles. An additional trend is the emphasis on interactive performance. In this paper, we integrate all of these requirements into a single geometric primitive by endowing the tri-variate tensor-product free-form solid with several important physical properties, including volume and internal deformation energy. Volume preservation is of benefit in several application areas of geometric modeling, including computer animation, industrial design and mechanical engineering. However, previous physics-based methods, which have usually used some form of \"energy\", have neglected the issue of volume (or area) preservation. We present a novel method for modeling an object composed of several tensor-product solids while preserving the desired volume of each primitive and ensuring high-order continuity constraints between the primitives. The method utilizes the Uzawa algorithm for non-linear optimization, with objective functions based on deformation energy or least squares. We show how the algorithm can be used in an interactive environment by relaxing exactness requirements while the user interactively manipulates free-form solid primitives. On current workstations, the algorithm runs in real-time for tri-quadratic volumes and close to real-time for tri-cubic volumes.',\n",
              "  \"Eliminating redundant primitives from set-theoretic solid models by a consideration of constituents.[SEP]Set-theoretic solid models often contain redundant primitives, which slow down rendering and other processes. They are not simple to remove, especially as there can be alternative eliminations that may not be equally desirable. Existing techniques for eliminating such redundant primitives do not fully consider the possibilities and rely on repeated evaluation of parts of the object's boundary, a process that is likely to be very slow. A technique that allows alternative eliminations to be examined is proposed and a potentially efficient, but geometrically approximate, method of implementation is outlined.< >\"],\n",
              " '81_electricity_households_heating_smart': ['Beyond demand management: the value of sharing electricity information.[SEP]Technologies such as smart meters and electricity feedback are becoming an increasingly compelling focus for HCI researchers in light of rising power prices and peak demand. We argue, however, that a pre-occupation with the goal of demand management has limited the scope of design for these technologies. In this paper we present our work-in-progress investigating the potential value of socially sharing electricity information as a means of broadening the scope of design for these devices. This paper outlines some preliminary findings gathered from a design workshop and a series of qualitative interviews with householders in Brisbane, Australia, regarding their attitudes towards electricity feedback and sharing consumption information. Preliminary findings suggest that; (1) the social sharing of electricity feedback information has the potential to be of value in better informing consumption decisions, however; (2) the potential for sharing may be constrained by attitudes towards privacy, trust and the possibility of misinformation being shared. We conclude by outlining ideas for our future research on this topic and invite comments on these ideas.',\n",
              "  'Comparative Feedback in the Street: Exposing Residential Energy Consumption on House Fa[SEP]This study investigates the impact of revealing the changes in daily residential energy consumption of individual households on their respective house faç ades. While energy feedback devices are now commercially available, still little is known about the potential of making such private information publicly available in order to encourage various forms of social involvement, such as peer pressure or healthy competition. This paper reports on the design rationale of a custom-made chalkboard that conveys different visualizations of household energy consumption, which were updated daily by hand. An in-situ, between-subject study was conducted during which the effects of such a public display were compared with two different control groups over a total period of 7 weeks. The competitive aspects of the public display led to more sustained behavior change and more effective energy conservation, as some graphical depictions such as a historical line graph raised awareness about consumption behavior, and the public character of the display prompted discussions in the wider community. The paper concludes with several considerations for the design of public displays, and of household energy consumption in particular.',\n",
              "  \"Studying always-on electricity feedback in the home.[SEP]The recent emphasis on sustainability has made consumers more aware of their responsibility for saving resources, in particular, electricity. Consumers can better understand how to save electricity by gaining awareness of their consumption beyond the typical monthly bill. We conducted a study to understand consumers' awareness of energy consumption in the home and to determine their requirements for an interactive, always-on interface for exploring data to gain awareness of home energy consumption. In this paper, we describe a three-stage approach to supporting electricity conservation routines: raise awareness, inform complex changes, and maintain sustainable routines. We then present the findings from our study to support design implications for energy consumption feedback interfaces.\"],\n",
              " '82_fractal_fractals_compression_chaos': ['Shape Approximation by a Fractal Model.[SEP]The use of fractals to synthesize complex objects is of current interest in the computer graphics community. A powerful way to compute fractals is the use of IFS (iterated function system) which is a set of contractions with associated probabilities which characterize the fractal. This theory, developed by M. Barnsley and al., can produce very complicated objects. We present a method to solve the inverse problem for these globally constructed fractals : given a set A (attractor), find an IFS that will approximately generate A. We use an optimisation method to minimize a distance between A and the current set L. Several distances have been tested and an algorithm has been implemented which gives good results. A test image is presented.',\n",
              "  'Visualizing Chemical Kinetics in Fractal Domains.[SEP]Chemical reactions occurring within complex domains, such as fractals, can display behavior which differs radically from the expectation of classical chemical kinetics. Rather than relaxing to a uniform distribution at the steady state, these nonclassical systems display large-scale order on many scales. Such self-organization is difficult to measure using the usual statistical techniques, but is visually apparent. The authors discuss some of the problems of visualizing chemical kinetics in fractal domains and describe evolution of the visualization as the chemist and visualization scientist collaborated.< >',\n",
              "  \"Transforming Fractals.[SEP]This issue's article examines the digital artwork of Rod Seeley, who transforms basic fractal images into complex works of art.\"],\n",
              " '83_memories_diary_life_everyday': ['Footprint tracker: supporting diary studies with lifelogging.[SEP]As HCI shifts \"to the wild\", in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.',\n",
              "  'Making love in the network closet: the benefits and work of family videochat.[SEP]In this paper, we explore the benefits of videochat for families and the corresponding work that home users engage in to make a video call run smoothly. We explore the varieties of social work required, including coordination work, presentation work, behavioral work, and scaffolding work, as well as the technical work necessary. We outline the benefits families enjoy for doing this work and discuss the ways in which families use videochat to reinforce their identity as a family and reinforce their family values, in effect making - as in creating - love. We conclude with recommendations for improving videochat and for designing with family values in mind more generally.',\n",
              "  \"AutoTypography: what can physical mementos tell us about digital memories?[SEP]Current technology makes it possible to capture huge amounts of information related to everyday experiences. Despite this, we know little about the processes by which people identify and manage mementos - objects which are directly meaningful to their memories. Among the millions of objects people encounter in a lifetime, few become such reminders of people, places or events. We report fieldwork where participants gave us a tour of their homes describing how and why particular objects become mementos. Our findings extend the existing digital memory literature; first our participants didn't view their activities as experiential 'capture', nor were mementos limited to pictorial representations of people and events; instead they included everyday objects. Furthermore, mementos were not only displayed and shared, but also integrated into everyday activities. Finally there were complex relations between house location and memento type. We discuss the theoretical and technical implications of our work.\"],\n",
              " '84_civic_civics_infrastructure_citizens': [\"Shared values/conflicting logics: working around e-government systems.[SEP]In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.\",\n",
              "  \"Civic Empowerment through Digitalisation: The Case of Greenlandic Women.[SEP]This paper explores the disruptive and transformative effects of digital technology on gendered security asymmetries in Greenland. Through ethnographic fieldwork conducted in Greenland and Denmark, research findings emerged through in-depth interviews, collaborative mappings and field observations with 51 participants. Employing a critical feminist lens, the paper identifies how Greenlandic women develop digital security practices to respond to Greenland's ecologically, politically and socially induced transformation processes. By connecting individual security concerns of Greenlandic women with the broader regional context, the findings highlight how digital technology has created transitory spaces in which collective security is cultivated, shaped and challenged. The contribution to HCI scholarship is therefore threefold: (1) identification and acknowledgement of gendered effects of increased usage of digital technology in remote and hard-to-reach communities, (2) a broader conceptualisation of digital security and (3) a recommendation for more contextualised, pluralistic digitalisation policies and design.\",\n",
              "  \"From Creating Spaces for Civic Discourse to Creating Resources for Action.[SEP]In this paper, we investigate the role of technology to address the concerns of a civil society group carrying out community-level consultation on the allocation of £1 million of community funds. We explore issues of devolved decision-making through the evaluation of a sociodigital system designed to foster deliberative virtues. We describe the ways in which this group used our system in their consultation practices. Our findings highlight how they adopted our technology to privilege specific forms of expression, ascertain issues in their community, make use of and make sense of community data, and create resources for action within their existing practices. Based on related fieldwork we discuss the impacts of structuring and configuring tools for 'talk-based' consultation in order to turn attention to the potential pitfalls and prospects for designing civic technologies that create resources for action for civil society.\"],\n",
              " '85_xml_query_xquery_queries': ['Holistic twig joins: optimal XML pattern matching.[SEP]XML employs a tree-structured data model, and, naturally, XML queries specify patterns of selection predicates on multiple elements related by a tree structure. Finding all occurrences of such a twig pattern in an XML database is a core operation for XML query processing. Prior work has typically decomposed the twig pattern into binary structural (parent-child and ancestor-descendant) relationships, and twig matching is achieved by: (i) using structural join algorithms to match the binary relationships against the XML database, and (ii) stitching together these basic matches. A limitation of this approach for matching twig patterns is that intermediate result sizes can get large, even when the input and output sizes are more manageable.In this paper, we propose a novel holistic twig join algorithm, TwigStack, for matching an XML query twig pattern. Our technique uses a chain of linked stacks to compactly represent partial results to root-to-leaf query paths, which are then composed to obtain matches for the twig pattern. When the twig pattern uses only ancestor-descendant relationships between elements, TwigStack is I/O and CPU optimal among all sequential algorithms that read the entire input: it is linear in the sum of sizes of the input lists and the final result list, but independent of the sizes of intermediate results. We then show how to use (a modification of) B-trees, along with TwigStack, to match query twig patterns in sub-linear time. Finally, we complement our analysis with experimental results on a range of real and synthetic data, and query twig patterns.',\n",
              "  \"Colorful XML: One Hierarchy Isn't Enough.[SEP]XML has a tree-structured data model, which is used to uniformly represent structured as well as semi-structured data, and also enable concise query specification in XQuery, via the use of its XPath (twig) patterns. This in turn can leverage the recently developed technology of structural join algorithms to evaluate the query efficiently. In this paper, we identify a fundamental tension in XML data modeling: (i) data represented as deep trees (which can make effective use of twig patterns) are often un-normalized, leading to update anomalies, while (ii) normalized data tends to be shallow, resulting in heavy use of expensive value-based joins in queries.Our solution to this data modeling problem is a novel multi-colored trees (MCT) logical data model, which is an evolutionary extension of the XML data model, and permits trees with multi-colored nodes to signify their participation in multiple hierarchies. This adds significant semantic structure to individual data nodes. We extend XQuery expressions to navigate between structurally related nodes, taking color into account, and also to create new colored trees as restructurings of an MCT database. While MCT serves as a significant evolutionary extension to XML as a logical data model, one of the key roles of XML is for information exchange. To enable exchange of MCT information, we develop algorithms for optimally serializing an MCT database as XML. We discuss alternative physical representations for MCT databases, using relational and native XML databases, and describe an implementation on top of the Timber native XML database. Experimental evaluation, using our prototype implementation, shows that not only are MCT queries/updates more succinct and easier to express than equivalent shallow tree XML queries, but they can also be significantly more efficient to evaluate than equivalent deep and shallow tree XML queries/updates.\",\n",
              "  'On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques.[SEP]Searching for all occurrences of a twig pattern in an XML document is an important operation in XML query processing. Recently a holistic method TwigStack. [2] has been proposed. The method avoids generating large intermediate results which do not contribute to the final answer and is CPU and I/O optimal when twig patterns only have ancestor-descendant relationships. Another important direction of XML query processing is to build structural indexes [3][8][13][15] over XML documents to avoid unnecessary scanning of source documents. We regard XML structural indexing as a technique to partition XML documents and call it streaming scheme in our paper. In this paper we develop a method to perform holistic twig pattern matching on XML documents partitioned using various streaming schemes. Our method avoids unnecessary scanning of irrelevant portion of XML documents. More importantly, depending on different streaming schemes used, it can process a large class of twig patterns consisting of both ancestor-descendant and parent-child relationships and avoid generating redundant intermediate results. Our experiments demonstrate the applicability and the performance advantages of our approach.'],\n",
              " '86_moral_dilemmas_judgment_harm': [\"Priming Effects of Religious Concepts on Moral Judgment: Between Mean Values and Variation.[SEP]Social psychological researchers have found that most conceptual structures can be primed, i.e. activated unobtrusively and exert an influence on subsequent behavior without the participant’s awareness of this influence. I investigated whether exposing people to words related to a punishing God or a forgiving Christian could influence subsequent moral judgment. Participants completed a 'scrambled sentence' task before rating five vignettes concerning various moral transgressions. Analysis showed that participants in the 'forgiving' condition on average made slightly less severe moral judgments than did participants in both the 'punishing' condition and a control condition. Whereas previous religious priming studies have often treated ‘religious’ concepts as a homogenous category with homogenous priming effects, the current experiment questions that assumption. Also, the study incorporated a measure of participants' associations with the prime words, revealing considerable variation. This suggests that participants’ different interpretations of religious words are an important topic and concern for future studies.\",\n",
              "  \"Apparent Paradoxes in Moral Reasoning; Or how you forced him to do it, even though he wasn't forced to do it.[SEP]The importance of situational constraint for moral evaluations is widely accepted in philosophy, psychology, and the law. However, recent work suggests that this relationship is actually bidirectional: moral evaluations can also influence our judgments of situational constraint. For example, if an agent is thought to have acted immorally rather than morally, that agent is often judged to have acted with greater freedom and under less situational constraint. Moreover, when considering interpersonal situations, we judge that an agent who forces another to act immorally (versus morally) uses more force. These two features can result in contradictory response patterns in which participants judge both that (1) a forcer forced a forcee to act and (2) the forcee was not forced by the forcer to act. Here, we characterize potential psychological mechanisms, in particular, “moral focus” and counterfactual reasoning that account for this paradoxical pattern of judgments.\",\n",
              "  'Mental states are more important in evaluating moral than conventional violations.[SEP]A perpetrator’s mental state – whether she had mens rea or a “guilty mind” – typically plays an important role in evaluating wrongness and assigning punishment. In two experiments, we find that this role for mental states is weaker in evaluating conventional violations relative to moral violations. We also find that this diminished role for mental states may be associated with the fact that conventional violations are wrong by virtue of having violated a rule, whereas moral violations are also wrong inherently.'],\n",
              " '87_volume_volumetric_rendering_opacity': ['Dataset Traversal with Motion-Controlled Transfer Functions.[SEP]In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.',\n",
              "  'ViSizer: A Visualization Resizing Framework.[SEP]Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.',\n",
              "  'Opacity Optimization for Surfaces.[SEP]In flow visualization, integral surfaces rapidly tend to expand, fold and produce vast amounts of occlusion. While silhouette enhancements and local transparency mappings proved useful for semi‐transparent depictions, they still introduce visual clutter when surfaces grow more complex. An effective visualization of the flow requires a balance between the presentation of interesting surface parts and the avoidance of occlusions that hinder the view. In this paper, we extend the concept of opacity optimization to surfaces to obtain a global approach to the occlusion problem. Starting with a partition of the surfaces into patches, we compute per‐patch opacity as minimizer of a bounded‐variable least‐squares problem. For the final rendering, opacity is interpolated on the surfaces. The resulting visualization technique is interactive, frame‐coherent, view‐dependent and driven by domain knowledge.'],\n",
              " '88_pointing_target_movement_targets': ['Control Theoretic Models of Pointing.[SEP]This article presents an empirical comparison of four models from manual control theory on their ability to model targeting behaviour by human users using a mouse: McRuer’s Crossover, Costello’s Surge, second-order lag (2OL), and the Bang-bang model. Such dynamic models are generative, estimating not only movement time, but also pointer position, velocity, and acceleration on a moment-to-moment basis. We describe an experimental framework for acquiring pointing actions and automatically fitting the parameters of mathematical models to the empirical data. We present the use of time-series, phase space, and Hooke plot visualisations of the experimental data, to gain insight into human pointing dynamics. We find that the identified control models can generate a range of dynamic behaviours that captures aspects of human pointing behaviour to varying degrees. Conditions with a low index of difficulty (ID) showed poorer fit because their unconstrained nature leads naturally to more behavioural variability. We report on characteristics of human surge behaviour (the initial, ballistic sub-movement) in pointing, as well as differences in a number of controller performance measures, including overshoot, settling time, peak time, and rise time. We describe trade-offs among the models. We conclude that control theory offers a promising complement to Fitts’ law based approaches in HCI, with models providing representations and predictions of human pointing dynamics, which can improve our understanding of pointing and inform design.',\n",
              "  'Modeling the Endpoint Uncertainty in Crossing-based Moving Target Selection.[SEP]Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.',\n",
              "  'A probabilistic approach to modeling two-dimensional pointing.[SEP]We investigate and model two-dimensional pointing where the target distance and size vary as does the angle of movement. We first study the spread of hits in a rapid approximate pointing task at varied distances and movement angles. Consistent with the literature, our results show that the spread of hits along the movement direction deviate more than the spread of hits in the direction perpendicular to movement, and both spreads increase with distance. Based on the distribution of this spread of hits, we propose and validate a new probabilistic model that describes two-dimensional pointing. Unlike previous models, our model accounts for more variables of two-dimensional pointing and can be generalized to any target shape, size, orientation, location, and dimension. In contrast to previous work, which suggests that target height has minimal impact on performance when it is larger than the width, our results show that, even when height is greater than width, it can significantly impact movement time.'],\n",
              " '89_indoor_location_positioning_rfid': ['A New Method for Auto-calibrated Object Tracking.[SEP]Ubiquitous computing technologies which are cheap and easy to use are more likely to be adopted by users beyond the ubiquitous computing community. We present an ultrasonic-only tracking system that is cheap to build, self-calibrating and self-orientating, and has a convenient form factor. The system tracks low-power tags in three dimensions. The tags are smaller than AAA batteries and last up to several years on their power source. The system can be configured to track either multiple near-stationary objects or a single fast moving object. Full test results are provided and use of the system within a home application is discussed.',\n",
              "  'Wideband powerline positioning for indoor localization.[SEP]Fingerprinting techniques for indoor localization have been widely explored. A particular approach by Patel et al. suggested leveraging of the residential powerline as the signaling mechanism for a domestic location capability. In this paper, we critically examine that initial work, called powerline positioning (PLP). We find the proposed technique lacking in temporal stability, requiring frequent and undesired recalibration in some environments. We also determine that there is no a priori method to determine a pair of signaling frequencies that will reliably work in any space. We propose a wideband approach to PLP (WPLP) that injects up to 44 different frequencies into the powerline. We show that this WPLP approach improves upon overall positioning accuracy, demonstrates greatly improved temporal stability and has the added advantage of working in commercial indoor spaces.',\n",
              "  'A Probabilistic Room Location Service for Wireless Networked Environments.[SEP]The popularity of wireless networks has increased in recent years and is becoming a common addition to LANs. In this paper we investigate a novel use for a wireless network based on the IEEE 802.11 standard: inferring the location of a wireless client from signal quality measures. Similar work has been limited to prototype systems that rely on nearest-neighbor techniques to infer location. In this paper, we describe Nibble, a Wi-Fi location service that uses Bayesian networks to infer the location of a device. We explain the general theory behind the system and how to use the system, along with describing our experiences at a university campus building and at a research lab. We also discuss how probabilistic modeling can be applied to a diverse range of applications that use sensor data.'],\n",
              " '8_database_query_queries_join': ['Synthesizing Type-Detection Logic for Rich Semantic Data Types using Open-source Code.[SEP]Given a table of data, existing systems can often detect basic atomic types (e.g., strings vs. numbers) for each column. A new generation of data-analytics and data-preparation systems are starting to automatically recognize rich semantic types such as date-time, email address, etc., for such metadata can bring an array of benefits including better table understanding, improved search relevance, precise data validation, and semantic data transformation. However, existing approaches only detect a limited number of types using regular-expression-like patterns, which are often inaccurate, and cannot handle rich semantic types such as credit card and ISBN numbers that encode semantic validations (e.g., checksum).',\n",
              "  'A New Characterization of Independence.[SEP]We introduce a restriction on the structure of a database scheme, called the primary key condition, and show that this condition characterizes independent database schemes when constraints are presented as keys. The primary key condition provides added insight into the structure of independent schemes, and leads to a general design methodology. We describe a linear-time algorithm for recognizing independent schemes.',\n",
              "  'Efficient and Extensible Algorithms for Multi Query Optimization.[SEP]Complex queries are becoming commonplace, with the growing use of decision support systems. These complex queries often have a lot of common sub-expressions, either within a single query, or across multiple such queries run as a batch. Multiquery optimization aims at exploiting common sub-expressions to reduce evaluation cost. Multi-query optimization has hither-to been viewed as impractical, since earlier algorithms were exhaustive, and explore a doubly exponential search space.',\n",
              "  'Leveraging compression in the tableau data engine.[SEP]Data sets are growing rapidly and there is an attendant need for tools that facilitate human analysis of them in a timely manner. To help meet this need, column-oriented databases (or \"column stores\") have come into wide use because of their low latency on analytic workloads. Column stores use a number of techniques to produce these dramatic performance techniques, including the ability to perform operations directly on compressed data. In this paper, we describe how the Tableau Data Engine (an internally developed column store) leverages a number of compression techniques to improve query performance. The approach is simpler than existing systems for operating on compressed data and more unified, removing the necessity for custom data access mechanisms. The approach also uses some novel metadata extraction techniques to improve the choices made by the system\\'s run-time optimizer.',\n",
              "  'ByteSlice: Pushing the Envelop of Main Memory Data Processing with a New Storage Layout.[SEP]Scan and lookup are two core operations in main memory column stores. A scan operation scans a column and returns a result bit vector that indicates which records satisfy a filter. Once a column scan is completed, the result bit vector is converted into a list of record numbers, which is then used to look up values from other columns of interest for a query. Recently there are several in-memory data layout proposals that aim to improve the performance of in-memory data processing. However, these solutions all stand at either end of a trade-off --- each is either good in lookup performance or good in scan performance, but not both. In this paper we present ByteSlice, a new main memory storage layout that supports both highly efficient scans and lookups. ByteSlice is a byte-level columnar layout that fully leverages SIMD data-parallelism. Micro-benchmark experiments show that ByteSlice achieves a data scan speed at less than 0.5 processor cycle per column value --- a new limit of main memory data scan, without sacrificing lookup performance. Our experiments on TPC-H data and real data show that ByteSlice offers significant performance improvement over all state-of-the-art approaches.',\n",
              "  'A Padded Encoding Scheme to Accelerate Scans by Leveraging Skew.[SEP]In-memory data analytic systems that use vertical bit-parallel scan methods generally use encoding techniques. We observe that in such environments, there is an opportunity to turn skew in both the data and predicate distributions (usually a problem for query processing) into a benefit that can be leveraged to encode the column values. This paper proposes a padded encoding scheme to address this opportunity. The proposed scheme creates encodings that map common attribute values to codes that can easily be distinguished from other codes by only examining a few bits in the full code. Consequently, scans on columns stored using the padded encoding scheme can safely prune the computation without examining all the bits in the code, thereby reducing the memory bandwidth and CPU cycles that are consumed when evaluating scan queries. Our padded encoding method results in a fixed-length encoding, as fixed-length encodings are easier to manage. However, the proposed padded encoding may produce longer (fixed-length) codes than those produced by popular order-preserving encoding methods, such as dictionary-based encoding. This additional space overhead has the potential to negate the gains from early pruning of the scan computation. However, as we demonstrate empirically, the additional space overhead is generally small, and the padded encoding scheme provides significant performance improvements.',\n",
              "  'Secondary-storage confidence computation for conjunctive queries with inequalities.[SEP]This paper investigates the problem of efficiently computing the confidences of distinct tuples in the answers to conjunctive queries with inequalities (<) on tuple-independent probabilistic databases. This problem is fundamental to probabilistic databases and was recently stated open.',\n",
              "  'A Query Engine for Probabilistic Preferences.[SEP]Models of uncertain preferences, such as Mallows, have been extensively studied due to their plethora of application domains. In a recent work, a conceptual and theoretical framework has been proposed for supporting uncertain preferences as first-class citizens in a relational database. The resulting database is probabilistic, and, consequently, query evaluation entails inference of marginal probabilities of query answers. In this paper, we embark on the challenge of a practical realization of this framework. We first describe an implementation of a query engine that supports querying probabilistic preferences alongside relational data. Our system accommodates preference distributions in the general form of the Repeated Insertion Model (RIM), which generalizes Mallows and other models. We then devise a novel inference algorithm for conjunctive queries over RIM, and show that it significantly outperforms the state of the art in terms of both asymptotic and empirical execution cost. We also develop performance optimizations that are based on sharing computation among different inference tasks in the workload. Finally, we conduct an extensive experimental evaluation and demonstrate that clear performance benefits can be realized by a query engine with built-in probabilistic inference, as compared to a stand alone implementation with a black-box inference solver.',\n",
              "  'US-SQL: managing uncertain schemata.[SEP]In this paper we describe a demo concerning the management of uncertain schemata. Many works have studied the problem of representing uncertainty on attribute values or tuples, like the fact that a value is 10 with probability .3 or 20 with probability .7, leading to the implementation of probabilistic database management systems. In our demo we deal with the representation of uncertainty about the meta-data, i.e., about the meaning of these values. Using our system it is possible to create alternative probabilistic schemata on a database, execute queries over uncertain schemata and verify how this additional information is stored in an underlying relational database and how queries are executed.',\n",
              "  'High-Performance Geospatial Analytics in HyPerSpace.[SEP]In the past few years, massive amounts of location-based data has been captured. Numerous datasets containing user location information are readily available to the public. Analyzing such datasets can lead to fascinating insights into the mobility patterns and behaviors of users. Moreover, in recent times a number of geospatial data-driven companies like Uber, Lyft, and Foursquare have emerged. Real-time analysis of geospatial data is essential and enables an emerging class of applications. Database support for geospatial operations is turning into a necessity instead of a distinct feature provided by only a few databases. Even though a lot of database systems provide geospatial support nowadays, queries often do not consider the most current database state. Geospatial queries are inherently slow given the fact that some of these queries require a couple of geometric computations. Disk-based database systems that do support geospatial datatypes and queries, provide rich features and functions, but they fall behind when performance is considered: specifically if real-time analysis of the latest transactional state is a requirement. In this demonstration, we present HyPerSpace, an extension to the high-performance main-memory database system HyPer developed at the Technical University of Munich, capable of processing geospatial queries with sub-second latencies.',\n",
              "  'Incremental Distance Join Algorithms for Spatial Databases.[SEP]Two new spatial join operations, distance join and distance semi-join, are introduced where the join output is ordered by the distance between the spatial attribute values of the joined tuples. Incremental algorithms are presented for computing these operations, which can be used in a pipelined fashion, thereby obviating the need to wait for their completion when only a few tuples are needed. The algorithms can be used with a large class of hierarchical spatial data structures and arbitrary spatial data types in any dimensions. In addition, any distance metric may be employed. A performance study using R-trees shows that the incremental algorithms outperform non-incremental approaches by an order of magnitude if only a small part of the result is needed, while the penalty, if any, for the incremental processing is modest if the entire join result is required.',\n",
              "  'STAR: A Distributed Stream Warehouse System for Spatial Data.[SEP]The proliferation of mobile phones and location-based services gives rise to an explosive growth of spatial data. This spatial data contains valuable information, and calls for data stream warehouse systems that can provide real-time analytical results with the latest integrated spatial data. In this demonstration, we present the STAR (Spatial Data Stream Warehouse) system. STAR is a distributed in-memory spatial data stream warehouse system that provides low-latency and up-to-date analytical results over a fast spatial data stream. STAR supports a rich set of aggregate queries for spatial data analytics, e.g., contrasting the frequencies of spatial objects that appear in different spatial regions, or showing the most frequently mentioned topics being tweeted in different cities. STAR processes aggregate queries by maintaining distributed materialized views. Additionally, STAR supports dynamic load adjustment that makes STAR scalable and adaptive. We demonstrate STAR on top of Amazon EC2 clusters using real data sets.'],\n",
              " '90_diffusion_tensor_tracts_brain': ['Case Study: Reconstruction, Visualization, and Quantification of Neuronal Fiber Pathways.[SEP]It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.',\n",
              "  'Topological Visualization of Brain Diffusion MRI Data.[SEP]Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.',\n",
              "  'Visualizing crossing probabilistic tracts.[SEP]Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.'],\n",
              " '91_ontology_schema_ontologies_schemas': ['Statistical Schema Matching across Web Query Interfaces.[SEP]Schema matching is a critical problem for integrating heterogeneous information sources. Traditionally, the problem of matching multiple schemas has essentially relied on finding pairwise-attribute correspondence. This paper proposes a different approach, motivated by integrating large numbers of data sources on the Internet. On this \"deep Web,\" we observe two distinguishing characteristics that offer a new view for considering schema matching: First, as the Web scales, there are ample sources that provide structured information in the same domains (e.g., books and automobiles). Second, while sources proliferate, their aggregate schema vocabulary tends to converge at a relatively small size. Motivated by these observations, we propose a new paradigm, statistical schema matching: Unlike traditional approaches using pairwise-attribute correspondence, we take a holistic approach to match all input schemas by finding an underlying generative schema model. We propose a general statistical framework MGS for such hidden model discovery, which consists of hypothesis modeling, generation, and selection. Further, we specialize the general framework to develop Algorithm MGSsd, targeting at synonym discovery, a canonical problem of schema matching, by designing and discovering a model that specifically captures synonym attributes. We demonstrate our approach over hundreds of real Web sources in four domains and the results show good accuracy.',\n",
              "  'JSON Schema Matching: Empirical Observations.[SEP]Database schema specifies the desired logical organization of the data it stores. A major challenge in database integration is that of schema matching [10, 12], which seeks to determine schema elements in different databases that correspond to the same real world entity. For example, a simple matcher may determine that the attribute ID in one schema is semantically equivalent to Identification in another.',\n",
              "  'SourceSight: Enabling Effective Source Selection.[SEP]Recently there has been a rapid increase in the number of data sources and data services, such as cloud-based data markets and data portals, that facilitate the collection, publishing and trading of data. Data sources typically exhibit large heterogeneity in the type and quality of data they provide. Unfortunately, when the number of data sources is large, it is difficult for users to reason about the actual usefulness of sources for their applications and the trade-offs between the benefits and costs of acquiring and integrating sources. In this demonstration we present \\\\textsc{SourceSight}, a system that allows users to interactively explore a large number of heterogeneous data sources, and discover valuable sets of sources for diverse integration tasks. \\\\textsc{SourceSight}~uses a novel multi-level source quality index that enables effective source selection at different granularity levels, and introduces a collection of new techniques to discover and evaluate relevant sources for integration.',\n",
              "  'Visualizing Conceptual Relations in Legal Terminology.[SEP]Underlying all specialized terminology is a concept system, which is particularly important in the legal domain. However, this concept system is not explicitly available in terminology management systems. We present a tool that analyzes the relations in a terminological database and presents an interactive visualization of those relations. This tool helps terminologists manage their information, including quality assurance and analysis of the information, as well as aiding in didactic presentations of terminology work.',\n",
              "  'A Visualisation Approach for Collaborative Planning Systems Based on Ontologies.[SEP]In the last decades, many advances have been made in intelligent planning systems. Significant improvements related to core problems, providing faster search algorithms and shortest plans have been proposed. However, there is a lack in researches allowing a better support for a proper use and interaction with planners, where, for instance, visualization can play an important role. This work proposes a way to address the problem of visualization in intelligent planning systems via a more general approach. It consists in an integrated ontology set and reasoning mechanism for multi-modality visualisation destined to collaborative planning environments. This framework will permit organizing and modeling the domain from the visualization perspective, and give a tailored support for presentation of information.',\n",
              "  'User-Friendly Ontology Editing and Visualization Tools: The OWLeasyViz Approach.[SEP]This paper aims to propose solutions to the issue of ontology visualization, by presenting intuitive and user-friendly ontology editing and visualization environments mainly oriented to domain experts. It starts with an overview of existing ontology visualization methods; afterwards it describes the Semantic DB system and the OWLeasyViz ontology editor. Semantic DB is a web application framework to create simple complete semantic web applications, integrating an ontology editor, a resource editor, an inference rule editor, a reasoner, and a search engine. OWLeasyViz is an ontology editor that combines a textual and a graphical representation of OWL ontologies. It meets different user needs by providing a simple and intuitive interface to end-users who are not ontologists, and offering more advanced tools to ontology experts. The OWLeasyViz editor is intended to be a module of a semantic web integrated working environment, developed within the context of a Swiss Government funded CTI applied research project in the domain of waste water management.'],\n",
              " '92_email_emails_mail_inbox': ['Going with the flow: email awareness and task management.[SEP]Email use in the context of everyday work practices, or email flow, has not been heavily studied. We present the results of a pair of studies examining how users interlace email with their day-to-day, ongoing work processes. We demonstrate that our subjects use email as a tool for managing moment-to-moment attention and task focus. We also provide a model of this workflow that builds upon an existing model by Venolia et al. Finally, we provide specific design recommendations to enhance the usability of email clients in support of these modes of interaction.',\n",
              "  \"Overload is overloaded: email in the age of Gmail.[SEP]The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.\",\n",
              "  'Revisiting Whittaker  Sidner\\'s \"email overload\" ten years later.[SEP]Ten years ago, Whittaker and Sidner [8] published research on email overload, coining a term that would drive a research area that continues today. We examine a sample of 600 mailboxes collected at a high-tech company to compare how users organize their email now to 1996. While inboxes are roughly the same size as in 1996, our population\\'s email archives have grown tenfold. We see little evidence of distinct strategies for handling email; most of our users fall into a middle ground. There remains a need for future innovations to help people manage growing archives of email and large inboxes.'],\n",
              " '93_security_traffic_cyber_intrusion': ['BubbleNet: A Cyber Security Dashboard for Visualizing Patterns.[SEP]The field of cyber security is faced with ever‐expanding amounts of data and a constant barrage of cyber attacks. Within this space, we have designed BubbleNet as a cyber security dashboard to help network analysts identify and summarize patterns within the data. This design study faced a range of interesting constraints from limited time with various expert users and working with users beyond the network analyst, such as network managers. To overcome these constraints, the design study employed a user‐centered design process and a variety of methods to incorporate user feedback throughout the design of BubbleNet. This approach resulted in a successfully evaluated dashboard with users and further deployments of these ideas in both research and operational environments. By explaining these methods and the process, it can benefit future visualization designers to help overcome similar challenges in cyber security or alternative domains.',\n",
              "  'situ: Situational understanding and discovery for cyber attacks.[SEP]Our entry into the VAST 2012 Mini Challenge 2 is a streaming visual analytic system that scores events based on anomalousness and maliciousness and presents each event to the user in a user-defined groupings in animated small-multiple views. The anomaly detection algorithm identifies low probability events, supporting awareness regarding atypical traffic patterns on the network. The maliciousness classifier incorporates both situated knowledge of an environment (policy and machine roles) and domain knowledge (encoded in the IDS alerts). We discuss the visualization design and classification techniques, as well as provide examples of timely detection from the challenge dataset.',\n",
              "  'Weaving a carpet from log entries: A network security visualization built with co-creation.[SEP]We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the \"Carpet\"). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers\\' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to define areas of interest for closer inspection.'],\n",
              " '94_outlier_outliers_datasets_distance': ['Human-in-the-loop Outlier Detection.[SEP]Outlier detection is critical to a large number of applications from finance fraud detection to health care. Although numerous approaches have been proposed to automatically detect outliers, such outliers detected based on statistical rarity do not necessarily correspond to the true outliers to the interest of applications. In this work, we propose a human-in-the-loop outlier detection approach HOD that effectively leverages human intelligence to discover the true outliers. There are two main challenges in HOD. The first is to design human-friendly questions such that humans can easily understand the questions even if humans know nothing about the outlier detection techniques. The second is to minimize the number of questions. To address the first challenge, we design a clustering-based method to effectively discover a small number of objects that are unlikely to be outliers (aka, inliers) and yet effectively represent the typical characteristics of the given dataset. HOD then leverages this set of inliers (called context inliers) to help humans understand the context in which the outliers occur. This ensures humans are able to easily identify the true outliers from the outlier candidates produced by the machine-based outlier detection techniques. To address the second challenge, we propose a bipartite graph-based question selection strategy that is theoretically proven to be able to minimize the number of questions needed to cover all outlier candidates. Our experimental results on real data sets show that HOD significantly outperforms the state-of-the-art methods on both human efforts and the quality of the discovered outliers.',\n",
              "  'Angle-based outlier detection in high-dimensional data.[SEP]Detecting outliers in a large set of data objects is a major data mining task aiming at finding different mechanisms responsible for different groups of objects in a data set. All existing approaches, however, are based on an assessment of distances (sometimes indirectly by assuming certain distributions) in the full-dimensional Euclidean data space. In high-dimensional data, these approaches are bound to deteriorate due to the notorious \"curse of dimensionality\". In this paper, we propose a novel approach named ABOD (Angle-Based Outlier Detection) and some variants assessing the variance in the angles between the difference vectors of a point to the other points. This way, the effects of the \"curse of dimensionality\" are alleviated compared to purely distance-based approaches. A main advantage of our new approach is that our method does not rely on any parameter selection influencing the quality of the achieved ranking. In a thorough experimental evaluation, we compare ABOD to the well-established distance-based method LOF for various artificial and a real world data set and show ABOD to perform especially well on high-dimensional data.',\n",
              "  'Online Outlier Exploration Over Large Datasets.[SEP]Traditional outlier detection systems process each individual outlier detection request instantiated with a particular parameter setting one at a time. This is not only prohibitively time-consuming for large datasets, but also tedious for analysts as they explore the data to hone in on the appropriate parameter setting and desired results.'],\n",
              " '95_video_videos_frames_temporal': ['CoSummary: adaptive fast-forwarding for surgical videos by detecting collaborative scenes using hand regions and gaze positions.[SEP]This paper presents CoSummary, an adaptive video fast-forwarding technique for browsing surgical videos recorded by wearable cameras. Current wearable technologies allow us to record complex surgical skills, however, an efficient browsing technique for these videos is not well established. In order to assist browsing surgical videos, our study focuses on adaptively changing playback speeds through the learning and detecting collaborative scenes based on surgeon hand placement and gaze information. Our evaluation shows that the proposed method is able to highlight important collaborative scenes and skip less important scenes during surgical procedures. We have also performed a subjective study with surgeons in order to have professional feedback. The results confirmed the effectiveness of the proposed method in comparison to uniform video fast-forwarding.',\n",
              "  'Temporal Magic Lens: Combined Spatial and Temporal Query and Presentation.[SEP]We introduce the concept of a Temporal Magic Lens, a novel interaction technique that supports querying and browsing for video data. Video data is available from an increasing number of sources, and yet analyzing and processing it is still often a manual, tedious task. A Temporal Magic Lens is an interactive tool that combines spatial and temporal components of video, creating a unified mechanism for analyzing video data; it can be used for viewing real-time video data, as well as for browsing and searching archival data. In this paper, we define the Temporal Magic Lens concept and identify its four key components. We present a sample implementation for each component, and then describe two usage scenarios for a prototype surveillance application.',\n",
              "  \"SmartPlayer: user-centric video fast-forwarding.[SEP]In this paper we propose a new video interaction model called adaptive fast-forwarding to help people quickly browse videos with predefined semantic rules. This model is designed around the metaphor of scenic car driving, in which the driver slows down near areas of interest and speeds through unexciting areas. Results from a preliminary user study of our video player suggest the following: (1) the player should adaptively adjust the current playback speed based on the complexity of the present scene and predefined semantic events; (2) the player should learn user preferences about predefined event types as well as a suitable playback speed; (3) the player should fast-forward the video continuously with a playback rate acceptable to the user to avoid missing any undefined events or areas of interest. Furthermore, our user study results suggest that for certain types of video, our SmartPlayer yields better user experiences in browsing and fast-forwarding videos than existing video players' interaction models.\"],\n",
              " '96_tree_trees_plant_plants': ['A Visualization Tool for Studying the Development of the Moss Physcomitrella patens.[SEP]The investigation of mechanisms responsible for the morphogenesis of complex biological organisms is an important area in biology. P. patens is an especially suitable plant for this research because it is a rather simple organism, facilitating its observation, yet it possesses developmental phenomena analogous to those which occur in higher plants, allowing the extrapolation of hypotheses to more complex organisms. The visualization consists of three components: biological data collection, computer-modelling (using L-systems), and model verification. The simulated developmental process is quite realistic and provides an excellent means for verifying the underlying hypotheses of morphogenesis.',\n",
              "  'Data-Driven Synthetic Modeling of Trees.[SEP]In this paper, we develop a data-driven technique to model trees from a single laser scan. A multi-layer representation of the tree structure is proposed to guide the modeling process. In this process, a marching cylinder algorithm is first developed to construct visible branches from the laser scan data. Three levels of crown feature points are then extracted from the scan data to synthesize three layers of non-visible branches. Based on the hierarchical particle flow technique, the branch synthesis method has the advantage of producing visually convincing tree models that are consistent with scan data. User intervention is extremely limited. The robustness of this technique has been validated on both conifer and broadleaf trees.',\n",
              "  'Interactive Design of Bonsai Tree Models.[SEP]Because of their complexity, plant models used in computer graphics are commonly created with proceduralmethods. A difficult problem is the user control of these models: a small number of parameters is insufficient tospecify plant characteristics in detail, while large numbers of parameters are tedious to manipulate and difficultto comprehend. To address this problem, we propose a method for managing parameters involved in plant modelmanipulation. Specifically, we introduce decomposition graphs as multiscale representations of plant structuresand present interactive tools for designing trees that operate on decomposition graphs. The supported operationsinclude browsing of the parameter space, editing of generalized parameters (scalars, functions, and branchingsystem silhouettes), and the definition of dependencies between parameters. We illustrate our method by creatingmodels of bonsai trees.'],\n",
              " '97_entity_entities_name_disambiguation': [\"Automatic Entity Recognition and Typing in Massive Text Data.[SEP]In today's computerized and information-based society, individuals are constantly presented with vast amounts of text data, ranging from news articles, scientific publications, product reviews, to a wide range of textual information from social media. To extract value from these large, multi-domain pools of text, it is of great importance to gain an understanding of entities and their relationships. In this tutorial, we introduce data-driven methods to recognize typed entities of interest in massive, domain-specific text corpora. These methods can automatically identify token spans as entity mentions in documents and label their fine-grained types (e.g., people, product and food) in a scalable way. Since these methods do not rely on annotated data, predefined typing schema or hand-crafted features, they can be quickly adapted to a new domain, genre and language. We demonstrate on real datasets including various genres (e.g., news articles, discussion forum posts, and tweets), domains (general vs. bio-medical domains) and languages (e.g., English, Chinese, Arabic, and even low-resource languages like Hausa and Yoruba) how these typed entities aid in knowledge discovery and management.\",\n",
              "  'Robust Entity Resolution using Random Graphs.[SEP]Entity resolution (ER) seeks to identify which records in a data set refer to the same real-world entity. Given the diversity of ways in which entities can be represented, matched and distinguished, ER is known to be a challenging task for automated strategies, but relatively easier for expert humans. In our work, we abstract the knowledge of experts with the notion of a binary oracle. Our oracle can answer questions of the form \"do records u and v refer to the same entity?\" under a flexible error model, allowing for some questions to be more difficult to answer correctly than others.',\n",
              "  'Entity Resolution with Markov Logic.[SEP]Entity resolution is the problem of determining which records in a database refer to the same entities, and is a crucial and expensive step in the data mining process. Interest in it has grown rapidly, and many approaches have been proposed. However, they tend to address only isolated aspects of the problem, and are often ad hoc. This paper proposes a well-founded, integrated solution to the entity resolution problem based on Markov logic. Markov logic combines first-order logic and probabilistic graphical models by attaching weights to first-order formulas, and viewing them as templates for features of Markov networks. We show how a number of previous approaches can be formulated and seamlessly combined in Markov logic, and how the resulting learning and inference problems can be solved efficiently. Experiments on two citation databases show the utility of this approach, and evaluate the contribution of the different components.'],\n",
              " '98_interruptions_interruption_interruptibility_task': [\"Investigating interruptions in the context of computerised cognitive testing for older adults.[SEP]Interruptions in the home pose a threat to the validity of self-administered computerised cognitive testing. We report the findings of a laboratory experiment investigating the effects of increased interruption workload demand on older adults' computerised cognitive test performance. Related work has reported interruptions having a range of inhibitory and facilitatory effects on primary task performance. Cognitive ageing literature suggests that increased interruption workload demand should have greater detrimental effects on older adults' performance, when compared to younger adults. With 36 participants from 3 age groups (20-54, 55-69, 70+), we found divergent effects of increased interruption demand on two primary tasks. Results suggest that older and younger adults experience interruptions differently, but at no age is test performance compromised by demanding interruptions. This finding is reassuring with respect to the success of a self-administered computerised cognitive assessment test, and is likely to be useful for other applications used by older adults.\",\n",
              "  \"Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors.[SEP]Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers.\",\n",
              "  'The effects of time constraints on user behavior for deferrable interruptions.[SEP]Previous studies of multitasking have highlighted the importance of cognitive load in interruptibility by showing that forced interruptions are least disruptive when cognitive load is low, and also that users prefer to address interruptions at low-load points when given a choice. We present an empirical study that uses a ringing-phone scenario to examine how users manage deferrable interruptions in the presence of varying time constraints. We found that while cognitive load did influence multitasking as expected, the time constraints placed on the user also had a significant impact. In particular, we observed three distinct strategies for addressing interruption: the expected strategy of switching at low-load points, but also two other strategies of continuing on after a low-load point or giving up at a high-load point. The presence of the latter two strategies strongly suggests that users can adapt their multitasking behavior with respect to the time constraints of the interrupting task.'],\n",
              " '99_coordination_interpersonal_synchrony_actions': ['Interpersonal Coordination of Perception and Memory in Real-Time Online Social Interaction.[SEP]The quiet hum of interpersonal coordination that runs throughout social communication and interaction shows how individuals can subtly influence one another’s behaviors, thoughts, and emotions over time. While the majority of research on coordination studies face-to-face interaction, recent advances in crowdsourcing afford the opportunity to conduct large-scale, real-time social interaction experiments. We take advantage of these tools to explore interpersonal coordination in a “minimally interactive context,” distilling the richness of natural communication into a tightly controlled setting to explore how people become coupled in their perceptual and memory systems while performing a task together. Consistent with previous work on postural sway and gaze, we found that individuals become coupled to one another’s cognitive processes without needing to be co-located or fully interactive with their partner; interestingly, although participants had no information about their partner and no means of direct communication, we also found hints that social forces can shape minimally interactive contexts, similar to effects observed in face-to-face interaction.',\n",
              "  'Facilitating interpersonal action coordination in a movement control task.[SEP]The present experiment examined how individuals and dyads coordinate action in a movement control task either with or without additional action effects. Participants pressed computer keys to keep a moving dot stimulus within a rectangle by certain key-movement mapping. Pressing a key could also cause visual, auditory, or no effect. Participants completed the task either alone or with a partner they could neither see nor hear. The results showed that individuals had better performance and longer key-press than dyads. The performance of dyads was improved by auditory effects, whereas the performance of individuals was not influenced by any additional action effect. In a subsequent STROOP-like task, participants were asked to press a computer key they used in the movement control task while being primed by either visual or auditory effects. The results revealed an association between auditory effects and correspondent key, whereas no such association was found for visual effects.',\n",
              "  'Synchronizing to Learn and Like.[SEP]Ever seen two people walking down the street in the exact same pace? This kind of interpersonal synchrony has been observed in both humans, as well as in animals (e.g., large groups of fireflies flash at the same time, schools of fish and flocks of birds synchronize their movement). For animals it appears to be beneficial (for survival) to synchronize their behavior, but what are the benefits for humans to do so? There are indications that interpersonal synchrony supports social bonding. Previous studies have shown that interpersonal synchrony can have both an effect on (e.g., increases memory), and can be affected by social factors (e.g., higher likeability ratings, more interpersonal synchrony). The goal of the present study was to examine whether social factors (e.g., popularity, friendship) affect interpersonal synchrony when working together. Furthermore, we looked at the relation between interpersonal synchrony and learning and likeability.'],\n",
              " '9_dimensional_visualization_multidimensional_scatterplots': ['SADIRE: a context-preserving sampling technique for dimensionality reduction visualizations.[SEP]Sampling techniques are widely used in the effort to reduce complexity and improve interpretability of datasets. Given the enormous availability of data, these techniques try to select representative data points that inherently reflect the data structure. In this work, we propose a novel sampling technique that preserves the structures imposed by dimensionality reduction techniques when visualized as scatter plots. In the experiments, we demonstrate how our technique is able to reflect the class boundaries and layout structures, besides decreasing redundancy of the datasets visualized as scatter plots. We also provide an user experiment regarding the perception of sampling from scatter plot visualizations.',\n",
              "  'Role of Human Perception in Cluster-based Visual Analysis of Multidimensional Data Projections.[SEP]Visualization of high-dimensional data requires a mapping to a visual space. Whenever the goal is to preserve similarity relations, multidimensional projections or other dimension reduction techniques are commonly used to project high-dimensional data point to a 2D point using a certain strategy for the 2D layout.Typical analysis tasks for projected multidimensional data do not necessarily match the expectations of human perception. Learning more about the effectiveness of projection layouts from a users perspective is an important step towards consolidating their role in supporting visual analytics tasks. Those tasks often involve detecting and correlating clusters. To understand the role of orientation and cluster properties of size, shape and density, we first conducted a study with synthetic 2D scatter plots, where we can set the respective properties manually. Then we picked five projection methods representative of different approaches to generate layouts of high dimensional dat',\n",
              "  \"Voronoi Diagram Based Dimensional Anchor Assessment for Radial Visualizations.[SEP]Selecting the most expressed dimensions from high dimensional data sets has motivated the design and application of a variety of statistical and machine learning techniques. Here, in our current work, we introduce a metric for assessing the effectiveness of these methods. Our formulation is based on the broad concepts of: (a) devising a formal method of partitioning a visualization's image space; (b) identifying regions that indicate the relative strength of the dimension selection based on how well they are populated by data images; and (c) similarily identifying those regions indicating a poor selection of dimensions. In particular, we explore assessing the quality of radial visualizations. Dimension selection in this class of visualizations strongly effects visualization quality and the sensitivity of cluster formation. We demonstrate the usefulness of Voronoi partitioning the RadViz image space; quantifying radial visualization quality is a direct measure of dimension selection. This work continues to develop and refine the formal theory behind the general class of Normalized Radial Visualizations, including RadViz.\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "17cld6YKKgmL"
      },
      "source": [
        "sorted_repre = sorted(repre_docs.keys())"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3K_Bmb9pLYMl",
        "outputId": "76e29a28-70c0-46e8-a626-52e09cb0a680"
      },
      "source": [
        "topic_list"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0_flow_fluid_vortex_jet',\n",
              " '1_language_word_linguistic_lexical',\n",
              " '2_visualization_topic_visual_visualizations',\n",
              " '3_recommendation_recommender_recommendations_users',\n",
              " '4_graph_graphs_network_networks',\n",
              " '5_shape_mesh_meshes_subdivision',\n",
              " '6_game_games_sports_play',\n",
              " '7_light_illumination_rendering_lighting',\n",
              " '8_database_query_queries_join',\n",
              " '9_dimensional_visualization_multidimensional_scatterplots',\n",
              " '10_motion_animation_motions_animations',\n",
              " '11_music_musical_voice_sound',\n",
              " '12_education_educational_teaching_classroom',\n",
              " '13_driving_vehicle_vehicles_driver',\n",
              " '14_gesture_gestures_touch_finger',\n",
              " '15_classification_class_feature_kernel',\n",
              " '16_gaze_eye_attention_head',\n",
              " '17_haptic_tactile_force_virtual',\n",
              " '18_rendering_graphics_gpu_splatting',\n",
              " '19_mining_frequent_itemsets_rules',\n",
              " '20_image_images_retrieval_recognition',\n",
              " '21_software_programmers_collaboration_developers',\n",
              " '22_brain_cognitive_attention_visual',\n",
              " '23_trajectory_trajectories_mobility_urban',\n",
              " '24_graphics_graphic_standards_phigs',\n",
              " '25_series_time_patterns_mining',\n",
              " '26_fabrication_printing_print_manufacturing',\n",
              " '27_smart_activities_context_interfaces',\n",
              " '28_vessel_imaging_ultrasound_clinical',\n",
              " '29_texture_textures_synthesis_image',\n",
              " '30_decision_choice_risk_risky',\n",
              " '31_weather_visualization_climate_ocean',\n",
              " '32_ray_rays_traversal_rendering',\n",
              " '33_twitter_tweets_media_sentiment',\n",
              " '34_creativity_painting_art_creative',\n",
              " '35_causal_beliefs_evidence_belief',\n",
              " '36_privacy_security_private_protection',\n",
              " '37_urban_city_building_buildings',\n",
              " '38_transaction_transactions_concurrency_distributed',\n",
              " '39_displays_display_navigation_lenses',\n",
              " '40_search_web_information_pages',\n",
              " '41_category_categories_categorization_similarity',\n",
              " '42_crowdsourcing_workers_crowd_worker',\n",
              " '43_patient_patients_care_clinical',\n",
              " '44_diagrams_diagrammatic_diagram_logic',\n",
              " '45_color_colors_palette_palettes',\n",
              " '46_hci_design_research_practice',\n",
              " '47_robot_robots_robotic_robotics',\n",
              " '48_label_labels_unlabeled_classification',\n",
              " '49_keyboard_keyboards_touch_finger',\n",
              " '50_sketching_sketches_drawing_design',\n",
              " '51_facial_face_animation_faces',\n",
              " '52_machine_fairness_deep_explanations',\n",
              " '53_papers_conference_issue_editorial',\n",
              " '54_heritage_museum_visitors_museums',\n",
              " '55_number_symbolic_magnitude_numbers',\n",
              " '56_facebook_social_privacy_friends',\n",
              " '57_influence_social_networks_network',\n",
              " '58_walking_virtual_locomotion_reality',\n",
              " '59_reality_augmented_virtual_interaction',\n",
              " '60_molecules_atoms_molecule_halos',\n",
              " '61_memory_insight_solving_task',\n",
              " '62_spline_splines_curves_cubic',\n",
              " '63_clustering_clusters_cluster_clusterings',\n",
              " '64_impaired_visually_tactile_impairments',\n",
              " '65_distributed_parallel_scientific_convergence',\n",
              " '66_wikipedia_communities_community_newcomers',\n",
              " '67_metaphors_metaphor_analogical_analogy',\n",
              " '68_crowd_crowds_simulation_pedestrians',\n",
              " '69_conversational_dialogue_agent_conversation',\n",
              " '70_tracking_camera_tracker_pose',\n",
              " '71_shadow_shadows_light_rendering',\n",
              " '72_narrative_story_stories_storytelling',\n",
              " '73_authentication_passwords_password_security',\n",
              " '74_students_math_solving_achievement',\n",
              " '75_health_patients_self_online',\n",
              " '76_route_map_navigation_wayfinding',\n",
              " '77_gene_genome_genomic_visualization',\n",
              " '78_image_smoothing_denoising_inpainting',\n",
              " '79_construction_visualisation_building_heritage',\n",
              " '80_solid_solids_boundary_polyhedral',\n",
              " '81_electricity_households_heating_smart',\n",
              " '82_fractal_fractals_compression_chaos',\n",
              " '83_memories_diary_life_everyday',\n",
              " '84_civic_civics_infrastructure_citizens',\n",
              " '85_xml_query_xquery_queries',\n",
              " '86_moral_dilemmas_judgment_harm',\n",
              " '87_volume_volumetric_rendering_opacity',\n",
              " '88_pointing_target_movement_targets',\n",
              " '89_indoor_location_positioning_rfid',\n",
              " '90_diffusion_tensor_tracts_brain',\n",
              " '91_ontology_schema_ontologies_schemas',\n",
              " '92_email_emails_mail_inbox',\n",
              " '93_security_traffic_cyber_intrusion',\n",
              " '94_outlier_outliers_datasets_distance',\n",
              " '95_video_videos_frames_temporal',\n",
              " '96_tree_trees_plant_plants',\n",
              " '97_entity_entities_name_disambiguation',\n",
              " '98_interruptions_interruption_interruptibility_task',\n",
              " '99_coordination_interpersonal_synchrony_actions',\n",
              " '100_terrain_rendering_terrains_resolution',\n",
              " '101_stream_drift_ensemble_drifting',\n",
              " '102_cartograms_map_maps_cartographic',\n",
              " '103_design_clothing_clothes_designers',\n",
              " '104_skeleton_skeletons_segmentation_mesh',\n",
              " '105_matrix_factorization_nonnegative_matrices',\n",
              " '106_parallel_compiler_cache_parallelism',\n",
              " '107_event_events_sentinel_ranking',\n",
              " '108_wavelet_wavelets_multiresolution_subdivision',\n",
              " '109_children_participatory_child_technologies',\n",
              " '110_tabletop_collaboration_touch_groupware',\n",
              " '111_collision_collisions_deformable_rigid',\n",
              " '112_chatbot_chatbots_chat_conversation',\n",
              " '113_hair_hairs_cloth_hairstyles',\n",
              " '114_watermarking_watermark_watermarks_attacks',\n",
              " '115_surgical_surgery_laparoscopic_minimally',\n",
              " '116_subspace_clustering_clusters_subspaces',\n",
              " '117_location_recommendation_friends_locations',\n",
              " '118_parents_parenting_child_life',\n",
              " '119_location_privacy_crowdsensing_obfuscation',\n",
              " '120_dance_dancers_dancer_choreographers',\n",
              " '121_line_clipping_algorithms_polygon',\n",
              " '122_occlusion_culling_rendering_occluded',\n",
              " '123_multimodal_modality_modalities_speech',\n",
              " '124_religious_dreaming_religion_cultural',\n",
              " '125_spreadsheet_spreadsheets_web_programming',\n",
              " '126_cleaning_repairing_repair_tuples',\n",
              " '127_polygons_polygon_hull_algorithm',\n",
              " '128_spatial_languages_across_meaning',\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner',\n",
              " '130_meetings_communication_informal_messaging',\n",
              " '131_provenance_lakes_workflows_lake']"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rOxcGqejMp8p",
        "outputId": "d48761a9-3b77-4266-b217-e2772aa567d4"
      },
      "source": [
        "sort_repre = {}\n",
        "for i in range(len(topic_list)):\n",
        "  sort_repre[topic_list[i]] = repre_docs[topic_list[i]]\n",
        "sort_repre"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0_flow_fluid_vortex_jet': ['Target Temperature Driven Dynamic Flame Animation.[SEP]Fire/flame plays an important role in virtual environment. Controlling the flame behavior in an intuitive yet precise manner remains a challenging open problem. In this paper, a target temperature driven simulation method is proposed to control flame animation. The diverse descriptions of target flame are unified by temperature field. An adaptive control force is presented to control the degree of target-driven changing over the temperature field. A bidirectional iterative method is proposed to subdivide the final goal into a plurality of intermediate targets. We take geometric model, image, and temperature field as target flames to test our method. Experimental results show that this method allows complex flame animations to be controllably generated with very little additional cost compared to ordinary flow simulations.',\n",
              "  'Simulation and interaction of fluid dynamics.[SEP]In the fluid simulation, the fluids and their surroundings may greatly change properties such as shape and temperature simultaneously, and different surroundings would characterize different interactions, which would change the shape and motion of the fluids in different ways. On the other hand, interactions among fluid mixtures of different kinds would generate more comprehensive behavior. To investigate the interaction behavior in physically based simulation of fluids, it is of importance to build physically correct models to represent the varying interactions between fluids and the environments, as well as interactions among the mixtures. In this paper, we will make a simple review of the interactions, and focus on those most interesting to us, and model them with various physical solutions. In particular, more detail will be given on the simulation of miscible and immiscible binary mixtures. In some of the methods, it is advantageous to be taken with the graphics processing unit (GPU) to achieve real-time computation for middle-scale simulation.',\n",
              "  'Visual simulation of smoke.[SEP]In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.',\n",
              "  'Construction of Vector Field Hierarchies.[SEP]Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.',\n",
              "  'Segmentation of Discrete Vector Fields.[SEP]In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement',\n",
              "  'PLIC: Briding the Gap Between Streamlines and LIC.[SEP]This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.',\n",
              "  'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow.[SEP]Numerical simulation of scramjet asymmetric nozzle flow is carried out to visualize and investigate the effects of interaction between engine exhaust and hypersonic external flow. The Single Expansion Ramp Nozzle (SERN) configuration studied here consists of flat ramp and a cowl with different combinations of ramp angle and cowl geometry. UsingPARAS 3D, simulations are performed for a free stream Mach number of 6.5 that constitutes the external flow around the vehicle. Appropriate specific heats ratio has been simulated for the jet and free stream flow. External shock wave due to jet plume interaction with free stream flow, the internal barrel shock wave and the shear layer emanating from the cowl trailing edge and sidewalls are well captured. Wall static pressure distribution on the nozzle ramp for different nozzle expansion angles has been computed for both with and without side fence. Axial thrust and normal force have been evaluated by integrating the wall static pressure. Effect of cowl length variation and side fence on the SERN performance has also been studied and found to be quite significant. Based on this study, an optimum ramp angle at which the SERN generates maximum axial thrust is obtained. SERN angle of 20° was found to be optimum when the flight axis coincides with nozzle axis.',\n",
              "  'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump.[SEP]Comparison between numerical simulation and experimental results for unsteady flow field in a radial diffuser pump is presented for the design operating point. The numerical result is obtained by solving three-dimensional, unsteady Reynolds-averaged Navier-Stokes equations by the commercial CFD code CFX-10 withk-ω based shear stress transport turbulence model. Two-dimensional PIV measurements are conducted to acquire the experiment result. The phase-averaged velocity and turbulent kinetic energy fields are compared in detail between the results by the two methods in the impeller, diffuser and return channel regions. The qualitative comparison between CFD and PIV results is quite good in the phase-averaged velocity field. Although the turbulence level by PIV is higher than that by CFD generally, the main turbulence features are nearly the same. Furthermore, the blade orientation effect and other associated unsteady phenomena are also examined, in order to enhance the understanding on impeller-diffuser interaction in a radial diffuser pump.',\n",
              "  'Characteristic flow phenomena on a tee-branch pipe.[SEP]Osao, A. et al., Advanced Materials Research, 33-37 (2008), 1037–1042.'],\n",
              " '100_terrain_rendering_terrains_resolution': ['Stereoscopic View-Dependent Visualization of Terrain Height Fields.[SEP]Visualization of large geometric environments has always been an important problem of computer graphics. We present a framework for the stereoscopic view-dependent visualization of large scale terrain models. We use a quadtree based multiresolution representation for the terrain data. This structure is queried to obtain the view-dependent approximations of the terrain model at different levels of detail. In order not to lose depth information, which is crucial for the stereoscopic visualization, we make use of a different simplification criterion, namely, distance-based angular error threshold. We also present an algorithm for the construction of stereo pairs in order to speed up the view-dependent stereoscopic visualization. The approach we use is the simultaneous generation of the triangles for two stereo images using a single draw-list so that the view frustum culling and vertex activation is done only once for each frame. The cracking problem is solved using the dependency information stored for each vertex. We eliminate the popping artifacts that can occur while switching between different resolutions of the data using morphing. We implemented the proposed algorithms on personal computers and graphics workstations. Performance experiments show that the second eye image can be produced approximately 45 percent faster than drawing the two images separately and a smooth stereoscopic visualization can be achieved at interactive frame rates using continuous multiresolution representation of height fields.',\n",
              "  'LOD-Sprite Technique for Accelerated Terrain Rendering.[SEP]We present a new rendering technique, termed LOD-sprite rendering, which uses a combination of a level-of-detail (LOD) representation of the scene together with reusing image sprites (previously rendered images). Our primary application is accelerating terrain rendering. The LOD-sprite technique renders an initial frame using a high-resolution model of the scene geometry. It renders subsequent frames with a much lower-resolution model of the scene geometry and texture-maps each polygon with the image sprite from the initial high-resolution frame. As it renders these subsequent frames the technique measures the error associated with the divergence of the view position from the position where the initial frame was rendered. Once this error exceeds a user-defined threshold, the technique re-renders the scene from the high-resolution model. We have efficiently implemented the LOD-sprite technique with texture-mapping graphics hardware. Although to date we have only applied LOD-sprite to terrain rendering, it could easily be extended to other applications. We feel LOD-sprite holds particular promise for real-time rendering systems.',\n",
              "  'Interactive Terrain Rendering van Volume Visualization on the Princeton Engine.[SEP]The implementation of truly interactive volume visualization and terrain rendering algorithms on the Princeton Engine (PE) video supercomputer is described. The PE is a single-instruction multiple-data (SIMD) computer. Since it was originally developed as a real-time digital television system simulator, it possesses many of the attributes necessary for interactive visualization: high-resolution displays, high-bandwidth I/O, supercomputer class computational performance, and a local memory array large enough to store multiple Landsat scenes and data volumes. It is shown that it is possible to generate truly interactive terrain rendering and volume visualization by computing images in real-time, at multiple frames/second.< >'],\n",
              " '101_stream_drift_ensemble_drifting': ['Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift.[SEP]Algorithms for tracking concept drift are important for many applications. We present a general method based on the weighted majority algorithm for using any online learner for concept drift. Dynamic weighted majority (DWM) maintains an ensemble of base learners, predicts using a weighted-majority vote of these \"experts\", and dynamically creates and deletes experts in response to changes in performance. We empirically evaluated two experimental systems based on the method using incremental naive Bayes and incremental tree inducer [ITI] as experts. For the sake of comparison, we also included Blum\\'s implementation of weighted majority. On the STAGGER concepts and on the SEA concepts, results suggest that the ensemble method learns drifting concepts almost as well as the base algorithms learn each concept individually. Indeed, we report the best overall results for these problems to date.',\n",
              "  'Polishing the Right Apple: Anytime Classification Also Benefits Data Streams with Constant Arrival Times.[SEP]Classification of items taken from data streams requires algorithms that operate in time sensitive and computationally constrained environments. Often, the available time for classification is not known a priori and may change as a consequence of external circumstances. Many traditional algorithms are unable to provide satisfactory performance while supporting the highly variable response times that exemplify such applications. In such contexts, anytime algorithms, which are amenable to trading time for accuracy, have been found to be exceptionally useful and constitute an area of increasing research activity. Previous techniques for improving anytime classification have generally been concerned with optimizing the probability of correctly classifying individual objects. However, as we shall see, serially optimizing the probability of correctly classifying individual objects K times, generally gives inferior results to batch optimizing the probability of correctly classifying K objects. In this work, we show that this simple observation can be exploited to improve overall classification performance by using an anytime framework to allocate resources among a set of objects buffered from a fast arriving stream. Our ideas are independent of object arrival behavior, and, perhaps unintuitively, even in data streams with constant arrival rates our technique exhibits a marked improvement in performance. The utility of our approach is demonstrated with extensive experimental evaluations conducted on a wide range of diverse datasets.',\n",
              "  'Detecting Recurring and Novel Classes in Concept-Drifting Data Streams.[SEP]Concept-evolution is one of the major challenges in data stream classification, which occurs when a new class evolves in the stream. This problem remains unaddressed by most state-of-the-art techniques. A recurring class is a special case of concept-evolution. This special case takes place when a class appears in the stream, then disappears for a long time, and again appears. Existing data stream classification techniques that address the concept-evolution problem, wrongly detect the recurring classes as novel class. This creates two main problems. First, much resource is wasted in detecting a recurring class as novel class, because novel class detection is much more computationally- and memory-intensive, as compared to simply recognizing an existing class. Second, when a novel class is identified, human experts are involved in collecting and labeling the instances of that class for future modeling. If a recurrent class is reported as novel class, it will be only a waste of human effort to find out whether it is really a novel class. In this paper, we address the recurring issue, and propose a more realistic novel class detection technique, which remembers a class and identifies it as \"not novel\" when it reappears after a long disappearance. Our approach has shown significant reduction in classification error over state-of-the-art stream classification techniques on several benchmark data streams.'],\n",
              " '102_cartograms_map_maps_cartographic': [\"Generating Tile Maps.[SEP]Tile maps are an important tool in thematic cartography with distinct qualities (and limitations) that distinguish them from better‐known techniques such as choropleths, cartograms and symbol maps. Specifically, tile maps display geographic regions as a grid of identical tiles so large regions do not dominate the viewer's attention and small regions are easily seen. Furthermore, complex data such as time series can be shown on each tile in a consistent format, and the grid layout facilitates comparisons across tiles. Whilst a small number of handcrafted tile maps have become popular, the time‐consuming process of creating new tile maps limits their wider use. To address this issue, we present an algorithm that generates a tile map of the specified type (e.g. square, hexagon, triangle) from raw shape data. Since the ‘best’ tile map depends on the specific geography visualized and the task to be performed, the algorithm generates and ranks multiple tile maps and allows the user to choose the most appropriate. The approach is demonstrated on a range of examples using a prototype browser‐based application.\",\n",
              "  'A prototype Spatial Data Management System.[SEP]Spatial Data Management is a technique for organizing and retrieving information by positioning it in a spatial framework. Data is accessed in a Spatial Data Management System (SDMS) via pictorial representations which are arranged in space and viewed through a computer graphics system. These pictures can be created by an interactive graphical editor, allowing an SDMS to serve as a personal repository of diagrams, text, and photographs. Pictograms can also be generated from data in a symbolic database management system, allowing SDMS to be used as an interface to large, shared databases.',\n",
              "  'A fast and economic scan-to-line-conversion algorithm.[SEP]In order to generate cartographic data bases, it is necessary to digitize a large number of existing base maps. One way of replacing the error-prone and very time-consuming manual digitization by an automatic method is scanning the map and extracting the linework from the resulting binary matrix. A sufficiently fast and economic scan-to-line-conversion algorithm has to be developed for the line extraction.'],\n",
              " '103_design_clothing_clothes_designers': [\"From codes to patterns: designing interactive decoration for tableware.[SEP]We explore the idea of making aesthetic decorative patterns that contain multiple visual codes. We chart an iterative collaboration with ceramic designers and a restaurant to refine a recognition technology to work reliably on ceramics, produce a pattern book of designs, and prototype sets of tableware and a mobile app to enhance a dining experience. We document how the designers learned to work with and creatively exploit the technology, enriching their patterns with embellishments and backgrounds and developing strategies for embedding codes into complex designs. We discuss the potential and challenges of interacting with such patterns. We argue for a transition from designing 'codes to patterns' that reflects the skills of designers alongside the development of new technologies.\",\n",
              "  \"Bod-IDE: An Augmented Reality Sandbox for eFashion Garments.[SEP]Electronic fashion (eFashion) garments use technology to augment the human body with wearable interaction. In developing ideas, eFashion designers need to prototype the role and behavior of the interactive garment in context; however, current wearable prototyping toolkits require semi-permanent construction with physical materials that cannot easily be altered. We present Bod-IDE, an augmented reality 'mirror' that allows eFashion designers to create virtual interactive garment prototypes. Designers can quickly build, refine, and test on-the-body interactions without the need to connect or program electronics. By envisioning interaction with the body in mind, eFashion designers can focus more on reimagining the relationship between bodies, clothing, and technology.\",\n",
              "  \"What if HCI Becomes a Fashion Driven Discipline?[SEP]Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers' thinking and practices throughout the design process. In this note, we draw our insights from fashion related research within HCI and interaction design, provide some observations about fashion-related design and research practices, raise questions about our field as moving forward towards fashion driven discipline.\"],\n",
              " '104_skeleton_skeletons_segmentation_mesh': ['Analytic Curve Skeletons for 3D Surface Modeling and Processing.[SEP]We present a new curve skeleton model designed for surface modeling and processing. This skeleton is defined as the geometrical integration of a piecewise harmonic parameterization defined over a disk‐cylinder surface decomposition. This decomposition is computed using a progressive Region Graph reduction based on both geometric and topological criteria which can be iteratively optimized to improve region boundaries. The skeleton has an analytical form with regularity inherited from the surface one. Such a form offers well‐defined surface‐skeleton and skeleton‐surface projections. The resulting skeleton satisfies quality criteria which are relevant for skeleton‐based modeling and processing. We propose applications that benefit from our skeleton model, including local thickness editing, inset surface creation for shell mapping, as well as a new mid‐scale feature preserving smoothing.',\n",
              "  'One-step Compact Skeletonization.[SEP]Computing a skeleton for a discretized boundary typically produces a noisy output, with a skeletal branch produced for each boundary pixel. A simplification step often follows to reduce these noisy branches. As a result, generating a clean skeleton is usually a 2-step process. In this article, we propose a skeletonization process that produces a clean skeleton in the first step, avoiding the creation of branches due to noise. The resulting skeleton compares favorably with the most common pruning methods on a large database of shapes. Our process also reduces execution time and requires only one parameter, e, that designates the desired boundary precision in the Hausdorff distance.',\n",
              "  'Skeleton computation of orthogonal polyhedra.[SEP]Skeletons are powerful geometric abstractions that provide useful representations for a number of geometric operations. The straight skeleton has a lower combinatorial complexity compared with the medial axis. Moreover, while the medial axis of a polyhedron is composed of quadric surfaces the straight skeleton just consist of planar faces. Although there exist several methods to compute the straight skeleton of a polygon, the straight skeleton of polyhedra has been paid much less attention. We require to compute the skeleton of very large datasets storing orthogonal polyhedra. Furthermore, we need to treat geometric degeneracies that usually arise when dealing with orthogonal polyhedra. We present a new approach so as to robustly compute the straight skeleton of orthogonal polyhedra. We follow a geometric technique that works directly with the boundary of an orthogonal polyhedron. Our approach is output sensitive with respect to the number of vertices of the skeleton and solves geometric degeneracies. Unlike the existing straight skeleton algorithms that shrink the object boundary to obtain the skeleton, our algorithm relies on the plane sweep paradigm. The resulting skeleton is only composed of axis‐aligned and 45° rotated planar faces and edges.'],\n",
              " '105_matrix_factorization_nonnegative_matrices': ['Unified Solution to Nonnegative Data Factorization Problems.[SEP]In this paper, we restudy the non-convex data factorization problems (regularized or not, unsupervised or supervised), where the optimization is confined in the nonnegative orthant, and provide a unified convergency provable solution based on multiplicative nonnegative update rules. This solution is general for optimization problems with block-wisely quadratic objective functions, and thus direct update rules can be derived by skipping over the tedious specific procedure deduction process and algorithmic convergence proof. By taking this unified solution as a general template, we i) re-explain several existing nonnegative data factorization algorithms, ii) develop a variant of nonnegative matrix factorization formulation for handling out-of-sample data, and Hi) propose a new nonnegative data factorization algorithm, called correlated co-decomposition (CCD), to simultaneously factorize two feature spaces by exploring the inter-correlated information. Experiments on both face recognition and multi-label image annotation tasks demonstrate the wide applicability of the unified solution as well as the effectiveness of two proposed new algorithms.',\n",
              "  'Multiplicative Algorithms for Constrained Non-negative Matrix Factorization.[SEP]Non-negative matrix factorization (NMF) provides the advantage of parts-based data representation through additive only combinations. It has been widely adopted in areas like item recommending, text mining, data clustering, speech denoising, etc. In this paper, we provide an algorithm that allows the factorization to have linear or approximately linear constraints with respect to each factor. We prove that if the constraint function is linear, algorithms within our multiplicative framework will converge. This theory supports a large variety of equality and inequality constraints, and can facilitate application of NMF to a much larger domain. Taking the recommender system as an example, we demonstrate how a specialized weighted and constrained NMF algorithm can be developed to fit exactly for the problem, and the tests justify that our constraints improve the performance for both weighted and unweighted NMF algorithms under several different metrics. In particular, on the Movie lens data with 94% of items, the Constrained NMF improves recall rate 3% compared to SVD50 and 45% compared to SVD150, which were reported as the best two in the top-N metric.',\n",
              "  'Recovering Low-Rank and Sparse Matrices via Robust Bilateral Factorization.[SEP]Recovering low-rank and sparse matrices from partial, incomplete or corrupted observations is an important problem in many areas of science and engineering. In this paper, we propose a scalable robust bilateral factorization (RBF) method to recover both structured matrices from missing and grossly corrupted data such as robust matrix completion (RMC), or incomplete and grossly corrupted measurements such as compressive principal component pursuit (CPCP). With the unified framework, we first present two robust trace norm regularized bilateral factorization models for RMC and CPCP problems, which can achieve an orthogonal dictionary and a robust data representation, simultaneously. Then, we apply the alternating direction method of multipliers to efficiently solve the RMC problems. Finally, we provide the convergence analysis of our algorithm, and extend it to address general CPCP problems. Experimental results verified both the efficiency and effectiveness of our RBF method compared with the state-of-the-art methods.'],\n",
              " '106_parallel_compiler_cache_parallelism': ['Speculative Execution and Branch Prediction on Parallel Machines.[SEP]Several recent studies on the limits of parallelism have reported that speculative execution can substantially increase the amount of exploitable parallelism in programs, especially non-numerical programs. This is true even for parallel machines models which allow multiple flows of control. However, most architectural techniques for speculation and branch prediction are geared toward conventional computers with a single flow of control, and little has been done in studying speculation models and techniques for parallel machines with multiple threads of control.',\n",
              "  'A Massively Parallel Optimizer for Expression Evaluation.[SEP]A number of “tricks” are known that trade multiplications for additions. The term “tricks” reflects the way these methods seem not to proceed from any general theory, but instead jump into existence as recipes that work. The Strassen method for 2 by 2 matrix product with 7 multiplications is a well-known example, as is the method for finding a complex number product in 3 multiplications. We have created a practical computer program for finding such tricks automatically, where massive parallelism makes the combinatorially explosive search tolerable for small problems. One result of this program is a method for computing cross products of 3-vectors using only 5 multiplications.',\n",
              "  \"Design considerations for parallel performance tools.[SEP]In recent years there has been a shift in microprocessor manufacture from building single-core processors towards providing multiple cores on the same chip. This shift has meant that a much wider population of developers are faced with the task of developing parallel software: a difficult, time consuming and expensive process. With the aim of identifying issues, emerging practices and design opportunities for support, we present in this paper a qualitative study in which we interviewed a range of software developers, in both industry and academia. We then perform a systematic analysis of the data and identify several cross-cutting themes. These analysis themes include the practical relevance of the probe effect, the significance of orchestration models in development and the mismatch between currently available tools and developers' needs. We also identify an important characteristic of parallel programming, where the process of optimisation goes hand in hand with the process of debugging, as opposed to clearer distinctions which may be made in traditional programming. We conclude with reflection on how the study can inform the design of software tools to support developers in the endeavour of parallel programming.\"],\n",
              " '107_event_events_sentinel_ranking': [\"Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization.[SEP]Event sequence data is common in many domains, ranging from electronic medical records (EMRs) to sports events. Moreover, such sequences often result in measurable outcomes (e.g., life or death, win or loss). Collections of event sequences can be aggregated together to form event progression pathways. These pathways can then be connected with outcomes to model how alternative chains of events may lead to different results. This paper describes the Outflow visualization technique, designed to (1) aggregate multiple event sequences, (2) display the aggregate pathways through different event states with timing and cardinality, (3) summarize the pathways' corresponding outcomes, and (4) allow users to explore external factors that correlate with specific pathway state transitions. Results from a user study with twelve participants show that users were able to learn how to use Outflow easily with limited training and perform a range of tasks both accurately and rapidly.\",\n",
              "  'Life on the Line: Interacting with Temporal Event Sequence Representations.[SEP]Sequences of events are part of people’s life, their travel, hospital visits, even web browsing experiences. Analysing collections of event sequences can be challenging even for skilled computer professionals. We will review a series of visualization techniques developed at the Human-Computer Interaction lab to handle temporal data.',\n",
              "  'Evaluating Alignment Approaches in Superimposed Time-Series and Temporal Event-Sequence Visualizations.[SEP]Composite temporal event sequence visualizations have included sentinel event alignment techniques to cope with data volume and variety. Prior work has demonstrated the utility of using single-event alignment for understanding the precursor, co-occurring, and aftereffect events surrounding a sentinel event. However, the usefulness of single-event alignment has not been sufficiently evaluated in composite visualizations. Furthermore, recently proposed dual-event alignment techniques have not been empirically evaluated. In this work, we designed tasks around temporal event sequence and timing analysis and conducted a controlled experiment on Amazon Mechanical Turk to examine four sentinel event alignment approaches: no sentinel event alignment (NoAlign), single-event alignment (SingleAlign), dual-event alignment with left justification (DualLeft), and dual-event alignment with stretch justification (DualStretch). Differences between approaches were most pronounced with more rows of data. For understanding intermediate events between two sentinel events, dual-event alignment was the clear winner for correctness-71% vs. 18% for NoAlign and SingleAlign. For understanding the duration between two sentinel events, NoAlign was the clear winner: correctness-88% vs. 36% for DualStretch- completion time-55 seconds vs. 101 seconds for DualLeft-and error-1.5% vs. 8.4% for DualStretch. For understanding precursor and aftereffect events, there was no significant difference among approaches. A free copy of this paper, the evaluation stimuli and data, and source code are available at osf.io/78fs5'],\n",
              " '108_wavelet_wavelets_multiresolution_subdivision': ['Biorthogonal wavelet construction for hybrid quad/triangle meshes.[SEP]Ever since its introduction by Stam and Loop, the quad/triangle subdivision scheme, which is a generalization of the well-known Catmull–Clark subdivision and Loop subdivision, has attracted a great deal of interest due to its flexibility of allowing both quads and triangles in the same model. In this paper, we present a novel biorthogonal wavelet—constructed through the lifting scheme—that accommodates the quad/triangle subdivision. The introduced wavelet smoothly unifies the Catmull–Clark subdivision wavelet (for quadrilateral meshes) and the Loop subdivision wavelet (for triangular meshes) in a single framework. It can be used to flexibly and efficiently process any complicated semi-regular hybrid meshes containing both quadrilateral and triangular regions. Because the analysis and synthesis algorithms of the wavelet are composed of only local lifting operations allowing fully in-place calculations, they can be performed in linear time. The experiments demonstrate sufficient stability and fine fitting quality of the presented wavelet, which are similar to those of the Catmull–Clark subdivision wavelet and the Loop subdivision wavelet. The wavelet analysis can be used in various applications, such as shape approximation, progressive transmission, data compression and multiresolution edit of complex models.',\n",
              "  'Graph-Based Wavelet Representation of Multi-Variate Terrain Data.[SEP]Terrain data can be processed from the double perspective of computer graphics and graph theory. We propose a hybrid method that uses geometrical and vertex attribute information to construct a weighted graph reflecting the variability of the vertex data. As a planar graph, a generic terrain data set is subjected to a geometry‐sensitive vertex partitioning procedure. Through the use of a combined, thin‐plate energy and multi‐dimensional quadric metric error, feature estimation heuristic, we construct ‘even’ and ‘odd’ node subsets. Using an invertible lifting scheme, adapted from generic weighted graphs, detail vectors are extracted and used to recover or filter the node information. The design of the prediction and update filters improves the root mean squared error of the signal over general graph‐based approaches. As a key property of this design, preserving the mean of the graph signal becomes essential for decreasing the error measure and conserving the salient shape features.',\n",
              "  'Multiresolution Analysis on Irregular Surface Meshes.[SEP]Wavelet-based methods have proven their efficiency for visualization at different levels of detail, progressive transmission, and compression of large data sets. The required core of all wavelet-based methods is a hierarchy of meshes that satisfies subdivision-connectivity. This hierarchy has to be the result of a subdivision process starting from a base mesh. Examples include quadtree uniform 2D meshes, octree uniform 3D meshes, or 4-to-1 split triangular meshes. In particular, the necessity of subdivision-connectivity prevents the application of wavelet-based methods on irregular triangular meshes. In this paper, a \"wavelet-like\" decomposition is introduced that works on piecewise constant data sets over irregular triangular surface meshes. The decomposition/reconstruction algorithms are based on an extension of wavelet-theory allowing hierarchical meshes without property. Among others, this approach has the following features: it allows exact reconstruction of the data set, even for nonregular triangulations, and it extends previous results on Haar-wavelets over 4-to-1 split triangulations.'],\n",
              " '109_children_participatory_child_technologies': ['Child-personas: fact or fiction?[SEP]This paper introduces a practice-based, child-centric method of creating child-user archetypes which extends adult-based persona theory to interaction design with children. Persona construction can help interaction designers better understand real child-users and result in rich child-user archetypes which are developmentally situated and contextually valid. Key differences between adult-personas and child-personas are highlighted. A description of an online mentoring application created for CBC4Kids.ca illustrates the value of child-personas in design practice.',\n",
              "  \"Children and 'smart' technologies: can children's experiences be interpreted and coded?[SEP]This paper has a focus on young children and their emerging new technologies. It examines children's drawings as an evaluation tool for capturing their experiences of different novel interfaces.\",\n",
              "  \"Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding.[SEP]In this case study, we describe a design workshop with 7 children age 4-6 using existing co-design techniques known to elicit design insights in older individuals. We found that our 5- and 6-year-old participants successfully generated design ideas using these methods, while 4-year-olds were unable to use create solutions in a traditional format. How-ever, these younger children enthusiastically offered opportunities where, with methodological guidance, the research-er could have followed the child's lead and shifted the design question to one that was potentially more meaningful for the participant. We propose a future work to examine the effectiveness of giving these younger participants great-er authority in defining and scoping the problem space.\"],\n",
              " '10_motion_animation_motions_animations': ['Real time animation of dynamic processes.[SEP]Animation and simulation processes are facilitated by the use of high level graphic languages. The results of these processes are not generally available in real time, developing of microfilm delaying the screening of the process until some time after the computer run.A technique is described which overcomes this problem whilst still allowing the use of a high level graphical language.The addition of a single feature to a \"static\" graphical language has transformed it into a \"dynamic\" graphical language allowing real time illustration of time varying processes.The technique is not restricted to the language described but may well be employed by other high level graphical languages.',\n",
              "  'Real time falling animation with active and protective responses.[SEP]Combined with motion capture and dynamic simulation, characters in animation have realistic motion details and can respond to unexpected contact forces. This paper proposes a novel and real-time character motion generation approach which introduces a parallel process, and uses an approximate nearest neighbor optimization search method. Besides, we employ a support vector machine (SVM), which is trained on a set of samples and predicts a subset of our ‘return-to’ motion capture (mocap) database in order to reduce the search time. In the dynamic simulation process, we focus on designing a biomechanics based controller which detects the balance of the characters in locomotion and drives them to take several active and protective responses when they fall to the ground in order to reduce the injuries to their bodies. Finally, we show the time costs in synthesis and the visual results of our approach. The experimental results indicate that our motion generation approach is suitable for interactive games or other real-time applications.',\n",
              "  'A system for algorithm animation.[SEP]A software environment is described which provides facilities at a variety of levels for “animating” algorithms: exposing properties of programs by displaying multiple dynamic views of the program and associated data structures. The system is operational on a network of graphics-based, personal workstations and has been used successfully in several applications for teaching and research in computer science and mathematics. In this paper, we outline the conceptual framework that we have developed for animating algorithms, describe the system that we have implemented, and give several examples drawn from the host of algorithms that we have animated.'],\n",
              " '110_tabletop_collaboration_touch_groupware': [\"Evaluating the effectiveness of height visualizations for improving gestural communication at distributed tabletops.[SEP]In co-located collaboration, people use the space above the table for deictic gestures, and height is an important part of these gestures. However, when collaborators work at distributed tables, we know little about how to convey information about gesture height. A few visualizations have been proposed, but these have not been evaluated in detail. To better understand how remote embodiments can show gesture height, we developed several visualizations and evaluated them in three studies. First, we show that touch visualizations significantly improve people's accuracy in identifying the type and target of a gesture. Second, we show that visualizations of height above the table help to convey gesture qualities such as confidence, emphasis, and specificity. Third, we show that people quickly make use of height visualizations in realistic collaborative tasks, and that height-enhanced embodiments are strongly preferred. Our work illustrates several designs for effective visualization of height, and provides the first comprehensive evidence of the value of height information as a way to improve gestural communication in distributed tabletop groupware.\",\n",
              "  \"Making big gestures: effects of gesture size on observability and identification for co-located group awareness.[SEP]Co-located work environments allow people to maintain awareness by observing others' actions (called consequen-tial communication), but the computerization of many tasks has dramatically reduced the observability of work actions. The recent interest in gestural interaction techniques offers the possibility of recreating some of the noticeability of previous work actions, but little is known about the observability and identifiability of command gestures. To investigate these basic issues, we carried out a study that asked people to observe and identify different sizes and morphologies of gestures from different locations, while carrying out an attention-demanding primary task. We studied small (tablet sized), medium (monitor-sized), and large (full-arm) gestures. Our study showed that although size did have significant effects, as expected, even small gestures were highly noticeable (rates above 75%) and identifiable (rates above 69%). Our results provide empirical guidance about the ways that gesture size, morphology, and location affect observation, and show that gestural interaction has potential for improving group awareness in co-located environments.\",\n",
              "  'Exploring the effects of group size and table size on interactions with tabletop shared-display groupware.[SEP]Interactive tabletops have been previously proposed and studied in the domain of co-located group applications. However, little fundamental research has been done to explore the issue of size. In this paper we identify a number of size considerations for tabletop design, and present an experiment to explore some of these issues, in particular the effects of group size and table size on the speed at which the task was performed, the distribution of work among group members, issues of shared resources, and user preference for table size. Our findings shed light on (1) how work strategies are affected by group size, (2) how social interaction varies with respect to table size, and (3) how the speed of task performance is influenced by group size but not by table size. In addition, our experiments revealed that for larger groups, designers might need to add additional vertical displays for shared information. This finding opens the door for extending single-display groupware to shared-display groupware settings that involve multiple, shared displays.'],\n",
              " '111_collision_collisions_deformable_rigid': ['Interactive continuous collision detection for non-convex polyhedra.[SEP]We present a highly interactive, continuous collision detection algorithm for rigid, general polyhedra. Given initial and final configurations of a moving polyhedral model, our algorithm creates a continuous motion with constant translational and angular velocities, thereby interpolating the initial and final configurations of the model. Then, our algorithm reports whether the model under the interpolated motion collides with other rigid polyhedral models in environments, and if it does, the algorithm reports its first time of contact (TOC) with the environment as well as its associated contact features at TOC.',\n",
              "  'A Collision Detection and Response Scheme for Simplified Physically Based Animation.[SEP]In this paper we describe a system for physical animation of rigid and deformable objects. These are represented as groups of particles linked by linear constraints, while a Verlet integrator is used for motion computation. Unlike traditional approaches, we accomplish physical simulation without explicitly computing orientation matrices, torques or inertia tensors. The main contribution of our work is related to the way collisions are handled by the system, which employs different approaches for deformable and rigid bodies. In particular, we show how collision detection using the GJK algorithm [9] and bounding sphere hierarchies can be combined with the projection based collision response technique described by Jakobsen [14].',\n",
              "  'Continuous collision detection for deformable objects using permissible clusters.[SEP]In this paper, we propose a new data structure to perform continuous collision detection (CCD) for deformable triangular meshes. The critical component of this data structure is permissible clusters. At the preprocessing phase, the triangular meshes are divided into permissible clusters. Then, the features of the triangular meshes are assigned to the permissible clusters. At the runtime phase, the potentially colliding feature pairs are collected and they are processed only once in the elementary processing. Our method has been integrated with a normal cone-based method and compared with other CCD methods. Experimental results show that our method improves the overall performance of CCD for deformable objects.'],\n",
              " '112_chatbot_chatbots_chat_conversation': ['Adding structured data in unstructured web chat conversation.[SEP]Web chat is becoming the primary customer contact channel in customer relationship management (CRM), and Question/Answer/Lookup (QAL) is the dominant communication pattern in CRM agent-to-customer chat. Text-based web chat for QAL has two main usability problems. Chat transcripts between agents and customers are not tightly integrated into agent-side applications, requiring customer service agents to re-enter customer typed data. Also, sensitive information posted in chat sessions in plain text raises security concerns. The addition of web form widgets to web chat not only solves both of these problems but also adds new usability benefits to QAL. Forms can be defined beforehand or, more flexibly, dynamically composed. Two preliminary user studies were conducted. An agent-side study showed that adding inline forms to web chat decreased overall QAL completion time by 47 percent and increased QAL accuracy by removing all potential human errors. A customer-side study showed that web chat with inline forms is intuitive to customers.',\n",
              "  \"Transformation through Provocation?[SEP]Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e.g. death, wealth distribution, gender equality, privacy) and, ultimately, soliciting specific actions from the user it converses with. We instantiate our design with a use case in the cultural sector, specifically a Neolithic archaeological site that acts as a stage of conversation on such hard themes. Our larger contributions include an interaction framework for bots of conviction, insights gained from an iterative process of participatory design and evaluation, and a vision for bot interaction mechanisms that can apply to the HCI community more widely.\",\n",
              "  \"A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot.[SEP]Task-oriented chatbots are becoming popular alternatives for fulfilling users' needs, but few studies have investigated how users cope with conversational 'non-progress' (NP) in their daily lives. Accordingly, we analyzed a three-month conversation log between 1,685 users and a task-oriented banking chatbot. In this data, we observed 12 types of conversational NP; five types of content that was unexpected and challenging for the chatbot to recognize; and 10 types of coping strategies. Moreover, we identified specific relationships between NP types and strategies, as well as signs that users were about to abandon the chatbot, including 1) three consecutive incidences of NP, 2) consecutive use of message reformulation or switching subjects, and 3) using message reformulation as the final strategy. Based on these findings, we provide design recommendations for task-oriented chatbots, aimed at reducing NP, guiding users through such NP, and improving user experiences to reduce the cessation of chatbot use.\"],\n",
              " '113_hair_hairs_cloth_hairstyles': ['3D Hair sketching for real-time dynamic  key frame animations.[SEP]Physically based simulation of human hair is a well studied and well known problem. But the “pure” physically based representation of hair (and other animation elements) is not the only concern of the animators, who want to “control” the creation and animation phases of the content. This paper describes a sketch-based tool, with which a user can both create hair models with different styling parameters and produce animations of these created hair models using physically and key frame-based techniques. The model creation and animation production tasks are all performed with direct manipulation techniques in real-time.',\n",
              "  'Hybrid fur rendering: combining volumetric fur with explicit hair strands.[SEP]Hair is typically modeled and rendered using either explicitly defined hair strand geometry or a volume texture of hair densities. Taken each on their own, these two hair representations have difficulties in the case of animal fur as it consists of very dense and thin undercoat hairs in combination with coarse guard hairs. Explicit hair strand geometry is not well-suited for the undercoat hairs, while volume textures are not well-suited for the guard hairs. To efficiently model and render both guard hairs and undercoat hairs, we present a hybrid technique that combines rasterization of explicitly defined guard hairs with ray marching of a prismatic shell volume with dynamic resolution. The latter is the key to practical combination of the two techniques, and it also enables a high degree of detail in the undercoat. We demonstrate that our hybrid technique creates a more detailed and soft fur appearance as compared with renderings that only use explicitly defined hair strands. Finally, our rasterization approach is based on order-independent transparency and renders high-quality fur images in seconds.',\n",
              "  \"Modeling Dynamic Hair as a Continuum.[SEP]In this paper we address the difficult problem of hair dynamics, particularly hair‐hair and hair‐air interactions. To model these interactions, we propose to consider hair volume as a continuum. Subsequently, we treat the interaction dynamics to be fluid dynamics. This proves to be a strong as well as viable approach for an otherwise very complex phenomenon. However, we retain the individual character of hair, which is vital to visually realistic rendering of hair animation. For that, we develop an elaborate model for stiffness and inertial dynamics of individual hair strand. Being a reduced coordinate formulation, the stiffness dynamics is numerically stable and fast. We then unify the continuum interaction dynamics and the individual hair's stiffness dynamics.\"],\n",
              " '114_watermarking_watermark_watermarks_attacks': ['Secure Authentication Watermarking for Binary Images.[SEP]Authentication watermarking is a hidden data inserted into an image, in order to detect any alterations. It seems to be almost impossible to design a really secure authentication watermarking without making use of the solid cryptography theory and techniques. In a cryptography-based authentication watermarking, a message authentication code (or digital signature) of the whole image is computed and the resulting code is inserted into the image itself. However, inserting the code alters the image and consequently its authentication code, invalidating the watermark. To avoid this problem, for gray-scale or color image, usually the least significant bits (LSBs) are cleared, the authentication code of the LSB-cleared image is computed and then the code is inserted into LSBs. Surely, one cannot perform the same procedure for binary images. We propose a quite simple solution for inserting a secure authentication watermarking in dispersed-dot halftone images. This technique can also be applied to any kind of binary images (including clustered-dot halftones), though the visual quality is not as good as when applied to dispersed-dot halftones. The proposed technique can be used with both secret-key or public-key ciphers.',\n",
              "  'A new multi-secret image sharing scheme based on DCT.[SEP]Multi-secret image sharing scheme (MSIS) is a technique to share multiple secret images over the internet. Normally, most of the secret image sharing schemes can share only a single secret image. However, due to the rapid development of internet technology, the necessity of sharing multiple images arises. An (n, n) MSIS is employed to share n images to n authorized participants. All the n participants are required to submit their respective shares to recover the original secret images. If the number of the participants is less than n, then reconstruction of the secret images is impossible. Most of the existing schemes which are in the frequency domain do not have the capability to handle multiple secret images. In this paper, a MSIS that uses the Discrete Cosine Transform is proposed to overcome the limitation present in the existing schemes. Moreover, the proposed scheme requires less computational time than the existing schemes. Security of the proposed scheme is analyzed and shows that the proposed scheme is computationally secure. Also, the proposed scheme can recover the same original secret images.',\n",
              "  'Digital Watermarking: From Concepts to Real-Time Video Applications.[SEP]Digital watermarking has been increasingly applied to hide information in digital multimedia data, thus enlisting the watermarking technology in the difficult fight against intellectual property rights infringement. The authors have developed a secure, robust watermarking algorithm and applied it in digital streaming MPEG-2 format video-the format of choice in the broadcast and video stock industry.'],\n",
              " '115_surgical_surgery_laparoscopic_minimally': ['Keynote Speaker: Virtual Reality: Current Uses in Medical Simulation and Future.[SEP]Virtual reality has gone from research to educational tool to indispensible clinical application in patient care. A brief review of the current status of the use of VR in medicine will provide the springboard for the current gaps that provide future opportunities in simulation as well as an introduction to new advanced technologies that are revolutionizing medicine and which will require VR for educational and training support and clinical applications. Some topics for discussion are virtual patients, cadavers and autopsies, surgical rehearsal, robotic surgery, suspended animation, regeneration and tissue engineering. The challenge: how creatively can VR support these incredible new technologies? The grand challenge ñ how will 3-D stereolithography revolutionize the practice of medicine? Have you bought your Makerbot yet?',\n",
              "  'Evaluation of a tool-mounted guidance display for computer-assisted surgery.[SEP]We attached a small LCD display and video camera to a surgical drill. The LCD shows the tool position with respect to a planned trajectory, overlaid on video captured by the camera. We performed a user study to determine whether such a tool-mounted guidance display yields faster and more accurate tool placement than the conventional guidance display on a separate computer monitor. Our study showed that the tool-mounted display provides better positional and angular accuracy than the conventional display but that the video camera provides no significant improvement in error.',\n",
              "  'Modelling Techniques for Enhanced Realism in an Open Surgery Simulation.[SEP]This paper is a continuation of work originating from the simulation of Inguinal Hernia Repair. Whilst the majority of research in the medical simulation field is for minimally invasive techniques, the objective of our research is to develop a general framework for open surgery simulation. We focus here on the finer details of implementing such a simulator using advanced rendering techniques, collision detection and haptic feedback.'],\n",
              " '116_subspace_clustering_clusters_subspaces': ['Subspace Selection for Clustering High-Dimensional Data.[SEP]In high-dimensional feature spaces traditional clustering algorithms tend to break down in terms of efficiency and quality. Nevertheless, the data sets often contain clusters which are hidden in various subspaces of the original feature space. In this paper, we present a feature selection technique called SURFING (subspaces relevant for clustering) that finds all subspaces interesting for clustering and sorts them by relevance. The sorting is based on a quality criterion for the interestingness of a subspace using the k-nearest neighbor distances of the objects. As our method is more or less parameterless, it addresses the unsupervised notion of the data mining task \"clustering\" in a best possible way. A broad evaluation based on synthetic and real-world data sets demonstrates that SURFING is suitable to find all relevant sub-spaces in high dimensional, sparse data sets and produces better results than comparative methods.',\n",
              "  'Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering.[SEP]A novel approach to subspace clustering is proposed to exhaustively and efficiently mine quantitative frequent item-sets (QFIs) from massive transaction data. For the computational tractability, our approach introduces adaptive density-based and Apriori-like algorithm. Its outstanding performance is shown through numerical experiments.',\n",
              "  \"Effective and Robust Mining of Temporal Subspace Clusters.[SEP]Mining temporal multivariate data by clustering is an important research topic. In today's complex data, interesting patterns are often neither bound to the whole dimensional nor temporal extent of the data domain. This challenge is met by temporal subspace clustering methods. Their effectiveness, however, is impeded by aspects unavoidable in real world data: Misalignments between time series, for example caused by out-of-sync sensors, and measurement errors. Under these conditions, existing temporal subspace clustering approaches miss the patterns contained in the data. In this paper, we propose a novel clustering method that mines temporal subspace clusters reflected by sets of objects and relevant intervals. We enable flexible handling of misaligned time series by adaptively shifting time series in the time domain, and we achieve robustness to measurement errors by allowing certain fractions of deviating values in each relevant point in time. We show the effectiveness of our method in experiments on real and synthetic data.\"],\n",
              " '117_location_recommendation_friends_locations': [\"Towards social user profiling: unified and discriminative influence model for inferring home locations.[SEP]Users' locations are important to many applications such as targeted advertisement and news recommendation. In this paper, we focus on the problem of profiling users' home locations in the context of social network (Twitter). The problem is nontrivial, because signals, which may help to identify a user's location, are scarce and noisy. We propose a unified discriminative influence model, named as UDI, to solve the problem. To overcome the challenge of scarce signals, UDI integrates signals observed from both social network (friends) and user-centric data (tweets) in a unified probabilistic framework. To overcome the challenge of noisy signals, UDI captures how likely a user connects to a signal with respect to 1) the distance between the user and the signal, and 2) the influence scope of the signal. Based on the model, we develop local and global location prediction methods. The experiments on a large scale data set show that our methods improve the state-of-the-art methods by 13%, and achieve the best performance.\",\n",
              "  'Geo-activity recommendations by using improved feature combination.[SEP]In this paper, we propose a new model to integrate additional data, which is obtained from geospatial resources other than original data set in order to improve Location/Activity recommendations. The data set that is used in this work is a GPS trajectory of some users, which is gathered over 2 years. In order to have more accurate predictions and recommendations, we present a model that injects additional information to the main data set and we aim to apply a mathematical method on the merged data. On the merged data set, singular value decomposition technique is applied to extract latent relations. Several tests have been conducted, and the results of our proposed method are compared with a similar work for the same data set.',\n",
              "  \"Followee recommendation in asymmetrical location-based social networks.[SEP]Researches on recommending followees in social networks have attracted a lot of attentions in recent years. Existing studies on this topic mostly treat this kind of recommendation as just a type of friend recommendation. However, apart from making friends, the reason of a user to follow someone in social networks is inherently to satisfy his/her information needs in asymmetrical manner. In this paper, we propose a novel mining-based recommendation approach named Geographic-Textual-Social Based Followee Recommendation (GTS-FR), which takes into account the user movements, online texting and social properties to discover the relationship between users' information needs and provided information for followee recommendation. The core idea of our proposal is to discover users' similarity in terms of all the three properties of information which are provided by the users in a Location-Based Social Network (LBSN). To achieve this goal, we define three kinds of features to capture the key properties of users' interestingness from their provided information. In GTS-FR approach, we propose a series of novel similarity measurements to calculate similarity of each pair of users based on various properties. Based on the similarity, we make on-line recommendation for the followee a user might be interested in following. To our best knowledge, this is the first work on followee recommendation in LBSNs by exploring the geographic, textual and social properties simultaneously. Through a comprehensive evaluation using a real LBSN dataset, we show that the proposed GTS-FR approach delivers excellent performance and outperforms existing stat-of-the-art friend recommendation methods significantly.\"],\n",
              " '118_parents_parenting_child_life': ['Dealing with death in design: developing systems for the bereaved.[SEP]Increasingly, systems are being developed and used in ways that involve end of life issues such as death, dying, and bereavement. Yet design considerations and guidelines for technologists working in this sensitive area are not well-established. We therefore report on exploratory fieldwork consisting of focus groups, observations, and consultation with bereavement experts aimed at understanding how technology might be designed to support bereaved parents. From this fieldwork, we derive a set of considerations useful for researchers and designers developing systems that deal specifically with bereavement, and with the end of life more broadly. These considerations focus on interpersonal communication, new ways of being in the world, and materiality. We conclude with a distillation of these considerations into practical design guidelines for working in this area.',\n",
              "  \"Looking for Respite and Support: Technological Opportunities for Spousal Caregivers.[SEP]Our research aims at informing the design of technological solutions to alleviate the stress resulting from the involvement of spouses of Alzheimer's disease patients as caregivers. For so doing, we have observed and analyzed the different offline solutions that are offered by a healthcare network in the Aube region (North-East of France). We discuss the key factors that we have identified for building an effective support network and identify five perspectives for the development of an online social support platform to lower the burden of spousal caregivers.\",\n",
              "  \"Understanding technology choices and values through social class.[SEP]This ethnographic study of 22 diverse families in the San Francisco Bay Area provides a holistic account of parents' attitudes about their children's use of technology. We found that parents from different socioeconomic classes have different values and practices around technology use, and that those values and practices reflect structural differences in their everyday lives. Calling attention to class differences in technology use challenges the prevailing practice in human-computer interaction of designing for those similar to oneself, which often privileges middle-class values and practices. By discussing the differences between these two groups and the advantages of researching both, this research highlights the benefits of explicitly engaging with socioeconomic status as a category of analysis in design.\"],\n",
              " '119_location_privacy_crowdsensing_obfuscation': [\"Differential Location Privacy for Sparse Mobile Crowdsensing.[SEP]Sparse Mobile Crowdsensing (MCS) has become a compelling approach to acquire and make inference on urban-scale sensing data. However, participants risk their location privacy when reporting data with their actual sensing positions. To address this issue, we adopt e-differential-privacy in Sparse MCS to provide a theoretical guarantee for participants' location privacy regardless of an adversary's prior knowledge. Furthermore, to reduce the data quality loss caused by differential location obfuscation, we propose a privacypreserving framework with three components. First, we learn a data adjustment function to fit the original sensing data to the obfuscated location. Second, we apply a linear program to select an optimal location obfuscation function, which aims to minimize the uncertainty in data adjustment. We also propose a fast approximated variant. Third, we propose an uncertaintyaware inference algorithm to improve the inference accuracy of obfuscated data. Evaluations with real environment and traffic datasets show that our optimal method reduces the data quality loss by up to 42% compared to existing differential privacy methods.\",\n",
              "  'Secure and private proofs for location-based activity summaries in urban areas.[SEP]Activity-based social networks, where people upload and share information about their location-based activities (e.g., the routes of their activities), are increasingly popular. Such systems, however, raise privacy and security issues: The service providers know the exact locations of their users; the users can report fake location information in order to, for example, unduly brag about their performance. In this paper, we propose a secure privacy-preserving system for reporting location-based activity summaries (e.g., the total distance covered and the elevation gain). Our solution is based on a combination of cryptographic techniques and geometric algorithms, and it relies on existing Wi-Fi access-point networks deployed in urban areas. We evaluate our solution by using real data sets from the FON community networks and from the Garmin Connect activity-based social network, and we show that it can achieve tight (up to a median accuracy of 76%) verifiable lower-bounds of the distance covered and of the elevation gain, while protecting the location privacy of the users with respect to both the social network operator and the access-point network operator(s).',\n",
              "  'Active Sparse Mobile Crowd Sensing Based on Matrix Completion.[SEP]A major factor that prevents the large scale deployment of Mobile Crowd Sensing (MCS) is its sensing and communication cost. Given the spatio-temporal correlation among the environment monitoring data, matrix completion (MC) can be exploited to only monitor a small part of locations and time, and infer the remaining data. Rather than only taking random measurements following the basic MC theory, to further reduce the cost of MCS while ensuring the quality of missing data inference, we propose an Active Sparse MCS (AS-MCS) scheme which includes a bipartite-graph-based sensing scheduling scheme to actively determine the sampling positions in each upcoming time slot, and a bipartite-graph-based matrix completion algorithm to robustly and accurately recover the un-sampled data in the presence of sensing and communications errors. We also incorporate the sensing cost into the bipartite-graph to facilitate low cost sample selection and consider the incentives for MCS. We have conducted extensive performance studies using the data sets from the monitoring of PM 2.5 air condition and road traffic speed, respectively. Our results demonstrate that our AS-MCS scheme can recover the missing data at very high accuracy with the sampling ratio only around $11%$, while the peer matrix completion algorithms with similar recovery performance requires up to 4-9 times the number of samples of ours for both the data sets.'],\n",
              " '11_music_musical_voice_sound': ['Dogmas of Understanding in Western Art Music Performance.[SEP]This paper presents an exploration of the ontological shift from musical materials (i.e. melody, harmony, rhythm, texture, timbre, register) to activities in music performance analysis. The “dogmas” extend Herbert H. Clark’s conceptual framework for the study of joint activity in language use to explore music performance in the WAM tradition. A systematic analysis of London Symphony Orchestra masterclasses examines the basic mechanisms of music making in four main areas: representation, audience, interaction, and tacit knowledge. This exploration leads to a broader account of cognition and creativity in music performance, one that bridges inner and outer processes of awareness around domains of coordination in joint activities. In this view, material conceptualizations are viewed as targets of focal awareness rather than the basis for cognition in music making. This account, grounded in a rich third-person phenomenological analysis of instructional materials, paves the way for a “meaningful analytics” of musical practice.',\n",
              "  'Visualizing the Semantic Structure in Classical Music Works.[SEP]A major obstacle in the appreciation of classical music is that extensive training is required to understand musical structure and compositional techniques toward comprehending the thoughts behind the musical work. In this paper, we propose an innovative visualization solution to reveal the semantic structure in classical orchestral works such that users can gain insights into musical structure and appreciate the beauty of music. We formulate the semantic structure into macrolevel layer interactions, microlevel theme variations, and macro-micro relationships between themes and layers to abstract the complicated construction of a musical composition. The visualization has been applied with success in understanding some classical music works as supported by highly promising user study results with the general audience and very positive feedback from music students and experts, demonstrating its effectiveness in conveying the sophistication and beauty of classical music to novice users with informative and intuitive displays.',\n",
              "  'Entrain: Encouraging Social Interaction in Collective Music Making.[SEP]Entrain is an adaptive agent designed to stimulate social interaction among users in collective music making. It registers individual user behavior and provides sonic feedback to encourage users to look up from their mobiles and interact with each other. We demonstrate a use case of Entrain in Coloop, a distributed and collective musical instrument.',\n",
              "  'Short-term memory for tonal and verbal information: Comparison with absolute and non-absolute pitch possessors.[SEP]This study examined the difference in the storage of pitch and phonological information in absolute pitch (AP) and non-AP (NAP) possessors. In a recognition task using musical tones (pitch information), speech sounds (phonological information), and visual patterns, participants were asked to retain two stimulus sequences. In the same type condition, the nature of the first and second stimulus set was different (e.g., one sequence was musical tones and the other was speech sounds). In the different type condition, the nature of the two sequences was the same (e.g., both sequences were musical tones). We found that, in NAP possessors, the recognition rate of musical tones and speech sounds in the different type condition was higher than in the same type condition. In AP possessors, however, the recognition rate of musical tones revealed no difference between these two conditions. These results suggest the use of different strategy in retaining musical tones between AP and NAP possessors.',\n",
              "  'What We Move to Moves Us: Biological Rhythmicity Predicts Musical Preferences.[SEP]For at least 350 centuries, humans have invented music that offered special aesthetic appeal. Yet, the reasons for these preferences and effects are not understood. Here, we show that listeners prefer music with an underlying rhythmic structure that closely approximates our biological structure. Specifically, listeners preferred music with musical (rhythmic) structures that correspond to biological rhythmicity (motions). This finding, grounded in a straightforward biological framework, provided an intellectual advancement in the long history of thought and experimental work on the basis of musical preferences.',\n",
              "  'Embodying Theoretical Research in Music Cognition: Four Proposals for Theory-Driven Experimentation.[SEP]Research in the field of music cognition typically focuses either on low-level, technically oriented approaches or on highly abstract ontological discussions that lack direct grounding in evidence. To bridge this gap, we propose a revision of the ontology underlying such research, from a perspective restricted to the acoustic and individual aspects of music to an embodied, extended, and anti-individualist approach. We explore the application of these ideas to empirical research by discussing two experiments conducted by our group. One of them tests whether the ability to play an instrument has an influence in how a subject listens to music; the other one explores the impact of visual information in the perception of sound as music. We comment on the results obtained and its theoretical significance. Our work shows that it is possible for abstract theorizing and concrete experimentation to go hand in hand in the field of music studies.',\n",
              "  \"Using language complexity to measure cognitive load for adaptive interaction design.[SEP]An adaptive interaction system, which is aware of the users' current cognitive load, can change its response, presentation and interaction flow to improve users' experience and their task performance. In this paper, we propose a novel speech content analysis approach for measuring users' cognitive load, based on their language and dialogue complexity. We have analysed the transcribed speech of operators working in computerized incident control rooms and involved in highly complex bushfire management tasks in Australia. The resulting patterns of language complexity show significant differences between the speech from cognitively low load and high load tasks. We also discuss the value of using this approach of cognitive load measurement for user interface evaluation and interaction design improvement.\",\n",
              "  'The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives.[SEP]The widespread availability of broadband connections has led to an increase in the use of Internet broadcasting (webcasting). Most webcasts are archived and accessed numerous times retrospectively. In the absence of transcripts of what was said, users have difficulty searching and scanning for specific topics. This research investigates user needs for transcription accuracy in webcast archives, and measures how the quality of transcripts affects user performance in a question-answering task, and how quality affects overall user experience. We tested 48 subjects in a within-subjects design under 4 conditions: perfect transcripts, transcripts with 25% Word Error Rate (WER), transcripts with 45% WER, and no transcript. Our data reveals that speech recognition accuracy linearly influences both user performance and experience, shows that transcripts with 45% WER are unsatisfactory, and suggests that transcripts having a WER of 25% or less would be useful and usable in webcast archives.',\n",
              "  'Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition System.[SEP]A study was conducted to evaluate user performance and satisfaction in completion of a set of text creation tasks using three commercially available continuous speech recognition systems. The study also compared user performance on similar tasks using keyboard input. One part of the study (Initial Use) involved 24 users who enrolled, received training and carried out practice tasks, and then completed a set of transcription and composition tasks in a single session. In a parallel effort (Extended Use), four researchers used speech recognition to carry out real work tasks over 10 sessions with each of the three speech recognition software products. This paper presents results from the Initial Use phase of the study along with some preliminary results from the Extended Use phase. We present details of the kinds of usability and system design problems likely in current systems and several common patterns of error correction that we found.',\n",
              "  \"Aural Proxies and Directionally-Varying Reverberation for Interactive Sound Propagation in Virtual Environments.[SEP]We present an efficient algorithm to compute spatially-varying, direction-dependent artificial reverberation and reflection filters in large dynamic scenes for interactive sound propagation in virtual environments and video games. Our approach performs Monte Carlo integration of local visibility and depth functions to compute directionally-varying reverberation effects. The algorithm also uses a dynamically-generated rectangular aural proxy to efficiently model 2-4 orders of early reflections. These two techniques are combined to generate reflection and reverberation filters which vary with the direction of incidence at the listener. This combination leads to better sound source localization and immersion. The overall algorithm is efficient, easy to implement, and can handle moving sound sources, listeners, and dynamic scenes, with minimal storage overhead. We have integrated our approach with the audio rendering pipeline in Valve's Source game engine, and use it to generate realistic directional sound propagation effects in indoor and outdoor scenes in real-time. We demonstrate, through quantitative comparisons as well as evaluations, that our approach leads to enhanced, immersive multi-modal interaction.\",\n",
              "  'Efficient and Accurate Sound Propagation Using Adaptive Rectangular Decomposition.[SEP]Accurate sound rendering can add significant realism to complement visual display in interactive applications, as well as facilitate acoustic predictions for many engineering applications, like accurate acoustic analysis for architectural design (Monks et al., 2000). Numerical simulation can provide this realism most naturally by modeling the underlying physics of wave propagation. However, wave simulation has traditionally posed a tough computational challenge. In this paper, we present a technique which relies on an adaptive rectangular decomposition of 3D scenes to enable efficient and accurate simulation of sound propagation in complex virtual environments. It exploits the known analytical solution of the wave equation in rectangular domains, and utilizes an efficient implementation of the discrete cosine transform on graphics processors (GPU) to achieve at least a 100-fold performance gain compared to a standard finite-difference time-domain (FDTD) implementation with comparable accuracy, while also being 10-fold more memory efficient. Consequently, we are able to perform accurate numerical acoustic simulation on large, complex scenes in the kilohertz range. To the best of our knowledge, it was not previously possible to perform such simulations on a desktop computer. Our work thus enables acoustic analysis on large scenes and auditory display for complex virtual environments on commodity hardware.',\n",
              "  \"Source and Listener Directivity for Interactive Wave-Based Sound Propagation.[SEP]We present an approach to model dynamic, data-driven source and listener directivity for interactive wave-based sound propagation in virtual environments and computer games. Our directional source representation is expressed as a linear combination of elementary spherical harmonic (SH) sources. In the preprocessing stage, we precompute and encode the propagated sound fields due to each SH source. At runtime, we perform the SH decomposition of the varying source directivity interactively and compute the total sound field at the listener position as a weighted sum of precomputed SH sound fields. We propose a novel plane-wave decomposition approach based on higher-order derivatives of the sound field that enables dynamic HRTF-based listener directivity at runtime. We provide a generic framework to incorporate our source and listener directivity in any offline or online frequency-domain wave-based sound propagation algorithm. We have integrated our sound propagation system in Valve's Source game engine and use it to demonstrate realistic acoustic effects such as sound amplification, diffraction low-passing, scattering, localization, externalization, and spatial sound, generated by wave-based propagation of directional sources and listener in complex scenarios. We also present results from our preliminary user study.\"],\n",
              " '120_dance_dancers_dancer_choreographers': ['Physical Skill and Idea Interaction in the Creation of New Dance Movements.[SEP]It has been suggested that in creative activities, cognition and physical action are related to each other. This study focuses on this relationship in breakdance, which is a creative activity of artistic and acrobatic movements. For four months, we conducted field observations of practice sessions of three expert breakdancers, and held interviews with them to investigate the creation process of new and original movements. The video records of the 34 practices and the interview data were analyzed with respect to two aspects: 1) Whether or not the dancers performed important movements appropriately; and 2) What the dancers were thinking when generating new aspects of the movements. The results show an interactive process between the development of dance movements and the generation of ideas. The dancers gradually became able to perform the movements appropriately by generating new ideas, and they generated new ideas using the somatic sensation of the new movements.',\n",
              "  \"Dance Movement: A Focus on the Technology.[SEP]Dance notation systems, like music notes, enable documentation of symbolic representations of movement as signs on paper for individual analysis and interpretation. Today, dance notation systems operate within a digital environment in dance notation applications that facilitate the process of recording movement. The author argues that a key objective in the development of these applications should be to provide the user with an unambiguous method to record and represent movement. These applications offer varying functionality in their use of technology for the representation of movement and can be broadly defined in three different categories. Dance notation applications make up the first category - they help notate or record specific forms of movement using dance notation. Notation-based applications, the second category, include applications that use dance notation as a basis for their development. The last category, dance technology, consists of applications that use emerging technologies to record and visualize movement. While each application has a defined use, it's important to consider how effective the technologies they employ are in successfully achieving their objectives. In this article, the author focuses on dance applications in these three categories. The author considers the limitations of existing technologies in their ability to effectively describe and record movement within a specific context.\",\n",
              "  'Designing Expressions of Movement Qualities.[SEP]Tango is a form of partner dancing in which two bodies sense one another, and move accordingly, in a dynamic, physical dialogue that is known for its subtle complexities, beauty and intimate experience. In MoCap Tango, we explore how we can build on our skills as designers to highlight and unravel these embedded qualities and use them as inspiration in designing interactions. In this pictorial, we invite the reader to actively participate in the designerly engagement that turns objective data into subjective expressions; highlighting the qualities embedded in the movements of professional dancers.'],\n",
              " '121_line_clipping_algorithms_polygon': ['Anti-Aliased Lines Using Run-Masks.[SEP]In recent work, a set of line digitization algorithms based on the hierarchy of runs in the digital line has unified and generalized the iterative line‐drawing algorithms used in computer graphics. In this paper, the additional structural information generated by these algorithms is leveraged to describe a run‐based approach to draw anti‐aliased line segments in which anti‐aliased run‐masks are substituted for the individual run lengths as the line is being drawn. The run‐masks are precomputed using a prefiltering technique such that one or more run‐masks are defined for each of the one or two possible run lengths that occur in the line. The run‐masks can be defined for any order or level of the hierarchy of runs in the digital line and the technique is illustrated using runs of pixels. Comparing the use of run‐masks to applying the prefiltering technique for each pixel in the line, a line of similar visual quality can be produced more efficiently. We place no restrictions on the placement of the end points of the line, which may reside anywhere on the two‐dimensional plane.',\n",
              "  'A new approach to line and line segment clipping in homogeneous coordinates.[SEP]The clipping operation is still the bottleneck of the graphics pipeline in spite of the latest developments in graphical hardware and a significant increase in performance. Algorithms for line and line segment clipping have been studied for a long time and many research papers have been published so far. This paper presents a new robust approach to line and line segment clipping using a rectangular window. A simple extension for the case of convex polygon clipping is presented as well.',\n",
              "  'A New Two Dimensional Line Clipping Algorithm for Small Windows.[SEP]A new algorithm for clipping lines against rectangular windows is described. It is suitable for computations in both object space (floating point arithmetic) and image space (integer arithmetic). The algorithm is compared with other object and image space algorithms and shown to be superior for small windows.'],\n",
              " '122_occlusion_culling_rendering_occluded': ['Towards Adaptive Occlusion Culling Using Camera Coherence.[SEP]Occlusion culling proves to be useful for the interactive visualization of environments that are not densely occluded. Those which are built up by dense geometric sets like aerospace engines composed of thousands of components and millions of polygons. In first place the convenience of using occlusion culling is studied with a simple scheme. Then improvements are analyzed. The key points to obtain frame rate speed-ups are: a convenient occlusion query scheduling provides the performance required; depth sorting is performed only when camera orientation changes more than a given threshold; coherence reduces the number of occlusion queries posted per frame. It is possible to select the percentage of occlusion queries that will be performed in each frame, from non-conservative schemes up to a conservative one. Furthermore, we propose a small addition to the GPU occlusion queries to perform faster renderings',\n",
              "  'Bent Normals and Cones in Screen-space.[SEP]Ambient occlusion (AO) is a popular technique for real-time as well as offline rendering. One of its benefits is a gain in efficiency due to the fact that occlusion and shading are decoupled which results in an average occlusion that modulates the surface shading. Its main drawback is a loss of realism due to the lack of directional occlusion and lighting. As a solution, the use of bent normals was proposed for offline rendering. This work describes how to compute bent normals and bent cones in combination with screen-space ambient occlusion. These extensions combine the speed and simplicity of AO with physically more plausible lighting.',\n",
              "  'Integrating Occlusion Culling with Levels of Detail through Hardly-Visible Sets.[SEP]Occlusion culling and level‐of‐detail rendering have become two powerful tools for accelerating the handling of very large models in real‐time visualization applications. We present a framework that combines both techniques to improve rendering times. Classical occlusion culling algorithms compute potentially visible sets (PVS), which are supersets of the sets of visible polygons. The novelty of our approach is to estimate the degree of visibility of each object of the PVS using synthesized coarse occluders. This allows to arrange the objects of each PVS into several Hardly‐Visible Sets (HVS) with similar occlusion degree. According to image accuracy and frame rate requirements, HVS provide a way to avoid sending to the graphics pipeline those objects whose pixel contribution is low due to partial occlusion. The image error can be bounded by the user at navigation time. On the other hand, as HVS offer a tighter estimation of the pixel contribution for each scene object, it can be used for a more convenient selection of the level‐of‐detail at which objects are rendered. In this paper, we describe the new framework technique, provide details of its implementation using a visibility octree as the chosen occlusion culling data structure and show some experimental results on the image quality.'],\n",
              " '123_multimodal_modality_modalities_speech': ['Usability of user interfaces: from monomodal to multimodal.[SEP]This workshop is aimed at reviewing and comparing existing Usability Evaluation Methods (UEMs) which are applicable to monomodal and multimodal applications, whether they are web-oriented or not. It addresses the problem on how to assess the usability of monomodal user interfaces according to techniques involving one or several modalities, in parallel or combined. In particular, how to synchronize results provided by different UEMs producing various types of results (e.g., audio, video, text, log files) is concerned. It also addresses the problem on how to assess the usability of multimodal user interfaces according to techniques based on multiple modalities. In particular, the question of generalizing the applicability of existing UEMs to these new types of user interfaces is concerned.',\n",
              "  'Multimodal Interaction within Ambient Environments: An Exploratory Study.[SEP]Inputs and outputs are not two independent phenomena in multimodal systems. This paper examines the relationship that exists between them. We present the results of a Wizard of Oz experiment which shows that output modalities used by the system have an influence on the users’ input modalities for a large category of users. The experiment took place in a smart room. This kind of environment does not require any particular knowledge about computers and their use and thus allowed us to study the behavior of ordinary people including subjects who are not familiar with computers. The experiment also shows that speech is a favorite modality within smart room environments for a large part of users. We think that the results presented in this paper will be useful for the design of intelligent multimodal systems.',\n",
              "  \"Designing socially acceptable multimodal interaction in cooking assistants.[SEP]Cooking assistant is an application that needs to find a trade-off between providing efficient help to the users (e.g., reminding them to stir a meal if it is about to burn) and avoiding users' annoyance. This trade-off may vary in different contexts, such as cooking alone or in a group, cooking new or known recipe etc. The results of the user study, presented in this paper, show which features of a multimodal interface users perceive as socially acceptable or unacceptable in different situations, and how this perception depends on user's age.\"],\n",
              " '124_religious_dreaming_religion_cultural': ['Immunity to error through misidentification and non-attributive self-reference.[SEP]Recent empirical literature (Jeannerod & Pacherie, 2004; Mizumoto & Ishikawa, 2005) purports to challenge the thesis that certain forms of self-awareness are immune to errors of misidentification with respect to the first-person (IEM). I argue, first, that these studies do not present a challenge to the IEM thesis, and furthermore that IEM is indicative of a fundamental distinction between two ways of being self-aware—a distinction that has real consequences for empirical studies of self-awareness. In the final section of the paper I suggest that the non-attributive self-reference (NSR) thesis better explains what is special about the distinction than IEM does by itself.',\n",
              "  'Predicting How People Feel: Ownership Matters for Preschoolers.[SEP]Ownership is central in our thinking about other people and objects. We consider ownership when deciding whether we are permitted to use an object and when predicting how owners would feel if their property was lost or broken. Recognizing and understanding ownership is not just evident in adults. Even young children appreciate ownership and its consequences. In this experiment, we show that children aged three years (N = 40) predict that an individual would be sadder when her property went missing than when someone else’s property went missing. These findings show that young children have a rich appreciation of ownership, and grasp relations between ownership and psychological states.',\n",
              "  'New Developments in the Cognitive Science of Religion. Hosted by the International Association for the Cognitive Science of Religion (IACSR).[SEP]The International Association for the Cognitive Science of Religion (IACSR) seeks to advance the naturalistic study of religion. The IACSR recognizes that the cognitive sciences encompass a wide array of disciplines and methods, including, among others, experimental research in psychology and neuroscience, computational modeling, ethnographic, historical, archaeological, and comparative studies of religious cognition, and the survey techniques of the social sciences. The main goal of the workshop is to introduce CSS members to topics that are cutting edge in the cognitive science of religion. Religion is obviously of global significance, and its study requires explanations from a variety of perspectives that involve broader issues relevant to cognitive science.'],\n",
              " '125_spreadsheet_spreadsheets_web_programming': ['Visualization Exploration and Encapsulation via a Spreadsheet-Like Interface.[SEP]Exploring complex, very large data sets requires interfaces to present and navigate through the visualization of the data. Two types of audience benefit from such coherent organization and representation: first, the user of the visualization system can examine and evaluate their data more efficiently; second, collaborators or reviewers can quickly understand and extend the visualization. The needs of these two groups are addressed by the spreadsheet-like interface described in this paper. The interface represents a 2D window in a multidimensional visualization parameter space. Data is explored by navigating this space via the interface. The visualization space is presented to the user in a manner that clearly identifies which parameters correspond to which visualized result. Operations defined on this space can be applied which generate new parameters or results. Combined with a general-purpose interpreter, these functions can be utilized to quickly extract desired results. Finally, by encapsulating the visualization process, redundant exploration is eliminated and collaboration is facilitated. The efficacy of this novel interface is demonstrated through examples using a variety of data sets in different domains.',\n",
              "  'Anti-Freeze for Large and Complex Spreadsheets: Asynchronous Formula Computation.[SEP]Spreadsheet systems enable users to store and analyze data in an intuitive and flexible interface. Yet the scale of data being analyzed often leads to spreadsheets hanging and freezing on small changes. We propose a new asynchronous formula computation framework: instead of freezing the interface we return control to users quickly to ensure interactivity, while computing the formulae in the background. To ensure consistency, we indicate formulae being computed in the background via visual cues on the spreadsheet. Our asynchronous computation framework introduces two novel challenges: (a) How do we identify dependencies for a given change in a bounded time? (b) How do we schedule computation to maximize the number of spreadsheet cells available to the user over time? We bound the dependency identification time by compressing the formula dependency graph lossily, a problem we show to be NP-Hard. A compressed dependency table enables us to quickly identify the spreadsheet cells that need recomputation and indicate them as such to users. Finding an optimal computation schedule to maximize cell availability is also NP-Hard, and even merely obtaining a schedule can be expensive-we propose an on-the-fly scheduling technique to address this. We have incorporated asynchronous computation in DataSpread, a scalable spreadsheet system targeted at operating on arbitrarily large datasets on a spreadsheet frontend.',\n",
              "  'Graphical Definitions: Expanding Spreadsheet Languages Through Direct Manipulation and Gestures.[SEP]In the past, attempts to extend the spreadsheet paradigm to support graphical objects, such as colored circles or user-defined graphical types, have led to approaches featuring either a direct way of creating objects graphically or strong compatibility with the spreadsheet paradigm, but not both. This inability to conveniently go beyond numbers and strings without straying outside the spreadsheet paradigm has been a limiting factor in the applicability of spreadsheet languages. In this article we present graphical definitions, an approach that removes this limitation, allowing both simple and complex graphical objects to be programmed directly using direct manipulation and gestures, in a manner that fits seamlessly within the spreadsheet paradigm. We also describe an empirical study, in which subjects programmed such objects faster and with fewer errors using this approach than when using a traditional approach to formula specification. Because the approach is expressive enough to be used with both built-in and user-defined types, it allows the directness of demonstrational and spreadsheet techniques to be used in programming a wider range of applications than has been possible before.'],\n",
              " '126_cleaning_repairing_repair_tuples': ['Tracing data errors with view-conditioned causality.[SEP]A surprising query result is often an indication of errors in the query or the underlying data. Recent work suggests using causal reasoning to find explanations for the surprising result. In practice, however, one often has multiple queries and/or multiple answers, some of which may be considered correct and others unexpected. In this paper, we focus on determining the causes of a set of unexpected results, possibly conditioned on some prior knowledge of the correctness of another set of results. We call this problem View-Conditioned Causality. We adapt the definitions of causality and responsibility for the case of multiple answers/views and provide a non-trivial algorithm that reduces the problem of finding causes and their responsibility to a satisfiability problem that can be solved with existing tools. We evaluate both the accuracy and effectiveness of our approach on a real dataset of user-generated mobile device tracking data, and demonstrate that it can identify causes of error more effectively than static Boolean influence and alternative notions of causality.',\n",
              "  \"Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes.[SEP]Various computational procedures or constraint-based methods for data repairing have been proposed over the last decades to identify errors and, when possible, correct them. However, these approaches have several limitations including the scalability and quality of the values to be used in replacement of the errors. In this paper, we propose a new data repairing approach that is based on maximizing the likelihood of replacement data given the data distribution, which can be modeled using statistical machine learning techniques. This is a novel approach combining machine learning and likelihood methods for cleaning dirty databases by value modification. We develop a quality measure of the repairing updates based on the likelihood benefit and the amount of changes applied to the database. We propose SCARE (SCalable Automatic REpairing), a systematic scalable framework that follows our approach. SCARE relies on a robust mechanism for horizontal data partitioning and a combination of machine learning techniques to predict the set of possible updates. Due to data partitioning, several updates can be predicted for a single record based on local views on each data partition. Therefore, we propose a mechanism to combine the local predictions and obtain accurate final predictions. Finally, we experimentally demonstrate the effectiveness, efficiency, and scalability of our approach on real-world datasets in comparison to recent data cleaning approaches.\",\n",
              "  'A Perspective on Databases and Data Mining.[SEP]We discuss the use of database methods for data mining. Recently impressive results have been achieved for some data mining problems using highly specialized and clever data structures. We study how well one can manage by using general purpose database management systems. We illustrate our ideas by investigating the use of a dbms for a well-researched area: the discovery of association rules. We present a simple algorithm, consisting of only union and intersection operations, and show that it achieves quite good performance on an efficient dbms. Our method can incorporate inheritance hierarchies to the association rule algorithm easily. We also present a technique that effectively reduces the number of database operations when searching large search spaces that contain only few interesting items. Our work shows that database techniques are promising for data mining: general architectures can achieve reasonable results.'],\n",
              " '127_polygons_polygon_hull_algorithm': ['The Implementation of a 2D Convex Hull Algorithm Using Perturbation.[SEP]This paper discusses the problem of geometric degeneracies and outlines possible solutions when converting geometric algorithms into practice. It concentrates on the application of one of the suggested solutions, a perturbation technique, to a 2D convex hull program. An outline of the relevant theory and its conversion into practice is given. Experimental results are presented and discussed.',\n",
              "  'On Compatible Star Decompositions of Simple Polygons.[SEP]The authors introduce the notion of compatible star decompositions of simple polygons. In general, given two polygons with a correspondence between their vertices, two polygonal decompositions of the two polygons are said to be compatible if there exists a one-to-one mapping between them such that the corresponding pieces are defined by corresponding vertices. For compatible star decompositions, they also require correspondence between star points of the star pieces. Compatible star decompositions have applications in computer animation and shape representation and analysis. They present two algorithms for constructing compatible star decompositions of two simple polygons. The first algorithm is optimal in the number of pieces in the decomposition, providing that such a decomposition exists without adding Steiner vertices. The second algorithm constructs compatible star decompositions with Steiner vertices, which are not minimal in the number of pieces but are asymptotically worst-case optimal in this number and in the number of added Steiner vertices. They prove that some pairs of polygons require /spl Omega/(n/sup 2/) pieces, and that the decompositions computed by the second algorithm possess no more than O(n/sup 2/) pieces. In addition to the contributions regarding compatible star decompositions, the paper also corrects an error in the only previously published polynomial algorithm for constructing a minimal star decomposition of a simple polygon, an error which might lead to a nonminimal decomposition.',\n",
              "  'Reducing the Number of Points on the Convex Hull Calculation Using the Polar Space Subdivision in E2.[SEP]A convex hull of points in E 2 is used in many applications. In spite of low computational complexity O(h logn) it takes considerable time if large data processing is needed. We present a new algorithm to speed up any planar convex hull calculation. It is based on a polar space subdivision and speed up known convex hull algorithms of 3,7 times and more. The algorithm estimates the central point using 10% of the data, this point is taken as the origin for the polar subdivision. The space subdivision enables a fast and very efficient reduction of the given points, which cannot contribute to the final convex hull. The proposed algorithm iteratively approximates the convex hull, leaving only a small number of points for the final processing, which is performed using a \"standard\" algorithm. Non-eliminated points are then processed by a selected standard convex hull algorithm. The algorithm is simple and easy to implement. Experiments proved numerical robustness as well.'],\n",
              " '128_spatial_languages_across_meaning': ['Both symbolic and embodied representations contribute to spatial language processing; Evidence from younger and older adults.[SEP]Building on earlier neuropsychological work, we adopted a novel individual differences approach to examine the relationship between spatial language and a wide range of both verbal and nonverbal abilities. Three new measures were developed for the assessment of spatial language processing: spatial naming, spatial verbal memory, and verbal comprehension in spatial perspective taking. Results from a sample of young adults revealed significant correlations between performance on the spatial language tasks and performance on both the analogous (non-spatial) verbal measures as well as on the (non-verbal) visual-spatial measures. Visual-spatial abilities, however, were more predictive of spatial language processing than verbal abilities. Furthermore, results from a sample of older adults revealed impairments in visual-spatial tasks and on spatial verbal memory. The results support dual process accounts of meaning, and provide further evidence of the close connection between the language of space and non-linguistic visual-spatial cognition.',\n",
              "  '\"Natural concepts\" revisited in the spatial-topological domain: Universal tendencies in focal spatial relations.[SEP]It has long been noted that the best examples, or foci, of color categories tend to align across diverse languages (Berlin & Kay, 1969)--but there is limited documentation of such universal foci in other semantic domains. Here, we explore whether spatial topological categories, such as \"in\" and \"on\" in English, have focal members comparable to those in color. We document names and best examples of topological spatial relations in Dutch, English, French, Japanese, Korean, Mandarin Chinese, and Spanish, and find substantial consensus, both within and across languages, on the best examples of such spatial categories. Our results provide empirical evidence for focal best examples in the spatial domain and contribute further support for a theory of \"natural concepts\" in this domain.',\n",
              "  'Spatial language and visual attention: A new approach to test linguistic relativity.[SEP]It is debated how far-reaching effects of language on cognition are - if they exist at all. Using a visual search paradigm, we tested whether native Korean and German speakers are differentially sensitive to visual 3D-object composites that only the Korean, but not the German (nor the English), language semantically distinguishes as tight- versus loose-fit. We instructed our participants to search for a colour-defined target composite among distractors. However, targets were also implicitly signalled by their tight- or loose-fit composites. Only Korean speakers picked up on this implicit target-defining characteristic, reflected in attention capture by target-similar composites. As these concepts are not grammticalised in the German language, our results demonstrate that language can determine which visual features capture attention. Our research introduces a novel approach because processing of the linguistically discriminated visual characteristics was neither instructed nor necessary for the task, demonstrating a case of linguistic relativity of cognition.'],\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner': ['Addressing Mobile Phone Diversity in Ubicomp Experience Development.[SEP]Mobile phones are a widely-available class of device with supporting communications infrastructure which can be appropriated and exploited to support ubicomp experiences. However mobile phones vary hugely in their capabilities. We explore how a single dimension of phone application type embodies the critical trade-off between capability and availability, i.e. between what can be done and the fraction of potential participants’ phones that can do this. We describe four different mobile phone ubicomp experiences that illustrate different points along this continuum (SMS, WAP/Web, and J2ME, Python and native applications) and the common software platform/toolkit, EQUIP2, that has been co-developed to support them. From this we propose four development strategies for addressing mobile phone diversity: prioritise support for server development (including web integration), migrate functionality between server(s) and handset(s), support flexible communication options, and use a loosely coupled (data-driven and component-based) software approach.',\n",
              "  'Towards Deeper Understanding of User Experience with Ubiquitous Computing Systems: Systematic Literature Review and Design Framework.[SEP]Over the past decades, a plethora of innovative ubiquitous computing (ubicomp) systems have been constructed. The acceptance of the systems, however, depends on how users experience them in real contexts. While many of the ubicomp research projects include some form of user study, there is no overview of how user experience (UX) is approached in ubicomp research. To this end, we conducted a systematic literature review of ubicomp UX studies. Our findings reveal that users‘experiences with ubicomp systems have often been investigated in rather lightweight ways, for example by addressing basic usability issues, collecting ratings by simple, predetermined scales, or producing descriptions of general experiences such as fun and trust. Based on the findings we argue that a deeper and more fine-grained understanding of user experience would help developing more successful ubicomp systems. We propose a ubicomp UX framework that can help design and evaluate ubicomp systems with a desirable set of target experiences.',\n",
              "  'Rapidly Exploring Application Design Through Speed Dating.[SEP]While the user-centered design methods we bring from human-computer interaction to ubicomp help sketch ideas and refine prototypes, few tools or techniques help explore divergent design concepts, reflect on their merits, and come to a new understanding of design opportunities and ways to address them. We present Speed Dating, a design method for rapidly exploring application concepts and their interactions and contextual dimensions without requiring any technology implementation. Situated between sketching and prototyping, Speed Dating structures comparison of concepts, helping identify and understand contextual risk factors and develop approaches to address them. We illustrate how to use Speed Dating by applying it to our research on the smart home and dual-income families, and highlight our findings from using this method.'],\n",
              " '12_education_educational_teaching_classroom': ['Distinctive Approaches to Computer Graphics Education.[SEP]This paper presents the latest advances and research in Computer Graphics education in a nutshell. It is concerned with topics that were presented at the Education Track of the Eurographics Conference held in Lisbon in 2016. We describe works corresponding to approaches to Computer Graphics education that are unconventional in some way and attempt to tackle unsolved problems and challenges regarding the role of arts in computer graphics education, the role of research‐oriented activities in undergraduate education and the interaction among different areas of Computer Graphics, as well as their application to courses or extra‐curricular activities. We present related works addressing these topics and report experiences, successes and issues in implementing the approaches.',\n",
              "  'Interactive computer graphics applied to chemistry: experiences and new developments.[SEP]This paper is essentially a progress report on three years of effort in computer graphics applied to chemistry. The major technical and human problems encountered when running our facility and integrating it into a chemistry department are described. Then progress of our research project, which is developing application programs in several areas of computer graphics applied to chemical education and research, is reviewed. Recent developments in the field of the representation of dynamic processes in molecules and illustrating some basic concepts of reaction mechanisms in organic chemistry are presented, and the important role of graphics in depicting adequately 3D reaction paths is stressed. Finally, some technical problems arising when using the calligraphic system as an audio‐visual tool for teaching chemistry are discussed and some possible solutions are presented.',\n",
              "  \"Integrating User Studies into Computer Graphics-Related Courses.[SEP]This paper presents computer graphics. Computer graphics and visualization are essentially about producing images for a target audience, be it the millions watching a new CG-animated movie or the small group of researchers trying to gain insight into the large amount of numerical data resulting from a scientific experiment. To ascertain the final images' effectiveness for their intended audience or the designed visualizations' accuracy and expressiveness, formal user studies are often essential. In human-computer interaction (HCI), such user studies play a similar fundamental role in evaluating the usability and applicability of interaction methods and metaphors for the various devices and software systems we use.\",\n",
              "  \"Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent.[SEP]Enrollment in online courses has sharply increased in higher education. Although online education can be scaled to large audiences, the lack of interaction between educators and learners is difficult to replace and remains a primary challenge in the field. Conversational agents may alleviate this problem by engaging in natural interaction and by scaffolding learners' understanding similarly to educators. However, whether this approach can also be used to enrich online video lectures has largely remained unknown. We developed Sara, a conversational agent that appears during an online video lecture. She provides scaffolds by voice and text when needed and includes a voice-based input mode. An evaluation with 182 learners in a 2 x 2 lab experiment demonstrated that Sara, compared to more traditional conversational agents, significantly improved learning in a programming task. This study highlights the importance of including scaffolding and voice-based conversational agents in online videos to improve meaningful learning.\",\n",
              "  \"How Peripheral Data Visualisation Systems Support Secondary School Teachers during VLE-Supported Lessons.[SEP]Through the integration of technology-enhanced learning (TEL) in the classrooms, there is an increase in Virtual Learning Environment-supported classes in secondary schools, which brings unintentional complexities in terms of monitoring for teachers [25]. To support secondary school teachers during VLE-supported lessons, a peripheral data visualisation system was designed and implemented in a three-week field study. Both qualitative and quantitative data were gathered and analysed through methodological triangulation in order to get an in-depth understanding about the use of the system by teachers. The key findings from our study were that the peripheral data visualisation tool, by being a distributed, highly visible system, was well integrated in the teachers' practice. The peripheral visualisation served as a trigger for teacher interventions where the teacher could confront the student's level of concentration and provide support when a student needs it. Furthermore, by offloading the secondary tasks of checking the students' level of concentration and progress to the visualisation, most teachers experienced more peace of mind and space to manage their primary teaching practice. Lastly, approximately 95% of 89 students experienced the data visualisation as neutral or motivating, while 5.7% of the students experienced violation of privacy by this medium.\",\n",
              "  'The Design of an Authoring Interface to Make eLearning Content Accessible.[SEP]This paper presents the rationale and design process of an authoring interface that enables didactic experts to create or modify eLearning content to make it accessible by learners with special needs. The tool has been designed according to a methodological framework and a set of guidelines for eLearning accessibility previously developed by our group. A key aspect of our framework consists in helping authors to preserve the didactic quality of the eLearning experiences provided to disabled learners (in particular, visually impaired ones) beyond assuring their mere physical access to online materials. A user-centred design process has been adopted to develop a usable prototype of the authoring interface, named aLearning, that we describe below.'],\n",
              " '130_meetings_communication_informal_messaging': ['The doing of doing stuff: understanding the coordination of social group-activities.[SEP]This paper explores how the adoption of mobile and social computing technologies has impacted upon the way in which we coordinate social group-activities. We present a diary study of 36 individuals that provides an overview of how group coordination is currently performed as well as the challenges people face. Our findings highlight that people primarily use open-channel communication tools (e.g., text messaging, phone calls, email) to coordinate because the alternatives are seen as either disrupting or curbing to the natural conversational processes. Yet the use of open-channel tools often results in conversational overload and a significant disparity of work between coordinating individuals. This in turn often leads to a sense of frustration and confusion about coordination details. We discuss how the findings argue for a significant shift in our thinking about the design of coordination support systems.',\n",
              "  \"Accessible Online Meetings and Presentations.[SEP]In our current situation, conferences, classes, and meetings are moving online. What steps can you take to ensure that your activities are welcoming to a diverse audience, including people with disabilities? This presentation will look at proactive strategies you can take to ensure that your meetings and presentations are accessible to a wide audience. We'll talk about communication with participants, preparation, presentation materials, technology, and accommodations.\",\n",
              "  'Automated Assistance for the Telemeeting Lifecycle.[SEP]We analyse eighteen months of national and international deployment of a prototype telemeeting system supporting synchronous remote meetings which make extensive use of shared documents as well as video and audio conferencing. Logistics of a telemeeting include scheduling people and equipment, document format conversion, pre-sending documents, training, equipment and call setup, and meeting followup. The logistics burden is much larger than expected and can be a barrier to adoption of telemeeting technology. Using a process model that recognises moving between solo and group, asynchronous and synchronous work modes, the paper explores the amenability of individual logistics tasks to automated assistance, proposes a framework for such assistance, and develops a set of design principles.'],\n",
              " '131_provenance_lakes_workflows_lake': [\"C[SEP]Datasets are often derived by manipulating raw data with statistical software packages. The derivation of a dataset must be recorded in terms of both the raw input and the manipulations applied to it. Statistics packages typically provide limited help in documenting provenance for the resulting derived data. At best, the operations performed by the statistical package are described in a script. Disparate representations make these scripts hard to understand for users. To address these challenges, we created Continuous Capture of Metadata (C2Metadata), a system to capture data transformations in scripts for statistical packages and represent it as metadata in a standard format that is easy to understand. We do so by devising a Structured Data Transformation Algebra (SDTA), which uses a small set of algebraic operators to express a large fraction of data manipulation performed in practce. We then implement SDTA, inspired by relational algebra, in a data transformation specification language we call SDTL. In this demonstration, we showcase C2metadata's capture of data transformations from a pool of sample transformation scripts in at least two languages: SPSS and Stata (SAS and R are under development), for social science data in a large academic repository. We will allow the audience to explore C2Metadata using a web-based interface, visualize the intermediate steps and trace the provenance and changes of data at different levels for better understanding of the process.\",\n",
              "  \"When the Web is your Data Lake: Creating a Search Engine for Datasets on the Web.[SEP]There are thousands of data repositories on the Web, providing access to millions of datasets. National and regional governments, scientific publishers and consortia, commercial data providers, and others publish data for fields ranging from social science to life science to high-energy physics to climate science and more. Access to this data is critical to facilitating reproducibility of research results, enabling scientists to build on others' work, and providing data journalists easier access to information and its provenance. In this talk, I will discuss our work on Dataset Search, which provides search capabilities over potentially all dataset repositories on the Web. I will talk about the open ecosystem for describing and citing datasets that we hope to encourage and the technical details on how we went about building Dataset Search. Finally, I will highlight research challenges in building a vibrant, heterogeneous, and open ecosystem where data becomes a first-class citizen.\",\n",
              "  'Debugging Big Data Analytics in Spark with [SEP]To process massive quantities of data, developers leverage Data-Intensive Scalable Computing (DISC) systems such as Apache Spark. In terms of debugging, DISC systems support only post-mortem log analysis and do not provide any debugging functionality. This demonstration paper showcases BigDebug: a tool enhancing Apache Spark with a set of interactive debugging features that can help users in debug their Big Data Applications.'],\n",
              " '13_driving_vehicle_vehicles_driver': ['The SKYNIVI Experience: Evoking Startle and Frustration in Dyads and Single Drivers.[SEP]To study naturalistic in-cabin emotion we developed SKYNIVI, a modified open source driving simulator, with scenarios designed to elicit startle and frustration. We target generating these emotions because we believe that by detecting these it will be possible for autonomous vehicles to learn to drive better. We show how to use SKYNIVI to develop datasets that capture naturalistic emotions in drivers and passengers for algorithmic development. We recruited 51 participants as dyads and single drivers to participate in two different scenarios. We show that we were able to evoke hundreds of instances of our target emotions in this cohort and present an analysis of factors we found to impact emotional expression including: scenario design , demographic factors, personality and baseline affect . We find that having a second person in the vehicle impacts observed expressions of emotion even when no difference in baseline affect is reported.',\n",
              "  'Autonomous Vehicle-Cyclist Interaction: Peril and Promise.[SEP]Autonomous vehicles (AVs) will redefine interactions between road users. Presently, cyclists and drivers communicate through implicit cues (vehicle motion) and explicit but imprecise signals (hand gestures, horns). Future AVs could consistently communicate awareness and intent and other feedback to cyclists based on their sensor data. We present an exploration of AV-cyclist interaction, starting with preliminary design studies which informed the implementation of an immersive VR AV-cyclist simulator, and the design and evaluation of a number of AV-cyclist interfaces. Our findings suggest that AV-cyclist interfaces can improve rider confidence in lane merging scenarios. We contribute an AV-cyclist immersive simulator, insights on trade-offs of various aspects of AV-cyclist interaction design including modalities, location, and complexity, and positive results suggesting improved rider confidence due to AV-cyclist interaction. While we are encouraged by the potential positive impact AV-cyclist interfaces can have on cyclist culture, we also emphasize the risks over-reliance can pose to cyclists.',\n",
              "  'CarNote: Reducing Misunderstanding between Drivers by Digital Augmentation.[SEP]The road environment can be seen as a social situation: Drivers need to coordinate with each other to share the infrastructure. In addition to the driving behaviour itself, lights, horn and speed are the most frequently used means to exchange information, limiting both the range and the bandwidth of the connectivity and leading to misunderstanding and conflict. With everywhere available connectivity and the broad penetration of social network services, the relationship between drivers on the road may gain more transparency, enabling social information to pass through the steel shell of the cars and giving opportunities to reduce misunderstanding and strengthen empathy. In this study, we present \"CarNote\", a concept that aims to reduce misunderstanding and conflict between drivers by showing their emergency driving status to others. This concept was prototyped and evaluated with users in a driving simulator. The results showed that CarNote enhances drivers\\' empathy, increases forgiveness and decreases anger to others on the road.',\n",
              "  \"Learning to Estimate the Travel Time.[SEP]Vehicle travel time estimation or estimated time of arrival (ETA) is one of the most important location-based services (LBS). It is becoming increasingly important and has been widely used as a basic service in navigation systems and intelligent transportation systems. This paper presents a novel machine learning solution to predict the vehicle travel time based on floating-car data. First, we formulate ETA as a pure spatial-temporal regression problem based on a large set of effective features. Second, we adapt different existing machine learning models to solve the regression problem. Furthermore, we propose a Wide-Deep-Recurrent (WDR) learning model to accurately predict the travel time along a given route at a given departure time. We then jointly train wide linear models, deep neural networks and recurrent neural networks together to take full advantages of all three models. We evaluate our solution offline with millions of historical vehicle travel data. We also deploy the proposed solution on Didi Chuxing's platform, which services billions of ETA requests and benefits millions of customers per day. Our extensive evaluations show that our proposed deep learning algorithm significantly outperforms the state-of-the-art learning algorithms, as well as the solutions provided by leading industry LBS providers.\",\n",
              "  'Exploiting Spatio-Temporal Correlations with Multiple 3D Convolutional Neural Networks for Citywide Vehicle Flow Prediction.[SEP]Predicting vehicle flows is of great importance to traffic management and public safety in smart cities, and very challenging as it is affected by many complex factors, such as spatio-temporal dependencies with external factors (e.g., holidays, events and weather). Recently, deep learning has shown remarkable performance on traditional challenging tasks, such as image classification, due to its powerful feature learning capabilities. Some works have utilized LSTMs to connect the high-level layers of 2D convolutional neural networks (CNNs) to learn the spatio-temporal features, and have shown better performance as compared to many classical methods in traffic prediction. However, these works only build temporal connections on the high-level features at the top layer while leaving the spatio-temporal correlations in the low-level layers not fully exploited. In this paper, we propose to apply 3D CNNs to learn the spatio-temporal correlation features jointly from low-level to high-level layers for traffic data. We also design an end-to-end structure, named as MST3D, especially for vehicle flow prediction. MST3D can learn spatial and multiple temporal dependencies jointly by multiple 3D CNNs, combine the learned features with external factors and assign different weights to different branches dynamically. To the best of our knowledge, it is the first framework that utilizes 3D CNNs for traffic prediction. Experiments on two vehicle flow datasets Beijing and New York City have demonstrated that the proposed framework, MST3D, outperforms the state-of-the-art methods.',\n",
              "  'Co-Prediction of Multiple Transportation Demands Based on Deep Spatio-Temporal Neural Network.[SEP]Taxi and sharing bike bring great convenience to urban transportation. A lot of efforts have been made to improve the efficiency of taxi service or bike sharing system by predicting the next-period pick-up or drop-off demand. Different from the existing research, this paper is motivated by the following two facts: 1) From a micro view, an observed spatial demand at any time slot could be decomposed as a combination of many hidden spatial demand bases; 2) From a macro view, the multiple transportation demands are strongly correlated with each other, both spatially and temporally. Definitely, the above two views have great potential to revolutionize the existing taxi or bike demand prediction methods. Along this line, this paper provides a novel Co-prediction method based on Spatio-Temporal neural Network, namely, CoST-Net. In particular, a deep convolutional neural network is constructed to decompose a spatial demand into a combination of hidden spatial demand bases. The combination weight vector is used as a representation of the decomposed spatial demand. Then, a heterogeneous Long Short-Term Memory (LSTM) is proposed to integrate the states of multiple transportation demands, and also model the dynamics of them mixedly. Last, the environmental features such as humidity and temperature are incorporated with the achieved overall hidden states to predict the multiple demands simultaneously. Experiments have been conducted on real-world taxi and sharing bike demand data, results demonstrate the superiority of the proposed method over both classical and the state-of-the-art transportation demand prediction methods.',\n",
              "  'End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks.[SEP]Despite extraordinary progress of Advanced Driver Assistance Systems (ADAS), an alarming number of over 1,2 million people are still fatally injured in traffic accidents every year 1 . Human error is mostly responsible for such casualties, as by the time the ADAS system has alarmed the driver, it is often too late. We present a vision-based system based on deep neural networks with 3D convolutions and residual learning for anticipating the future maneuver based on driver observation. While previous work focuses on hand-crafted features (e.g. head pose), our model predicts the intention directly from video in an end-to-end fashion. Our architecture consists of three components: a neural network for extraction of optical flow, a 3D residual network for maneuver classification and a Long Short-Term Memory network (LSTM) for handling temporal data of varying length. To evaluate our idea, we conduct thorough experiments on the publicly available Brain4Cars benchmark, which covers both inside and outside views for future maneuver anticipation. Our model is able to predict driver intention with an accuracy of 83,12% and 4,07s before the beginning of the maneuver, outperforming state-of-the-art approaches, while considering the inside view only.',\n",
              "  \"Learning Interaction-Aware Probabilistic Driver Behavior Models from Urban Scenarios.[SEP]Human drivers have complex and individual behavior characteristics which describe how they act in a specific situation. Accurate behavior models are essential for many applications in the field of autonomous driving, ranging from microscopic traffic simulation, intention estimation and trajectory prediction, to interactive and cooperative motion planning. Designing such models by hand is cumbersome and inaccurate, especially in urban environments, with their high variety of situations and the corresponding diversity in human behavior. Learning how humans act from recorded scenarios is a promising way to overcome these problems. However, predicting complete trajectories at once is challenging, as one needs to account for multiple hypotheses and long-term interactions between multiple agents. In contrast, we propose to learn Markovian action models with deep neural networks that are conditioned on a driver's route intention (such as turning left or right) and the situational context. Step-wise forward simulation of these models for the different possible routes of all agents allows for multi-modal and interaction-aware scene predictions at arbitrary road layouts. Learning to predict only one time step ahead given a specific route reduces learning complexity, such that simpler and faster models are obtained. This enables the integration into particle-based algorithms such as Monte Carlo tree search or particle filtering. We evaluate the learned model both on its own and integrated into our previously presented dynamic Bayesian network for intention estimation and show that it outperforms our previous hand-tuned rule-based model.\",\n",
              "  'Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning.[SEP]For highly automated driving above SAE level 3, behavior generation algorithms must reliably consider the inherent uncertainties of the traffic environment, e.g. arising from the variety of human driving styles. Such uncertainties can generate ambiguous decisions, requiring the algorithm to appropriately balance low-probability hazardous events, e.g. collisions, and high-probability beneficial events, e.g. quickly crossing the intersection. State-of-the-art behavior generation algorithms lack a distributional treatment of decision outcome. This impedes a proper risk evaluation in ambiguous situations, often encouraging either unsafe or conservative behavior. Thus, we propose a two-step approach for risk-sensitive behavior generation combining offline distribution learning with online risk assessment. Specifically, we first learn an optimal policy in an uncertain environment with Deep Distributional Reinforcement Learning. During execution, the optimal risk-sensitive action is selected by applying established risk criteria, such as the Conditional Value at Risk, to the learned state-action return distributions. In intersection crossing scenarios, we evaluate different risk criteria and demonstrate that our approach increases safety, while maintaining an active driving style. Our approach shall encourage further studies about the benefits of risk-sensitive approaches for self-driving vehicles.',\n",
              "  'Deep, spatially coherent Inverse Sensor Models with Uncertainty Incorporation using the evidential Framework.[SEP]To perform high speed tasks, sensors of autonomous cars have to provide as much information in as few time steps as possible. However, radars, one of the sensor modalities autonomous cars heavily rely on, often only provide sparse, noisy detections. These have to be accumulated over time to reach a high enough confidence about the static parts of the environment. For radars, the state is typically estimated by accumulating inverse detection models (IDMs). We employ the recently proposed evidential convolutional neural networks which, in contrast to IDMs, compute dense, spatially coherent inference of the environment state. Moreover, these networks are able to incorporate sensor noise in a principled way which we further extend to also incorporate model uncertainty. We present experimental results which show that this approach leads to a denser environment perception in only one time step while at the same time reducing the false positive and negative rates.',\n",
              "  \"Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image.[SEP]In this paper, we present a method for estimating a position, size, and orientation using a single monocular image. The proposed method makes use of an inverse perspective mapping to effectively estimate the distance from the image. The proposed method consists of two stages: 1) cancel the pitch and roll motion of the camera using inertial measurement unit and project the corrected front view image onto the bird's eye view using inverse perspective mapping. 2) detect the position, size, and orientation of the vehicle using a convolutional neural network. The camera motion cancellation process makes vanishing point to be located at the same point regardless of the ego vehicle attitude change. Through this process, the projected bird's eye view image can be parallel and linear to the x-y plane of the vehicle coordinate system. The convolutional neural network predicts not only the position and size but also the orientation of the vehicle for the 3D localization. The predicted oriented bounding box from the bird's eye view image is converted in the meter unit by the inverse projection matrix. The proposed method was evaluated on the KITTI raw dataset on the metric of the root mean square error, mean average percentage error, and average precision. Despite the conceptually simple architecture, the proposed method achieves promising performance compared to other image based approaches. The video demonstration is available online [1].\",\n",
              "  'Camera and LiDAR Fusion for On-road Vehicle Tracking with Reinforcement Learning.[SEP]We formulate camera and LiDAR fusion tracking as a sequential decision-making process. With our deep reinforcement learning framework, we try to optimize the tracking trajectory to be as accurate, smooth, and long as possible. In contrast to traditional fusion algorithms involving complex feature and strategy design and hyperparameters tuned for different scenarios, our fusion agent can learn the confidence of each input by tracking the results from raw observation in a data-driven fashion. Given the input states of different sensors, our approach chooses one input with a higher expected cumulative reward as the observation of a Kalman filter to iteratively predict the target position. The expected cumulative reward is estimated with a convolutional neural network, trained with a modified DQN algorithm, which takes inputs from both LiDAR and a camera. Through case studies and quantitative result evaluation on our dataset from the 4th Ring Road in Beijing, our algorithm is validated to achieve more accurate and robust tracking performance.',\n",
              "  \"An Integrated Path-following and Yaw Motion Control Strategy for Autonomous Distributed Drive Electric Vehicles with Differential Steering.[SEP]This paper proposes a novel control strategy integrated path-following with yaw motion control for autonomous distributed drive electric vehicles with differential steering (DS) technology. First, the path-following and vehicle dynamics model, and DS system are introduced and analyzed. Then, the control framework is proposed, where the model predictive control (MPC) is adopted for path-following and yaw motion control. Given the optimized command by MPC, the quadratic programming (QP) algorithm is applied for in-wheel motors' torque allocation optimization. Series of simulation validations are carried out, proving that the proposed strategy can effectively achieve superior path-following effect, guarantee the vehicle yaw stability, and implement the steering control in DS system, simultaneously.\",\n",
              "  \"Predictive Trajectory Planning in Situations with Hidden Road Users Using Partially Observable Markov Decision Processes.[SEP]State of the art emergency brake assistant systems solely based on sensor measurements reduced the number of traffic accidents and casualties drastically in recent years. In order to be able to react on road users who elude a vehicle's field of view because of sensor limits or occlusions, this paper presents an approach to anticipate potential hidden traffic participants in occluded areas in the decision making process of an autonomous vehicle. A Partially Observable Markov Decision Process is used to determine the vehicle's longitudinal motion. Observations are made using the vehicle's field of view. Therefore the field of view is calculated with a generic model of a sensor setup in dependence of the current or the predicted environment. In this way, the vehicle can either observe that it detects a previously hidden road user or receives information that the road is clear. In total, that allows the vehicle to better anticipate future developments. Therefore, assumptions about vehicles that may be located in hidden areas need to be made. We demonstrate the approach in two scenarios. Firstly in a scenario, where the vehicle has to move cautiously into the intersection with a minimum number of actions and secondly in a typical scenario for urban traffic. Evaluation shows, that the approach is able to anticipate hidden road users correctly and act accordingly.\",\n",
              "  'Semi-Active Suspension Control on Bicycles: Anti-Dive during Road Excitation.[SEP]Suspension systems on bicycles have a tendency to severe brake-induced dive-in, caused by the small wheelbase in combination with a high center of gravity. Semi-active dampers allow the implementation of anti-dive functionality, preventing this behavior. Experimental analysis has shown that this yields significant advantages during brake control on level surfaces. In the presence of additional road excitation, however, a strong conflict arises. A specific test case is a bump occurring while braking, when the damping is set to the hardest value in order to mitigate dive-in. A simulative analysis illustrates that especially the dynamic wheel load is affected, which during braking is safety critical. By simulation and experimental implementation it is shown that using a simple semi-active control rule a decent trade-off can be found. Finally, the influence of the actuator response time is evaluated.'],\n",
              " '14_gesture_gestures_touch_finger': ['Preschoolers understand the representational and communicative nature of iconic gestures.[SEP]Twenty 3.5- to 4-year-olds participated in a study to investigate children’s understanding of the representative and communicative nature of iconic gestures. Two toys, one of them with a sticker attached, were presented to the child. It was not possible to request the toy with the sticker by asking (experimenter wore headphones) or pointing (toys were too close together), but they could show the experimenter which toy they wanted by performing the correct gesture. Children had to generate the correct iconic gestures themselves as the gestures were not modeled during test trials. On 70% of the trials children performed a correct gesture (p = .045), instead of only producing other response types (no response, verbal request, wrong gesture, pointing). This study shows that children understand that iconic gestures can represent objects, and also that they can use iconic gestures to communicate.',\n",
              "  'Gesture structure affects syntactic structure in speech.[SEP]Different functions have been proposed for the hand gestures speakers spontaneously produce while speaking. The Information Packaging Hypothesis (Kita, 2000) states that gestures can structure rich spatio-motoric information into packages suitable for speaking. It therefore predicts that how information is divided over different gestures affects how it is divided over different processing units in speech: clauses. We indeed found that if participants were asked to express the manner and path of a motion in one gesture, they were also more likely to conflate this information into one clause in speech, whereas if they were asked to produce separate gestures, they were more likely to express manner and path in separate clauses too. These results support the view that there are speaker-internal motivations for gesture production. They confirm predictions made by the Information Packaging Hypothesis, which the Lexical Retrieval Hypothesis and the Image Activation Hypothesis do not make.',\n",
              "  'Sign processes in emergence of communication.[SEP]Communication depends on the production and interpretation of representations, but the study of representational processes underlying communication finds little discussion in computational experiments. Here we present an experiment on the emergence of both interpretation and production of multiple representations, with multiple referents, where referential processes can be tracked. Results show the dynamics of semiotic processes during the evolution of artificial creatures and the emergence of a variety of semiotic processes, such as sign production, sign interpretation, and sign-object-interpretant relations.',\n",
              "  \"Understanding users' preferences for surface gestures.[SEP]We compare two gesture sets for interactive surfaces---a set of gestures created by an end-user elicitation method and a set of gestures authored by three HCI researchers. Twenty-two participants who were blind to the gestures' authorship evaluated 81 gestures presented and performed on a Microsoft Surface. Our findings indicate that participants preferred gestures authored by larger groups of people, such as those created by end-user elicitation methodologies or those proposed by more than one researcher. This preference pattern seems to arise in part because the HCI researchers proposed more physically and conceptually complex gestures than end-users. We discuss our findings in detail, including the implications for surface gesture design.\",\n",
              "  'Designer Led Computational Approach to Generate Mappings for Devices with Low Gestural Resolution.[SEP]We present an approach for the semi-automatic generation of gesture mappings for devices with low gestural resolution such as the Myo Armband, an off-the-shelf EMG capture device. As an exemplar interactive task, we use text-entry: a pervasive and highly complex interaction. We quantify data related to interaction combining systematic studies (i.e., error, speed, accuracy) and semi-structured workshops with experts (e.g., cognitive load, heuristics). We then formalize these factors in a mathematical model and use optimization algorithms (i.e. simulated annealing) to find an optimum gesture mapping. We demonstrated our method in a text-entry application (i.e., complex interactive dialogue) comparing our approach with other computationally determined mappings using naive cost functions. Our results showed that the designers mapping (with all factors weighted by designers) presented a good balance on performance in all factors involved (speed, accuracy, comfort, memorability, etc.), consistently performing better than purely computational mappings. The results indicate that our hybrid approach can yield better results than either pure user-driven methodologies or pure data-driven approaches, for our application context featuring a large solution space and complex high-level factors.',\n",
              "  'Designing Mid-Air TV Gestures for Blind People Using User- and Choice-Based Elicitation Approaches.[SEP]Mid-air gestures enable intuitive and natural interactions. However, few studies have investigated the use of mid-air gestures for blind people. TV interactions are one promising use of mid-air gestures for blind people, as \"listening\"\\' to TV is one of their most common activities. Thus, we investigated mid-air TV gestures for blind people through two studies. Study 1 used a user-elicitation approach where blind people were asked to define gestures given a set of commands. Then, we present a classification of gesture types and the frequency of body parts usage. Nevertheless, our participants had difficulty imagining gestures for some commands. Thus, we conducted Study 2 that used a choice-based elicitation approach where the participants selected their favorite gesture from a predefined list of choices. We found that providing choices help guide users to discover suitable gestures for unfamiliar commands. We discuss concrete design guidelines for mid-air TV gestures for blind people.',\n",
              "  'CyclopsRing: Enabling Whole-Hand and Context-Aware Interactions Through a Fisheye Ring.[SEP]This paper presents CyclopsRing, a ring-style fisheye imaging wearable device that can be worn on hand webbings to en- able whole-hand and context-aware interactions. Observing from a central position of the hand through a fisheye perspective, CyclopsRing sees not only the operating hand, but also the environmental contexts that involve with the hand-based interactions. Since CyclopsRing is a finger-worn device, it also allows users to fully preserve skin feedback of the hands. This paper demonstrates a proof-of-concept device, reports the performance in hand-gesture recognition using random decision forest (RDF) method, and, upon the gesture recognizer, presents a set of interaction techniques including on-finger pinch-and-slide input, in-air pinch-and-motion input, palm-writing input, and their interactions with the environ- mental contexts. The experiment obtained an 84.75% recognition rate of hand gesture input from a database of seven hand gestures collected from 15 participants. To our knowledge, CyclopsRing is the first ring-wearable device that supports whole-hand and context-aware interactions.',\n",
              "  \"Small gestures go a long way: how many bits per gesture do recognizers actually need?[SEP]We investigate in this work the effect of bit depth on the performance of today's commonly used nearest-neighbor gesture recognizers. As current bit representations are typically an artifact of today's hardware and file formats, they are not reflective of the true cardinality of gesture data. We show that as few as 4-5 bits per gesture channel (x/y) are enough in order to attain peak recognition for Euclidean, Cosine, DTW, and Hausdorff distances. We also show how reduction in bit depth can lead to 85 times less memory for storing the training set without ruining recognition performance. The results will benefit practitioners of the next age of gesture sensing gadgets and devices that need to optimize speed, memory, and bit depth representation in their software and hardware designs.\",\n",
              "  'Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard.[SEP]We present a new type of augmented mechanical keyboard, capable of sensing rich and expressive motion gestures performed both on and directly above the device. Our hardware comprises of low-resolution matrix of infrared (IR) proximity sensors interspersed between the keys of a regular mechanical keyboard. This results in coarse but high frame-rate motion data. We extend a machine learning algorithm, traditionally used for static classification only, to robustly support dynamic, temporal gestures. We propose the use of motion signatures a technique that utilizes pairs of motion history images and a random forest based classifier to robustly recognize a large set of motion gestures on and directly above the keyboard. Our technique achieves a mean per-frame classification accuracy of 75.6% in leave-one-subject-out and 89.9% in half-test/half-training cross-validation. We detail our hardware and gesture recognition algorithm, provide performance and accuracy numbers, and demonstrate a large set of gestures designed to be performed with our device. We conclude with qualitative feedback from users, discussion of limitations and areas for future work.'],\n",
              " '15_classification_class_feature_kernel': ['Regularized discriminant analysis for high dimensional, low sample size data.[SEP]Linear and Quadratic Discriminant Analysis have been used widely in many areas of data mining, machine learning, and bioinformatics. Friedman proposed a compromise between Linear and Quadratic Discriminant Analysis, called Regularized Discriminant Analysis (RDA), which has been shown to be more flexible in dealing with various class distributions. RDA applies the regularization techniques by employing two regularization parameters, which are chosen to jointly maximize the classification performance. The optimal pair of parameters is commonly estimated via cross-validation from a set of candidate pairs. It is computationally prohibitive for high dimensional data, especially when the candidate set is large, which limits the applications of RDA to low dimensional data.In this paper, a novel algorithm for RDA is presented for high dimensional data. It can estimate the optimal regularization parameters from a large set of parameter candidates efficiently. Experiments on a variety of datasets confirm the claimed theoretical estimate of the efficiency, and also show that, for a properly chosen pair of regularization parameters, RDA performs favorably in classification, in comparison with other existing classification methods.',\n",
              "  'Binary Classifier Calibration Using an Ensemble of Near Isotonic Regression Models.[SEP]Learning accurate probabilistic models from data is crucial in many practical tasks in data mining. In this paper we present a new non-parametric calibration method called Ensemble of Near Isotonic Regression (ENIR). The method can be considered as an extension of BBQ, a recently proposed calibration method, as well as the commonly used calibration method based on isotonic regression (IsoRegC). ENIR is designed to address the key limitation of IsoRegC which is the monotonicity assumption of the predictions. Similar to BBQ, the method post-processes the output of a binary classifier to obtain calibrated probabilities. Thus it can be used with many existing classification models to generate accurate probabilistic predictions. We demonstrate the performance of ENIR on synthetic and real datasets for commonly applied binary classification models. Experimental results show that the method outperforms several common binary classifier calibration methods. In particular on the real data, ENIR commonly performs statistically significantly better than the other methods, and never worse. It is able to improve the calibration power of classifiers, while retaining their discrimination power. The method is also computationally tractable for large scale datasets, as it is O(N log N) time, where N is the number of samples.',\n",
              "  'Transductive Component Analysis.[SEP]In this paper, we study semisupervised linear dimensionality reduction. Beyond conventional supervised methods which merely consider labeled instances, the semisupervised scheme allows to leverage abundant and ample unlabeled instances into learning so as to achieve better generalization performance. Under semisupervised settings, our objective is to learn a smooth as well as discriminative subspace and linear dimensionality reduction is thus achieved by mapping all samples into the subspace. Specifically, we present the transductive component analysis (TCA) algorithm to generate such a subspace founded on a graph-theoretic framework. Considering TCA is nonorthogonal, we further present the orthogonal transductive component analysis (OTCA) algorithm to iteratively produce a series of orthogonal basis vectors. OTCA has better discriminating power than TCA. Experiments carried out on synthetic and real-world datasets by OTCA show a clear improvement over the results of representative dimensionality reduction algorithms.',\n",
              "  'Extracting key-substring-group features for text classification.[SEP]In many text classification applications, it is appealing to take every document as a string of characters rather than a bag of words. Previous research studies in this area mostly focused on different variants of generative Markov chain models. Although discriminative machine learning methods like Support Vector Machine (SVM) have been quite successful in text classification with word features, it is neither effective nor efficient to apply them straightforwardly taking all substrings in the corpus as features. In this paper, we propose to partition all substrings into statistical equivalence groups, and then pick those groups which are important (in the statistical sense) as features (named key-substring-group features) for text classification. In particular, we propose a suffix tree based algorithm that can extract such features in linear time (with respect to the total number of characters in the corpus). Our experiments on English, Chinese and Greek datasets show that SVM with key-substring-group features can achieve outstanding performance for various text classification tasks.',\n",
              "  'A parallel learning algorithm for text classification.[SEP]Text classification is the process of classifying documents into predefined categories based on their content. Existing supervised learning algorithms to automatically classify text need sufficient labeled documents to learn accurately. Applying the Expectation-Maximization (EM) algorithm to this problem is an alternative approach that utilizes a large pool of unlabeled documents to augment the available labeled documents. Unfortunately, the time needed to learn with these large unlabeled documents is too high. This paper introduces a novel parallel learning algorithm for text classification task. The parallel algorithm is based on the combination of the EM algorithm and the naive Bayes classifier. Our goal is to improve the computational time in learning and classifying process. We studied the performance of our parallel algorithm on a large Linux PC cluster called PIRUN Cluster. We report both timing and accuracy results. These results indicate that the proposed parallel algorithm is capable of handling large document collections.',\n",
              "  \"A Bayesian Hierarchical Model for Comparing Average F1 Scores.[SEP]In multi-class text classification, the performance (effectiveness) of a classifier is usually measured by micro-averaged and macro-averaged F1 scores. However, the scores themselves do not tell us how reliable they are in terms of forecasting the classifier's future performance on unseen data. In this paper, we propose a novel approach to explicitly modelling the uncertainty of average F1 scores through Bayesian reasoning, and demonstrate that it can provide much more comprehensive performance comparison between text classifiers than the traditional frequentist null hypothesis significance testing (NHST).\"],\n",
              " '16_gaze_eye_attention_head': [\"Detecting eye contact using wearable eye-tracking glasses.[SEP]We describe a system for detecting moments of eye contact between an adult and a child, based on a single pair of gaze-tracking glasses which are worn by the adult. Our method utilizes commercial gaze tracking technology to determine the adult's point of gaze, and combines this with computer vision analysis of video of the child's face to determine their gaze direction. Eye contact is then detected as the event of simultaneous, mutual looking at faces by the dyad. We report encouraging findings from an initial implementation and evaluation of this approach.\",\n",
              "  'VRpursuits: interaction in virtual reality using smooth pursuit eye movements.[SEP]Gaze-based interaction using smooth pursuit eye movements (Pursuits) is attractive given that it is intuitive and overcomes the Midas touch problem. At the same time, eye tracking is becoming increasingly popular for VR applications. While Pursuits was shown to be effective in several interaction contexts, it was never explored in-depth for VR before. In a user study (N=26), we investigated how parameters that are specific to VR settings influence the performance of Pursuits. For example, we found that Pursuits is robust against different sizes of virtual 3D targets. However performance improves when the trajectory size (e.g., radius) is larger, particularly if the user is walking while interacting. While walking, selecting moving targets via Pursuits is generally feasible albeit less accurate than when stationary. Finally, we discuss the implications of these findings and the potential of smooth pursuits for interaction in VR by demonstrating two sample use cases: 1) gaze-based authentication in VR, and 2) a space meteors shooting game.',\n",
              "  'Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets.[SEP]Although gaze is an attractive modality for pervasive interactions, the real-world implementation of eye-based interfaces poses significant challenges, such as calibration. We present Pursuits, an innovative interaction technique that enables truly spontaneous interaction with eye-based interfaces. A user can simply walk up to the screen and readily interact with moving targets. Instead of being based on gaze location, Pursuits correlates eye pursuit movements with objects dynamically moving on the interface. We evaluate the influence of target speed, number and trajectory and develop guidelines for designing Pursuits-based interfaces. We then describe six realistic usage scenarios and implement three of them to evaluate the method in a usability study and a field study. Our results show that Pursuits is a versatile and robust technique and that users can interact with Pursuits-based interfaces without prior knowledge or preparation phase.'],\n",
              " '17_haptic_tactile_force_virtual': [\"Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation.[SEP]We present Haptic Links, electro-mechanically actuated physical connections capable of rendering variable stiffness between two commodity handheld virtual reality (VR) controllers. When attached, Haptic Links can dynamically alter the forces perceived between the user's hands to support the haptic rendering of a variety of two-handed objects and interactions. They can rigidly lock controllers in an arbitrary configuration, constrain specific degrees of freedom or directions of motion, and dynamically set stiffness along a continuous range. We demonstrate and compare three prototype Haptic Links: Chain, Layer-Hinge, and Ratchet-Hinge. We then describe interaction techniques and scenarios leveraging the capabilities of each. Our user evaluation results confirm that users can perceive many two-handed objects or interactions as more realistic with Haptic Links than with typical unlinked VR controllers.\",\n",
              "  \"Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality.[SEP]Influence of interaction fidelity and rendering quality on perceived user experience have been largely explored in Virtual Reality (VR). However, differences in interaction choices triggered by these rendering cues have not yet been explored. We present a study analysing the effect of thermal visual cues and contextual information on 50 participants' approach to grasp and move a virtual mug. This study comprises 3 different temperature cues (baseline empty, hot and cold) and 4 contextual representations; all embedded in a VR scenario. We evaluate 2 different hand representations (abstract and human) to assess grasp metrics. Results show temperature cues influenced grasp location, with the mug handle being predominantly grasped with a smaller grasp aperture for the hot condition, while the body and top were preferred for baseline and cold conditions.\",\n",
              "  'Haptic Device Control - Will it Fit Standardized Input Models?[SEP]Over recent years a wide variety of interaction devices involving haptic feedback have been brought to the market, but they vary widely in terms of input measures recorded. These range from one dimensional input on a haptic feedback steering wheel to a six degree of freedom position and orientation device and further, to assemblies of such devices. On the surface most of the variations can be accommodated logically with standardized input models combining existing logical input devices and haptic feedback processes as acknowledgement/echos. However it is very uncertain whether such a model can adequately model the system requirements for effective haptic feedback.'],\n",
              " '18_rendering_graphics_gpu_splatting': ['Graphics processing on a graphics supercomputer.[SEP]A description is given of the Titan Graphics Supercomputer. The primary design philosophy was to have as little redundant hardware as possible and to make as much of the hardware available to compiled application code as possible. This led to a design with multiple parallel processors, each with an integer unit and a vector floating-point unit. The system provides 3D graphics and image processing, using the main processors for most computations. The graphics subsystem consists of only a frame buffer with rasterization (vector and triangle pixel drawing) support. The Titan architecture provides a very good balance of computation and graphics but to make it more competitive in graphics or imaging-intensive applications, a special-purpose accelerator also fits into the architecture.< >',\n",
              "  'A display system for the Stellar graphics supercomputer model GS1000.[SEP]This paper describes a high performance display system that has been incorporated into the overall architecture of the Stellar Graphics Supercomputer Model GS1000. The display system is tightly coupled to the CPU, memory system and vector processing unit of this supercomputer, and is capable of rendering 150,000 shaded triangles/sec, and 600,000 short vectors/sec. The goal of the architecture is to share hardware resources between the CPU and display system and achieve a high bandwidth connection between them. This coupling of the display system and the processor, the architecture of the rendering processor, and the two ASICs that are used to implement the rendering processor are described.In addition, the display system architecture is contrasted to other approaches to high performance graphics, and design trade-offs and possible extensions are described. The implementation of popular display algorithms on the architecture is discussed, and their performance specified. The reader is advised that Stellar Computer Inc. is seeking patent protection for work described in this paper.',\n",
              "  'The Truga001: A Scalable Rendering Processor.[SEP]To support the increasing interest in virtual reality systems, computer graphics must now be extremely powerful to obtain realistic images. VR systems are based on two technical tools: graphics accelerators and pixel renderers. The paper discusses the Truga001 single-chip rendering processor for virtual reality and multimedia systems. It embeds 12 graphics processors and 7 special modules in a single chip.',\n",
              "  'An efficient multi-resolution framework for high quality interactive rendering of massive point clouds using multi-way kd-trees.[SEP]We present an efficient technique for out-of-core multi-resolution construction and high quality interactive visualization of massive point clouds. Our approach introduces a novel hierarchical level of detail (LOD) organization based on multi-way kd-trees, which simplifies memory management and allows control over the LOD-tree height. The LOD tree, constructed bottom up using a fast high-quality point simplification method, is fully balanced and contains all uniformly sized nodes. To this end, we introduce and analyze three efficient point simplification approaches that yield a desired number of high-quality output points. For constant rendering performance, we propose an efficient rendering-on-a-budget method with asynchronous data loading, which delivers fully continuous high quality rendering through LOD geo-morphing and deferred blending. Our algorithm is incorporated in a full end-to-end rendering system, which supports both local rendering and cluster-parallel distributed rendering. The method is evaluated on complex models made of hundreds of millions of point samples.',\n",
              "  \"Optimized Pattern-Based Adaptive Mesh Refinement Using GPU.[SEP]The high performance of GPUs and the increasing use of their programming mechanisms have fostered the development of graphics applications that better exploit the raw power of these devices to achieve higher levels of realism. Silhouette refinement, as one of the techniques that help to improve realism, has profited from GPUs' advances in recent years. In this paper, we present a method for triangular mesh refinement which alleviates the problem of rugged silhouettes. We demonstrate that, through a clever indexing scheme, our method is able to use adaptive patterns in an optimized way, taking full advantage of the GPU's parallelism. The ideas we used were adapted from distinct previous works, but our method presents astounding performance gains. Also, our method works very well with existing meshes, therefore, it can improve the visual appearance of existing models without mesh redesign.\",\n",
              "  'Optimized View-Dependent Rendering for Large Polygonal Datasets.[SEP]In this paper we are presenting a novel approach for rendering large datasets in a view-dependent manner. In a typical view-dependent rendering framework, an appropriate level of detail is selected and sent to the graphics hardware for rendering at each frame. In our approach, we have successfully managed to speed up the selection of the level of detail as well as the rendering of the selected levels. We have accelerated the selection of the appropriate level of detail by not scanning active nodes that do not contribute to the incremental update of the selected level of detail. Our idea is based on imposing a spatial subdivision over the view-dependence trees data-structure, which allows spatial tree cells to refine and merge in real-time rendering to comply with the changes in the active nodes list. The rendering of the selected level of detail is accelerated by using vertex arrays. To overcome the dynamic changes in the selected levels of detail we use multiple small vertex arrays whose sizes depend on the memory on the graphics hardware. These multiple vertex arrays are attached to the active cells of the spatial tree and represent the active nodes of these cells. These vertex arrays, which are sent to the graphics hardware at each frame, merge and split with respect to the changes in the cells of the spatial tree.',\n",
              "  'Volume Rendering on a Distributed Memory Parallel Computer.[SEP]A prototype implementation of a splatting volume renderer (SVR) on a commercially available distributed memory MIMD (multiple instruction stream, multiple data stream) parallel processor, the nCUBE2, is described. Some relatively good rendering times can be achieved with the nCUBE SVR. Message-passing bottlenecks occur when large numbers of floating-point values have to be collected from every processor for every picture. For large images this is a severe limitation. An initial implementation of a SVR on a distributed memory parallel computer demonstrates the need for parallel computers with high-bandwidth connections between processors, and also for new parallelizable volume rendering algorithms.< >',\n",
              "  'Algorithms for rendering realistic terrain image sequences and their parallel implementation.[SEP]We present algorithms for rendering realistic images of large terrains and their implementation on a parallel computer for rapid production of terrain-animation sequences. “Large” means datasets too large for RAM. A hybrid ray-casting and projection technique incorporates quadtree subdivision techniques and filtering using precomputed bit masks. Hilbert space-filling curves determine the imagepixel rendering order. A parallel version of the algorithm is based on a Meiko parallel computer architecture, designed to relieve dataflow bottlenecks and exploit temporal image coherence. Our parallel system, incorporating 26 processors, can generate a full color-terrain image at video resolution (without noticable aliasing artifacts) every 2 s, including I/O and communication overheads.',\n",
              "  'A sorting classification of parallel rendering.[SEP]We describe a classification scheme that we believe provides a more structured framework for reasoning about parallel rendering. The scheme is based on where the sort from object coordinates to screen coordinates occurs, which we believe is fundamental whenever both geometry processing and rasterization are performed in parallel. This classification scheme supports the analysis of computational and communication costs, and encompasses the bulk of current and proposed highly parallel renderers - both hardware and software. We begin by reviewing the standard feed-forward rendering pipeline, showing how different ways of parallelizing it lead to three classes of rendering algorithms. Next, we consider each of these classes in detail, analyzing their aggregate processing and communication costs, possible variations, and constraints they may impose on rendering applications. Finally, we use these analyses to compare the classes and identify when each is likely to be preferable.< >'],\n",
              " '19_mining_frequent_itemsets_rules': ['Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking.[SEP]Mining for frequent item sets can generate an overwhelming number of patterns, often exceeding the size of the original transactional database. One way to deal with this issue is to set filters and interestingness measures. Others advocate the use of constraints to apply to the patterns, either on the form of the patterns or on descriptors of the items in the patterns. However, typically the filtering of patterns based on these constraints is done as a post-processing phase. Filtering the patterns post-mining adds a significant overhead, still suffers from the sheer size of the pattern set and loses the opportunity to exploit those constraints. In this paper we propose an approach that allows the efficient mining of frequent item sets patterns, while pushing simultaneously both monotone and anti-monotone constraints during and at different strategic stages of the mining process. Our implementation shows a significant improvement when considering the constraints early and a better performance over Dualminer which also considers both types of constraints.',\n",
              "  'Optimizing Constraint-Based Mining by Automatically Relaxing Constraints.[SEP]In constraint-based mining, the monotone and anti-monotone properties are exploited to reduce the search space. Even if a constraint has not such suitable properties, existing algorithms can be re-used thanks to an approximation, called relaxation. In this paper, we automatically compute monotone relaxations of primitive-based constraints. First, we show that the latter are a superclass of combinations of both kinds of monotone constraints. Second, we add two operators to detect the properties of monotonicity of such constraints. Finally, we define relaxing operators to obtain monotone relaxations of them.',\n",
              "  'DualMiner: a dual-pruning algorithm for itemsets with constraints.[SEP]Constraint-based mining of itemsets for questions such as \"find all frequent itemsets where the total price is at least $50\" has received much attention recently. Two classes of constraints, monotone and antimonotone, have been identified as very useful. There are algorithms that efficiently take advantage of either one of these two classes, but no previous algorithms can efficiently handle both types of constraints simultaneously. In this paper, we present the first algorithm (called DualMiner) that uses both monotone and antimonotone constraints to prune its search space. We complement a theoretical analysis and proof of correctness of DualMiner with an experimental study that shows the efficacy of DualMiner compared to previous work.',\n",
              "  'CoLe: A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection.[SEP]We present CoLe, a cooperative data mining approach for discovering hybrid knowledge. It employs multiple different data mining algorithms, and combines results from them to enhance the mined knowledge. For our medical application area, we analyse several focusing strategies that allowed us to gain medically significant results.',\n",
              "  'MMAC: A New Multi-Class, Multi-Label Associative Classification Approach.[SEP]Building fast and accurate classifiers for large-scale databases is an important task in data mining. There is growing evidence that integrating classification and association rule mining together can produce more efficient and accurate classifiers than traditional classification techniques. In this paper, the problem of producing rules with multiple labels is investigated. We propose a new associative classification approach called multi-class, multi-label associative classification (MMAC). This paper also presents three measures for evaluating the accuracy of data mining classification approaches to a wide range of traditional and multi-label classification problems. Results for 28 different datasets show that the MMAC approach is an accurate and effective classification technique, highly competitive and scalable in comparison with other classification approaches.',\n",
              "  'Brute-Force Mining of High-Confidence Classification Rules.[SEP]This paper investigates a brute-force technique for mining classification rules from large data sets. We employ an association rule miner enhanced with new pruning strategies to control combinatorial explosion in the number of candidates counted with each database pass. The approach effectively and efficiently extracts high confidence classification rules that apply to most if not all of the data in several classification benchmarks.'],\n",
              " '1_language_word_linguistic_lexical': ['The role of word-word co-occurrence in word learning.[SEP]A growing body of research on early word learning suggests that learners gather word-object co-occurrence statistics across learning situations. Here we test a new mechanism whereby learners are also sensitive to word-word co-occurrence statistics. Indeed, we find that participants can infer the likely referent of a novel word based on its co-occurrence with other words, in a way that mimics a machine learning algorithm dubbed ‘zero-shot learning’. We suggest that the interaction between referential and distributional regularities can bring robustness to the process of word acquisition',\n",
              "  'Interlocutors preserve complexity in language.[SEP]Why do languages change? One possibility is they evolve in response to two competing pressures: (1) to be easily learned, and (2) to be effective for communication. In a number of domains, variation in the world’s natural languages appears to be accounted for by different but near-optimal tradeoffs between these pressures. Models of these evolutionary processes have used transmission chain paradigms in which errors of learning by one agent become the input for the subsequent generation. However, a critical feature of human language is that children do not learn in isolation. Rather, they learn in communicative interactions with caregivers who draw inferences from their errorful productions to their intended interests. In a set of iterated reproduction experiments, we show that this supportive context can have a powerful stabilizing role in the development of artificial patterned systems, allowing them to achieve higher levels of complexity than they would by vertical transmission alone while retaining equivalent transmission accuracies.',\n",
              "  'Linguistic Structure Evolves to Match Meaning Structure.[SEP]Quantitative analysis has usually highlighted the random nature of linguistic forms (Zipf, 1949). We zoom in on three structured samples of language (numerals; playing cards; and a corpus of artificial languages from Kirby, Cornish & Smith 2008) to quantitative explore and illustrate the idea that linguistic forms are nonrandom in that their structure reflects the structure of the meanings they convey. A novel methodology returns frequency spectra showing the distribution of character n-gram frequencies in our language samples. These spectra, purely derived from linguistic form, clearly reflect the quantitative structure of the underlying meaning spaces, as verified with a new information theoretical metric of compositionality. Moreover, analyses of a diachronic corpus of languages show that linguistic structure gradually adapts to match the structure of meanings over cultural transmission.',\n",
              "  'Eye-tracking situated language comprehension: Immediate actor gaze versus recent action events.[SEP]Visual-world eye-tracking findings suggest visual cues rapidly affect spoken sentence comprehension. When participants saw an actor perform an action and then listened to a related sentence (NP1-VERB-ADV-NP2), they preferentially inspected the “recent” over another “future” event target, and this even when future events were much more frequent. The current studies assessed to which extent this recent-event preference is modulated by another situation-immediate cue to the future event target (an actor’s gaze). Half of the sentences referenced a future event, and the experimenter performed one “recent” action before and one “future” action after the sentence. On 50% of the trials, he gazed at the future target object during the verb (Experiment 1) or at verb onset (Experiment 2). Results showed that gaze and future tense together cued attention to the future target; however gaze did not completely override the recent event preference.',\n",
              "  'Response direction and sentence-tense compatibility effects: An eye tracking study.[SEP]Recent evidence shows tense-response compatibility effects only when the task relates to sentence tense (Ulrich & Maienborn, 2010). In two eye-tracking experiments, we investigated tense-response compatibility effects. In our first experiment (E1, where sentence tense was relevant to the task) we found compatibility effects at the beginning of the sentence (e.g., Yesterday versus Tomorrow), which shifted to interference effects by sentence end. Overall, we also found compatibility effects in response times, replicating Ulrich and Maienborn. Both compatibility effects in Experiment 1 (E1) were stronger for low- compared to high-WM readers. In Experiment 2 (E2, where tense was irrelevant), we found compatibility effects for high-WM readers, but only in early reading measures. These results suggest that compatibility effects are weaker depending on the task, but not eliminated; an implication which may help refine a strict view of embodied cognition.',\n",
              "  \"Visual attention during spatial language comprehension: Reference alone isn't enough.[SEP]When people listen to sentences referring to objects and events in visual context, their visual attention to objects is closely time-locked to words in the unfolding utterance. How precisely people deploy attention during situated language understanding and in verifying (spatial) utterances is, however, unclear. A ‘visual world’ hypothesis suggests that we look at what is mentioned (Tanenhaus et al., 1995) and anticipate likely referents based on linguistic cues (Altmann & Kamide, 1999). In spatial language research, in contrast, the Attention Vector Sum model (Regier & Carlson, 2001) predicts that in order to process a sentence such as “The plant is above the clock”, attention must shift from the clock to the plant. An eye-tracking study examined whether gaze pattern during comprehension of spatial descriptions support the visual world or the Attention Vector Sum account. Analyses of eye movements indicate that we need both accounts to accommodate the findings.\",\n",
              "  \"Monsieur, azonnal k[SEP]Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems. This paper proposes a new way to compensate for such resource-scarce languages, based on the fact that most languages share a common vocabulary. Concretely, our approach leverages a family of languages closely related to the speaker's native language to construct translations in a coherent mix of these languages. Experimental results indicate that these translations can be easily understood, being also a useful aid for users who are not proficient in foreign languages. Therefore this work significantly contributes to HCI in two ways: it establishes a language that can improve how applications communicate to their users, and it reports insights on the user acceptance towards the method.\",\n",
              "  'Effects of machine translation on collaborative work.[SEP]Even though multilingual communities that use machine translation to overcome language barriers are increasing, we still lack a complete understanding of how machine translation affects communication. In this study, eight pairs from three different language communities--China, Korea, and Japan--worked on referential tasks in their shared second language (English) and in their native languages using a machine translation embedded chat system. Drawing upon prior research, we predicted differences in conversational efficiency and content, and in the shortening of referring expressions over trials. Quantitative results combined with interview data show that lexical entrainment was disrupted in machine translation-mediated communication because echoing is disrupted by asymmetries in machine translations. In addition, the process of shortening referring expressions is also disrupted because the translations do not translate the same terms consistently throughout the conversation. To support natural referring behavior in machine translation-mediated communication, we need to resolve asymmetries and inconsistencies caused by machine translations.',\n",
              "  \"Machine translation vs. common language: effects on idea exchange in cross-lingual groups.[SEP]Diversity among members of international teams can be a valuable source of novel ideas. However, to reap these benefits, groups need to overcome communication barriers that stem from differences in members' native languages. We compare two strategies for overcoming these barriers: the use of English as a common language, and the use of machine translation (MT) tools that allow each person to communicate in his or her own native language. Dyads consisting of one English-speaking American and one native Mandarin-speaking Chinese participant exchanged ideas to perform brainstorming tasks, either through English or using MT. We found that MT helped the non-native English speakers produce ideas but that both native and non-native English speakers viewed MT-mediated messages as less comprehensible than English messages. The findings suggest it can be effective to support cross-lingual communication with asymmetric design, using MT technology to help people produce messages in their native languages, while leaving incoming messages untranslated and leveraging people's second language proficiency for comprehension.\"],\n",
              " '20_image_images_retrieval_recognition': ['A Strategy for Boundary Detection Combining Region and Edge Information.[SEP]A method to detect boundaries in in natural color images is here proposed, combining edge information and region information. This unsupervised fully automatic process uses edge map information to eliminate false boundaries in the image region map, and region map information to remove noise in the image edge map. Thus, it integrates these two maps into a single one to get the final result. This proposal is extensively compared to the multi-label graph cut approach, since both approaches are unsupervised and fully automatic, as well as receive the same two inputs, although performing different processing. Experiments performed on a large set of natural color images were the base for such comparison. The results show that the approach here proposed is promising, besides allowing interesting interpretations about boundary detection.',\n",
              "  'How to Complete Any Segmentation Process Interactively via Image Foresting Transform.[SEP]The segmentation of poorly defined structures in medical imaging and heterogeneous objects in natural images usually call for considerable user assistance. Consequently, automatic results are often far from desirable and interactive repairs become an essential feature to consider. However, how to import automatic results obtained from external processes and complete their segmentation interactively is an issue, since different tools are based on different optimization criteria. Another simpler related problem concerns how to continue a previous segmentation obtained by the same interactive tool. This ability to stop and later resume interactive segmentation sessions is specially important for tridimensional images and video. However, very often crucial data (e.g., the history of user input) are no longer available; or are no longer reliable, as consequence of some post-processing. How to offer a comprehensive recovery and resume capability, comprising all these different scenarios, under the framework of the \"Image Foresting Transform\" (IFT) is the central focus of this paper.',\n",
              "  'Interactive Segmentation by Image Foresting Transform on Superpixel Graphs.[SEP]There are many scenarios in which user interaction is essential for effective image segmentation. In this paper, we present a new interactive segmentation method based on the Image Foresting Transform (IFT). The method over segments the input image, creates a graph based on these segments (super pixels), receives markers (labels) drawn by the user on some super pixels and organizes a competition to label every pixel in the image. Our method has several interesting properties: it is effective, efficient, capable of segmenting multiple objects in almost linear time on the number of super pixels, readily extendable through previously published techniques, and benefits from domain-specific feature extraction. We also present a comparison with another technique based on the IFT, which can be seen as its pixel-based counterpart. Another contribution of this paper is the description of automatic (robot) users. Given a ground truth image, these robots simulate interactive segmentation by trained and untrained users, reducing the costs and biases involved in comparing segmentation techniques.',\n",
              "  'Spatio-Temporal Frames in a Bag-of-Visual-Features Approach for Human Actions Recognition.[SEP]The recognition of human actions from videos has several interesting and important applications, and a vast amount of different approaches has been proposed for this task in different settings. Such approaches can be broadly categorized in model-based and model-free. Typically, model-based approaches work only in very constrained settings, and because of that, a number of model-free approaches appeared in the last years. Among them, those based in bag-of-visual-features (BoVF) have been proving to be the most consistently successful, being used by several independent authors. For videos to be represented by BoVFs, though, an important issue that arises is how to represent dynamic information. Most existing proposals consider the video as a spatio-temporal volume and then describe \"volumetric patches\" around 3D interest points. In this work, we propose to build a BoVF representation for videos by collecting 2D interest points directly. The basic idea is to gather such points not only from the traditional frames (xy planes), but also from those planes along the time axis, which we call the spatio-temporal frames. Our assumption is that such features are able to capture dynamic information from the videos, and are therefore well-suited to recognize human actions from them, without the need of 3D extentions for the descriptors. In our experiments, this approach achieved state-of-the-art recognition rates on a well-known human actions database, even when compared to more sophisticated schemes.',\n",
              "  'A survey on activity recognition and behavior understanding in video surveillance.[SEP]This paper provides a comprehensive survey for activity recognition in video surveillance. It starts with a description of simple and complex human activity, and various applications. The applications of activity recognition are manifold, ranging from visual surveillance through content based retrieval to human computer interaction. The organization of this paper covers all aspects of the general framework of human activity recognition. Then it summarizes and categorizes recent-published research progresses under a general framework. Finally, this paper also provides an overview of benchmark databases for activity recognition, the market analysis of video surveillance, and future directions to work on for this application.',\n",
              "  'Online robust action recognition based on a hierarchical model.[SEP]Action recognition solely based on video data has known to be very sensitive to background activity, and also lacks the ability to discriminate complex 3D motion. With the development of commercial depth cameras, skeleton-based action recognition is becoming more and more popular. However, the skeleton-based approach is still very challenging because of the large variation in human actions and temporal dynamics. In this paper, we propose a hierarchical model for action recognition. To handle confusing motions, a motion-based grouping method is proposed, which can efficiently assign each video a group label, and then for each group, a pre-trained classifier is used for frame-labeling. Unlike previous methods, we adopt a bottom-up approach that first performs action recognition for each frame. The final action label is obtained by fusing the classification to its frames, with the effect of each frame being adaptively adjusted based on its local properties. To achieve online real-time performance and suppressing noise, bag-of-words is used to represent the classification features. The proposed method is evaluated using two challenge datasets captured by a Kinect. Experiments show that our method can robustly recognize actions in real-time.',\n",
              "  'A co-boost framework for learning object categories from Google Images with 1st and 2nd order features.[SEP]Conventional object recognition techniques rely heavily on manually annotated image datasets to achieve good performances. However, collecting high quality datasets is really laborious. The image search engines such as Google Images seem to provide quantities of object images. Unfortunately, a large portion of the search images are irrelevant. In this paper, we propose a semi-supervised framework for learning visual categories from Google Images. We exploit a co-training algorithm, the CoBoost algorithm, and integrate it with two kinds of features, the 1st and 2nd order features, which define bag of words representation and spatial relationship between local features, respectively. We create two boosting classifiers based on the 1st and 2nd order features in the training, during which one classifier provides labels for the other. The 2nd order features are generated dynamically rather than extracted exhaustively to avoid high computation. An active learning technique is also introduced to further improve the performance. Experimental results show that the object models learned from Google Images by our method are competitive with the state-of-the-art unsupervised approaches and some supervised techniques on the standard benchmark datasets.',\n",
              "  'Fast Feature-Oriented Visual Connection for Large Image Collections.[SEP]Deriving the visual connectivity across large image collections is a computationally expensive task. Different from current image‐oriented match graph construction methods which build on pairwise image matching, we present a novel and scalable feature‐oriented image matching algorithm for large collections. Our method improves the match graph construction procedure in three ways. First, instead of building trees repeatedly, we put the feature points of the input image collection into a single kd‐tree and select the leaves as our anchor points. Then we construct an anchor graph from which each feature can intelligently find a small portion of related candidates to match. Finally, we design a new form of adjacency matrix for fast feature similarity measuring, and return all the matches in different photos across the whole dataset directly. Experiments show that our feature‐oriented correspondence algorithm can explore visual connectivity between images with significant improvement in speed.',\n",
              "  'Delimitation of Regions of Interest in Similarity Queries Visualization.[SEP]In Content Based Image Retrieval (CBIR) systems, the visualization of queries allows to add the human visual perception in the analysis process and facilitate the discovery of knowledge. Content-based queries can be performed comparing features extracted from images, such as color, texture, and shape. In this paper we propose ways to delimit the region of interest to be visualized in the execution of queries by similarity in complex datasets. Limiting the amount of data to be visualized allows keeping the distribution of mapped data closer to the real distribution, besides allowing the application of more expensive computational methods for multidimensional projection. The proposed techniques were implemented in a prototype that allows visualizing only the region in which the query is being performed, mapping the data in three-dimensional spaces and allowing users to interact with them, being favored by human perception to improve the analysis and understanding of the data.',\n",
              "  'Computer-Aided Diagnosis in Brain Computed Tomography Screening.[SEP]Currently, interpretation of medical images is almost exclusively made by specialized physicians. Although, the next decades will most certainly be of change and computer-aided diagnosis systems will play an important role in the reading process. Assisted interpretation of medical images has become one of the major research subjects in medical imaging and diagnostic radiology. From a methodological point of view, the main attraction for the resolution of this kind of problem arises from the combination of the image reading made by the radiologists, with the results obtained from using Artificial Intelligence based applications that will contribute to the reduction and eventually the elimination of perception errors. This article describes how machine learning algorithms can help distinguish normal readings in brain Computed Tomography from all its variations. The goal is to have a system that is able to detect normal appearing structures, thus identifying normal studies, making the reading by the radiologist unnecessary for a large proportion of the brain Computed Tomography scans.',\n",
              "  'Effect of layer-wise fine-tuning in magnification-dependent classification of breast cancer histopathological image.[SEP]A large and balanced training data are the foremost requirement in proper convergence of a deep convolutional neural network (CNN). Medical data always suffer from the problem of unbalancing and inadequacy that makes it difficult to train CNN from scratch. It is known that the transfer learning approach provides great potential to deal with inadequate dataset besides the benefit of faster training. The efficient transfer of knowledge from natural images to histopathological images has yet to be achieved. In view of the foregoing, an attempt has been made toward the classification of BreakHis dataset using pre-trained ‘AlexNet’ model with a suitable fine-tuning approach. The effective depth of fine-tuning is also determined at different levels of magnification (40×, 100×, 200× and 400 ×). The experimental trials conform that the moderate level of fine-tuning is an optimum choice for the classification of magnification-dependent histology images in contrast to the shallow and deep tuning of the pre-trained network which in turn depends on the size and relative distribution of a dataset. Additionally, the layer-wise fine-tuning approach provides a neck-to-neck performance with the latest state-of-the-art developments.',\n",
              "  'Semi-supervised Tissue Segmentation of 3D Brain MR Images.[SEP]Clustering algorithms have been popularly applied in tissue segmentation in MRI. However, traditional clustering algorithms could not take advantage of some prior knowledge of data even when it does exist. In this paper, we propose a new approach to tissue segmentation of 3D brain MRI using semi-supervised spectral clustering. Spectral clustering algorithm is more powerful than traditional clustering algorithms since it models the voxel-to-voxel relationship as opposed to voxel-to-cluster relationships. In the semi-supervised spectral clustering, two types of instance-level constraints: must-link and cannot-link as background prior knowledge are incorporated into spectral clustering, and the self-tuning parameter is applied to avoid the selection of the scaling parameter of spectral clustering. The semi-supervised spectral clustering is an effective tissue segmentation method because of its advantages in (1) better discovery of real data structure since there is no cluster shape restriction, (2) high quality segmentation results as it can obtain the global optimal solutions in the relaxed continuous domain by eigen-decomposition and combines the pairwise constraints information. Experimental results on simulated and real MRI data demonstrate its effectiveness.',\n",
              "  'Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring.[SEP]Locality-Sensitive Hashing (LSH) is one of the most popular methods for c-Approximate Nearest Neighbor Search (c-ANNS) in high-dimensional spaces. In this paper, we propose a novel LSH scheme based on the Longest Circular Co-Substring (LCCS) search framework (LCCS-LSH) with a theoretical guarantee. We introduce a novel concept of LCCS and a new data structure named Circular Shift Array (CSA) for k-LCCS search. The insight of LCCS search framework is that close data objects will have a longer LCCS than the far-apart ones with high probability. LCCS-LSH is LSH-family-independent, and it supports c-ANNS with different kinds of distance metrics. We also introduce a multi-probe version of LCCS-LSH and conduct extensive experiments over five real-life datasets. The experimental results demonstrate that LCCS-LSH outperforms state-of-the-art LSH schemes.',\n",
              "  'PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension.[SEP]Similarity search has been widely used in various fields, particularly in the Alibaba ecosystem. The open-source solutions to a similarity search of vectors can only support a query with a single vector, whereas real-life scenarios generally require a processing of compound queries. Moreover, existing open-source implementations only provide runtime libraries, which have difficulty meeting the requirements of industrial applications. To address these issues, we designed a novel scheme for extending the index-type of PostgreSQL (PG), which enables a similar vector search and achieves a high-performance level and strong reliability of PG. Two representative types of nearest neighbor search (NNS) algorithms are presented herein. These algorithms achieve a high performance, and afford advantages such as the support of composite queries and seamless integration of existing business data. The other NNS algorithms can be easily implemented under the proposed framework. Experiments were conducted on large datasets to illustrate the efficiency of the proposed retrieval mechanism.',\n",
              "  'A General and Efficient Querying Method for Learning to Hash.[SEP]As an effective solution to the approximate nearest neighbors (ANN) search problem, learning to hash (L2H) is able to learn similarity-preserving hash functions tailored for a given dataset. However, existing L2H research mainly focuses on improving query performance by learning good hash functions, while Hamming ranking (HR) is used as the default querying method. We show by analysis and experiments that Hamming distance, the similarity indicator used in HR, is too coarse-grained and thus limits the performance of query processing. We propose a new fine-grained similarity indicator, quantization distance (QD), which provides more information about the similarity between a query and the items in a bucket. We then develop two efficient querying methods based on QD, which achieve significantly better query performance than HR. Our methods are general and can work with various L2H algorithms. Our experiments demonstrate that a simple and elegant querying method can produce performance gain equivalent to advanced and complicated learning algorithms.'],\n",
              " '21_software_programmers_collaboration_developers': ['Variolite: Supporting Exploratory Programming by Data Scientists.[SEP]How do people ideate through code? Using semi-structured interviews and a survey, we studied data scientists who program, often with small scripts, to experiment with data. These studies show that data scientists frequently code new analysis ideas by building off of their code from a previous idea. They often rely on informal versioning interactions like copying code, keeping unused code, and commenting out code to repurpose older analysis code while attempting to keep those older analyses intact. Unlike conventional version control, these informal practices allow for fast versioning of any size code snippet, and quick comparisons by interchanging which versions are run. However, data scientists must maintain a strong mental map of their code in order to distinguish versions, leading to errors and confusion. We explore the needs for improving version control tools for exploratory tasks, and demonstrate a tool for lightweight local versioning, called Variolite, which programmers found usable and desirable in a preliminary usability study.',\n",
              "  'Consistency maintenance in real-time collaborative graphics editing systems.[SEP]Real-time collaborative graphics editing systems allow a group of users to view and edit the same graphics document at the same time from geographically dispersed sites connected by communication networks. Consistency maintenance in the face of concurrent accesses to shared objects is one of the core issues in the design of these types of systems. In this article, we propose an object-level multiversioning approach to consistency maintenance in real-time collaborative graphic editors. This approach is novel in achieving intention preservation and convergence, in preserving the work concurrently produced by multiple users in the face of conflict, and in minimizing the number of object versions for conflict resolution. Major technical contributions of this work include a formal specification of a unique combined effect for an arbitrary group of conflict and compatible operations, a distributed algorithm for incremental creation of multiple object versions, a consistent object identification scheme for multiple object versions, and a convergent layering scheme for overlapping objects. All algorithms and schemes presented in this article have been implemented in an Internet-based GRACE (graphics collaborative editing) system.',\n",
              "  'DistEdit: A Distributed Toolkit for Supporting Multiple Group Editors.[SEP]The purpose of our project is to provide toolkits for building applications that support collaboration between people in distributed environments. In this paper, we describe one such toolkit, called DistEdit, that can be used to build interactive group editors for distributed environments. This toolkit has the ability to support different editors simultaneously and provides a high degree of fault-tolerance against machine crashes. To evaluate the toolkit, we modified two editors to make use of the toolkit. The resulting editors allow users to take turns at making changes while other users observe the changes as they occur. We give an evaluation of the toolkit based on the development and use of these editors.',\n",
              "  'Elucidate: employing information visualisation to aid pedagogy for students.[SEP]Understanding the intricacies behind concurrency within object-oriented programming languages has always been a challenge for undergraduate students. While the lecture is a relatively passive learning experience for the student, the use of software visualisation offers the chance to examine the concepts covered in the lecture in an interactive, visual environment. Students can add further dimensions and greater depth to their understanding previously hindered by the pedagogy of this passive environment. Elucidate makes use of the JDI architecture in the Java language to create its own environment that allows students to execute any program within it. Elucidate utilises several information workspaces, each presenting a different perspective about the information, thus facilitating a students ability to employ it in a manner that best allows them to construct their own understanding. Students are able to navigate around multiple views, and through various levels of abstraction, revealing the inner workings and sequence of events in what would otherwise be a black-box program.',\n",
              "  'Viewing Object-Oriented Software with MetricAttitude: An Empirical Evaluation.[SEP]MetricAttitude is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In this paper, we present a preliminary empirical investigation based on a questionnaire-based survey to assess Metric Attitude with respect to source code comprehension tasks. Participants involved in this study were Computer Science students and software professionals. The results suggest that Metric Attitude is a viable means to comprehend source code and that both kinds of participants in the empirical investigation considered it to be appropriate in source code comprehension.',\n",
              "  'Enhancing Software Visualization with Information Retrieval.[SEP]I have enhanced Metric Attitude. It is a visualization tool based on static analysis that provides a mental picture by viewing an object-oriented software system by means of polymetric views. In particular, we have integrated an Information Retrieval engine and named this new version of visualization tool as Metric Attitude++. It allows the user to formulate a textual query and to show on the visual representation of the subject software the elements that are more similar to that query. This could be useful in all those cases in which a user needs to identify (or to localize) features implemented in the source code. Several filters are also available to hide possibly irrelevant details and to ease the browsing and then the comprehension of a software system. Finally, we have applied Metric Attitude++ on a number of object-oriented software systems. In this paper, we report preliminary results of a quantitative study on a widely studied open-source software, namely JEdit. On the basis of our results it seems that Metric Attitude++ can be effectively applied to different kinds of source code comprehension tasks and to concept location in source code, in particular.'],\n",
              " '22_brain_cognitive_attention_visual': ['Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation.[SEP]The rich literature on multiple object tracking (MOT) conclusively demonstrates that humans are able to visually track a small number of objects (Pylyshyn & Storm 1988, Alvarez & Franconeri 2007). There is considerably less agreement on what perceptual and cognitive processes are involved. While it is clear that MOT is attentionally demanding, various accounts of MOT performance centrally involve pre-attentional mechanisms as well. In this paper we present an account of object tracking in the ARCADIA framework (Bridewell & Bello 2015) that treats MOT as dependent upon both pre-attentive and attention-bound processes. We show that with minimal addition this model replicates a variety of core phenomena in the MOT literature and provides an algorithmic explanation of human performance limitations.',\n",
              "  'A Bayesian Model of the Effect of Object Context on Visual Attention.[SEP]Research in visual cognition has demonstrated that scene understanding is influenced by the contextual properties of objects, and a number of computational models have been proposed that capture specific context effects. However, a general model that predicts the fit of an arbitrary object with the context established by the rest of the scene is until now lacking. In this paper, we explain the contextual fit of objects in visual scenes using Bayesian topic models, which we induce from a database of annotated images. We evaluate our models firstly on synthetic object intrusion data, and then on eye-tracking data from a spot-the-difference task and from an object naming experiment. For the synthetic data, we find that our models are able to detect object intrusions accurately. For the eye-tracking data, we show that context scores derived from our models are associated with fixation latencies on target objects.',\n",
              "  'Inattentional Blindness in Visual Search.[SEP]Models of visual salience normally belong to one of two camps: models such as Experience Guided Search (E-GS), which emphasize top-down guidance based on task features, and models such as Attention as Information Maximisation (AIM), which emphasize the role of bottom-up saliency. In this paper, we show that E-GS and AIM are structurally similar and can be unified to create a general model of visual search with includes a generic prior over potential non-task related objects. We demonstrate that this model displays inattentional blindness, and that blindness can be modulated by adjusting the relative precisions of several terms within the model. At the same time, our model correctly accounts for a series of classical visual search results.',\n",
              "  'Learning and Variability in Spiking Neural Networks.[SEP]Neural networks exhibit ongoing, spatio-temporal patterns of spiking activity. Evidence shows that these patterns are metastable, i.e. temporary, transient, and non-stationary. Metastability is theorized to be adaptive for neural and cognitive function, but learning must somehow remain stable in the context of highly variable spike dynamics. In the present study, a neural network learning algorithm is developed to co-exist with intrinsic variability that arises from regulating spike propagation to stay near its critical branching point. The learning algorithm is based on reinforcement traces stored at synapses that change much more slowly than synaptic switches triggered to maintain critical branching. As a result, learning establishes a stable synaptic space within which variability and metastability can arise from critical branching. Model efficacy is demonstrated using time-delayed XOR learning, and spike dynamics are compared with evidence of metastability in hippocampal recordings.',\n",
              "  'Improving with Practice: A Neural Model of Mathematical Development.[SEP]The ability to improve in speed and accuracy as a result of repeating some task is an important hallmark of intelligent biological systems. We model the progression from a counting-based strategy for addition to a recall-based strategy. The model consists of two networks working in parallel: a slower basal ganglia loop, and a faster cortical network. The slow network methodically computes the count from one digit given another, corresponding to the addition of two digits, while the fast network gradually \"memorizes\" the output from the slow network. The faster network eventually learns how to add the same digits that initially drove the behaviour of the slower network. Performance of this model is demonstrated by simulating a fully spiking neural network that includes basal ganglia, thalamus and various cortical areas.',\n",
              "  'Thermodynamics and Cognition: Towards a Lawful Explanation of the Mind.[SEP]An argument is developed to show that the theoretical methods of description for biological and physical systems can be corroborated by appealing to the second law of thermodynamics. The separation dates back to Modern western philosophy, but we show that the second law’s influence on the evolutionary history of life at the scale of the global Earth system—a system that has demonstrated an exponential increase of entropy production over time— justifies rescinding this separation. From this perspective it appears that the necessity of ever increasing entropy in nature may constrain the organization and behavior of living organisms and cognitive processes. We suggest a new framework for understanding cognition by explaining memory at the scale of the brain-body-environment system with respect to its role in increasing entropy in nature. This framework, if developed further, may lead to a fruitful understanding of cognition by appealing to the necessity of physical laws.',\n",
              "  'This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy.[SEP]This project represents a first step towards bridging the gap between HCI and cognition research. Using functional near-infrared spectroscopy (fNIRS), we introduce tech-niques to non-invasively measure a range of cognitive workload states that have implications to HCI research, most directly usability testing. We present a set of usability experiments that illustrates how fNIRS brain measurement provides information about the cognitive demands placed on computer users by different interface designs.',\n",
              "  'Visualizing and manipulating brain dynamics.[SEP]Brain is not a mere input-output information transformation system, but a dynamical system that generates spontaneous spatiotemporal patterns even without sensory inputs, executed movements, or cognitive tasks. These spontaneously generated patterns by brain dynamics are called spontaneous brain activities for experimental animals, and resting state brain activities for humans. The resting state brain activity of an individual contains much information about age, cognitive capability, mental disorder etc. By combining information decoding from brain activity and its neurofeedback in reinforcement learning paradigms, we can unconsciously control brain activity patterns corresponding to specific information. This leads to therapies of psychiatric disorders, unconscious manipulation of facial preferences, color qualia, confidence in decision making, increase of cognitive capability, etc. Ubicomp community can expect this technology will soon be available in much cheaper and lighter devices such as EEG and near infrared spectroscopy instead of heavy and expensive fMRI or MEG.',\n",
              "  'Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks.[SEP]Recent efforts have shown that functional near-infrared spectroscopy (fNIRS) has potential value for brain sensing in HCI user studies. Research has shown that, although large head movement significantly affects fNIRS data, typical keyboard use, mouse movement, and non-task-related verbalisations do not affect measurements during Verbal tasks. This work aims to examine the Reliability of fNIRS, by 1) confirming these prior findings, and 2) significantly extending our understanding of how artefacts affect recordings during Spatial tasks, since much of user interfaces and interaction is inherently spatial. Our results show that artefacts have a significantly different impact during Verbal and Spatial tasks. We contribute clearer insights into using fNIRS as a tool within HCI user studies.',\n",
              "  \"Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze.[SEP]We introduce an image annotation approach for the analysis of volumetric electron microscopic imagery of brain tissue. The core task is to identify and link tubular objects (neuronal fibers) in images taken from consecutive ultrathin sections of brain tissue. In our approach an individual 'flies' through the 3D data at a high speed and maintains eye gaze focus on a single neuronal fiber, aided by navigation with a handheld gamepad controller. The continuous foveation on a fiber of interest constitutes an intuitive means to define a trace that is seamlessly recorded with a desktop eyetracker and transformed into precise 3D coordinates of the annotated fiber (skeleton tracing). In a participant experiment we validate the approach by demonstrating a tracing accuracy of about the respective radiuses of the traced fibers with browsing speeds of up to 40 brain sections per second.\",\n",
              "  'NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity.[SEP]We present NeuroLines, a novel visualization technique designed for scalable detailed analysis of neuronal connectivity at the nanoscale level. The topology of 3D brain tissue data is abstracted into a multi-scale, relative distance-preserving subway map visualization that allows domain scientists to conduct an interactive analysis of neurons and their connectivity. Nanoscale connectomics aims at reverse-engineering the wiring of the brain. Reconstructing and analyzing the detailed connectivity of neurons and neurites (axons, dendrites) will be crucial for understanding the brain and its development and diseases. However, the enormous scale and complexity of nanoscale neuronal connectivity pose big challenges to existing visualization techniques in terms of scalability. NeuroLines offers a scalable visualization framework that can interactively render thousands of neurites, and that supports the detailed analysis of neuronal structures and their connectivity. We describe and analyze the design of NeuroLines based on two real-world use-cases of our collaborators in developmental neuroscience, and investigate its scalability to large-scale neuronal connectivity data.',\n",
              "  \"The Neuron Navigator: Exploring the information pathway through the neural maze.[SEP]Recent advances in microscopic imaging technology have enabled neuroscientists to obtain unprecedentedly clear images of neurons. To extract additional knowledge from the tangled neurons, for example, their connective relationships, is key to understanding how information is processed and transmitted within the brain. In this paper, we will introduce our recent endeavor, the Neuron Navigator (NNG), which integrates a 3D neuron image database into an easy-to-use visual interface. Via a flexible and user-friendly interface, NNG is designed to help researchers analyze and observe the connectivity within the neural maze and discover possible pathways. With NNG's 3D neuron image database, researchers can perform volumetric searches using the location of neural terminals, or the occupation of neuron volumes within the 3D brain space. Also, the presence of the neurons under a combination of spatial restrictions can be shown as well. NNG is a result of a multi-discipline collaboration between neuroscientists and computer scientists, and NNG has now been implemented on a coordinated brain space, that being, the Drosophila (fruit fly) brain. NNG is accessible through: http://211.73.64.34/NNG.\"],\n",
              " '23_trajectory_trajectories_mobility_urban': ['Visual Exploration of Sparse Traffic Trajectory Data.[SEP]In this paper, we present a visual analysis system to explore sparse traffic trajectory data recorded by transportation cells. Such data contains the movements of nearly all moving vehicles on the major roads of a city. Therefore it is very suitable for macro-traffic analysis. However, the vehicle movements are recorded only when they pass through the cells. The exact tracks between two consecutive cells are unknown. To deal with such uncertainties, we first design a local animation, showing the vehicle movements only in the vicinity of cells. Besides, we ignore the micro-behaviors of individual vehicles, and focus on the macro-traffic patterns. We apply existing trajectory aggregation techniques to the dataset, studying cell status pattern and inter-cell flow pattern. Beyond that, we propose to study the correlation between these two patterns with dynamic graph visualization techniques. It allows us to check how traffic congestion on one cell is correlated with traffic flows on neighbouring links, and with route selection in its neighbourhood. Case studies show the effectiveness of our system.',\n",
              "  'Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit.[SEP]The Geospatial Visual Analytics Toolkit intended for exploratory analysis of spatial and spatio-temporal data has been recently enriched with specific visual and computational techniques supporting analysis of data about movement. We applied these and other techniques to the data and tasks of Mini Challenge 4, where it was necessary to analyze tracks of moving people.CR Categories and Subject Descriptors: H.1.2 [User/Machine Systems]: Human information processing - Visual Analytics; 1.6.9 [Visualization]: information visualization.',\n",
              "  'Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats.[SEP]We provide a description of the tools and techniques used in our analysis of the VAST 2008 Challenge dealing with mass movement of persons departing Isla Del Sue.no on boats for the United States during 2005-2007. We used visual analytics to explore migration patterns, characterize the choice and evolution of landing sites, characterize the geographical patterns of interdictions and determine the successful landing rate. Our ComVis tool, in connection with some helper applications and Google Earth, allowed us to explore geo-temporal characteristics of the data set and answer the challenge questions. The ComVis project file captures the visual analysis context and facilitates better collaboration among team members.',\n",
              "  'Mining large-scale, sparse GPS traces for map inference: comparison of approaches.[SEP]We address the problem of inferring road maps from large-scale GPS traces that have relatively low resolution and sampling frequency. Unlike past published work that requires high-resolution traces with dense sampling, we focus on situations with coarse granularity data, such as that obtained from thousands of taxis in Shanghai, which transmit their location as seldom as once per minute. Such data sources can be made available inexpensively as byproducts of existing processes, rather than having to drive every road with high-quality GPS instrumentation just for map building - and having to re-drive roads for periodic updates. Although the challenges in using opportunistic probe data are significant, successful mining algorithms could potentially enable the creation of continuously updated maps at very low cost.',\n",
              "  'Traveling Salesman in Reverse: Conditional Markov Entropy for Trajectory Segmentation.[SEP]We are interested in inferring the set of waypoints (or intermediate destinations) of a mobility trajectory in the absence of timing information. We find that, by mining a dataset of real mobility traces, computing the entropy of conditional Markov trajectory enables us to uncover waypoints, even though no timing information nor absolute geographic location is provided. We build on this observation and design an efficient algorithm for trajectory segmentation. Our empirical evaluation demonstrates that the entropy-based heuristic used by our segmentation algorithm outperforms alternative approaches as it is 43% more accurate than a geometric approach and 20% more accurate than path-stretch based approach. We further explore the link between trajectory entropy, mobility predictability and the nature of intermediate locations using a route choice model on real city maps.',\n",
              "  \"CityMomentum: an online approach for crowd behavior prediction at a citywide level.[SEP]Human movements are difficult to predict, especially, when we consider rare behaviors that deviate from normal daily routines. By tracing the behavior of a person over a long period, we can model their daily routines and predict periodical behaviors, whereas rare behaviors, such as participating in the New Year's Eve countdown, can hardly be predicted readily and thus they have usually been treated as outliers of the daily routines in most existing studies. However, for scenarios such as emergency management or intelligent traffic regulation, we are more interested in rare behaviors than daily routines. Using human mobility Big Data, the rare behavior of each individual in a social crowd is no longer rare and thus it may be predicted when we analyze the crowd behavior at a citywide level. Therefore in this study, instead of predicting movement based on daily routines, we make short-term predictions based on the recent movement observations. We propose a novel model called CityMomentum as a predicting-by-clustering framework for sampling future movement using a mixture of multiple random Markov chains, each of which is a Naive Movement Predictive model trained with the movements of the subjects that belong to each cluster. We apply our approach to a big mobile phone GPS log dataset and predict the short-term future movements, especially during the Comiket 80 and New Year's Eve celebration. We evaluate our prediction by a Earth Mover Distance (EMD) based metric, and show our approach accurately predicts the crowd behavior during the rare crowd events, which makes an early crowd event warning and regulation possible in the emergent situations.\"],\n",
              " '24_graphics_graphic_standards_phigs': ['Object-Oriented Data Modelling for Graphics Databases: a Declarative Approach.[SEP]This paper presents a new scheme to integrate the declarative approach to graphics and object‐oriented data modelling techniques to form a fruitful symbiosis for constraint‐based graphics database systems. It has rich modelling constructs to describe graphics data and allows sharing of representation. It also provides useful mechanisms for management of integrity constraints. We have also identified important classes of constraints in the context of object‐oriented graphics database systems. Examples are given for maintenance of constraints at the time of insertion, deletion and modification.',\n",
              "  'GKS-9x: The Design Output Primitive, an Approach to a Specification.[SEP]This paper describes an approach to the formal definition of the design primitive introduced in the revision of the ISO/IEC computer graphics standard, GKS. The paper starts with a general description of the design primitive and then describes the specification (which is given in the Z notation) and the motivation for the approach taken in some detail. The paper concludes with a reflection on the contribution of this work, and the descriptive style adopted an the GKS revision, to the role of formal description in the presentation of graphics standards.',\n",
              "  'The Effectiveness of High-level Graphical Languages in Dealing with Various Graphical Domains.[SEP]There are many domains in which graphical programming languages can be applied. Use of a particular graphical programing language will be limited if the domains in which it can be applied are restricted. High-level graphical languages provide simply expressed constructs for the definition, manipulation, inquiry, and external representation of graphical data. These capabilities permit the application to various domains of high-level graphical languages. Five specific domains are discussed; an example of an application of the graphical language LIG is presented in each domain.',\n",
              "  'Preface.[SEP]In this issue, we have four additional papers from 35th Computer Graphics International conference (CGI 2018) held on 11–14 June, 2018 in Bintan, Indonesia. Moreover, three papers from Euro VA 2017 held on 12–13 June 2017 in Barcelona, Spain and three papers from Cyberworlds 2017 held on 20–22 September 2017 in Chester, UK are included.',\n",
              "  'A Breezy Summer Read.[SEP]Editor in Chief Torsten Möller discusses the articles in the July/August 2018 issue of IEEE Computer Graphics and Applications.',\n",
              "  'Steps to Effective Business Graphics.[SEP]Europe is becoming aware that a political determination to collaborate is required, if it wants to attain the position it could claim on the basis of its research achievements. This is especially true in the field of Computer Graphics. The program ESPRIT is hopefully a decisive step in this direction.'],\n",
              " '25_series_time_patterns_mining': ['Dual-Domain Hierarchical Classification of Phonetic Time Series.[SEP]Phonemes are the smallest units of sound produced by a human being. Automatic classification of phonemes is a well-researched topic in linguistics due to its potential for robust speech recognition. With the recent advancement of phonetic segmentation algorithms, it is now possible to generate datasets of millions of phonemes automatically. Phoneme classification on such datasets is a challenging data mining task because of the large number of classes (over a hundred) and complexities of the existing methods. In this paper, we introduce the phoneme classification problem as a data mining task. We propose a dual-domain (time and frequency) hierarchical classification algorithm. Our method uses a Dynamic Time Warping (DTW) based classifier in the top layers and time-frequency features in the lower layer. We cross-validate our method on phonemes from three online dictionaries and achieved up to 35% improvement in classification compared to existing techniques. We provide case studies on classifying accented phonemes and speaker invariant phoneme classification.',\n",
              "  \"Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels.[SEP]Unsupervised semantic segmentation in the time series domain is a much-studied problem due to its potential to detect unexpected regularities and regimes in poorly understood data. However, the current techniques have several shortcomings, which have limited the adoption of time series semantic segmentation beyond academic settings for three primary reasons. First, most methods require setting/learning many parameters and thus may have problems generalizing to novel situations. Second, most methods implicitly assume that all the data is segmentable, and have difficulty when that assumption is unwarranted. Finally, most research efforts have been confined to the batch case, but online segmentation is clearly more useful and actionable. To address these issues, we present an algorithm which is domain agnostic, has only one easily determined parameter, and can handle data streaming at a high rate. In this context, we test our algorithm on the largest and most diverse collection of time series datasets ever considered, and demonstrate our algorithm's superiority over current solutions. Furthermore, we are the first to show that semantic segmentation may be possible at superhuman performance levels.\",\n",
              "  'On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis.[SEP]Multivariate time series (MTS) data sets are common in-various multimedia, medical and financial application domains. These applications perform several data-analysis operations on large number of MTS data sets such as similarity searches, feature-subset-selection, clustering and classifications. Correlation-based techniques, such as principal component analysis (PCA), have proven to improve the efficiency of many of the above-mentioned data-analysis operations on MTS, which implies that the correlation coefficients concisely represent the original MTS data. However, if the statistical properties (e.g., variance) of MTS data change over time dimension, i.e., MTS data is non-stationary, the correlation coefficients are not stable. In this paper, we propose to utilize the stationarity of the MTS data sets, in order to represent the original MTS data more stably, as well as concisely with the correlation coefficients. That is, before performing any correlation-based data analysis, we first executes the stationarity test to decide whether the MTS data is stationary or not, i.e., whether the correlation is stable or not. Subsequently, for a non-stationary MTS data set, we difference it to render the data set stationary. Even though our approach is general, to focus the discussion we describe our approach within the context of our previously proposed technique for MTS similarity search. In order to show the validity of our approach, we performed several experiments on four real-world data sets. The results show that the performance of our similarity search technique have significantly improved in terms of precision/recall.',\n",
              "  \"Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations.[SEP]We investigate techniques for visualizing time series data and evaluate their effect in value comparison tasks. We compare line charts with horizon graphs - a space-efficient time series visualization technique - across a range of chart sizes, measuring the speed and accuracy of subjects' estimates of value differences between charts. We identify transition points at which reducing the chart height results in significantly differing drops in estimation accuracy across the compared chart types, and we find optimal positions in the speed-accuracy tradeoff curve at which viewers performed quickly without attendant drops in accuracy. Based on these results, we propose approaches for increasing data density that optimize graphical perception.\",\n",
              "  'Visual-Interactive Preprocessing of Multivariate Time Series Data.[SEP]Pre‐processing is a prerequisite to conduct effective and efficient downstream data analysis. Pre‐processing pipelines often require multiple routines to address data quality challenges and to bring the data into a usable form. For both the construction and the refinement of pre‐processing pipelines, human‐in‐the‐loop approaches are highly beneficial. This particularly applies to multivariate time series, a complex data type with multiple values developing over time. Due to the high specificity of this domain, it has not been subject to in‐depth research in visual analytics. We present a visual‐interactive approach for preprocessing multivariate time series data with the following aspects. Our approach supports analysts to carry out six core analysis tasks related to pre‐processing of multivariate time series. To support these tasks, we identify requirements to baseline toolkits that may help practitioners in their choice. We characterize the space of visualization designs for uncertainty‐aware pre‐processing and justify our decisions. Two usage scenarios demonstrate applicability of our approach, design choices, and uncertainty visualizations for the six analysis tasks. This work is one step towards strengthening the visual analytics support for data pre‐processing in general and for uncertainty‐aware pre‐processing of multivariate time series in particular.',\n",
              "  'Qualizon graphs: space-efficient time-series visualization with qualitative abstractions.[SEP]In several application fields, the joint visualization of quantitative data and qualitative abstractions can help analysts make sense of complex time series data by associating precise numeric values with corresponding domain-specific interpretations, such as good, bad, high, low, normal. At the same time, the need to analyse large multivariate time-oriented datasets often calls for keeping visualizations as compact as possible. In this paper, we introduce Qualizon Graphs, a compact visualization that combines quantitative data and qualitative abstractions. It is based on the well known Horizon Graphs, but instead of a predefined number of equally sized bands, it uses as many bands as qualitative categories with corresponding different sizes. In this way, Qualizon Graphs increase the data density of visualized quantitative values and inherently integrate qualitative abstractions. A user study shows that Qualizon Graphs are as fast and accurate as Horizon Graphs for quantitative data, and are an alternative to state-of-the-art visualizations for both quantitative and qualitative data, enabling a trade-off between speed and accuracy.'],\n",
              " '26_fabrication_printing_print_manufacturing': ['Stress-Constrained Thickness Optimization for Shell Object Fabrication.[SEP]We present an approach to fabricate shell objects with thickness parameters, which are computed to maintain the user‐specified structural stability. Given a boundary surface and user‐specified external forces, we optimize the thickness parameters according to stress constraints to extrude the surface. Our approach mainly consists of two technical components: First, we develop a patch‐based shell simulation technique to efficiently support the static simulation of extruded shell objects using finite element methods. Second, we analytically compute the derivative of stress required in the sensitivity analysis technique to turn the optimization into a sequential linear programming problem. Experimental results demonstrate that our approach can optimize the thickness parameters for arbitrary surfaces in a few minutes and well predict the physical properties, such as the deformation and stress of the fabricated object.',\n",
              "  'Computational Design and Fabrication.[SEP]Computer graphics research is increasingly interested in the high-level analysis and processing of geometric objects. By acquiring a structural or functional understanding of 3D shapes, researchers are able to tackle mid- to high-level design problems for which machine computations can replace or at least relieve human efforts. In parallel, with the rapid advances in 3D printing technologies, many design solutions explored by researchers and practitioners are focusing on the needs and constraints arising from physical fabrication. The contributions in this special issue are cross-disciplinary, connecting physical fabrication with design and processing tasks in new domains including circuit design, geospatial visualization, and 3D scanning, leading to never-before-seen 3D printing applications.',\n",
              "  'Cost-effective printing of 3D objects with self-supporting property.[SEP]The fused deposition modeling (FDM) printer is a simple, affordable and widely used device in the 3D printing society. However, the high price of printing materials is one of major restrictive factors for its further application. Based on the self-supporting property of printing materials, we present an optimization method to reduce the total material consumption of 3D printed objects themselves and their support structures for FDM printers in this paper. We first develop an orientation optimization scheme to reduce the outer support volume of a printed model. The volume is evaluated according to the depths of 3D model fragments obtained by the depth peeling technique in an optimization process. We then build a self-supporting frame with a set of scale-adaptive parallelepiped grids to replace the solid interior of the printed model for further reducing the material consumption. In our orientation optimization scheme, the overhanging area detecting function can detect the self-supporting regions of a 3D model in terms of the depths stored in the graphical processing unit memory. The self-supporting frame with grid structures inside printed models does not need to add additional support structures during the printing process. Experimental results indicate that our method is faster and consumes less printing materials than the state-of-the-art algorithms.',\n",
              "  'TuVe: A Shape-changeable Display using Fluids in a Tube.[SEP]We propose TuVe, a novel shape-changing display consisting of a flexible tube and fluids, in which the droplets flowing through the tube compose the display medium that represents information. In this system, every colored droplet is flowed by controlling valves and a pump connected to the tube. The display part employs a flexible tube that can be shaped to any structure (e.g., wrapped around a specific object), which is achieved by a calibration made to capture the tube structure using image processing with a camera. A performance evaluation reveals that our prototype succeeds in controlling each droplet with a positional error of 2 mm or less, which is small enough to show such simple characters as alphabetic characters using a 7 × 7-pixel resolution display. We also discuss example applications, such as large public displays and flow-direction visualization, that illustrate the characteristics of the TuVe display.',\n",
              "  'Happy Moves, Sad Grooves: Using Theories of Biological Motion and Affect to Design Shape-Changing Interfaces.[SEP]The design of shape-changing interfaces to show emotions relies on craft skill with few clear guidelines. Through two experiments, we explore how to design such interfaces using theories of the relation between biological motion and affect. In the first experiment, 19 participants viewed six shape-changing behaviors that varied the velocity, fluidity, direction, and orientation of the movement of an extrusion from a small box in accordance with existing theories of affective motion. Participants were able to recognize four of the six intended basic Ekman emotions (sadness, fear, happiness, surprise) with above-chance probability. The second experiment used 36 shape-changing behaviors that systematically varied speed, regularity of motion, and direction. For each behavior, 23 participants rated valence, arousal, and dominance. Speed, direction, and orientation impacted emotion ratings significantly and in the predicted directions. These results offer an initial basis for the systematic design of emotions in shape-changing interfaces.',\n",
              "  'Understanding the Benefits and Drawbacks of Shape Change in Contrast or Addition to other Modalities.[SEP]Shape changing interfaces enable exciting new ways to interact with devices, to communicate information, meaning and affect, and provide dynamic affordance. Such interfaces are often complex and more expensive to fabricate compared to tangible, screen-based and voice interfaces. The research field has yet to explore the advantages and drawbacks of shape change in contrast to other modalities. The research outlined in this paper aims to evaluate shape changing interfaces for different purposes in contrast to interfaces that rely on tangible, screen-based or voice interaction. Shape change will be explored in the context of explainable AI to examine how it affects aspects like usability, user experience, user engagement and trust. The aim of this research is to generate an understanding about the conditions under which shape changing interfaces are beneficial and when traditional or multimodal interfaces are more appropriate.',\n",
              "  'Instrumenting and Analyzing Fabrication Activities, Users, and Expertise.[SEP]The recent proliferation of fabrication and making activities has introduced a large number of users to a variety of tools and equipment. Monitored, reactive and adaptive fabrication spaces are needed to provide personalized information, feedback and assistance to users. This paper explores the sensorization of making and fabrication activities, where the environment, tools, and users were considered to be separate entities that could be instrumented for data collection. From this exploration, we present the design of a modular system that can capture data from the varied sensors and infer contextual information. Using this system, we collected data from fourteen participants with varying levels of expertise as they performed seven representative making tasks. From the collected data, we predict which activities are being performed, which users are performing the activities, and what expertise the users have. We present several use cases of this contextual information for future interactive fabrication spaces.',\n",
              "  \"Automatics: Dynamically Generating Fabrication Tasks to Adapt to Varying Contexts.[SEP]When fabricating, it is common to follow a prescribed set of steps in a tutorial or how-to. While popular, such explicit knowledge resources have many inconsistencies and omissions, use static illustrations, and cannot adapt to drop-in makers or a maker's mistakes. To overcome many of these issues, this work presents Automatics, a novel explicit knowledge resource system that dynamically generates fabrication activities for one or more makers based on their current environmental and fabrication context. Automatics assigns tasks to makers based on the past tools and components the maker was working with, enables makers to recover from mistakes through model regeneration, suggests alternative tools if a needed tool is unavailable or in use, and allows multiple makers to drop-in throughout a fabrication activity. Initial usage and feedback from novice makers showed that Automatics increases the number of tasks that can be completed compared to paper instructions, decreases frustration, and improves one's understanding of the global context of assigned tasks during fabrication activities.\",\n",
              "  \"Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures.[SEP]Digital fabrication tools have transformed how people work in micro- and small-scale manufacturing settings. While increasing efficiency and precision, these tools raise concerns around user agency and control. This paper describes an exploratory study investigating the felt work experience and desired futures of professionals who use fabrication tools. We conducted co-design workshops with 23 professionals who use 3D printers, laser cutters, and CNC routers. We probed about current practices; machine awareness and autonomy; and user agency. Our findings reveal that current tools are not very professional. They are unreliable and untrustworthy. Participants desired smarter tools that can actively prevent errors and perform self-calibration and self-maintenance. They had few concerns that more intelligence would impact agency. They desired tools that could negotiate trade-offs between time, cost, and quality; and that can operate as super-human shop assistants. We discuss the implications of these findings as opportunities for research that can improve professionals' work experience.\"],\n",
              " '27_smart_activities_context_interfaces': [\"Mixed-initiative conflict resolution for context-aware applications.[SEP]A number of technologies have contributed to automatically resolving resource conflicts between multiple users in a smart space. However, such systems eliminate the users' ability to perform this conflict resolution by themselves, which they actually prefer to do in certain circumstances. Since both resolution approaches have their merits, we propose a mixed-initiative conflict resolution system, which combines automatic conflict resolution with mediated, or user-driven, resolution by exploiting contextual information in context-aware applications. An evaluation of our system found that users prefer to use a mediated resolution approach when their preferences about outcome are very different from others', but have no preferred method when their preferences about outcome are similar to others'.\",\n",
              "  \"A user's perspective of design for context-awareness.[SEP]Along with the development of microchip and sensing technologies, more and more Context-Aware applications have been introduced to our daily life to engage us in information-rich environments. Unlike many desktop applications, Context-Aware applications have usually been used to support users in dynamic situations by utilizing many resources available through physical environments. This research takes a user's perspective on Context-Aware activities, to focus on user's motivation and perception among dynamic surroundings, and aims to demonstrate the role and importance of user involvement for Context-Aware services.\",\n",
              "  'A goal-oriented interface to consumer electronics using planning and commonsense reasoning.[SEP]We are reaching a crisis with design of user interfaces for consumer electronics. Flashing 12:00 time indicators, push-and-hold buttons, and interminable modes and menus are all symptoms of trying to maintain a one-to-one correspondence between functions and physical controls, which becomes hopeless as the number of capabilities of devices grows. We propose instead to orient interfaces around the goals that users have for the use of devices.We present Roadie, a user interface agent that provides intelligent context-sensitive help and assistance for a network of consumer devices. Roadie uses a Commonsense knowledge base to map between user goals and functions of the devices, and an AI partial-order planner to provide mixed-initiative assistance with executing multi-step procedures and debugging help when things go wrong.',\n",
              "  'Modelling internet based applications for designing multi-device adaptive interfaces.[SEP]The wide spread of mobile devices in the consumer market has posed a number of new issues in the design of internet applications and their user interfaces. In particular, applications need to adapt their interaction modalities to different portable devices. In this paper we address the problem of defining models and techniques for designing internet based applications that automatically adapt to different mobile devices. First, we define a formal model that allows for specifying the interaction in a way that is abstract enough to be decoupled from the presentation layer, which is to be adapted to different contexts. The model is mainly based on the idea of describing the user interaction in terms of elementary actions. Then, we provide a formal device characterization showing how to effectively implements the AIUs in a multidevice context.',\n",
              "  'Robust Annotation of Mobile Application Interfaces in Methods for Accessibility Repair and Enhancement.[SEP]Accessibility issues in mobile apps make those apps difficult or impossible to access for many people. Examples include elements that fail to provide alternative text for a screen reader, navigation orders that are difficult, or custom widgets that leave key functionality inaccessible. Social annotation techniques have demonstrated compelling approaches to such accessibility concerns in the web, but have been difficult to apply in mobile apps because of the challenges of robustly annotating interfaces. This research develops methods for robust annotation of mobile app interface elements. Designed for use in runtime interface modification, our methods are based in screen identifiers, element identifiers, and screen equivalence heuristics. We implement initial developer tools for annotating mobile app accessibility metadata, evaluate our current screen equivalence heuristics in a dataset of 2038 screens collected from 50 mobile apps, present three case studies implementing runtime repair of common accessibility issues, and examine repair of real-world accessibility issues in 26 apps. These contributions overall demonstrate strong opportunities for social annotation in mobile accessibility.',\n",
              "  'Workshop W2: multi-user and ubiquitous user interfaces (MU3I 2006).[SEP]The main objective of the third workshop on Multi-User and Ubiquitous User Interfaces (MU3I 2006) is to bring people with relevant backgrounds (e.g. interface design, CSCW, ubiquitous computing) together to discuss two key questions in this field: How can we build interfaces, which span multiple devices so that the user knows that they can be used to control a specific application? How can we build interfaces for public displays? Therefore, the main outcome of the workshop is expected to consists of further insights into those problems, potential solutions and a research agenda to investigate these further.',\n",
              "  \"The Upcycled Home: Removing Barriers to Lightweight Modification of the Home's Everyday Objects.[SEP]The Internet-of-things (IoT) embeds computing in everyday objects, but has largely focused on new devices while ignoring the home's many existing possessions. We present a field study with 10 American families to understand how these possessions could be included in the smart home through upcycling. We describe three patterns for how families collaborate around home responsibilities; we explore families' mental models of home that may be in tension with existing IoT systems; and we identify ways that families can more easily imagine a smart home that includes their existing possessions. These insights can help us design an upcycled approach to IoT that supports users in reconfiguring objects (and social roles as mediated by objects) in a way that is sensitive to what will be displaced, discarded, or made obsolete. Our findings inform the design of future lightweight systems for the upcycled home.\",\n",
              "  'Alternative Avenues for IoT: Designing with Non-Stereotypical Homes.[SEP]We report on the findings of a co-speculative design inquiry that investigates alternative visions of the Internet of Things (IoT) for the home. We worked with 16 people living in non-stereotypical homes to develop situated and personal concepts attuned to their home. As a prompt for co-speculation and discussion, we created handmade booklets where we took turns overlaying sketched design concepts on top of photos taken with participants in their homes. Our findings reveal new avenues for the design of IoT systems such as: acknowledging porous boundaries of the home, exposing neighborly relations, exploring diverse timescales, revisiting agency, and embracing imaginary and potential uses. We invite human-computer interaction and design researchers to use these avenues as starting points to broaden current assumptions embedded in design and research practices for domestic technologies. We conclude by highlighting the value of examining divergent perspectives and surfacing the unseen.',\n",
              "  \"Making place for clutter and other ideas of home.[SEP]In this article, we examine the containment of clutter in family homes and, from this, outline considerations for design. Selected materials from an ethnographically informed study of home life are used to detail the ways in which families contain their clutter in bowls and drawers. Clutter, within these containers, is found to be made up of a heterogeneous collection of things that, for all manner of reasons, hold an ambiguous status in the home. It is shown that bowls and drawers provide a “safe” site of containment for clutter, giving the miscellany of content the “space” to be properly dealt with and classified, or to be left unresolved. The shared but idiosyncratic practices families use to contain their clutter are seen to be one of the ways in which the home, or at least the idea of home, is collectively produced. It is also part of the means by which families come to make their homes distinct and unique. These findings are used to consider what it might mean to design for the home, and to do so in ways that are sensitive to the idiosyncratic systems of household organization. In conclusion, thought is given to how we design for people's ideas of home, and how we might build sites of uncertainty into homes, where physical as well as digital things might coalesce.\",\n",
              "  'Applications of mobile activity recognition.[SEP]Activity Recognition (AR), which identifies the activity that a user performs, is attracting a tremendous amount of attention, especially with the recent explosion of smart mobile devices. These ubiquitous mobile devices, most notably but not exclusively smartphones, provide the sensors, processing, and communication capabilities that enable the development of diverse and innovative activity recognition-based applications. However, although there has been a great deal of research into activity recognition, surprisingly little practical work has been done in the area of applications in mobile devices. In this paper we describe and categorize a variety of activity recognition-based applications. Our hope is that this work will encourage the development of such applications and also influence the direction of activity recognition research.',\n",
              "  'Learning from less for better: semi-supervised activity recognition via shared structure discovery.[SEP]Despite the active research into, and the development of, human activity recognition over the decades, existing techniques still have several limitations, in particular, poor performance due to insufficient ground-truth data and little support of intra-class variability of activities (i.e., the same activity may be performed in different ways by different individuals, or even by the same individuals with different time frames). Aiming to tackle these two issues, in this paper, we present a robust activity recognition approach by extracting the intrinsic shared structures from activities to handle intra-class variability, and the approach is embedded into a semi-supervised learning framework by utilizing the learned correlations from both labeled and easily-obtained unlabeled data simultaneously. We use l2,1 minimization on both loss function and regularizations to effectively resist outliers in noisy sensor data and improve recognition accuracy by discerning underlying commonalities from activities. Extensive experimental evaluations on four community-contributed public datasets indicate that with little training samples, our proposed approach outperforms a set of classical supervised learning methods as well as those recently proposed semi-supervised approaches.',\n",
              "  \"Supporting activity recognition by visual analytics.[SEP]Recognizing activities has become increasingly relevant in many application domains, such as security or ambient assisted living. To handle different scenarios, the underlying automated algorithms are configured using multiple input parameters. However, the influence and interplay of these parameters is often not clear, making exhaustive evaluations necessary. On this account, we propose a visual analytics approach to supporting users in understanding the complex relationships among parameters, recognized activities, and associated accuracies. First, representative parameter settings are determined. Then, the respective output is computed and statistically analyzed to assess parameters' influence in general. Finally, visualizing the parameter settings along with the activities provides overview and allows to investigate the computed results in detail. Coordinated interaction helps to explore dependencies, compare different settings, and examine individual activities. By integrating automated, visual, and interactive means users can select parameter values that meet desired quality criteria. We demonstrate the application of our solution in a use case with realistic complexity, involving a study of human protagonists in daily living with respect to hundreds of parameter settings.\"],\n",
              " '28_vessel_imaging_ultrasound_clinical': ['HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments.[SEP]High Intensity Focused Ultrasound (HIFU) is a non invasive therapeutic method, which has been a subject of interest for the treatment of various kinds of tumors. Despite the numerous advantages, HIFU techniques do not reach the high delivery precision like other therapies (e.g., radiotherapy). For this reason, a correct therapy planning and monitoring in HIFU treatments remains a challenge. We propose HIFUpm, a visual analytics approach which enables the visualization of the HIFU simulation results, while guiding the user in the evaluation of the procedure. We illustrate the use of HIFUpm for an ablative treatment of an osteoid osteoma. This use case demonstrates that HIFUpm provides a flexible visual environment to plan and monitor HIFU procedures.',\n",
              "  '3D heart-vessel reconstruction from biplane angiograms.[SEP]Biplane angiography generates just two time equivalent X-ray images. These X-ray systems can be rotated independently from each other (restricted by possible collisions only). The article explains how highly accurate 3D models of vessel systems can be reconstructed, visualized, and quantitatively evaluated from these X-ray images.',\n",
              "  \"Automatic Transfer Function Specification for Visual Emphasis of Coronary Artery Plaque.[SEP]Cardiovascular imaging with current multislice spiral computed tomography (MSCT) technology enables a non‐invasive evaluation of the coronary arteries. Contrast‐enhanced MSCT angiography with high spatial resolution allows for a segmentation of the coronary artery tree. We present an automatically adapted transfer function (TF) specification to highlight pathologic changes of the vessel wall based on the segmentation result of the coronary artery tree. The TFs are combined with common visualization techniques, such as multiplanar reformation and direct volume rendering for the evaluation of coronary arteries in MSCT image data. The presented TF‐based mapping of CT values in Hounsfield Units (HU) to color and opacity leads to a different color coding for different plaque types. To account for varying HU values of the vessel lumen caused by the contrast medium, the TFs are adapted to each dataset by local histogram analysis. We describe an informal evaluation with three board‐certified radiologists which indicates that the represented visualizations guide the user's attention to pathologic changes of the vessel wall as well as provide an overview about spatial variations.\",\n",
              "  'Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms.[SEP]Blood flow simulations play an important role for the understanding of vascular diseases, such as aneurysms. However, analysis of the resulting flow patterns, especially comparisons across patient groups, are challenging. Typically, the hemodynamic analysis relies on trial and error inspection of the flow data based on pathline visualizations and surface renderings. Visualizing too many pathlines at once may obstruct interesting features, e.g., embedded vortices, whereas with too little pathlines, particularities such as flow characteristics in aneurysm blebs might be missed. While filtering and clustering techniques support this task, they require the pre-computation of pathlines densely sampled in the space-time domain. Not only does this become prohibitively expensive for large patient groups, but the results often suffer from undersampling artifacts. In this work, we propose the usage of evolutionary algorithms to reduce the overhead of computing pathlines that do not contribute to the analysis, while simultaneously reducing the undersampling artifacts. Integrated in an interactive framework, it efficiently supports the evaluation of hemodynamics for clinical research and treatment planning in case of cerebral aneurysms. The specification of general optimization criteria for entire patient groups allows the blood flow data to be batch-processed. We present clinical cases to demonstrate the benefits of our approach especially in presence of aneurysm blebs. Furthermore, we conducted an evaluation with four expert neuroradiologists. As a result, we report advantages of our method for treatment planning to underpin its clinical potential.',\n",
              "  'Illustration-Inspired Visualization of Blood Flow Dynamics.[SEP]Image-based computational fluid dynamics (CFD) is a central tool in the evaluation of hemodynamic factors in cardiovascular disease development and treatment, to the point where major vendors are now seeking to deploy CFD solvers on their medical imaging platforms. Detailed hemodynamic data available from CFD generate large data sets due to complex flow, which are difficult to render clearly - and thus communicate to clinical stakeholders - using conventional engineering flow visualization techniques. This is especially challenging considering the four-dimensional nature of the flow patterns (i.e., Rapidly varying in space and time), as well as the clinical need for generating static reports rather than cumbersome digital animations. Taking a cue from the rich history of biomedical illustration, our goal is to use this opportunity for developing new data-driven paradigms for visualizing blood flow based on the principles of illustration, sequential art, and the visual vocabularies and conventions of radiology and vascular surgery.',\n",
              "  'Occlusion-free Blood Flow Animation with Wall Thickness Visualization.[SEP]We present the first visualization tool that combines pathlines from blood flow and wall thickness information. Our method uses illustrative techniques to provide occlusion-free visualization of the flow. We thus offer medical researchers an effective visual analysis tool for aneurysm treatment risk assessment. Such aneurysms bear a high risk of rupture and significant treatment-related risks. Therefore, to get a fully informed decision it is essential to both investigate the vessel morphology and the hemodynamic data. Ongoing research emphasizes the importance of analyzing the wall thickness in risk assessment. Our combination of blood flow visualization and wall thickness representation is a significant improvement for the exploration and analysis of aneurysms. As all presented information is spatially intertwined, occlusion problems occur. We solve these occlusion problems by dynamic cutaway surfaces. We combine this approach with a glyph-based blood flow representation and a visual mapping of wall thickness onto the vessel surface. We developed a GPU-based implementation of our visualizations which facilitates wall thickness analysis through real-time rendering and flexible interactive data exploration mechanisms. We designed our techniques in collaboration with domain experts, and we provide details about the evaluation of the technique and tool.'],\n",
              " '29_texture_textures_synthesis_image': ['Texture Synthesis for Mobile Data Communications.[SEP]This paper presents an approach to image coding that first paints a regularly arranged dotted pattern, using colors picked from a texture sample with features corresponding to the embedded data. It then camouflages the dotted pattern using the same texture sample while preserving quality comparable to that of existing synthesis techniques.',\n",
              "  'Deterministic Texture Analysis and Synthesis Using Tree Structure Vector Quantization.[SEP]Texture analysis and synthesis is very important for computer graphics, vision, and image processing. This paper describes an algorithm which can produce new textures with a matching visual appearance from a given example image. Our algorithm is based on a model that characterizes textures using a nonlinear deterministic function. During analysis, an example texture is summarized into this function using tree structure vector quantization. An output texture, initially random noise, is then synthesized from this estimated function. Compared to existing approaches, our algorithm can efficiently generate a wide variety of textures. The effectiveness of our approach is demonstrated using standard test images from the Brodatz texture album.',\n",
              "  'Hidden message in a deformation-based texture.[SEP]We present stego-texture, a unique texture synthesis method that allows users to deliver personalized messages with beautiful, decorative textures. Our approach was inspired by the success of recent work generating marbling textures using mathematical functions. We were able to transform an input image or a text message into an intricate texture by combining the seven basic, reversible functions provided in the system. Later, the input image or message could be recovered by reversing the process of these functions. During the design process, the parameters of operations were automatically recorded, encrypted and invisibly embedded into the final pattern to create a stego-texture. In this way, the receiver could extract the hidden message from the stego-texture without the need for extra information from the sender. To ensure that the delivered message is unnoticeably covered by the texture, we propose a new technique for automatically creating a background that is harmonious with the message based on a set of visual perception cues.',\n",
              "  'Application-Specific Tone Mapping Via Genetic Programming.[SEP]High dynamic range (HDR) imagery permits the manipulation of real‐world data distinct from the limitations of the traditional, low dynamic range (LDR), content. The process of retargeting HDR content to traditional LDR imagery via tone mapping operators (TMOs) is useful for visualizing HDR content on traditional displays, supporting backwards‐compatible HDR compression and, more recently, is being frequently used for input into a wide variety of computer vision applications. This work presents the automatic generation of TMOs for specific applications via the evolutionary computing method of genetic programming (GP). A straightforward, generic GP method that generates TMOs for a given fitness function and HDR content is presented. Its efficacy is demonstrated in the context of three applications: Visualization of HDR content on LDR displays, feature mapping and compression. For these applications, results show good performance for the generated TMOs when compared to traditional methods. Furthermore, they demonstrate that the method is generalizable and could be used across various applications that require TMOs but for which dedicated successful TMOs have not yet been discovered.',\n",
              "  'A Tone Reproduction Operator for All Luminance Ranges Considering Human Color Perception.[SEP]In this paper, we present a novel tone reproduction operator that is able to handle the color shift that occurs in photopic, mesopic, and scotopic vision, using a model based on a two-stage model of human color vision and psychophysical data obtained from measurements of human color perception. Since conventional methods are limited to generating images under a certain visual condition, it is difficult to apply just one operator to deal with scenes with continuous change within a wide luminance range, such as various scenes in movies. To overcome this problem, we have developed a model based on psychophysical data involving wavelength discrimination within a wide luminance range, which provides us with clues about the change of color perception. That is, the spectral sensitivity shifts toward the short wavelengths and decreases according to the adaptation light levels. By integrating the wavelength discrimination into our model, the proposed operator enables us to compute the transition of color perception under a wide range of viewing conditions.',\n",
              "  'Style Aware Tone Expansion for HDR Displays.[SEP]The vast majority of video content existing today is in Standard Dynamic Range (SDR) format and there is a strong interest in upscaling this content for upcoming High Dynamic Range (HDR) displays. Tone expansion or inverse tone mapping converts SDR content into HDR format using Expansion Operators (EO). In this paper, we show that current EO’s do not perform as well when dealing with content of various lighting style aesthetics. In addition to this, we present a series of perceptual user studies evaluating user preference for lighting style in HDR content. This study shows that tone expansion of stylized content takes the form of gamma correction and we propose a method that adapts the gamma value to the style of the video. We validate our method through a subjective evaluation against state-of-the-art methods. Furthermore, our work has been oriented for 1000 nits HDR displays and we present a framework positioning our method in conformance with existing SDR standards and upcoming HDR TV standards.'],\n",
              " '2_visualization_topic_visual_visualizations': ['Patterns for visualization evaluation.[SEP]We propose a patterns-based approach to evaluating data visualization: a set of general and reusable solutions to commonly occurring problems in evaluating tools, techniques, and systems for visual sensemaking. Patterns have had significant impact in a wide array of disciplines, particularly software engineering, and we believe that they provide a powerful lens for looking at visualization evaluation by offering practical, tried-and-tested tips and tricks that can be adopted immediately. The 12 patterns presented here have also been added to a freely editable Wiki repository. The motivation for creating this evaluation pattern language is to (a) disseminate hard-won experience on visualization evaluation to researchers and practitioners alike; to (b) provide a standardized vocabulary for designing visualization evaluation; and to (c) invite the community to add new evaluation patterns to a growing repository of patterns.',\n",
              "  \"Metrics for measuring human interaction with interactive visualizations for information analysis.[SEP]There is a lack of widely-accepted metrics for evaluating analysts' experiences with interactive visualizations (IV) for information analysis. We report an approach for developing analyst-centered IV metrics that is built upon understanding the workplace needs and experiences of information analysts with respect to IVs. We derive metrics from human-computer interaction heuristics, specializing the metrics to address the characteristics of IVs and analysts. When there are no existing heuristics, analysts' needs and experiences inform new heuristics.\",\n",
              "  'Learning-based evaluation of visual analytic systems.[SEP]Evaluation in visualization remains a difficult problem because of the unique constraints and opportunities inherent to visualization use. While many potentially useful methodologies have been proposed, there remain significant gaps in assessing the value of the open-ended exploration and complex task-solving that the visualization community holds up as an ideal. In this paper, we propose a methodology to quantitatively evaluate a visual analytics (VA) system based on measuring what is learned by its users as the users reapply the knowledge to a different problem or domain. The motivation for this methodology is based on the observation that the ultimate goal of a user of a VA system is to gain knowledge of and expertise with the dataset, task, or tool itself. We propose a framework for describing and measuring knowledge gain in the analytical process based on these three types of knowledge and discuss considerations for evaluating each. We propose that through careful design of tests that examine how well participants can reapply knowledge learned from using a VA system, the utility of the visualization can be more directly assessed.',\n",
              "  'Text visualization techniques: Taxonomy, visual survey, and community insights.[SEP]Text visualization has become a growing and increasingly important subfield of information visualization. Thus, it is getting harder for researchers to look for related work with specific tasks or visual metaphors in mind. In this paper, we present an interactive visual survey of text visualization techniques that can be used for the purposes of search for related work, introduction to the subfield and gaining insight into research trends. We describe the taxonomy used for categorization of text visualization techniques and compare it to approaches employed in several other surveys. Finally, we present results of analyses performed on the entries data.',\n",
              "  'Visualizing the Performance of Computational Linguistics Algorithms.[SEP]We have built a visualization system and analysis portal for evaluating the performance of computational linguistics algorithms. Our system focuses on algorithms that classify and cluster documents by assigning weights to words and scoring each document against high dimensional reference concept vectors. The visualization and algorithm analysis techniques include confusion matrices, ROC curves, document visualizations showing word importance, and interactive reports. One of the unique aspects of our system is that the visualizations are thin-client Web-based components built using SVG visualization components',\n",
              "  'Quantity estimation in visualizations of tagged text.[SEP]A valuable task in text visualization is to have viewers make judgments about text that has been annotated (either by hand or by some algorithm such as text clustering or entity extraction). In this work we look at the ability of viewers to make judgments about the relative quantities of tags in annotated text (specifically text tagged with one of a set of qualitatively distinct colors), and examine design choices that can improve performance at extracting statistical information from these texts. We find that viewers can efficiently and accurately estimate the proportions of tag levels over a range of situations; however accuracy can be improved through color choice and area adjustments.',\n",
              "  'MetaLDA: A Topic Model that Efficiently Incorporates Meta Information.[SEP]Besides the text content, documents and their associated words usually come with rich sets of meta information, such as categories of documents and semantic/syntactic features of words, like those encoded in word embeddings. Incorporating such meta information directly into the generative process of topic models can improve modelling accuracy and topic quality, especially in the case where the word-occurrence information in the training data is insufficient. In this paper, we present a topic model, called MetaLDA, which is able to leverage either document or word meta information, or both of them jointly. With two data argumentation techniques, we can derive an efficient Gibbs sampling algorithm, which benefits from the fully local conjugacy of the model. Moreover, the algorithm is favoured by the sparsity of the meta information. Extensive experiments on several real world datasets demonstrate that our model achieves comparable or improved performance in terms of both perplexity and topic quality, particularly in handling sparse texts. In addition, compared with other models using meta information, our model runs significantly faster.',\n",
              "  'Discriminatively Enhanced Topic Models.[SEP]This paper proposes a space-efficient, discriminatively enhanced topic model: a V structured topic model with an embedded log-linear component. The discriminative log-linear component reduces the number of parameters to be learnt while outperforming baseline generative models. At the same time, the explanatory power of the generative component is not compromised. We establish its superiority over a purely generative model by applying it to two different ranking tasks: (a) In the first task, we look at the problem of proposing alternative citations given textual and bibliographic evidence. We solve it as a ranking problem in itself and as a platform for further qualitative analysis of convergence of scientific phenomenon. (b) In the second task we address the problem of ranking potential email recipients based on email content and sender information.',\n",
              "  'Stochastic collapsed variational Bayesian inference for latent Dirichlet allocation.[SEP]There has been an explosion in the amount of digital text information available in recent years, leading to challenges of scale for traditional inference algorithms for topic models. Recent advances in stochastic variational inference algorithms for latent Dirichlet allocation (LDA) have made it feasible to learn topic models on very large-scale corpora, but these methods do not currently take full advantage of the collapsed representation of the model. We propose a stochastic algorithm for collapsed variational Bayesian inference for LDA, which is simpler and more efficient than the state of the art method. In experiments on large-scale text corpora, the algorithm was found to converge faster and often to a better solution than previous methods. Human-subject experiments also demonstrated that the method can learn coherent topics in seconds on small corpora, facilitating the use of topic models in interactive document analysis software.'],\n",
              " '30_decision_choice_risk_risky': ['Bar-Gain Boxes: An Informative Illustration of the Pairing Problem.[SEP]A practical problem in command and control is to assign assets (e.g., bomber planes) to targets (e.g., hostile sites), one-on-one, in order to optimize an overall operation. The asset-target pairing must be completed quickly (before targets act), and the expected effectiveness of an asset against a target depends on a number of factual and judgmental factors. Here I present a diagram called ”Bar-Gain Boxes” designed to help people solve the problem. The diagram uses a matrix of boxes to illustrate the possible pairings, along with color-coded bars (in each box) to illustrate the gain associated with each individual asset-target pair. The diagram is informative because it displays algorithmic results and underlying reasons, for normative and alternative solutions.',\n",
              "  'Context effects and risk amplification: Why more is risky.[SEP]Research on risky choice has been dominantly based on studies of choice between two alternatives, with the findings often generalized to environments with more than two alternatives. One prominent claim of this research is that choices differ with respect to risk when alternatives are described (the description paradigm) as opposed to experienced (the experience paradigm): Individuals appear to make decisions as if they over-weight small probabilities in the description paradigm, but under-weight the same probabilities in the experience paradigm. Here, we show that the under-weighting in the experience paradigm is sensitive to the choice set size in the gain domain. Two experiments show that as set sizes increase, choices systematically favour risky alternatives in the experience paradigm. Using simulations of three choice models, we further demonstrate that this risk-amplification is independent of choice and search strategies and is predicted by the statistical structure of pay-offs. The results suggest caution in generalising findings from two-choice environments to many-choice environments and further indicate a robust and systematic problem with increasing choice set sizes.',\n",
              "  \"How Does Prospect Theory Reflect Heuristics' Probability Sensitivity in Risky Choice?[SEP]Two prominent approaches to describing how people make decisions between risky options are algebraic models and heuristics. The two approaches are based on fundamentally different algorithms and are thus usually treated as antithetical, suggesting that they may be incommensurable. Using cumulative prospect theory (CPT; Tversky & Kahneman, 1992) as an illustrative case of an algebraic model, we demonstrate how algebraic models and heuristics can mutually inform each other. Specifically, we highlight that CPT describes decisions in terms of psychophysical characteristics, such as diminishing sensitivity to probabilities, and we show that this holds even when the underlying process is heuristic in nature. Our results suggest that algebraic models and heuristics might offer complementary rather than rival modeling frameworks and highlight the potential role of heuristic principles in information processing for prominent descriptive constructs in risky choice.\"],\n",
              " '31_weather_visualization_climate_ocean': ['User-defined feature comparison for vector field ensembles.[SEP]Most of the existing approaches to visualize vector field ensembles are to reveal the uncertainty of individual variables, for example, statistics, variability, etc. However, a user-defined derived feature like vortex or air mass is also quite significant, since they make more sense to domain scientists. In this paper, we present a new framework to extract user-defined derived features from different simulation runs. Specially, we use a detail-to-overview searching scheme to help extract vortex with a user-defined shape. We further compute the geometry information including the size, the geo-spatial location of the extracted vortexes. We also design some linked views to compare them between different runs. At last, the temporal information such as the occurrence time of the feature is further estimated and compared. Results show that our method is capable of extracting the features across different runs and comparing them spatially and temporally.',\n",
              "  \"Analysis of Decadal Climate Predictions with User-guided Hierarchical Ensemble Clustering.[SEP]In order to gain probabilistic results, ensemble simulation techniques are increasingly applied in the weather and climate sciences (as well as in various other scientific disciplines). In many cases, however, only mean results or other abstracted quantities such as percentiles are used for further analyses and dissemination of the data. In this work, we aim at a more detailed visualization of the temporal development of the whole ensemble that takes the variability of all single members into account. We propose a visual analytics tool that allows an effective analysis process based on a hierarchical clustering of the time‐dependent scalar fields. The system includes a flow chart that shows the ensemble members' cluster affiliation over time, reflecting the whole cluster hierarchy. The latter one can be dynamically explored using a visualization derived from a dendrogram. As an aid in linking the different views, we have developed an adaptive coloring scheme that takes into account cluster similarity and the containment relationships. Finally, standard visualizations of the involved field data (cluster means, ground truth data, etc.) are also incorporated. We include results of our work on real‐world datasets to showcase the utility of our approach.\",\n",
              "  'Extraction and Visual Analysis of Potential Vorticity Banners around the Alps.[SEP]Potential vorticity is among the most important scalar quantities in atmospheric dynamics. For instance, potential vorticity plays a key role in particularly strong wind peaks in extratropical cyclones and it is able to explain the occurrence of frontal rain bands. Potential vorticity combines the key quantities of atmospheric dynamics, namely rotation and stratification. Under suitable wind conditions elongated banners of potential vorticity appear in the lee of mountains. Their role in atmospheric dynamics has recently raised considerable interest in the meteorological community for instance due to their influence in aviation wind hazards and maritime transport. In order to support meteorologists and climatologists in the analysis of these structures, we developed an extraction algorithm and a visual exploration framework consisting of multiple linked views. For the extraction we apply a predictor-corrector algorithm that follows streamlines and realigns them with extremal lines of potential vorticity. Using the agglomerative hierarchical clustering algorithm, we group banners from different sources based on their proximity. To visually analyze the time-dependent banner geometry, we provide interactive overviews and enable the query for detail on demand, including the analysis of different time steps, potentially correlated scalar quantities, and the wind vector field. In particular, we study the relationship between relative humidity and the banners for their potential in indicating the development of precipitation. Working with our method, the collaborating meteorologists gained a deeper understanding of the three-dimensional processes, which may spur follow-up research in the future.',\n",
              "  'Exploratory Hierarchical Clustering for Management Zone Delineation in Precision Agriculture.[SEP]Precision Agriculture has become an emerging topic over the last ten years. It is concerned with the integration of information technology into agricultural processes. This is especially true for the ongoing and growing data collection in agriculture. Novel ground-based sensors, aerial and satellite imagery as well as soil sampling provide large georeferenced data sets with high spatial resolution. However, these data lead to the data mining problem of finding novel and useful information in these data sets.',\n",
              "  'Gaussian multiple instance learning approach for mapping the slums of the world using very high resolution imagery.[SEP]In this paper, we present a computationally efficient algorithm based on multiple instance learning for mapping informal settlements (slums) using very high-resolution remote sensing imagery. From remote sensing perspective, informal settlements share unique spatial characteristics that distinguish them from other urban structures like industrial, commercial, and formal residential settlements. However, regular pattern recognition and machine learning methods, which are predominantly single-instance or per-pixel classifiers, often fail to accurately map the informal settlements as they do not capture the complex spatial patterns. To overcome these limitations we employed a multiple instance based machine learning approach, where groups of contiguous pixels (image patches) are modeled as generated by a Gaussian distribution. We have conducted several experiments on very high-resolution satellite imagery, representing four unique geographic regions across the world. Our method showed consistent improvement in accurately identifying informal settlements.',\n",
              "  'Regression Models for Spatial Data: An Example from Precision Agriculture.[SEP]The term precision agriculture refers to the application of state-of-the-art GPS technology in connection with small-scale, sensor-based treatment of the crop. This data-driven approach to agriculture poses a number of data mining problems. One of those is also an obviously important task in agriculture: yield prediction. Given a precise, geographically annotated data set for a certain field, can a season’s yield be predicted?'],\n",
              " '32_ray_rays_traversal_rendering': ['Adaptive Ray Tracing of Subdivision Surfaces.[SEP]Subdivision Surfaces as well as (interactive) ray tracing have become an important issue in computer graphics.But ray tracing of subdivision surfaces has received only little attention. We present a new approach for raytracing of subdivision surfaces. The algorithm uses a projection of the ray onto the surface and works mainly intwo dimensions along this projection. While proceeding from patch to patch, we examine the bounding volume oftheir borders: the lower the distance between ray and subdivision surface, the more refinement steps are adaptivelyapplied to the surface but only along the projection of the ray. The adaptive refinement of a patch is controlled bycurvature, size, its membership to the silhouette, and its potential contribution to the light transport. The algorithmis simple and mainly consists of elementary geometric computations. Hence it is fast and easy to implementwithout the need for elaborate preprocessing. The algorithm is robust in the sense that it deals with all features ofsubdivision surfaces like creases and corners.',\n",
              "  'Octree-R: An Adaptive Octree for Efficient Ray Tracing.[SEP]Ray tracing requires many ray-object intersection tests. A way of reducing the number of ray-object intersection tests is to subdivide the space occupied by objects into many nonoverlapping subregions, called voxels, and to construct an octree for the subdivided space. We propose the Octree-R, an octree-variant data structure for efficient ray tracing. The algorithm for constructing the Octree-R first estimates the number of ray-object intersection tests. Then, it partitions the space along the plane that minimizes the estimated number of ray-object intersection tests. We present the results of experiments for verifying the effectiveness of the Octree-R. In the experiment, the Octree-R provides a 4% to 47% performance gain over the conventional octree. The result shows the more skewed the object distribution (as is typical for real data), the more performance gain the Octree-R achieves.',\n",
              "  'Improved techniques for ray tracing parametric surfaces.[SEP]Several techniques for acceleration of ray tracing parametric surfaces are presented. Some of these are entirely new to ray tracing, while others are improvements of previously known techniques. First a uniform spatial subdivision scheme is adapted to parametric surfaces. A new space- and time-efficient algorithm for finding raysurface intersections is introduced. It combines numerical and subdivision techniques, thus allowing utilization of ray coherence and greatly reducing the average ray-surface intersection time. Non-scanline sampling orders of the image plane are proposed that facilitate utilization of coherence. Finally, a method to handle reflected, refracted, and shadow rays in a more efficient manner is described. Results of timing tests indicating the efficiency of these techniques for various environments are presented.'],\n",
              " '33_twitter_tweets_media_sentiment': ['#Indigenous: Tracking the Connective Actions of Native American Advocates on Twitter.[SEP]With fewer than 66% of eligible voters registered and voter turnout rates 5-14 percentage points lower than any other ethnic group, Native Americans comprise the least participatory ethnic group in U.S. political elections [42, 57, 49, 25]. While discourse surrounding Native American issues and interests has increasingly moved to social media [55, 56], there is a lack of data about Native American political discourse on these platforms. Given the heterogeneity of Native American peoples in the U.S., one way to begin approaching a holistic understanding of Native American political discourse on social media is to characterize how Native American advocates utilize social media platforms for connective action. Using a post-structural, interdisciplinary, mixed methods approach, we use theories of connective action [5] and media richness [14] to analyze a Twitter data set culled from influential Native American advocates and their followers during the 2016 primary presidential election season. Our study sheds light on how Native American advocates use social media to propagate political information and identifies which issues are central to the political discourse of Native American advocates. Furthermore, we demonstrate how the bandwidth characteristics of content impact its propagation and we discuss this in the context of pernicious digital divide effects present in Indian Country.',\n",
              "  'Thanks and tweets: comparing two public displays.[SEP]Two public display systems, with different methods of posting, were deployed over several years. One, the Thank You Board, was designed to give people an outlet specifically for publicly thanking and acknowledging others in the community. The other, SI Display, showed any Twitter post directed to the display and did not have explicit usage guidelines. People preferred the flexibility of the latter, but ambiguity about its purpose and norms of usage persisted even six months after deployment and made some people hesitant to post. Also, using Twitter as the posting mechanism facilitated participation for some but also created barriers for those not using Twitter and for Twitter users who were wary of mixing their professional and non-professional contexts.',\n",
              "  '(How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian uprising.[SEP]This paper examines microblogging information diffusion activity during the 2011 Egyptian political uprisings. Specifically, we examine the use of the retweet mechanism on Twitter, using empirical evidence of information propagation to reveal aspects of work that the crowd conducts. Analysis of the widespread contagion of a popular meme reveals interaction between those who were \"on the ground\" in Cairo and those who were not. However, differences between information that appeals to the larger crowd and those who were doing on-the-ground work reveal important interplay between the two realms. Through both qualitative and statistical description, we show how the crowd expresses solidarity and does the work of information processing through recommendation and filtering. We discuss how these aspects of work mutually sustain crowd interaction in a politically sensitive context. In addition, we show how features of this retweet-recommendation behavior could be used in combination with other indicators to identify information that is new and likely coming from the ground.',\n",
              "  \"ScatterBlogs: Geo-spatial document analysis.[SEP]We presented Scatterblogs, a system for microblog analysis that seamlessly integrates search backend and visual frontend. It provides powerful, automatic algorithms for detecting spatio-temporal `anomalies' within blog entries as well as corresponding visual representations and interaction facilities for inspecting anomalies or exploiting them in further analytic steps. Apart from that, we consider the system's combinatoric facilities for building complex hypotheses from temporal, spatial, and content-related aspects an important feature. This was the key for creating a cross-checked analysis for MC1.\",\n",
              "  'TimeSets: Temporal Sensemaking in Intelligence Analysis.[SEP]TimeSets is a temporal data visualization technique designed to reveal insights into event sets, such as all the events linked to one person or organization. In this article, we describe two TimeSets-based visual analytics tools for intelligence analysis. In the first case, TimeSets is integrated with other visual analytics tools to support open-source intelligence analysis with Twitter data, particularly the challenge of finding the right questions to ask. The second case uses TimeSets in a participatory design process with analysts that aims to meet their requirements of uncertainty analysis involving fake news. Lessons learned are potentially beneficial to other application domains.',\n",
              "  \"Can Twitter Save Lives? A Broad-Scale Study on Visual Social Media Analytics for Public Safety.[SEP]The use of social media monitoring for public safety is on the brink of commercialization and practical adoption. To close the gap between research and application, this paper presents results of a two-phase study on visual analytics of social media for public safety. For the first phase, we conducted a large field study, in which 29 practitioners from disaster response and critical infrastructure management were asked to investigate crisis intelligence tasks based on Twitter data recorded during the 2013 German Flood. To this end, the ScatterBlogs visual analytics system, a platform that provides reference implementations of tools and techniques popular in research, was given to them as an integrated toolbox. We reviewed the domain experts' individual performances with the system as well as their comments about the usefulness of techniques. In the second phase, we built on this feedback about ScatterBlogs in order to sketch out a system and create additional tools specifically adapted to the collected requirements. The performance of the old lab prototype is finally compared against the re-design in a controlled user study.\"],\n",
              " '34_creativity_painting_art_creative': ['Systematic Integration of Solution Elements: How Does Digital Creativity Support Change Group Dynamics?[SEP]In practice, most creativity techniques are still performed with traditional tools, such as pen and paper, whiteboards, and flipcharts. When transforming these techniques into a digital environment, the reduction of organizational overhead is the main goal to foster accessibility. Still, we do not know if overhead reduction fosters creativity or if it eliminates an important part of the creative process. To get a deeper understanding of these effects, we compare the performance of the creativity technique SIS (Systematic Integration of Solution Elements) in a traditional setting with a setup based on multiple interactive surfaces. By using a mix of diverse evaluation methods, we show how the use of a digital interactive creativity room can really foster creativity and produce better results.',\n",
              "  'Understanding Creativity Methods in Design.[SEP]This paper contributes an analytical framework to improve understanding of the composition of recognized creativity methods used in design. Based on an extensive literature review, our framework synthesizes key concepts from design and particularly creativity research, and is further supported by significant experience with creativity methods in design. We propose that nine concepts are relevant for analyzing creativity methods in design: process structure, materials, tools, combination, metaphor, analogy, framing, divergence, and convergence. To test their relevance as components of an analytical framework, we use these key concepts to analyze three recognized creativity methods that we have often used ourselves: Inspiration Card Workshops, Fictional Inquiry, and Extreme Characters. Our analytical framework expands current categorizations of methods and offers new insight into how creativity methods are composed, how and why they work, and how they potentially may be tweaked or refined for enhanced deployment in design.',\n",
              "  'What You See Is What You Get: The Impact of Visual Perceived Finishedness (PF) on Collaboration Comments during Electronic Idea Generation.[SEP]Micro-level visual phenomena significantly impact visually-supported interactions, and require further exploration. This study uses a laboratory experiment with managerial participants to examine the impact of typeface appearance on number of comments concerning collaboration process during use of an electronic ideation platform. The typefaces verifiably differed on perceived finishedness (PF) level. Low typeface PF was expected to lead to freer, more frequent interaction on the collaboration process. Contrary to expectations, this study found that participant familiarity with the high PF typeface led to a significant increase in the amount of collaboration process comments. This study examines the complementary new ideation metric of collaboration comment number in light of the benefits social metacognition can bring to the structuring of group creativity processes.',\n",
              "  'The Best of Both Realities.[SEP]This paper looks at the work of Dan Turner, who creates art based on digital imagery.',\n",
              "  'Her Work Is All the Buzz.[SEP]This installment looks at the work of Lita Albuquerque, who creates art based on digital imagery.',\n",
              "  \"A Space to Dream.[SEP]Dolores Kaufmann's work is a cross between photo manipulation and computer-generated imagery. She creates her works using Kai Power Tools' Hyper Tiling plug in.\",\n",
              "  'Image-Based Color Ink Diffusion Rendering.[SEP]This paper proposes an image-based painterly rendering algorithm for automatically synthesizing an image with color ink diffusion. We suggest a mathematical model with a physical base to simulate the phenomenon of color colloidal ink diffusing into absorbent paper. Our algorithm contains three main parts: a feature extraction phase, a Kubelka-Munk (KM) color mixing phase, and a color ink diffusion synthesis phase. In the feature extraction phase, the information of the reference image is simplified by luminance division and color segmentation. In the color mixing phase, the KM theory is employed to approximate the result when one pigment is painted upon another pigment layer. Then, in the color ink diffusion synthesis phase, the physically-based model that we propose is employed to simulate the result of color ink diffusion in absorbent paper using a texture synthesis technique. Our image-based ink diffusing rendering (IBCIDR) algorithm eliminates the drawback of conventional Chinese ink simulations, which are limited to the black ink domain, and our approach demonstrates that, without using any strokes, a color image can be automatically converted to the diffused ink style with a visually pleasing appearance',\n",
              "  'Pixel Art with Refracted Light by Rearrangeable Sticks.[SEP]Pixel art is a kind of digital art that through per‐pixel manipulation enables production of a diverse array of artistic images. In this paper, we present a new way for people to experience and express pixel art. Our digital art consists of a set of sticks made of acrylate resin, each of which refracts light from a parallel light source, in certain directions. Artistic users are able to easily rearrange these sticks and view their digital art through the refracted light projection on any planar surface. As we demonstrate in this paper, a user can generate various artistic images using only a single set of sticks. We additionally envision that our pixel art with rearrangeable sticks would have great entertainment appeal, e.g., as an art puzzle.',\n",
              "  'Artistic relighting of paintings and drawings.[SEP]We present a practical solution to the problem of subject relighting in paintings and drawings. Our interactive technique uses 3-D shading proxies and can be applied to objects with arbitrary geometries. Given a user-provided guess for the shading of an object in a painting/drawing and its corresponding target shading, we refine them using shading-color correlation and a multi-scale scheme. These refined shadings are then used to create a multi-channel shading-ratio image to perform relighting, while taking into account the colors used by the artists to convey shading information. We demonstrate the effectiveness of our solution on a variety of artistic styles, including paintings with strong brush strokes and unconventional shading encodings, drawings, and other types of artwork. Our method is the first to perform relighting of paintings and drawings and, in addition to relighting, can transfer smooth normal and depth maps from 3-D proxies to images.'],\n",
              " '35_causal_beliefs_evidence_belief': ['Stable Causal Relationships are Better Causal Relationships.[SEP]We report two experiments investigating whether people’s judgments about causal relationships are sensitive to the robustness or stability of such relationships across a wide range of background circumstances. We demonstrate that people prefer stable causal relationships even when overall causal strength is held constant, and show that this effect is unlikely to be driven by a causal generalization’s actual scope of application. This documents a previously unacknowledged factor that shapes people’s causal reasoning.',\n",
              "  'Informative Transitions: A Heuristic for Conditionalized Causal Strength Learning.[SEP]Controlling for alternative causes is essential for learning the strength of any one cause on an effect. Several processes have been proposed for how people control for alternative causes, including probabilistic contrasts within focal sets and associative processes. We investigated another mechanism called the informative transitions heuristic; people selectively attend to temporally adjacent observations (informative transitions; IT) in which the state of the target cause changes but the alternative causes remain the same. Within ITs, whether the effect also changes in the same direction, does not change, or changes in the opposite direction implies that the target cause has a positive, neutral, or negative influence on the effect. Participants judged the strength of the relationship between two drugs and a side effect in a trial-by-trial learning task. Causes with more positive as opposed to neutral ITs were judged to have stronger causal relations, consistent with the IT heuristic.',\n",
              "  'Causal Reasoning with Continuous Outcomes.[SEP]We describe an attempt to understand causal reasoning in situations where a binary cause produces a change on a continuous magnitude dimension. We consider established theories of binary probabilistic causal inference – ΔP and Power PC – and adapt them to continuous non-probabilistic outcomes. While ΔP describes causal strength as the difference of effect occurrence between the presence and absence of the cause, Power PC normalizes this difference with the effect base-rate to obtain a proportional measure of causal power, relative to the maximum possible strength. Two experiments compared the applicability of each approach by creating scenarios where binary probabilistic scenarios were directly mapped onto inference problems involving continuous magnitude dimensions. Results from counterfactual judgments tentatively indicate that people reason about causal relations with continuous outcomes by adopting a proportional approach when evaluation preventive causal powers, and a difference approach in generative scenarios.'],\n",
              " '36_privacy_security_private_protection': ['Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security Practices.[SEP]A primary goal of research in usable security and privacy is to understand the differences and similarities between users. While past researchers have clustered users into different groups, past categories of users have proven to be poor predictors of end-user behaviors. In this paper, we perform an alternative clustering of users based on their behaviors. Through the analysis of data from surveys and interviews of participants, we identify five user clusters that emerge from end-user behaviors-Fundamentalists, Lazy Experts, Technicians, Amateurs and the Marginally Concerned. We examine the stability of our clusters through a survey-based study of an alternative sample, showing that clustering remains consistent. We conduct a small-scale design study to demonstrate the utility of our clusters in design. Finally, we argue that our clusters complement past work in understanding privacy choices, and that our categorization technique can aid in the design of new computer security technologies.',\n",
              "  \"Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps.[SEP]Most users of smartphone apps remain unaware of what data about them is being collected, by whom, and how these data are being used. In this mixed methods investigation, we examine the question of whether revealing key data collection practices of smartphone apps may help people make more informed privacy-related decisions. To investigate this question, we designed and prototyped a new class of privacy indicators, called Data Controller Indicators (DCIs), that expose previously hidden information flows out of the apps. Our lab study of DCIs suggests that such indicators do support people in making more confident and consistent choices, informed by a more diverse range of factors, including the number and nature of third-party companies that access users' data. Furthermore, personalised DCIs, which are contextualised against the other apps an individual already uses, enable them to reason effectively about the differential impacts on their overall information exposure.\",\n",
              "  'Privacy as part of the app decision-making process.[SEP]Smartphones have unprecedented access to sensitive personal information. While users report having privacy concerns, they may not actively consider privacy while downloading apps from smartphone application marketplaces. Currently, Android users have only the Android permissions display, which appears after they have selected an app to download, to help them understand how applications access their information. We investigate how permissions and privacy could play a more active role in app-selection decisions. We designed a short \"Privacy Facts\\' display, which we tested in a 20-participant lab study and a 366-participant online experiment. We found that by bringing privacy information to the user when they were making the decision and by presenting it in a clearer fashion, we could assist users in choosing applications that request fewer permissions.',\n",
              "  'Maximum Likelihood Postprocessing for Differential Privacy under Consistency Constraints.[SEP]When analyzing data that has been perturbed for privacy reasons, one is often concerned about its usefulness. Recent research on differential privacy has shown that the accuracy of many data queries can be improved by post-processing the perturbed data to ensure consistency constraints that are known to hold for the original data. Most prior work converted this post-processing step into a least squares minimization problem with customized efficient solutions. While improving accuracy, this approach ignored the noise distribution in the perturbed data.',\n",
              "  'Inference Analysis in Privacy-Preserving Data Re-publishing.[SEP]Privacy-Preserving Data Re-publishing (PPDR) deals with publishing microdata in dynamic scenarios. Due to privacy concerns, data must be disguised before being published. Research in privacy-preserving data publishing (PPDP) has proposed many such methods on static data. In PPDR, multiple appeared records can be used to infer private information of other records. Therefore, inference channels exist among different releases. To understand the privacy property of data re-publishing, we need to analyze the impact of these inference channels. Previous studies show such analysis when data are updated or disguised in special ways, however, no general method has been proposed. Using the Maximum Entropy Modeling method, we have developed a general solution. Our method can conduct inference analysis when data are arbitrarily updated or arbitrarily disguised using either generalization or bucketization, two most common data disguise methods in PPDR. Through analysis and experiments, we demonstrate the advantage and the effectiveness of our method.',\n",
              "  'Concentrated Differentially Private Gradient Descent with Adaptive per-Iteration Privacy Budget.[SEP]Iterative algorithms, like gradient descent, are common tools for solving a variety of problems, such as model fitting. For this reason, there is interest in creating differentially private versions of them. However, their conversion to differentially private algorithms is often naive. For instance, a fixed number of iterations are chosen, the privacy budget is split evenly among them, and at each iteration, parameters are updated with a noisy gradient.'],\n",
              " '37_urban_city_building_buildings': ['Staging Urban Interactions with Media Fa[SEP]Using media façades as a subcategory of urban computing, this paper contributes to the understanding of spatial interaction, sense-making, and social mediation as part of identifying key characteristics of interaction with media façades. Our research addresses in particular the open-ended but framed nature of interaction, which in conjunction with varying interpretations enables individual sense-making. Moreover, we contribute to the understanding of flexible social interaction by addressing urban interaction in relation to distributed attention, shared focus, dialogue and collective action. Finally we address challenges for interaction designers encountered in a complex spatial setting calling for a need to take into account multiple viewing and action positions. Our research-through-design approach has included a real-life design intervention in terms of the design, implementation, and reflective evaluation of a 180 m2 (1937 square feet) interactive media façade in operation 24/7 for more than 50 days.',\n",
              "  'Immersive Street-level Social Media in the 3D Virtual City: Anticipated User Experience and Conceptual Development.[SEP]In this paper we explore immersive street-level integration of social media content into collaborative virtual 3D city environments on two levels: i) public, where the virtual environment is populated with relevant social media content (e.g. Twitter and Facebook feeds of shops, non-governmetal organizations, the City organization); and ii) personal, where the virtual user, through his/her avatar, is able to access his/her personal social media feeds while immersed in the virtual city. We conducted a qualitative anticipated user experience study with 14 participants in four focus groups, who were asked to create designs of how they imagined social networking services could be integrated into virtual city environments. Further, participants were asked to comment on two visual concepts created by researchers. Results show that people appreciate the concept of having virtual cities populated with up-to-date content from social media services, but linking their own social media accounts is a more complex issue.',\n",
              "  'Projected Realities: Conceptual Design for Cultural Effect.[SEP]As a part of a European Union sponsored project, we have proposed a system which aggregates peoples expressions over a widening network of public electronic displays in a massive Dutch housing development. Reflecting ideas from contemporary arts as well as from research on media spaces, this is an example of a conceptual design intended to produce meaningful effects on a local culture. In this paper, we describe the methods and ideas that led to this proposal, as an example of research on technologies from the traditions of artist-designers.',\n",
              "  'A Survey of Urban Reconstruction.[SEP]This paper provides a comprehensive overview of urban reconstruction. While there exists a considerable body of literature, this topic is still under very active research. The work reviewed in this survey stems from the following three research communities: computer graphics, computer vision, and photogrammetry and remote sensing. Our goal is to provide a survey that will help researchers to better position their own work in the context of existing solutions, and to help newcomers and practitioners in computer graphics to quickly gain an overview of this vast field. Further, we would like to bring the mentioned research communities to even more interdisciplinary work, since the reconstruction problem itself is by far not solved.',\n",
              "  'Generating 3D Building Models from Architectural Drawings: A Survey.[SEP]Automatically generating 3D building models from 2D architectural drawings has many useful applications in the architecture engineering and construction community. This survey of model generation from paper and CAD-based architectural drawings covers the common pipeline and compares various algorithms for each step of the process.',\n",
              "  \"Automatic Integration of Facade Textures into 3D Building Models with a Projective Geometry Based Line Clustering.[SEP]Visualization of city scenes is important for many applications including entertainment and urban mission planning. Models covering wide areas can be efficiently constructed from aerial images. However, only roof details are visible from aerial views; ground views are needed to provide details of the building facades for high quality 'fly‐through' visualization or simulation applications. We present an automatic method of integrating facade textures from ground view images into 3D building models for urban site modeling. We first segment the input image into building facade regions using a hybrid feature extraction method, which combines global feature extraction with Hough transform on an adaptively tessellated Gaussian Sphere and local region segmentation. We estimate the external camera parameters by using the corner points of the extracted facade regions to integrate the facade textures into the 3D building models. We validate our approach with a set of experiments on some urban sites.\"],\n",
              " '38_transaction_transactions_concurrency_distributed': ['Efficient Concurrency Control for Broadcast Environments.[SEP]A crucial consideration in environments where data is broadcast to clients is the low bandwidth available for clients to communicate with servers. Advanced applications in such environments do need to read data that is mutually consistent as well as current. However, given the asymmetric communication capabilities and the needs of clients in mobile environments, traditional serializability-based approaches are too restrictive, unnecessary, and impractical. We thus propose the use of a weaker correctness criterion called update consistency and outline mechanisms based on this criterion that ensure (1) the mutual consistency of data maintained by the server and read by clients, and (2) the currency of data read by clients. Using these mechanisms, clients can obtain data that is current and mutually consistent “off the air”, i.e., without contacting the server to, say, obtain locks. Experimental results show a substantial reduction in response times as compared to existing (serializability-based) approaches. A further attractive feature of the approach is that if caching is possible at a client, weaker forms of currency can be obtained while still satisfying the mutual consistency of data.',\n",
              "  \"Concepts for Transaction Recovery in Nested Transactions.[SEP]The concept of nested transactions offers more decomposable execution units and finer grained control over recovery and concurrency as compared to 'flat' transactions. To exploit these advantages, especially transaction recovery has to be refined and adjusted to the requirements of the control structure.\",\n",
              "  'Implementing Recoverable Requests Using Queues.[SEP]Transactions have been rigorously defined and extensively studied in the database and transaction processing literature, but little has been said about the handling of the requests for transaction execution in commercial TP systems, especially distributed ones, managing the flow of requests is often as important as executing the transactions themselves.'],\n",
              " '39_displays_display_navigation_lenses': [\"360° panoramic overviews for location-based services.[SEP]We investigate 360° panoramas as overviews to support users in the task of locating objects in the surrounding environment. Panoramas are typically visualized as rectangular photographs, but this does not provide clear cues for physical directions in the environment. In this paper, we conduct a series of studies with three different shapes: Frontal, Top-Down and Bird's Eye; the last two shapes are chosen because they provide a clearer representation of the spatial mapping between panorama and environment. Our results show that good readability of the panorama is most important and that a clear representation of the spatial mapping plays a secondary role. This paper is the first to provide understanding on how users exploit 360° panoramic over-views to locate objects in the surrounding environment and how different design factors can affect user performance.\",\n",
              "  'Effects of display size and navigation type on a classification task.[SEP]The advent of ultra-high resolution wall-size displays and their use for complex tasks require a more systematic analysis and deeper understanding of their advantages and drawbacks compared with desktop monitors. While previous work has mostly addressed search, visualization and sense-making tasks, we have designed an abstract classification task that involves explicit data manipulation. Based on our observations of real uses of a wall display, this task represents a large category of applications. We report on a controlled experiment that uses this task to compare physical navigation in front of a wall-size display with virtual navigation using pan-and-zoom on the desktop. Our main finding is a robust interaction effect between display type and task difficulty: while the desktop can be faster than the wall for simple tasks, the wall gains a sizable advantage as the task becomes more difficult. A follow-up study shows that other desktop techniques (overview+detail, lens) do not perform better than pan-and-zoom and are therefore slower than the wall for difficult tasks.',\n",
              "  'Wedge: clutter-free visualization of off-screen locations.[SEP]To overcome display limitations of small-screen devices, researchers have proposed techniques that point users to objects located off-screen. Arrow-based techniques such as City Lights convey only direction. Halo conveys direction and distance, but is susceptible to clutter resulting from overlapping halos. We present Wedge, a visualization technique that conveys direction and distance, yet avoids overlap and clutter. Wedge represents each off-screen location using an acute isosceles triangle: the tip coincides with the off-screen locations, and the two corners are located on-screen. A wedge conveys location awareness primarily by means of its two legs pointing towards the target. Wedges avoid overlap programmatically by repelling each other, causing them to rotate until overlap is resolved. As a result, wedges can be applied to numbers and configurations of targets that would lead to clutter if visualized using halos. We report on a user study comparing Wedge and Halo for three off-screen tasks. Participants were significantly more accurate when using Wedge than when using Halo.',\n",
              "  \"Elastic windows: improved spatial layout and rapid multiple window operations.[SEP]Most windowing systems follow the independent overlapping windows approach, which emerged as an answer to the needs of the 80s' application and technology. Advances in computers, display technology, and the applications demand more functionality from window management systems. Based on these changes and the problems of current windowing appraoches, we have updated the requirements for multiwindow systems to guide new methods of window management. We propose elastic windows with improved spatial layout and rapid multi-window operations. Multi-window operations are achieved by issuing operations on window groups hierachically organized in a space-filling tiled layout. Sophisticated multi-window operations and spatial layout dynamics helps users to handle fast task-switching and to structure thier work environment to their rapidly changing needs. We claim that these multi-window operations and the improved spatial layout decrease the cognitive load on users. Users found our prototype system to be comprehensible and enjoyable as they playfully explored the way multiple windows are reshaped.\",\n",
              "  'Copy-and-paste between overlapping windows.[SEP]Copy-and-paste, one of the fundamental operations of modern userinterfaces, can be performed through various means (e.g. using the keyboard, mouse-based direct manipulation or menus). When users copy-and-paste between two different windows, the process is complicated by window management tasks. In this paper, we propose two new window management techniques to facilitate these tasks in the particular case of partially overlapping windows. We describe an experiment comparing four commonly-used copy-and-paste techniques under four window management conditions -- non-overlapping windows, partially overlapping windows, and partially overlapping ones with one of our two window management techniques. Results show that our new window management techniques significantly reduce task completion time for all copy-and-paste techniques. They also show that X Window copy-and-paste is faster than the other three techniques under all four window management conditions.',\n",
              "  'A window system with leafing through mode: BookWindow.[SEP]This paper describes “Book Window” that we implemented, a window system based on the “book” metaphor, that displays information not by scrolling but by using the animation of paging through. The BookWindow system equips some bookmarks, tabs, etc., by which we can access to an expected page through our requirements. BookWindow can support our work environment which navigates us through information space flexibly, because human beings are quite familiar with “books”.',\n",
              "  \"ThinVR: Heterogeneous microlens arrays for compact, 180 degree FOV VR near-eye displays.[SEP]Today's Virtual Reality (VR) displays are dramatically better than the head-worn displays offered 30 years ago, but today's displays remain nearly as bulky as their predecessors in the 1980's. Also, almost all consumer VR displays today provide 90-110 degrees field of view (FOV), which is much smaller than the human visual system's FOV which extends beyond 180 degrees horizontally. In this paper, we propose ThinVR as a new approach to simultaneously address the bulk and limited FOV of head-worn VR displays. ThinVR enables a head-worn VR display to provide 180 degrees horizontal FOV in a thin, compact form factor. Our approach is to replace traditional large optics with a curved microlens array of custom-designed heterogeneous lenslets and place these in front of a curved display. We found that heterogeneous optics were crucial to make this approach work, since over a wide FOV, many lenslets are viewed off the central axis. We developed a custom optimizer for designing custom heterogeneous lenslets to ensure a sufficient eyebox while reducing distortions. The contribution includes an analysis of the design space for curved microlens arrays, implementation of physical prototypes, and an assessment of the image quality, eyebox, FOV, reduction in volume and pupil swim distortion. To our knowledge, this is the first work to demonstrate and analyze the potential for curved, heterogeneous microlens arrays to enable compact, wide FOV head-worn VR displays.\",\n",
              "  \"Gaussian Light Field: Estimation of Viewpoint-Dependent Blur for Optical See-Through Head-Mounted Displays.[SEP]We propose a method to calibrate viewpoint-dependent, channel-wise image blur of near-eye displays, especially of Optical See-Through Head-Mounted Displays (OST-HMDs). Imperfections in HMD optics cause channel-wise image shift and blur that degrade the image quality of the display at a user's viewpoint. If we can estimate such characteristics perfectly, we could mitigate the effect by applying correction techniques from the computational photography in computer vision as analogous to cameras. Unfortunately, directly applying existing calibration techniques of cameras to OST-HMDs is not a straightforward task. Unlike ordinary imaging systems, image blur in OST-HMDs is viewpoint-dependent, i.e., the optical characteristic of a display dynamically changes depending on the current viewpoint of the user. This constraint makes the problem challenging since we must measure image blur of an HMD, ideally, over the entire 3D eyebox in which a user can see an image. To overcome this problem, we model the viewpoint-dependent blur as a Gaussian Light Field (GLF) that stores spatial information of the display screen as a (4D) light field with depth information and the blur as point-spread functions in the form of Gaussian kernels, respectively. We first describe both our GLF model and a calibration procedure to learn a GLF for a given OST-HMD. We then apply our calibration method to two HMDs that use different optics: a cubic prism or holographic gratings. The results show that our method achieves significantly better accuracy in Point-Spread Function (PSF) estimations with an accuracy about 2 to 7 dB in Peak SNR.\",\n",
              "  \"A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays.[SEP]Optical see-through head-mounted displays (OST HMDs) are a major output medium for Augmented Reality, which have seen significant growth in popularity and usage among the general public due to the growing release of consumer-oriented models, such as the Microsoft Hololens. Unlike Virtual Reality headsets, OST HMDs inherently support the addition of computer-generated graphics directly into the light path between a user's eyes and their view of the physical world. As with most Augmented and Virtual Reality systems, the physical position of an OST HMD is typically determined by an external or embedded 6-Degree-of-Freedom tracking system. However, in order to properly render virtual objects, which are perceived as spatially aligned with the physical environment, it is also necessary to accurately measure the position of the user's eyes within the tracking system's coordinate frame. For over 20 years, researchers have proposed various calibration methods to determine this needed eye position. However, to date, there has not been a comprehensive overview of these procedures and their requirements. Hence, this paper surveys the field of calibration methods for OST HMDs. Specifically, it provides insights into the fundamentals of calibration techniques, and presents an overview of both manual and automatic approaches, as well as evaluation methods and metrics. Finally, it also identifies opportunities for future research.\",\n",
              "  \"The Immersive Visualization Probe for Exploring n-Dimensional Spaces.[SEP]A new tool uses two types of dimensional navigation to display continuous 4D subsets of n-dimensional data. Thanks to the tool's embedded coordinate systems, researchers can better understand a model's underlying physical or mathematical process. Here, we describe a new method for visualizing data structure or models defined in higher-dimensional spaces. This technique is suitable for applications in which a scalar function, defined mathematically or procedurally, depends on n variables or parameters. The function's values essentially describe a set of points in n-dimensional space. To visualize these sets, we fix all but three of the parameters and then sample the resulting 4D set (the three parameters and the function's resulting value) on several discrete grids located on planes in the 3D space. We compose the image by using color to represent the fourth dimension (the function's value) at discrete locations on these grids. Interactive control over the way the parameters are fixed results in a highly dynamic system that researchers can easily use to explore the n-dimensional space's structure.\",\n",
              "  'Multidimensional virtual reality-MVR method: a new method of visualization of multidimensional worlds.[SEP]The paper presents a new, original method of multidimensional worlds’ visualization. It allows to present views of any dimension objects out of which it is possible to construct even the most complicated multidimensional virtual world on a computer screen. Due to this, it is possible to observe multidimensional worlds modeled in this way, analyze mutual relations between multidimensional objects, move between them and, most importantly, verify whether human brain is able to adapt to the perception of more than three-dimensional space. This paper presents example interior views of four-dimensional and five-dimensional labyrinths. It also presents results of the research performed on 97 IT students at the AGH University of Science and Technology. Students in total made 357 attempts to leave virtual four-dimensional and five-dimensional labyrinths, each having three difficulty levels. The method presented in this paper is sufficiently general to allow observation of objects in an n-dimensional space for any 𝑛≥3n≥3. Simultaneously, it is the natural extension of our reality perception because using this method for 𝑛=3n=3 we obtain views known to us from our human experience from the three-dimensional space.',\n",
              "  'ImAxes: Immersive Axes as Embodied Affordances for Interactive Multivariate Data Visualisation.[SEP]We introduce ImAxes immersive system for exploring multivariate data using fluid, modeless interaction. The basic interface element is an embodied data axis. The user can manipulate these axes like physical objects in the immersive environment and combine them into sophisticated visualisations. The type of visualisation that appears depends on the proximity and relative orientation of the axes with respect to one another, which we describe with a formal grammar. This straight-forward composability leads to a number of emergent visualisations and interactions, which we review, and then demonstrate with a detailed multivariate data analysis use case.'],\n",
              " '3_recommendation_recommender_recommendations_users': ['Smart Pacing for Effective Online Ad Campaign Optimization.[SEP]In targeted online advertising, advertisers look for maximizing campaign performance under delivery constraint within budget schedule. Most of the advertisers typically prefer to impose the delivery constraint to spend budget smoothly over the time in order to reach a wider range of audiences and have a sustainable impact. Since lots of impressions are traded through public auctions for online advertising today, the liquidity makes price elasticity and bid landscape between demand and supply change quite dynamically. Therefore, it is challenging to perform smooth pacing control and maximize campaign performance simultaneously. In this paper, we propose a smart pacing approach in which the delivery pace of each campaign is learned from both offline and online data to achieve smooth delivery and optimal performance goals. The implementation of the proposed approach in a real DSP system is also presented. Experimental evaluations on both real online ad campaigns and offline simulations show that our approach can effectively improve campaign performance and achieve delivery goals.',\n",
              "  'From 0.5 Million to 2.5 Million: Efficiently Scaling up Real-Time Bidding.[SEP]Real-Time Bidding allows an advertiser to purchase media inventory through an auction system that unfolds in the order of milliseconds. Media providers are increasingly being integrated into such programmatic buying platforms. It is typical for a contemporary Real-Time Bidding system to receive millions of bid requests per second at peak time, and have a large portion of these to be irrelevant to any advertiser. Meanwhile, given a valuable bid request, tens of thousands of advertisements might be qualified for scoring. We present our efforts in building selection models for both bid requests and advertisements to handle this scalability challenge. Our bid request model treats the system load as a hierarchical resource allocation problem and directs traffic based on the estimated quality of bid requests. Next, our exploration/exploitation advertisement model selects a limited number of qualified advertisements for thorough scoring based on the expected value of a bid request to the advertiser given its features. Our combined bid request and advertisement model is able to win more auctions and bring more value to clients by stabilizing the bidding pipeline. We empirically show that our deployed system is capable of handling 5x more bid requests.',\n",
              "  \"An Engagement-Based Customer Lifetime Value System for E-commerce.[SEP]A comprehensive understanding of individual customer value is crucial to any successful customer relationship management strategy. It is also the key to building products for long-term value returns. Modeling customer lifetime value (CLTV) can be fraught with technical difficulties, however, due to both the noisy nature of user-level behavior and the potentially large customer base. Here we describe a new CLTV system that solves these problems. This was built at Groupon, a large global e-commerce company, where confronting the unique challenges of local commerce means quickly iterating on new products and the optimal inventory to appeal to a wide and diverse audience. Given current purchaser frequency we need a faster way to determine the health of individual customers, and given finite resources we need to know where to focus our energy. Our CLTV system predicts future value on an individual user basis with a random forest model which includes features that account for nearly all aspects of each customer's relationship with our platform. This feature set includes those quantifying engagement via email and our mobile app, which give us the ability to predict changes in value far more quickly than models based solely on purchase behavior. We further model different customer types, such as one-time buyers and power users, separately so as to allow for different feature weights and to enhance the interpretability of our results. Additionally, we developed an economical scoring framework wherein we re-score a user when any trigger events occur and apply a decay function otherwise, to enable frequent scoring of a large customer base with a complex model. This system is deployed, predicting the value of hundreds of millions of users on a daily cadence, and is actively being used across our products and business initiatives.\"],\n",
              " '40_search_web_information_pages': [\"Internet Search Roles of Adults in their Homes.[SEP]Internet search is one of the major activities that American adults engage in online. Building on studies of youth Internet search roles, this paper investigates adults' online information seeking processes within the home. Through in-home interviews and observations of search task performance with 40 adult participants, we identify and describe characteristics of 9 search roles. By comparing these roles with those of youths, we explain how previously identified roles, such as Power Searcher and Social Searcher, have evolved in adult populations, and how new roles, such as Efficient Searcher and Interest-driven Searcher, have emerged. We also review the challenges and benefits associated with search roles and their potential impacts on search performance. The findings of this study provide a better understanding of how contextual factors influence search roles in relation to ELIS, what can be learned from search roles, and opportunities to support different search roles.\",\n",
              "  'Designing the Search Experience.[SEP]This half-day tutorial provides a practical introduction to Human-Centred Design for information search, access and discovery. We present a concise overview of the fundamental concepts and principles of human information-seeking behaviour and show how to apply these in the design of search user experiences. A key element of the tutorial is the opportunity to practice these skills in a group exercise.',\n",
              "  'Adaptive information search: age-dependent interactions between cognitive profiles and strategies.[SEP]Previous research has shown that older adults performed worse in web search tasks, and attributed poorer performance to a decline in their cognitive abilities. We conducted a study involving younger and older adults to compare their web search behavior and performance in ill-defined and well-defined information tasks using a health information website. In ill-defined tasks, only a general description about information needs was given, while in well-defined tasks, information needs as well as the specific target information were given. We found that older adults performed worse than younger adults in well-defined tasks, but the reverse was true in ill-defined tasks. Older adults compensated for their lower cognitive abilities by adopting a top-down knowledge-driven strategy to achieve the same level of performance in the ill-defined tasks. Indeed, path models showed that cognitive abilities, health literacy, and knowledge influenced search strategies adopted by older and younger adults. Design implications are also discussed.',\n",
              "  \"Exploring multi-session web tasks.[SEP]Users are now performing more sophisticated web tasks. In this work, we explore web tasks that require multiple web sessions to complete (multi-session tasks) to satisfy a goal. We conducted a web-based diary study and a field study that used a customized version of Firefox which logged the participants' interactions for multi-session tasks and all their web activity. We found that multi-session tasks occur frequently and that users utilize a variety of browser tools and actions to help complete these tasks.\",\n",
              "  'Interest-Determining Web Browser.[SEP]This paper investigates the application of data-mining techniques on a user’s browsing history for the purpose of determining the user’s interests. More specifically, a system is outlined that attempts to determine certain keywords that a user may or may not be interested in. This is done by first applying a term-frequency/inverse-document frequency filter to extract keywords from webpages in the user’s history, after which a Self-Organizing Map (SOM) neural network is utilized to determine if these keywords are of interest to the user. Such a system could enable web-browsers to highlight areas of web pages that may be of higher interest to the user. It is found that while the system is indeed successful in identifying many keywords of user-interest, it also mis-classifies many uninteresting words boasting only a 62% accuracy rate.',\n",
              "  \"How do people find information on a familiar website?[SEP]Previous research has investigated how people either navigate the web as a whole, or find information on websites of which they have little previous knowledge. However, it is now common for people to make frequent use of one site (e.g., their employer's intranet). This paper reports how participants recalled and navigated a familiar website they had used for 8--20 months. Sketch maps showed that participants' memory for the site's content and structure was very limited in extent, but generally accurate. Navigation data showed that participants had much more difficulty finding the region of the site that contained a piece of information, than then finding the information itself. These data highlight the need for directly accessed pages to be given greater prominence in browser history mechanisms and designers to make information regions memorable. Finally, two navigational path metrics (stratum and percentage of revisit actions) that correlated with participants' performance were identified.\",\n",
              "  'Freebase: a collaboratively created graph database for structuring human knowledge.[SEP]Freebase is a practical, scalable tuple database used to structure general human knowledge. The data in Freebase is collaboratively created, structured, and maintained. Freebase currently contains more than 125,000,000 tuples, more than 4000 types, and more than 7000 properties. Public read/write access to Freebase is allowed through an HTTP-based graph-query API using the Metaweb Query Language (MQL) as a data query and manipulation language. MQL provides an easy-to-use object-oriented interface to the tuple data in Freebase and is designed to facilitate the creation of collaborative, Web-based data-oriented applications.',\n",
              "  'Hybrid in-database inference for declarative information extraction.[SEP]In the database community, work on information extraction (IE) has centered on two themes: how to effectively manage IE tasks, and how to manage the uncertainties that arise in the IE process in a scalable manner. Recent work has proposed a probabilistic database (PDB) based declarative IE system that supports a leading statistical IE model, and an associated inference algorithm to answer top-k-style queries over the probabilistic IE outcome. Still, the broader problem of effectively supporting general probabilistic inference inside a PDB-based declarative IE system remains open. In this paper, we explore the in-database implementations of a wide variety of inference algorithms suited to IE, including two Markov chain Monte Carlo algorithms, the Viterbi and the sum-product algorithms. We describe the rules for choosing appropriate inference algorithms based on the model, the query and the text, considering the trade-off between accuracy and runtime. Based on these rules, we describe a hybrid approach to optimize the execution of a single probabilistic IE query to employ different inference algorithms appropriate for different records. We show that our techniques can achieve up to 10-fold speedups compared to the non-hybrid solutions proposed in the literature.',\n",
              "  'ONDUX: on-demand unsupervised learning for information extraction.[SEP]Information extraction by text segmentation (IETS) applies to cases in which data values of interest are organized in implicit semi-structured records available in textual sources (e.g. postal addresses, bibliographic information, ads). It is an important practical problem that has been frequently addressed in the recent literature. In this paper we introduce ONDUX (On Demand Unsupervised Information Extraction), a new unsupervised probabilistic approach for IETS. As other unsupervised IETS approaches, ONDUX relies on information available on pre-existing data to associate segments in the input string with attributes of a given domain. Unlike other approaches, we rely on very effective matching strategies instead of explicit learning strategies. The effectiveness of this matching strategy is also exploited to disambiguate the extraction of certain attributes through a reinforcement step that explores sequencing and positioning of attribute values directly learned on-demand from test data, with no previous human-driven training, a feature unique to ONDUX. This assigns to ONDUX a high degree of flexibility and results in superior effectiveness, as demonstrated by the experimental evaluation we report with textual sources from different domains, in which ONDUX is compared with a state-of-art IETS approach.'],\n",
              " '41_category_categories_categorization_similarity': ['Similarity-based Ordering of Instances for Efficient Concept Learning.[SEP]Theories in concept learning predict that interleaving instances of different concepts is especially beneficial if the concepts are highly similar to each other, whereas blocking instances belonging to the same concept provides an advantage for learning low-similarity concept structures. This suggests that the performance in concept learning tasks can be improved by grouping the instances of given concepts based on their similarity. To explore this hypothesis, we use Physical Bongard Problems, a rich categorization task with an open feature space, to analyze the combined effects of comparing dissimilar and similar instances within and across categories. We manipulate the within- and between-category similarity of instances presented close to each other in blocked, interleaved and simultaneous presentation schedules. The results show that grouping instances to promote dissimilar within- and similar between-category comparisons improves the learning results, to a degree depending on the strategy used by the learner.',\n",
              "  'Models of Human Category Learning: Do they Generalize?[SEP]Generalization to new examples is an essential aspect of categorization. However, recent category learning research has not focused on how people generalize their category knowledge. Taking generalization to be a critical basis for evaluating formal models of category learning, we employed a ‘minimal case’ approach to begin a systematic investigation of generalization. Human participants received supervised training on a two-way artificial classification task based on two dimensions that were each perfect predictors. Learners were then asked to classify new examples sampled from the stimulus space. Most participants based their judgments on one or the other dimension. Varying the relative levels of dimension salience influenced generalization outcomes, but varying category size (2, 4, or 8 items) did not. We fit two theoretically distinct similarity-based models (ALCOVE and DIVA) to aggregate learning data and tested on the generalization set. Both models could explain important aspects of human performance, but DIVA produced a superior overall account.',\n",
              "  'Perceptual Learning in Correlation Estimation: The Role of Learning Category Organization.[SEP]Research has shown that estimation of correlation from scatter plots is done poorly by both novices and experts. We tested whether proficiency in correlation estimation could be improved by perceptual learning interventions, in the form of perceptual-adaptive learning modules (PALMs). We also tested learning effects of alternative category structures in perceptual learning. We organized the same set of 252 scatter plot displays either into a PALM that implemented spacing in learning by shape categories or one in which the categories were ranges of correlation strength. Both PALMs produced markedly reduced errors, and both led trained participants to classify near transfer items as accurately as trained items. Differences in category organization produced modest effects on learning; there was some indication of more consistent reduction of absolute error when learning categories were organized by shape, whereas average bias of judgments was best reduced by categories organized by different numerical ranges of correlation.'],\n",
              " '42_crowdsourcing_workers_crowd_worker': ['Demonstration of Qurk: a query processor for humanoperators.[SEP]Crowdsourcing technologies such as Amazon\\'s Mechanical Turk (\"MTurk\") service have exploded in popularity in recent years. These services are increasingly used for complex human-reliant data processing tasks, such as labelling a collection of images, combining two sets of images to identify people that appear in both, or extracting sentiment from a corpus of text snippets. There are several challenges in designing a workflow that filters, aggregates, sorts and joins human-generated data sources. Currently, crowdsourcing-based workflows are hand-built, resulting in increasingly complex programs. Additionally, developers must hand-optimize tradeoffs among monetary cost, accuracy, and time to completion of results. These challenges are well-suited to a declarative query interface that allows developers to describe their worflow at a high level and automatically optimizes workflow and tuning parameters. In this demonstration, we will present Qurk, a novel query system that allows human-based processing for relational databases. The audience will interact with the system to build queries and monitor their progress. The audience will also see Qurk from an MTurk user\\'s perspective, and complete several tasks to better understand how a query is processed.',\n",
              "  \"CrowdFill: collecting structured data from the crowd.[SEP]We present CrowdFill, a system for collecting structured data from the crowd. While a typical microtask-based approach would pose specific questions to each worker and assemble the answers, CrowdFill shows a partially-filled table to all participating workers. Workers contribute by filling in empty cells, as well as upvoting and downvoting data entered by other workers. The system's synchronization scheme, based on a careful model of primitive operations, enables workers to collaboratively complete the table without latency overhead. CrowdFill allows the specification of constraints on the collected data, and has mechanisms for resolving inconsistencies. Its compensation scheme takes into account each worker's contribution to the final table, and the varying difficulty of data entry tasks. The paper includes some preliminary experimental results.\",\n",
              "  'CrowdDQS: Dynamic Question Selection in Crowdsourcing Systems.[SEP]In this paper, we present CrowdDQS, a system that uses the most recent set of crowdsourced voting evidence to dynamically issue questions to workers on Amazon Mechanical Turk (AMT). CrowdDQS posts all questions to AMT in a single batch, but delays the decision of the exact question to issue a worker until the last moment, concentrating votes on uncertain questions to maximize accuracy. Unlike previous works, CrowdDQS also (1) optionally can decide when it is more beneficial to issue gold standard questions with known answers than to solicit new votes (both can help us estimate worker accuracy, but gold standard questions provide a less noisy estimate of worker accuracy at the expense of not obtaining new votes), (2) estimates worker accuracies in real-time even with limited evidence (with or without gold standard questions), and (3) infers the distribution of worker skill levels to actively block poor workers. We deploy our system live on AMT to over 1000 crowdworkers, and find that CrowdDQS can accurately answer questions using up to 6x fewer votes than standard approaches. We also find there are many non-obvious practical challenges involved in deploying such a system seamlessly to crowdworkers, and discuss techniques to overcome these challenges.'],\n",
              " '43_patient_patients_care_clinical': ['Local-universality: designing EMR to support localized informal documentation practices.[SEP]In this paper, we describe a practice that is common across multiple heterogeneous contexts but enacted differently depending on the unique constellation of resources and demands present in each local context. Using the case of informal documentation practices in two departments of a single hospital, Emergency and Labor & Delivery, we describe how clinicians in each department develop contextualized informal documentation practices after deployment of a new EMR system. We describe three underlying functions of informal documentation that are inherent to the practice of medical personnel: \"memory work,\" abstraction work,\" and \"future work.\" We then find that the newly deployed EMR technology does not support these kinds of work. We argue that hospital documentation work systems should be designed with an eye to such universal work practices, while keeping in mind that the effectiveness of informal documentation practices is rooted in its adaptive and flexible deployment in heterogeneous work settings.',\n",
              "  \"Accountability in an alarming environment.[SEP]This paper considers how adjustable alarms support collaborative monitoring work within the intensive care unit. Drawing on examples from an observational study, it hopes to stimulate new ways of thinking about the role that alarms play in supporting awareness of not only changes in the environment but also awareness of colleagues' actions. Adjustable alarms allow nurses to fit the alarm limits to both the patient state and the nurse's level of experience. The setting of alarm limits is an accountable activity, being visible to and observed by colleagues.\",\n",
              "  \"Documenting transitional information in EMR.[SEP]An observational study was conducted to examine EMR-based documentation in an Emergency Department (ED), with an emphasis on computerized documentation activities in the complex flow of clinical processes. This study revealed a gap between the formal EMR documentation and the actual clinical workflow, which leads ED staff to rely on intermediate - transitional artifacts to facilitate their work. The analysis of these transitional artifacts in four different clinical workflows shows that the EMR system's inability to document procedural information, capture key information, and present information according to the actual clinical workflow are accountable for leading to the use of transitional artifacts. The findings of this study call for designing EMR system not only for keeping patients' formal records, but also for documenting transitional information in the chart-writing process.\",\n",
              "  'Patient Subtyping via Time-Aware LSTM Networks.[SEP]In the study of various diseases, heterogeneity among patients usually leads to different progression patterns and may require different types of therapeutic intervention. Therefore, it is important to study patient subtyping, which is grouping of patients into disease characterizing subtypes. Subtyping from complex patient data is challenging because of the information heterogeneity and temporal dynamics. Long-Short Term Memory (LSTM) has been successfully used in many domains for processing sequential data, and recently applied for analyzing longitudinal patient records. The LSTM units are designed to handle data with constant elapsed times between consecutive elements of a sequence. Given that time lapse between successive elements in patient records can vary from days to months, the design of traditional LSTM may lead to suboptimal performance. In this paper, we propose a novel LSTM unit called Time-Aware LSTM (T-LSTM) to handle irregular time intervals in longitudinal patient records. We learn a subspace decomposition of the cell memory which enables time decay to discount the memory content according to the elapsed time. We propose a patient subtyping model that leverages the proposed T-LSTM in an auto-encoder to learn a powerful single representation for sequential records of patients, which are then used to cluster patients into clinical subtypes. Experiments on synthetic and real world datasets show that the proposed T-LSTM architecture captures the underlying structures in the sequences with time irregularities.',\n",
              "  'Dynamic Illness Severity Prediction via Multi-task RNNs for Intensive Care Unit.[SEP]Most of the existing analytics on ICU data mainly focus on mortality risk prediction and phenotyping analysis. However, they have limitations in providing sufficient evidence for decision making in a dynamically changing clinical environment. In this paper, we propose a novel approach that simultaneously analyses different organ systems to predict the illness severity of patients in an ICU, which can intuitively reflect the condition of the patients in a timely fashion. Specifically, we develop a novel deep learning model, namely MTRNN-ATT, which is based on multi-task recurrent neural networks. The physiological features of each organ system in time-series representations are learned by a single long short-term memory unit as a specific task. To utilize the relationships between organ systems, we use a shared LSTM unit to exploit the correlations between different tasks for further performance improvement. Also, we apply an attention mechanism in our deep model to learn the selective features at each stage to achieve better prediction results. We conduct extensive experiments on a real-world clinical dataset (MIMIC-III) to compare our method with many state-of-the-art methods. The experiment results demonstrate that the proposed approach performs better on the prediction tasks of illness severity scores.',\n",
              "  'Multi-layer Representation Learning for Medical Concepts.[SEP]Proper representations of medical concepts such as diagnosis, medication, procedure codes and visits from Electronic Health Records (EHR) has broad applications in healthcare analytics. Patient EHR data consists of a sequence of visits over time, where each visit includes multiple medical concepts, e.g., diagnosis, procedure, and medication codes. This hierarchical structure provides two types of relational information, namely sequential order of visits and co-occurrence of the codes within a visit. In this work, we propose Med2Vec, which not only learns the representations for both medical codes and visits from large EHR datasets with over million visits, but also allows us to interpret the learned representations confirmed positively by clinical experts. In the experiments, Med2Vec shows significant improvement in prediction accuracy in clinical applications compared to baselines such as Skip-gram, GloVe, and stacked autoencoder, while providing clinically meaningful interpretation.'],\n",
              " '44_diagrams_diagrammatic_diagram_logic': ['Aristotelian and Duality Relations Beyond the Square of Opposition.[SEP]Nearly all squares of opposition found in the literature represent both the Aristotelian relations and the duality relations, and exhibit a very close correspondence between both types of logical relations. This paper investigates the interplay between Aristotelian and duality relations in diagrams beyond the square. In particular, we study a Buridan octagon, a Lenzen octagon, a Keynes-Johnson octagon and a Moretti octagon. Each of these octagons is a natural extension of the square, both from an Aristotelian perspective and from a duality perspective. The results of our comparative analysis turn out to be highly nuanced.',\n",
              "  'A Semiotic-Conceptual Analysis of Euler and Hasse Diagrams.[SEP]Semiotic-Conceptual Analysis (SCA) considers diagrams (and in general any signs) as consisting of representamens, denotations and interpretations which supports investigating these three components individually and jointly. A core notion for diagram research is “observability” which refers to logically valid statements that can be visually extracted from diagrams. This notion is included into the SCA vocabulary and discussed with respect to Euler and Hasse diagrams.',\n",
              "  'Euler Diagrams for Defeasible Reasoning.[SEP]We investigate Euler diagrammatic systems for defeasible reasoning by extending the usual systems for Euler and Venn diagrams corresponding to standard classical logic. To achieve this, we use the generalized quantifier “most” to formalize defeasible reasoning, as proposed by Schlechta (1995), where defeasible knowledge is represented as “Most A are B” and axioms for “most” are defined. We introduce an Euler diagrammatic system for defeasible reasoning by introducing circle mA that represents “most A” for each circle A. We show that our Euler diagrammatic system is a diagrammatic representation of the symbolic system of the generalized quantifier “most”. Furthermore, we investigate skeptical and credulous strategies in defeasible reasoning with our Euler diagrams.',\n",
              "  'The Diagram of Flow: Its Departure from Software Engineering and Its Return.[SEP]The first diagrammatic notation used in software engineering represented the concept of flow. This paper considers the factors that affected the apparent departure of the flowchart from software engineering practice during the 1970s and 1980s and its subsequent return in the 1990s. A new emphasis on hierarchy (as level of abstraction) and on data structure meant that the general concept of flow was completely superseded, only to re-emerge later as a new duality of control flow and data flow. This reappearance took a variety of forms with varying semantics until its stabilisation in the latest version of the Unified Modeling Language. Flow is there re-instated as a fundamental concept in software engineering although its importance, and that of the activity diagram used to represent it, diminished as a consequence of its becoming just one among a wider set of paradigms for software systems development, each associated with its own diagrams.',\n",
              "  'Notations for Software Engineering Class Structures.[SEP]This builds on previous work in which we have developed diagramming principles based on theories of structural object perception. We call these geon diagrams. We have previously shown that such diagrams are easy to remember and to analyze. To evaluate our hypothesis that geon diagrams should also be easy to understand we carried out an empirical study to evaluate the learnability of geon diagram semantics in comparison with the well-established UML convention. The results support our theory of learnability. Both ”novices” and ”experts” found the geon diagram syntax easier to apply in a diagram-to-textual description matching task than the equivalent UML syntax.',\n",
              "  'Enhancing State-Space Tree Diagrams for Collaborative Problem Solving.[SEP]State-space search methods in problem solving have often been illustrated using tree diagrams. We explore a set of issues related to coordination in collaborative problem solving and design, and we present a variety of interactive features for state-space search trees intended to facilitate such activity. Issues include how to show provenance of decisions, how to combine work and views produced separately, and how to represent work performed by computer agents. Some of the features have been implemented in a kit “TStar” and a design tool “PRIME Designer.”'],\n",
              " '45_color_colors_palette_palettes': ['Color, Change and Control for Quantitative Data Display.[SEP]Calico, a dynamic tool for the creation and manipulation of color mappings for the exploration of multivariate, quantitative data, was used to study the effects of user control and smooth change on user preference, accuracy, and confidence. The results of the study, as well as other user experiences with Calico, support the hypothesis that dynamic manipulation of color mappings is a useful feature of systems for the exploration of quantitative data using color. The main effect observed is a clear user preference for representations providing control over the mapping, a small but significant increase in accuracy, and greater confidence in information gleaned from manipulable displays. A smaller and less consistent effect showed greater user preference for an confidence in representations which provided smooth change between images.< >',\n",
              "  \"Examining Implicit Discretization in Spectral Schemes.[SEP]Two of the primary reasons rainbow color maps are considered ineffective trace back to the idea that they implicitly discretize encoded data into hue‐based bands, yet no research addresses what this discretization looks like or how consistent it is across individuals. This paper presents an exploratory study designed to empirically investigate the implicit discretization of common spectral schemes and explore whether the phenomenon can be modeled by variations in lightness, chroma, and hue. Our results suggest that three commonly used rainbow color maps are implicitly discretized with consistency across individuals. The results also indicate, however, that this implicit discretization varies across different datasets, in a way that suggests the visualization community's understanding of both rainbow color maps, and more generally effective color usage, remains incomplete.\",\n",
              "  \"Modeling Color Difference for Visualization Design.[SEP]Color is frequently used to encode values in visualizations. For color encodings to be effective, the mapping between colors and values must preserve important differences in the data. However, most guidelines for effective color choice in visualization are based on either color perceptions measured using large, uniform fields in optimal viewing environments or on qualitative intuitions. These limitations may cause data misinterpretation in visualizations, which frequently use small, elongated marks. Our goal is to develop quantitative metrics to help people use color more effectively in visualizations. We present a series of crowdsourced studies measuring color difference perceptions for three common mark types: points, bars, and lines. Our results indicate that peoples' abilities to perceive color differences varies significantly across mark types. Probabilistic models constructed from the resulting data can provide objective guidance for designers, allowing them to anticipate viewer perceptions in order to inform effective encoding design.\"],\n",
              " '46_hci_design_research_practice': ['Metaprobes, Metaphysical Workshops and Sketchy Philosophy.[SEP]The intersection of philosophy and HCI is a longstanding site of interest for the field that has been attracting special attention in recent years. In this paper, we present metaphysical probes (Metaprobes) as a tool for design-led philosophical inquiry. A Metaprobe is a design artifact used to study a metaphysical idea without concealing the philosophical tools mobilized by the designers or the designerly knowledge attained after deployment. We introduce the concept of a Metaphysical Workshop. This is the set of sketchy philosophical notions that a designer mobilizes in order to research a philosophical idea through design. We then present a case study that comprises: the philosophical issue under examination, the Metaprobes designed to study it, the metaphysical workshop used and the designerly insight produced. We conclude with a discussion of the potentials and weaknesses of Metaprobes in relation to other critical and speculative research-through-design practices. We aim to provide one way to make philosophies already present in design more explicit and make other philosophical concepts relevant to HCI more accessible and workable for designers.',\n",
              "  'From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product.[SEP]As we increasingly strive for scientific rigor and generalizability in HCI research, should we entertain any hope that by doing good science, our discoveries will eventually be more transferrable to industry? We present an in-depth case study of how an HCI research innovation goes through the process of transitioning from a university project to a revenue-generating startup financed by venture capital. The innovation is a novel contextual help system for the Web, and we reflect on the different methods used to evaluate it and how research insights endure attempted dissemination as a commercial product. Although the extent to which any innovation succeeds commercially depends on a number of factors like market forces, we found that our HCI innovation with user-centered origins was in a unique position to gain traction with customers and garner buy-in from investors. However, since end users were not the buyers of our product, a strong user-centered focus obfuscated other critical needs of the startup and pushed out perspectives of non-user-centered stakeholders. To make the research-to-product transition, we had to focus on adoption-centered design, the process of understanding and designing for adopters and stakeholders of the product. Our case study raises questions about how we evaluate the novelty and research contributions of HCI innovations with respect to their potential for commercial impact.',\n",
              "  'Design Justice and User Interface Design.[SEP]In this keynote talk, Dr. Costanza-Chock will explore the theory and practice of design justice, discuss how design affordances, disaffordances, and dysaffordances distribute benefits and burdens unequally according to users? location within the matrix of domination (white supremacy, heteropatriarchy, ableism, capitalism, and settler colonialism), and invite us to consider how user interface designers can intentionally contribute to building ?a better world?, a world where many worlds fit; linked worlds of collective liberation and ecological sustainability.'],\n",
              " '47_robot_robots_robotic_robotics': ['Museum guide robot based on sociological interaction analysis.[SEP]We are currently working on a museum guide robot with an emphasis on \"friendly\" human-robot interaction displayed through nonverbal behaviors. In this paper, we focus on head gestures during explanations of exhibits. The outline of our research is as follows. We first examined human head gestures through an experimental, sociological approach. From this research, we have discovered how human guides coordinate their head movement along with their talk when explaining exhibits. Second, we developed a robot system based on these findings. Third, we evaluated human-robot interaction, again using an experimental, sociological approach, and then modified the robot based on the results. Our experimental results suggest that robot head turning may lead to heightened engagement of museum visitors with the robot. Based on our preliminary findings, we will describe a museum guide robot that first works autonomously and, if necessary, can turn into remote-control mode operated by a human to engage in more complex interaction with visitors.',\n",
              "  \"A Survey of Users' Expectations Towards On-body Companion Robots.[SEP]Being as a robotic companion is an extensive application of on-body robots; yet, as an emerging type of robots, few previous works focus on the design of on-body companion robots from the users' perspective, remaining users' expectations towards this type of robots unclear. To assist designers in the design process of on-body companion robots, we surveyed users' expectations towards on-body companion robots (n=215) by a questionnaire constituting of questions on factors that may affect robot acceptance, including robot functionality, robot appearance, and robot social ability. Based on the survey results, we stated design guidelines for the design of on-body companion robots supporting designers with insights into users. To demonstrate how to design on-body companion robots based on our findings, we organized a workshop with experienced designers to develop a conceptual on-body companion robot, and they proposed Bubo, an example prototype of on-body companion robot.\",\n",
              "  \"Authoring and Verifying Human-Robot Interactions.[SEP]As social agents, robots designed for human interaction must adhere to human social norms. How can we enable designers, engineers, and roboticists to design robot behaviors that adhere to human social norms and do not result in interaction breakdowns? In this paper, we use automated formal-verification methods to facilitate the encoding of appropriate social norms into the interaction design of social robots and the detection of breakdowns and norm violations in order to prevent them. We have developed an authoring environment that utilizes these methods to provide developers of social-robot applications with feedback at design time and evaluated the benefits of their use in reducing such breakdowns and violations in human-robot interactions. Our evaluation with application developers (N=9) shows that the use of formal-verification methods increases designers' ability to identify and contextualize social-norm violations. We discuss the implications of our approach for the future development of tools for effective design of social-robot applications.\"],\n",
              " '48_label_labels_unlabeled_classification': ['Active Learning from Multiple Noisy Labelers with Varied Costs.[SEP]In active learning, where a learning algorithm has to purchase the labels of its training examples, it is often assumed that there is only one labeler available to label examples, and that this labeler is noise-free. In reality, it is possible that there are multiple labelers available (such as human labelers in the online annotation tool Amazon Mechanical Turk) and that each such labeler has a different cost and accuracy. We address the active learning problem with multiple labelers where each labeler has a different (known) cost and a different (unknown) accuracy. Our approach uses the idea of adjusted cost, which allows labelers with different costs and accuracies to be directly compared. This allows our algorithm to find low-cost combinations of labelers that result in high-accuracy labelings of instances. Our algorithm further reduces costs by pruning under-performing labelers from the set under consideration, and by halting the process of estimating the accuracy of the labelers as early as it can. We found that our algorithm often outperforms, and is always competitive with, other algorithms in the literature.',\n",
              "  'Neural Conditional Energy Models for Multi-label Classification.[SEP]Multi-label classification (MLC) is a type of structured output prediction problems where a given instance can be associated to more than one labels at a time. From the probabilistic point of view, a model predicts a set of labels y given an input vector v by learning a conditional distribution p(y|v). This paper presents a powerful model called a Neural Conditional Energy Model (NCEM) to solve MLC. The model can be viewed as a hybrid deterministic-stochastic network of which we use a deterministic neural network to transform the input data, before contributing to the energy landscape of v, y, and a single stochastic hidden layer h. Non-linear transformation given by the neural network makes our model more expressive and more capable of capturing complex relations between input and output, and using deterministic neurons facilitates exact inference. We present an efficient learning algorithm that is simple to implement. We conduct extensive experiments on 15 real-world datasets from wide variety of domains with various evaluation metrics to confirm that NCEM is significantly superior to current state-of-the-art models most of the time based on pair-wise t-test at 5% significance level. The MATLAB source code to replicate our experiments are available at https://github.com/Kublai-Jing/NCEM.',\n",
              "  'Inductive Semi-supervised Multi-Label Learning with Co-Training.[SEP]In multi-label learning, each training example is associated with multiple class labels and the task is to learn a mapping from the feature space to the power set of label space. It is generally demanding and time-consuming to obtain labels for training examples, especially for multi-label learning task where a number of class labels need to be annotated for the instance. To circumvent this difficulty, semi-supervised multi-label learning aims to exploit the readily-available unlabeled data to help build multi-label predictive model. Nonetheless, most semi-supervised solutions to multi-label learning work under transductive setting, which only focus on making predictions on existing unlabeled data and cannot generalize to unseen instances. In this paper, a novel approach named COINS is proposed to learning from labeled and unlabeled data by adapting the well-known co-training strategy which naturally works under inductive setting. In each co-training round, a dichotomy over the feature space is learned by maximizing the diversity between the two classifiers induced on either dichotomized feature subset. After that, pairwise ranking predictions on unlabeled data are communicated between either classifier for model refinement. Extensive experiments on a number of benchmark data sets show that COINS performs favorably against state-of-the-art multi-label learning approaches.'],\n",
              " '49_keyboard_keyboards_touch_finger': ['Alphabetically constrained keypad designs for text entry on mobile devices.[SEP]The creation of text will remain a necessary part of human-computer interaction with mobile devices, even as they continue to shrink in size. On mobile phones, text is often entered using keypads and predictive text entry techniques, which attempt to minimize the effort (e.g., number of key presses) needed to enter words. This research presents results from the design and testing of alphabetically-constrained keypads, optimized on various word lists, for predictive text entry on mobile devices. Complete enumeration and Genetic Algorithm-based heuristics were used to find keypad designs based on different numbers of keys. Results show that alphabetically-constrained designs can be found that are close to unconstrained designs in terms of performance. User testing supports the hypothesis that novice ease of learning, usability, and performance is greater for constrained designs when compared to unconstrained designs. The effect of different word lists on keypad design and performance is also discussed.',\n",
              "  'DualKey: Miniature Screen Text Entry via Finger Identification.[SEP]Fast and accurate access to keys for text entry remains an open question for miniature screens. Existing works typically use a cumbersome two-step selection process, first to zero-in on a particular zone and second to make the key selection. We introduce DualKey, a miniature screen text entry technique with a single selection step that relies on finger identification. We report on the results of a 10 day longitudinal study with 10 participants that evaluated speed, accuracy, and learning. DualKey outperformed the existing techniques on long-term performance with a speed of 19.6 WPM. We then optimized the keyboard layout for reducing finger switching time based on the study data. A second 10 day study with eight participants showed that the new sweqty layout improved upon DualKey even further to 21.59 WPM for long-term speed, was comparable to existing techniques on novice speed and outperformed existing techniques on novice accuracy rate.',\n",
              "  'Language modeling for soft keyboards.[SEP]Language models predict the probability of letter sequences. Soft keyboards are images of keyboards on a touch screen for input on Personal Digital Assistants. When a soft keyboard user hits a key near the boundary of a key position, the language model and key press model are combined to select the most probable key sequence. This leads to an overall error rate reduction by a factor of 1.67 to 1.87. An extended version of this paper [4] is available.'],\n",
              " '4_graph_graphs_network_networks': [\"Discrete Overlapping Community Detection with Pseudo Supervision.[SEP]Community detection is of significant importance in understanding the structures and functions of networks. Recently, overlapping community detection has drawn much attention due to the ubiquity of overlapping community structures in real-world networks. Nonnegative matrix factorization (NMF), as an emerging standard framework, has been widely employed for overlapping community detection, which obtains nodes' soft community memberships by factorizing the adjacency matrix into low-rank factor matrices. However, in order to determine the ultimate community memberships, we have to post-process the real-valued factor matrix by manually specifying a threshold on it, which is undoubtedly a difficult task. Even worse, a unified threshold may not be suitable for all nodes. To circumvent the cumbersome post-processing step, we propose a novel discrete overlapping community detection approach, i.e., Discrete Nonnegative Matrix Factorization (DNMF), which seeks for a discrete (binary) community membership matrix directly. Thus DNMF is able to assign explicit community memberships to nodes without post-processing. Moreover, DNMF incorporates a pseudo supervision module into it to exploit the discriminative information in an unsupervised manner, which further enhances its robustness. We thoroughly evaluate DNMF using both synthetic and real-world networks. Experiments show that DNMF has the ability to outperform state-of-the-art baseline approaches.\",\n",
              "  'Communities in Preference Networks: Refined Axioms and Beyond.[SEP]Borgs et al. [2016] investigated essential requirements for communities in preference networks. They defined six axioms on community functions, i.e., community detection rules. Though having elegant properties, the practicality of this axiomsystem is compromised by the intractability of checking twocritical axioms, so no nontrivial consistent community functionwas reported in [Borgs et al., 2016]. By adapting the two axioms in a natural way, we propose two new axioms that are efficiently-checkable. We show that most of the desirable properties of the original axiom system are preserved. More importantly, the new axioms provide a general approach to constructing consistent community functions. We further find a natural consistent community function that is also enumerable and samplable, answering an open problem in the literature.',\n",
              "  'Joint Community and Structural Hole Spanner Detection via Harmonic Modularity.[SEP]Detecting communities (or modular structures) and structural hole spanners, the nodes bridging different communities in a network, are two essential tasks in the realm of network analytics. Due to the topological nature of communities and structural hole spanners, these two tasks are naturally tangled with each other, while there has been little synergy between them. In this paper, we propose a novel harmonic modularity method to tackle both tasks simultaneously. Specifically, we apply a harmonic function to measure the smoothness of community structure and to obtain the community indicator. We then investigate the sparsity level of the interactions between communities, with particular emphasis on the nodes connecting to multiple communities, to discriminate the indicator of SH spanners and assist the community guidance. Extensive experiments on real-world networks demonstrate that our proposed method outperforms several state-of-the-art methods in the community detection task and also in the SH spanner identification task (even the methods that require the supervised community information). Furthermore, by removing the SH spanners spotted by our method, we show that the quality of other community detection methods can be further improved.',\n",
              "  \"Gragnostics: Fast, Interpretable Features for Comparing Graphs.[SEP]Many analytical tasks, such as social network analysis, depend on comparing graphs. Existing methods are slow, or can be difficult to understand. To address these challenges, this paper proposes gragnostics, a set of 10 fast, layperson-understandable graph-level features. Each can be computed in linear time. To evaluate the ability of these features to discriminate different topologies and types of graphs, this paper compares a machine learning classifier using gragnostics to alternative classifiers, and the evaluation finds that the gragnostics classifier achieves higher performance. To evaluate gragnostics' utility in interactive visualization tools, this paper presents Chiron, a graph visualization tool that enables users to explore the subgraphs of a larger graph. Example usage scenarios of Chiron demonstrate that using gragnostics in a rank-by-feature framework can be effective for finding interesting subgraphs.\",\n",
              "  'Interactively Uncluttering Node Overlaps for Network Visualization.[SEP]Visual interaction with networks have been promising in the sense that we can successfully elucidate underlying relationships hidden behind complicated mutual relationships such as co-authorship networks, product co purchasing networks, and scale-free social networks. However, it is still burdensome to alleviate visual clutter arising from overlaps among node labels especially in such interactive environments as the networks become dense in terms of the topological connectivity. This paper presents a novel approach for dynamically rearranging the network layouts by incorporating centroidal Voronoi tessellation for better readability of node labels. Our idea is to smoothly transform the network layouts obtained through the conventional force-directed algorithm to that produced by the centroidal Voronoi tessellation to seek a plausible compromise between them. We also incorporated the Chebyshev distance metric into the centroidal Voronoi tessellation while adaptively adjusting the aspect ratios of the Voronoi cells so that we can place rectangular labels compactly over the network nodes. Finally, we applied the proposed approach to relatively large networks to demonstrate the feasibility of our formulation especially in interactive environments.',\n",
              "  'Multilayer graph edge bundling.[SEP]Many real world information can be represented by a graph with a set of nodes interconnected with each other by multiple type of relations called edge layers (e.g., social network, biological data). Edge bundling techniques have been proposed to solve cluttering issue for standard graphs while few efforts were done to deal with the similar issue for multilayer graphs. In multilayer graphs scenario, not only the clutter induced by large amount of edges is a problem but also the fact that different type of edges can overlap each other making useless the final visualization. In this paper we introduce a new multilayer graph edge bundling technique that firstly produces a preliminary edge bundling independently of the different edge layers and then deals with the specificity of multilayer graphs where more than one type of edges can be routed on the same bundle. The proposed visualization is tested on a real world case study and the outcomes point out the ability of our proposal to discover patterns present in the data.',\n",
              "  \"Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks.[SEP]We introduce MultiPiles, a visualization to explore time‐series of dense, weighted networks. MultiPiles is based on the physical analogy of piling adjacency matrices, each one representing a single temporal snapshot. Common interfaces for visualizing dynamic networks use techniques such as: flipping/animation; small multiples; or summary views in isolation. Our proposed ‘piling’ metaphor presents a hybrid of these techniques, leveraging each one's advantages, as well as offering the ability to scale to networks with hundreds of temporal snapshots. While the MultiPiles technique is applicable to many domains, our prototype was initially designed to help neuroscientists investigate changes in brain connectivity networks over several hundred snapshots. The piling metaphor and associated interaction and visual encodings allowed neuroscientists to explore their data, prior to a statistical analysis. They detected high‐level temporal patterns in individual networks and this helped them to formulate and reject several hypotheses.\",\n",
              "  'Edge-stacked Timelines for Visualizing Dynamic Weighted Digraphs.[SEP]We investigate the problem of visually encoding time-varying weighted digraphs to provide an overview about dynamic graphs. Starting from a rough overview of dynamic relational data an analyst can subsequently explore the data in more detail to gain further insights. To reach this goal we first map the graph vertices in the graph sequence to a common horizontal axis. Edges between vertices are represented as stacked horizontal and color-coded links starting and ending at their corresponding start and end vertex positions. The direction of each edge is indicated by placing it either above or below the horizontal vertex line. We attach a vertically aligned timeline to each link to show the weight evolution for those links. The order of the vertices and stacked edges is important for the readability of the visualization. We support interactive reordering and sorting in the vertex, edge, and timeline representations. The usefulness of our edge-stacked timelines is illustrated in a case st',\n",
              "  'Interactive Time-Series of Measures for Exploring Dynamic Networks.[SEP]We present MeasureFlow, an interface to visually and interactively explore dynamic networks through time-series of network measures such as link number, graph density, or node activation. When networks contain many time steps, become large and more dense, or contain high frequencies of change, traditional visualizations that focus on network topology, such as animations or small multiples, fail to provide adequate overviews and thus fail to guide the analyst towards interesting time points and periods. MeasureFlow presents a complementary approach that relies on visualizing time-series of common network measures to provide a detailed yet comprehensive overview of when changes are happening and which network measures they involve. As dynamic networks undergo changes of varying rates and characteristics, network measures provide important hints on the pace and nature of their evolution and can guide an analysts in their exploration; based on a set of interactive and signal-processing methods, MeasureFlow allows an analyst to select and navigate periods of interest in the network. We demonstrate MeasureFlow through case studies with real-world data.',\n",
              "  'Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees.[SEP]Finding dense subgraphs is an important graph-mining task with many applications. Given that the direct optimization of edge density is not meaningful, as even a single edge achieves maximum density, research has focused on optimizing alternative density functions. A very popular among such functions is the average degree, whose maximization leads to the well-known densest-subgraph notion. Surprisingly enough, however, densest subgraphs are typically large graphs, with small edge density and large diameter.',\n",
              "  'Graph-Structured Sparse Optimization for Connected Subgraph Detection.[SEP]Structured sparse optimization is an important and challenging problem for analyzing high-dimensional data in a variety of applications such as bioinformatics, medical imaging, social networks, and astronomy. Although a number of structured sparsity models have been explored, such as trees, groups, clusters, and paths, connected subgraphs have been rarely explored in the current literature. One of the main technical challenges is that there is no structured sparsity-inducing norm that can directly model the space of connected subgraphs, and there is no exact implementation of a projection oracle for connected subgraphs due to its NP-hardness. In this paper, we explore efficient approximate projection oracles for connected subgraphs, and propose two new efficient algorithms, namely, Graph-IHT and Graph-GHTP, to optimize a generic nonlinear objective function subject to connectivity constraint on the support of the variables. Our proposed algorithms enjoy strong guarantees analogous to several current methods for sparsity-constrained optimization, such as Projected Gradient Descent (PGD), Approximate Model Iterative Hard Thresholding (AM-IHT), and Gradient Hard Thresholding Pursuit (GHTP) with respect to convergence rate and approximation accuracy. We apply our proposed algorithms to optimize several well-known graph scan statistics in several applications of connected subgraph detection as a case study, and the experimental results demonstrate that our proposed algorithms outperform state-of-the-art methods.',\n",
              "  'Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling.[SEP]This paper studies the problem of efficiently computing a maximum independent set from a large graph, a fundamental problem in graph analysis. Due to the hardness results of computing an exact maximum independent set or an approximate maximum independent set with accuracy guarantee, the existing algorithms resort to heuristic techniques for approximately computing a maximum independent set with good performance in practice but no accuracy guarantee theoretically. Observing that the existing techniques have various limits, in this paper, we aim to develop efficient algorithms (with linear or near-linear time complexity) that can generate a high-quality (large-size) independent set from a graph in practice. In particular, firstly we develop a Reducing-Peeling framework which iteratively reduces the graph size by applying reduction rules on vertices with very low degrees (Reducing) and temporarily removing the vertex with the highest degree (Peeling) if the reduction rules cannot be applied. Secondly, based on our framework we design two baseline algorithms, BDOne and BDTwo, by utilizing the existing reduction rules for handling degree-one and degree-two vertices, respectively. Both algorithms can generate higher-quality (larger-size) independent sets than the existing algorithms. Thirdly, we propose a linear-time algorithm, LinearTime, and a near-linear time algorithm, NearLinear, by designing new reduction rules and developing techniques for efficiently and incrementally applying reduction rules. In practice, LinearTime takes similar time and space to BDOne but computes a higher quality independent set, similar in size to that of an independent set generated by BDTwo. Moreover, in practice NearLinear has a good chance to generate a maximum independent set and it often generates near-maximum independent sets. Fourthly, we extend our techniques to accelerate the existing iterated local search algorithms. Extensive empirical studies show that all our algorithms output much larger independent sets than the existing linear-time algorithms while having a similar running time, as well as achieve significant speedup against the existing iterated local search algorithms.',\n",
              "  \"Quegel: A General-Purpose System for Querying Big Graphs.[SEP]Inspired by Google's Pregel, many distributed graph processing systems have been developed recently to process big graphs. These systems expose a vertex-centric programming interface to users, where a programmer thinks like a vertex when designing parallel graph algorithms. However, existing systems are designed for tasks where most vertices in a graph participate in the computation, and they are not suitable for processing light-workload graph queries which only access a small portion of vertices. This is because their programming model can seriously under-utilize the resources in a cluster for processing graph queries. In this demonstration, we introduce a general-purpose system for querying big graphs, called Quegel, which treats queries as first-class citizens in the design of its computing model. Quegel adopts a novel superstep-sharing execution model to overcome the weaknesses of existing systems. We demonstrate it is user-friendly to write parallel graph-querying programs with Quegel's interface; and we also show that Quegel is able to achieve real-time response time in various applications, including the two applications that we plan to demonstrate: point-to-point shortest-path queries and XML keyword search.\",\n",
              "  'DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine.[SEP]Subgraph enumeration is important for many applications such as subgraph frequencies, network motif discovery, graphlet kernel computation, and studying the evolution of social networks. Most earlier work on subgraph enumeration assumes that graphs are resident in memory, which results in serious scalability problems. Recently, efforts to enumerate all subgraphs in a large-scale graph have seemed to enjoy some success by partitioning the data graph and exploiting the distributed frameworks such as MapReduce and distributed graph engines. However, we notice that all existing distributed approaches have serious performance problems for subgraph enumeration due to the explosive number of partial results. In this paper, we design and implement a disk-based, single machine parallel subgraph enumeration solution called DualSim that can handle massive graphs without maintaining exponential numbers of partial results. Specifically, we propose a novel concept of the dual approach for subgraph enumeration. The dual approach swaps the roles of the data graph and the query graph. Specifically, instead of fixing the matching order in the query and then matching data vertices, it fixes the data vertices by fixing a set of disk pages and then finds all subgraph matchings in these pages. This enables us to significantly reduce the number of disk reads. We conduct extensive experiments with various real-world graphs to systematically demonstrate the superiority of DualSim over state-of-the-art distributed subgraph enumeration methods. DualSim outperforms the state-of-the-art methods by up to orders of magnitude, while they fail for many queries due to explosive intermediate results.',\n",
              "  'GTS: A Fast and Scalable Graph Processing Method based on Streaming Topology to GPUs.[SEP]A fast and scalable graph processing method becomes increasingly important as graphs become popular in a wide range of applications and their sizes are growing rapidly. Most of distributed graph processing methods require a lot of machines equipped with a total of thousands of CPU cores and a few terabyte main memory for handling billion-scale graphs. Meanwhile, GPUs could be a promising direction toward fast processing of large-scale graphs by exploiting thousands of GPU cores. All of the existing methods using GPUs, however, fail to process large-scale graphs that do not fit in main memory of a single machine. Here, we propose a fast and scalable graph processing method GTS that handles even RMAT32 (64 billion edges) very efficiently only by using a single machine. The proposed method stores graphs in PCI-E SSDs and executes a graph algorithm using thousands of GPU cores while streaming topology data of graphs to GPUs via PCI-E interface. GTS is fast due to no communication overhead and scalable due to no data duplication from graph partitioning among machines. Through extensive experiments, we show that GTS consistently and significantly outperforms the major distributed graph processing methods, GraphX, Giraph, and PowerGraph, and the state-of-the-art GPU-based method TOTEM.',\n",
              "  'Unsupervised Differentiable Multi-aspect Network Embedding.[SEP]Network embedding is an influential graph mining technique for representing nodes in a graph as distributed vectors. However, the majority of network embedding methods focus on learning a single vector representation for each node, which has been recently criticized for not being capable of modeling multiple aspects of a node. To capture the multiple aspects of each node, existing studies mainly rely on offline graph clustering performed prior to the actual embedding, which results in the cluster membership of each node (i.e., node aspect distribution) fixed throughout training of the embedding model. We argue that this not only makes each node always have the same aspect distribution regardless of its dynamic context, but also hinders the end-to-end training of the model that eventually leads to the final embedding quality largely dependent on the clustering. In this paper, we propose a novel end-to-end framework for multi-aspect network embedding, called asp2vec, in which the aspects of each node are dynamically assigned based on its local context. More precisely, among multiple aspects, we dynamically assign a single aspect to each node based on its current context, and our aspect selection module is end-to-end differentiable via the Gumbel-Softmax trick. We also introduce the aspect regularization framework to capture the interactions among the multiple aspects in terms of relatedness and diversity. We further demonstrate that our proposed framework can be readily extended to heterogeneous networks. Extensive experiments towards various downstream tasks on various types of homogeneous networks and a heterogeneous network demonstrate the superiority of asp2vec.',\n",
              "  \"DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph Classification.[SEP]Graph data widely exist in many high-impact applications. Inspired by the success of deep learning in grid-structured data, graph neural network models have been proposed to learn powerful node-level or graph-level representation. However, most of the existing graph neural networks suffer from the following limitations: (1) there is limited analysis regarding the graph convolution properties, such as seed-oriented, degree-aware and order-free; (2) the node's degreespecific graph structure is not explicitly expressed in graph convolution for distinguishing structure-aware node neighborhoods; (3) the theoretical explanation regarding the graph-level pooling schemes is unclear.\",\n",
              "  'AM-GCN: Adaptive Multi-channel Graph Convolutional Networks.[SEP]Graph Convolutional Networks (GCNs) have gained great popularity in tackling various analytics tasks on graph and network data. However, some recent studies raise concerns about whether GCNs can optimally integrate node features and topological structures in a complex graph with rich information. In this paper, we first present an experimental investigation. Surprisingly, our experimental results clearly show that the capability of the state-of-the-art GCNs in fusing node features and topological structures is distant from optimal or even satisfactory. The weakness may severely hinder the capability of GCNs in some classification tasks, since GCNs may not be able to adaptively learn some deep correlation information between topological structures and node features. Can we remedy the weakness and design a new type of GCNs that can retain the advantages of the state-of-the-art GCNs and, at the same time, enhance the capability of fusing topological structures and node features substantially? We tackle the challenge and propose an adaptive multi-channel graph convolutional networks for semi-supervised classification (AM-GCN). The central idea is that we extract the specific and common embeddings from node features, topological structures, and their combinations simultaneously, and use the attention mechanism to learn adaptive importance weights of the embeddings. Our extensive experiments on benchmark data sets clearly show that AM-GCN extracts the most correlated information from both node features and topological structures substantially, and improves the classification accuracy with a clear margin.',\n",
              "  'Consistency Meets Inconsistency: A Unified Graph Learning Framework for Multi-view Clustering.[SEP]Graph Learning has emerged as a promising technique for multi-view clustering, and has recently attracted lots of attention due to its capability of adaptively learning a unified and probably better graph from multiple views. However, the existing multi-view graph learning methods mostly focus on the multi-view consistency, but neglect the potential multi-view inconsistency (which may be incurred by noise, corruptions, or view-specific characteristics). To address this, this paper presents a new graph learning-based multi-view clustering approach, which for the first time, to our knowledge, simultaneously and explicitly formulates the multi-view consistency and the multi-view inconsistency in a unified optimization model. To solve this model, a new alternating optimization scheme is designed, where the consistent and inconsistent parts of each single-view graph as well as the unified graph that fuses the consistent parts of all views can be iteratively learned. It is noteworthy that our multi-view graph learning model is applicable to both similarity graphs and dissimilarity graphs, leading to two graph fusion-based variants, namely, distance (dissimilarity) graph fusion and similarity graph fusion. Experiments on various multi-view datasets demonstrate the superiority of our approach. The MATLAB source code is available at https://github.com/youweiliang/ConsistentGraphLearning.',\n",
              "  'Dual active feature and sample selection for graph classification.[SEP]Graph classification has become an important and active research topic in the last decade. Current research on graph classification focuses on mining discriminative subgraph features under supervised settings. The basic assumption is that a large number of labeled graphs are available. However, labeling graph data is quite expensive and time consuming for many real-world applications. In order to reduce the labeling cost for graph data, we address the problem of how to select the most important graph to query for the label. This problem is challenging and different from conventional active learning problems because there is no predefined feature vector. Moreover, the subgraph enumeration problem is NP-hard. The active sample selection problem and the feature selection problem are correlated for graph data. Before we can solve the active sample selection problem, we need to find a set of optimal subgraph features. To address this challenge, we demonstrate how one can simultaneously estimate the usefulness of a query graph and a set of subgraph features. The idea is to maximize the dependency between subgraph features and graph labels using an active learning framework. We propose a branch-and-bound algorithm to search for the optimal query graph and optimal features simultaneously. Empirical studies on nine real-world tasks demonstrate that the proposed method can obtain better accuracy on graph data than alternative approaches.',\n",
              "  'Shortest-Path Kernels on Graphs.[SEP]Data mining algorithms are facing the challenge to deal with an increasing number of complex objects. For graph data, a whole toolbox of data mining algorithms becomes available by defining a kernel function on instances of graphs. Graph kernels based on walks, subtrees and cycles in graphs have been proposed so far. As a general problem, these kernels are either computationally expensive or limited in their expressiveness. We try to overcome this problem by defining expressive graph kernels which are based on paths. As the computation of all paths and longest paths in a graph is NP-hard, we propose graph kernels based on shortest paths. These kernels are computable in polynomial time, retain expressivity and are still positive definite. In experiments on classification of graph models of proteins, our shortest-path kernels show significantly higher classification accuracy than walk-based kernels.'],\n",
              " '50_sketching_sketches_drawing_design': ['nuSketch battlespace: a demonstration.[SEP]Sketching provides a natural means of interaction for many spatially-oriented tasks. One task where sketching is used extensively is when military planners are formulating battle plans, called Courses of Action (COAs). This paper describes a system we have built, nuSketch Battlespace (nSB), which provides a sketching interface for creating COAs. The system is described in the paper \"Sketching for Military Courses of Action\" in these proceedings. The demonstration will highlight:',\n",
              "  'Getting Started with Sketch Tools.[SEP]Diagrams are an important, if not pivotal, part in both education and design. In an effort to understand abstract concepts, students play an active role in their education by specifying visual and abstract concepts in hand-sketched diagrams. While students are understanding abstract concepts through hand-drawn diagrams, designers are creating those abstract concepts. Just as the act of hand-drawing a diagram (as opposed to using a mouse-and-palette CAD tool) better engages the student in the learning process, the act of hand-drawing a diagram also improves the design process by freeing the designer of constraints that may otherwise impede creativity and innovation.',\n",
              "  'Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals.[SEP]Sketching is a practical and useful skill that can benefit communication and problem solving. However, it remains a difficult skill to learn because of low confidence and motivation among students and limited availability for instruction and personalized feedback among teachers. There is an need to improve the educational experience for both groups, and we hypothesized that integrating technology could provide a variety of benefits. We designed and developed an intelligent tutoring system for sketching fundamentals called Sketchtivity, and deployed it in to six existing courses at the high school and university level during the 2017-2018 school year. 268 students used the tool and produced more than 116,000 sketches of basic primitives. We conducted semi-structured interviews with the six teachers who implemented the software, as well as nine students from a course where the tool was used extensively. Using grounded theory, we found ten categories which unveiled the benefits and limitations of integrating an intelligent tutoring system for sketching fundamentals in to existing pedagogy.'],\n",
              " '51_facial_face_animation_faces': ['Bilinear interpolation for facial expression and metamorphosis in real-time animation.[SEP]This paper describes a new method for generating facial animation in which facial expression and shape can be changed simultaneously in real time. A 2D parameter space independent of facial shape is defined, on which facial expressions are superimposed so that the expressions can be applied to various facial shapes. A facial model is transformed by a bilinear interpolation, which enables a rapid change in facial expression with metamorphosis. The practical efficiency of this method has been demonstrated by a real-time animation system based on this method in live theater.',\n",
              "  'Transferring of Speech Movements from Video to 3D Face Space.[SEP]We present a novel method for transferring speech animation recorded in low quality videos to high resolution 3D face models. The basic idea is to synthesize the animated faces by an interpolation based on a small set of 3D key face shapes which span a 3D face space. The 3D key shapes are extracted by an unsupervised learning process in 2D video space to form a set of 2D visemes which are then mapped to the 3D face space. The learning process consists of two main phases: 1) isomap-based nonlinear dimensionality reduction to embed the video speech movements into a low-dimensional manifold and 2) k-means clustering in the low-dimensional space to extract 2D key viseme frames. Our main contribution is that we use the isomap-based learning method to extract intrinsic geometry of the speech video space and thus to make it possible to define the 3D key viseme shapes. To do so, we need only to capture a limited number of 3D key face models by using a general 3D scanner. Moreover, we also develop a skull movement recovery method based on simple anatomical structures to enhance 3D realism in local mouth movements. Experimental results show that our method can achieve realistic 3D animation effects with a small number of 3D key face models',\n",
              "  'Design, transformation and animation of human faces.[SEP]Creation of new human faces for synthetic actors is a tedious and painful task. The situation may be improved by introducing tools for the creation. Two approaches are discussed in this paper: modification and edition of an existing synthetic actor using local transformations; generation of new synthetic actors obtained by interpolation between two existing actors; creation of a synthetic actor by composition of different parts. This paper also describes the methods used in the facial animation of synthetic actors who change their personalities from one person to another. This means that our purpose is to transform one character into another, and also to transform the animation at the same time. The interpolation must be at several levels: the shape level, the parameter level, the expression level and the script level. For the animation, we introduce three levels of inbetweens: inbetween parameters, inbetween expressions and inbetween scripts. The method has been completely implemented and integrated into the Human Factory software.',\n",
              "  'Spatial pyramid face feature representation and weighted dissimilarity matching for improved face recognition.[SEP]In this paper, we present a novel face recognition (FR) algorithm based on multiresolution spatial pyramid. In our method, a face is subdivided into increasingly finer subregions (local regions) and represented at multiple levels of histogram representations. To address image misalignment problem, overlapped patch-based local descriptor extraction has been also developed in an effective way. To preserve multiple levels of detail in facial local characteristics and to encode holistic spatial configuration, face features obtained for concatenated histograms (coming from all levels of spatial pyramid) are integrated into a combined feature set, termed spatial pyramid face feature representation (SPFR). In addition, to perform recognition by matching between the pair of probe and gallery SPFR sets, we propose the use of a weighted sum of the dissimilarity scores computed at all spatial pyramid levels. For this purpose, we develop a novel weight determination solution based on class-wise discriminant power estimation for face feature at a specific pyramid level. We incorporate our proposed algorithm into general FR pipeline and achieve encouraging identification results on the CMU-PIE, FERET, and LFW datasets, compared to previously developed methods. In addition, the feasibility of our method has been successfully demonstrated by making comparisons with other state-of-the-art FR methods (including deep CNN based method) under the FERET and FRGC 2.0 evaluation protocols. Based on results, our method is advantageous in terms of high recognition accuracy and low complexity, as well as straightforward implementation.',\n",
              "  'On the Learning of Deep Local Features for Robust Face Spoofing Detection.[SEP]Biometrics emerged as a robust solution for security systems. However, given the dissemination of biometric applications, criminals are developing techniques to circumvent them by simulating physical or behavioral traits of legal users (spoofing attacks). Despite face being a promising characteristic due to its universality, acceptability and presence of cameras almost everywhere, face recognition systems are extremely vulnerable to such frauds since they can be easily fooled with common printed facial photographs. State-of-the-art approaches, based on Convolutional Neural Networks (CNNs), present good results in face spoofing detection. However, these methods do not consider the importance of learning deep local features from each facial region, even though it is known from face recognition that each facial region presents different visual aspects, which can also be exploited for face spoofing detection. In this work we propose a novel CNN architecture trained in two steps for such task. Initially, each part of the neural network learns features from a given facial region. Afterwards, the whole model is fine-tuned on the whole facial images. Results show that such pre-training step allows the CNN to learn different local spoofing cues, improving the performance and the convergence speed of the final model, outperforming the state-of-the-art approaches.',\n",
              "  'Analysis of the Eyes on Face Images for Compliance with ISO/ICAO Requirements.[SEP]The face has been used in identity documents and represents the ideal biometric characteristic in many applications. The International Civil Aviation Organization endorsed the use of face as the globally interoperable biometric characteristic. Successively, the International Standard Organization proposed the ISO/IEC 19794-5 standard for face usage in travel documents. The purpose of this work is to evaluate the quality of face images for identification documents and check if the face images satisfy the requirements defined by the ISO/IEC 19794-5. This work presents approaches for the evaluation of the following ISO/ICAO requirements: eyes state, red eyes and looking away. In addition, an approach to estimate the location of the center of the eyes is proposed. The proposed methods to check ISO/ICAO requirements were evaluated using the BioLab-ICAO Framework. The results achieved by the proposed methods were satisfactory, overcoming almost all the works in the literature for this purpose.'],\n",
              " '52_machine_fairness_deep_explanations': ['Chainer: A Deep Learning Framework for Accelerating the Research Cycle.[SEP]Software frameworks for neural networks play a key role in the development and application of deep learning methods. In this paper, we introduce the Chainer framework, which intends to provide a flexible, intuitive, and high performance means of implementing the full range of deep learning models needed by researchers and practitioners. Chainer provides acceleration using Graphics Processing Units with a familiar NumPy-like API through CuPy, supports general and dynamic models in Python through Define-by-Run, and also provides add-on packages for state-of-the-art computer vision models as well as distributed training.',\n",
              "  'The business impact of deep learning.[SEP]In the last year deep learning has gone from being a special purpose machine learning technique used mainly for image and speech recognition, to becoming a general purpose machine learning tool. This has broad implications for all organizations that rely on data analysis. It represents the latest development in a general trend towards more automated algorithms, and away from domain specific knowledge. For organizations that rely on domain expertise for their competitive advantage, this trend could be extremely disruptive. For start-ups interested in entering established markets, this trend could be a major opportunity. This talk will be a non-technical introduction to general-purpose deep learning, and its potential business impact.',\n",
              "  \"Principles of Explanatory Debugging to Personalize Interactive Machine Learning.[SEP]How can end users efficiently influence the predictions that machine learning systems make on their behalf? This paper presents Explanatory Debugging, an approach in which the system explains to users how it made each of its predictions, and the user then explains any necessary corrections back to the learning system. We present the principles underlying this approach and a prototype instantiating it. An empirical evaluation shows that Explanatory Debugging increased participants' understanding of the learning system by 52% and allowed participants to correct its mistakes up to twice as efficiently as participants using a traditional learning system.\"],\n",
              " '53_papers_conference_issue_editorial': ['ScreenCrayons: annotating anything.[SEP]ScreenCrayons is a system for collecting annotations on any type of document or visual information from any application. The basis for the system is a screen capture upon which the user can highlight the relevant portions of the image. The user can define any number of topics for organizing notes. Each topic is associated with a highlighting \"crayon.\" In addition the user can supply annotations in digital ink or text. Algorithms are described that summarize captured images based on the highlight strokes so as to provide overviews of many annotations as well as being able to \"zoom in\" on particular information about a given note and the context of that note.',\n",
              "  'Reflowing digital ink annotations.[SEP]Annotating paper documents with a pen is a familiar and indispensable activity across a wide variety of work and educational settings. Recent developments in pen-based computing promise to bring this experience to digital documents. However, digital documents are more flexible than their paper counterparts. When a digital document is edited, or displayed on different devices, its layout adapts to the new situation. Freeform digital ink annotations made on such a document must likewise adapt, or \"reflow.\" But their unconstrained nature yields only vague guidelines for how these annotations should be transformed. Few systems have considered this issue, and still fewer have addressed it from a user\\'s point of view. This paper reports the results of a study of user expectations for reflowing digital ink annotations. We explore user reaction to reflow in common cases, how sensitive users are to reflow errors, and how important it is that personal style survive reflow. Our findings can help designers and system builders support freeform annotation more effectively.',\n",
              "  'The Breadth and Depth of E-reading and Paper-reading.[SEP]The present study investigated the differences between e-reading and paper-reading in their breadth and depth. Our results showed that (1) breadth and depth of reading were both greater in e-reading than in paper-reading; (2) possession of a tablet tended to facilitate breadth of e-reading; (3) breadth of e-reading was greater than breadth of paper-reading for news, magazines, and others, but not for novels; (4) depth of e-reading was greater than depth of paper-reading for novels, but the reverse was true for news and magazines; (5) people tended to read research articles, books and magazines on paper, but news and others on digital devices; (6) people tended to read longer on paper than on digital devices, but the percentage of contents they could remember was no different between e-reading and paper-reading. We conclude that modern readers have become accustomed to e-reading and can do it more efficiently than paper-reading.',\n",
              "  'Preface.[SEP]In this issue, we have fourteen regular papers and two corrections for previously published papers:',\n",
              "  'VIS capstone address.[SEP]Useful as each of them can be, a large body of tips and tricks is impossible to remember, at least in a practical, usable way, unless it is structured into a balanced, meaningful hierarchy. This talk proposes and illustrates three simple yet solid ideas that lead to more effective communication and that underpin every other guideline: easy to remember, readily applicable, and always relevant—in short, valuable for the rest of your life.',\n",
              "  'Preface.[SEP]In this issue, we have ten regular papers and one erratum:',\n",
              "  'A Survey of Topology-based Methods in Visualization.[SEP]This paper presents the state of the art in the area of topology‐based visualization. It describes the process and results of an extensive annotation for generating a definition and terminology for the field. The terminology enabled a typology for topological models which is used to organize research results and the state of the art. Our report discusses relations among topological models and for each model describes research results for the computation, simplification, visualization, and application. The paper identifies themes common to subfields, current frontiers, and unexplored territory in this research area.',\n",
              "  'Editor\\'s Note [2013 Best Associate Editor Award  2013 Best Reviewer Award].[SEP]The success of a journal relies heavily on the quality of submissions and of their reviews. The latter is primarily the work and efforts of the associate editors and the anonymous reviewers. The dedication of associate editors and of external reviewers is essential to the continuing growth of the journal. To continue recognizing these \"unsung heroes\" who drive the scientific peer review process for IEEE Transactions on Visualization and Computer Graphics (TVCG), it is my pleasure to announce the 2013 Best Associate Editor Award and the 2013 Best Reviewer Award. Three associate editors (AEs) for are recognized their dedication and hard work in 2013: Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi. They handled a large number of submissions efficiently with the quickest turnaround (averaging less than 50 days) and provided consistently high-quality, thoughtful AE summary to the authors. In recognizing their distinguished service to the IEEE TVCG, the 2013 TVCG Best Associate Editor Award goes to Shi-Min Hu, Alla Sheffer, and Shigeo Takahashi.',\n",
              "  \"Guest Editors' Introduction: Special Section on the IEEE Pacific Visualization Symposium 2012.[SEP]The papers in this special section are extended versions of three selected papers from the IEEE Pacific Visualization Symposium 2012 (PacificVis) which took place in Songdo, Korea from 28 February to 2 March 2012.\"],\n",
              " '54_heritage_museum_visitors_museums': ['Web3D representation and cultural heritage: from annotations to narrations.[SEP]Storytelling is a powerful means for teaching, often used for engaging pupils while educating them. This paper describes an innovative web tool for creating engaging narrations for educational purposes that can be shared on the web. The tool is integrated with ToBoA-3D, a web platform for annotating 3D environments and taking advantage of the crowdsourced effort of its users for creating linear stories that can be shared on the web. An example focused on an educational narration about Renaissance architecture will be shown.',\n",
              "  'Unearthing Virtual History: Using Diverse Interfaces to Reveal Hidden Virtual Worlds.[SEP]We describe an application in which museum visitors hunt for virtual history outdoors, capture it, and bring it back indoors for detailed inspection. This application provides visitors with ubiquitous access to a parallel virtual world as they move through an extended physical space. Diverse devices, including mobile wireless interfaces for locating hotspots of virtual activity outdoors, provide radically different experiences of the virtual depending upon location, task, and available equipment. Initial reflections suggest that the physical design of such devices needs careful attention so as to encourage an appropriate style of use. We also consider the extension of our experience to support enacted scenes. Finally, we discuss potential benefits of using diverse devices to make a shared underlying virtual world ubiquitously available throughout physical space.',\n",
              "  'Making Place: Designing and Building an Engaging, Interactive and Pedagogical Historical World.[SEP]Digital visualisation technologies have transformed the field of heritage. The digital re-creation of a place demands much more than architectural modeling. Designers of virtual heritage places can learn from commercial computer games which can be very successful at creating a sense of place. The Virtual Sydney Rocks is designed to undertake research into the role that user preference for interaction strategy has on engagement in a Virtual Heritage Environment. Users can explore an experiential model of Sydney Cove between 1788 and 2008 in three different ways; by self directed exploration, by playing a game or by taking a tour. Users set the date and time to determine the position of the sun, the weather, the sounds that are heard and the buildings that are displayed. Users can also alter the speed of time. Additional information is accessed via the interlinked Virtual Sydney Rocks Guidebook.',\n",
              "  \"Visitors' Evaluations of ICTs Used in Cultural Heritage.[SEP]Technology that serves to enhance the visitors experience is gradually becoming more commonplace at Cultural Heritage (CH) sites. However ICT is not usually the CH professional s area of expertise and they have to make choices from a bewildering array of technology, often without fully understanding their visitors ICT needs. This research aims to alleviate the situation by gathering visitors evaluations of technologies that are frequently used at CH sites along with advanced applications, to identify which technologies visitors use and what they need. The research took place in five CH attractions in the UK and incorporates the results of one hundred and sixty four interviews with visitors. Both CH professionals and technology developers can use this research to gain insights into the use of ICT applications at sites and to identify emerging needs in the marketplace. The findings of this research indicate that ICTs in use at the CH sites involved were underutilised. Despite this, respondents strongly supported the advanced applications which included: Augmented Reality; an Interactive Museum Installation; a Mobile Media Guide and an Avatar Application. This is because they could see how they would benefit. This paper concludes that the use of ICT was supported by visitors to some degree. However in order to encourage use, the benefits must be clearly communicated to visitors.\",\n",
              "  \"Digital Exhibit Labels in Museums: Promoting Visitor Engagement with Cultural Artifacts.[SEP]How can we use interactive displays in museums to help visitors appreciate authentic objects and artifacts that they can't otherwise touch or manipulate? This paper shares results from a design-based research study on the use of interactive displays to help visitors learn about artifacts in an exhibit on the history and culture of China. To explore the potential afforded by these displays, we unobtrusively video recorded 834 museum visitor groups who stopped in front of one collection of objects. Drawing on cognitive models of curiosity, we tested three redesigns of this display, each focusing on a different strategy to spark visitor curiosity, interest, and engagement. To understand the relative effectiveness of these designs, we analyzed visitor interaction and conversation. Our results uncovered significant differences across the conditions suggesting implications for the use of such technology in museums.\",\n",
              "  'Articulating Co-Design in Museums: Reflections on Two Participatory Processes.[SEP]In this paper we reflect on the process of co-design by detailing and comparing two strategies for the participatory development of interaction concepts and prototypes in the context of technologically-enhanced museum visiting experiences. While much work in CSCW, HCI and related disciplines has examined different role configurations in co-design, more research is needed on examining how collaborative design processes can unfold in different ways. Here we present two instances of co-design of museum visiting aids, one stemming from an open brief, another from an initial working prototype; we discuss the process in each case and discuss how these alternative strategies presented the team with different possibilities as well as constraints, and led to different patterns of collaboration within the design team. Finally, we draw a set of themes for discussion and reflection to inform and aid researchers and practitioners participating in similar co-design processes, particularly in the domain of cultural heritage.',\n",
              "  'Innovative Digital Heuristic Approaches in Architectural Historical Research.[SEP]In recent years a great debate has aroused concerning the deep transformations triggered by the so-called \"digital revolution\" in all research fields. Architecture has been highly affected by this phenomenon but, while it is commonplace to measure these changes in terms of \"science\", much less popular are those aspects connected with the Humanities integrated in any architectural work. History of Architecture represents from this standpoint a perfect example of how new digital tools and approaches can help to disclose novel research opportunities. The paper presents two projects regarding the Vatican Basilica (the Sangallo\\'s wooden model for the New St. Peter and the reconstruction of St. Peter\\'s square \"the day before\" the moving of the Vatican Obelisk led by Domenico Fontana) as paradigmatic showcases.',\n",
              "  'Managing the real with the virtual: A role for digital media recording in archaeological fieldwork.[SEP]Recent innovations in digital media have allowed for a surge of new techniques to be applied to an old problem - how to record and archive the archaeological record and the process of archaeological fieldwork. Like many new technologies, digital recording is rife with limitations and challenges - low resolution when compared to traditional film, a lack of standards for both media types and archiving methods, expensive entry costs and a relatively high technical skill level required for implementing a complete digital recording methodology, to name a few. However, the benefits of embracing digital recording techniques range from the practical to the profound, for once the initial investment has been made, digital media is relatively inexpensive and allows for a more rich and finer grain of recording, including exciting innovations in GIS-information systems and visualization tools. While the benefits may outweigh the costs, there is within the field of archaeology a strong \"Resistance To Change\" and a feeling that digital media recording, while novel and promising, is nonessential when compared to traditional photography and illustration.',\n",
              "  'A Repository for Heterogeneous and Complex Digital Cultural Objects.[SEP]The paper proposes a solution for a repository of digital cultural objects, which can manage complex data as 3D objects, videos and more, together with the related metadata. The repository is built with open source components and may be easily installed and managed. Basing on an example, interfaces are shown for the most common operations. The system allows for text searches, semantic searches as well as facet refinements. The proposed system can support a full-featured digital library for its modularity and easy personalization.'],\n",
              " '55_number_symbolic_magnitude_numbers': ['Magnitude Comparisons of Improper Fractions.[SEP]Previous studies examining the mental representations of fractions have focused on fractions with magnitudes less than one (e.g., 2/3). In the current study, we examine the mental representations of fractions with magnitudes greater than one, specifically those of improper fractions. Participants were asked to make magnitude comparisons of these improper fractions to a reference that was in an improper fraction, a mixed fraction, or a decimal format. Results show that magnitudes of improper fractions were more accurately accessed when they were compared to mixed fractions and decimals. This suggests that the reinterpretation of these improper fractions benefited magnitude processing. Distance effects on error rate and response time were observed for all three reference formats and more consistently took the form of a Welford function, which predicts worse performance above rather than below the reference. Possible explanations of these results are discussed.',\n",
              "  'Mathematical Model of Developmental Changes in Number Cognition.[SEP]Numerical discrimination is a primary measure of the acuity of children’s approximate number system (ANS). ANS acuity is associated with key developmental outcomes such as symbolic number skill, standardized test scores and even employment outcomes. The current study examines the factors that contribute to children’s performance on non-symbolic numerical discrimination tasks. The current study evaluates the contribution of absolute value in children’s numerical discrimination, and how that contribution may change during development. We use a combination of behavioral and computational results to illustrate a U-shaped developmental change in the factors that predict numerical discriminability. Computational modeling based on the neural coding of numerical perception demonstrates why the reported behavioral data is expected. The novel inclusion of absolute value as a predictive factor in children’s numerical discrimination suggests reevaluation of connections between numerical acuity and educational outcomes.',\n",
              "  'Are Fractions Natural Numbers, Too?[SEP]This study presents evidence in favor of a cognitive primitives hypothesis for processing fraction magnitudes. This account holds that humans have perceptual access to fractional magnitudes and that this may be used to support symbolic fraction knowledge. In speeded cross-format comparisons, participants picked the larger of two stimuli, which were either symbolic fractions or nonsymbolic ratios composed of pairs of dot arrays or pairs of circles. Participants demonstrated distance effects across formats, demonstrating that they could compare analog fractional magnitudes independently of the particular formats in which they were presented. These results pose a challenge to innate constraints accounts that argue that human cortical structures are ill-suited for processing fractions. These results may have important implications both for theorizing about the nature of human number sense and for optimizing instruction of fractional concepts.'],\n",
              " '56_facebook_social_privacy_friends': ['\"Is it Weird to Still Be a Virgin\": Anonymous, Locally Targeted Questions on Facebook Confession Boards.[SEP]People have long sought answers to questions online, typically using either anonymous or pseudonymous forums or social network platforms that primarily use real names. Systems that allow anonymous communication afford freedom to explore identity and discuss taboo topics, but can result in negative disinhibited behavior such as cyberbullying. Identifiable communication systems allows one to reach a known audience and avoid negative disinhibition, but can constrain behavior with concerns about privacy and reputation. One persistent design issue is understanding how to leverage the benefits of anonymity without suffering its drawbacks. This paper presents a case study analysis of question asking on Facebook confession boards (FCBs), a tool popular on some college campuses. FCBs present a unique configuration in which members of an offline community (e.g., a university) anonymously submit content to a moderator who posts it to a Facebook page where others in the community can view it and respond. Response is via identifiable Facebook comments and likes. Our results show users asking about taboo and stigmatized topics with local others, and receiving relevant responses with little cyberbullying or negativity.',\n",
              "  \"The post that wasn't: exploring self-censorship on facebook.[SEP]Social networking site users must decide what content to share and with whom. Many social networks, including Facebook, provide tools that allow users to selectively share content or block people from viewing content. However, sometimes instead of targeting a particular audience, users will self-censor, or choose not to share. We report the results from an 18-participant user study designed to explore self-censorship behavior as well as the subset of unshared content participants would have potentially shared if they could have specifically targeted desired audiences. We asked participants to report all content they thought about sharing but decided not to share on Facebook and interviewed participants about why they made sharing decisions and with whom they would have liked to have shared or not shared. Participants reported that they would have shared approximately half the unshared content if they had been able to exactly target their desired audiences.\",\n",
              "  'Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content.[SEP]Researchers have recognized the need to pay attention to negative aspects and non-use of social media services to uncover usage barriers and surface shortcomings of these systems. We contribute to these efforts by analyzing comments on posts related to Facebook on two blogs with a technically savvy readership: Slashdot and Schneier on Security. Our analysis indicates that technically savvy individuals exhibit notably large negative sentiment toward Facebook with nearly 45% of the 3,000 reader comments we coded expressing such views. Qualitative coding revealed Privacy and Security, User Experience, and Personal Disposition as key factors underlying the negative views. Our findings suggest that negative sentiment is an explicit higher level factor driving non-use practices. Further, we confirm several non-use practices reported in the literature and identify additional aspects connected to recent technological and societal developments. Our results demonstrate that analysis of user generated content can be useful for surfacing usage practices on a large scale.'],\n",
              " '57_influence_social_networks_network': ['Influence maximization: near-optimal time complexity meets practical efficiency.[SEP]Given a social network G and a constant $k$, the influence maximization problem asks for k nodes in G that (directly and indirectly) influence the largest number of nodes under a pre-defined diffusion model. This problem finds important applications in viral marketing, and has been extensively studied in the literature. Existing algorithms for influence maximization, however, either trade approximation guarantees for practical efficiency, or vice versa. In particular, among the algorithms that achieve constant factor approximations under the prominent independent cascade (IC) model or linear threshold (LT) model, none can handle a million-node graph without incurring prohibitive overheads.',\n",
              "  'Minimizing seed set selection with probabilistic coverage guarantee in a social network.[SEP]A topic propagating in a social network reaches its tipping point if the number of users discussing it in the network exceeds a critical threshold such that a wide cascade on the topic is likely to occur. In this paper, we consider the task of selecting initial seed users of a topic with minimum size so that {\\\\em with a guaranteed probability} the number of users discussing the topic would reach a given threshold. We formulate the task as an optimization problem called {\\\\em seed minimization with probabilistic coverage guarantee (SM-PCG)}. This problem departs from the previous studies on social influence maximization or seed minimization because it considers influence coverage with {\\\\em probabilistic} guarantees instead of guarantees on {\\\\em expected} influence coverage. We show that the problem is not submodular, and thus is harder than previously studied problems based on submodular function optimization. We provide an approximation algorithm and show that it approximates the optimal solution with both a multiplicative ratio and an additive error. The multiplicative ratio is tight while the additive error would be small if influence coverage distributions of certain seed sets are well concentrated. For one-way bipartite graphs we analytically prove the concentration condition and obtain an approximation algorithm with an $O(\\\\log n)$ multiplicative ratio and an $O(\\\\sqrt{n})$ additive error, where $n$ is the total number of nodes in the social graph. Moreover, we empirically verify the concentration condition in real-world networks and experimentally demonstrate the effectiveness of our proposed algorithm comparing to commonly adopted benchmark algorithms.',\n",
              "  'Effective Large-Scale Online Influence Maximization.[SEP]In this paper, we study a highly generic version of influence maximization (IM), one of optimizing influence campaigns by sequentially selecting \"spread seeds\" from a set of candidates, a small subset of the node population, under the hypothesis that, in a given campaign, previously activated nodes remain \"persistently\" active throughout and thus do not yield further rewards. We call this problem online influence maximization with persistence. We introduce an estimator on the candidates\\' missing mass - the expected number of nodes that can still be reached from a given seed candidate - and justify its strength to rapidly estimate the desired value. We then describe a novel algorithm, GT-UCB, relying on upper confidence bounds on the missing mass. We show that our approach leads to high-quality spreads on classic IM datasets, even though it makes almost no assumptions on the diffusion medium. Importantly, it is orders of magnitude faster than state-of-the-art IM methods.'],\n",
              " '58_walking_virtual_locomotion_reality': ['Velocity-Dependent Dynamic Curvature Gain for Redirected Walking.[SEP]Redirected walking techniques allow people to walk in a larger virtual space than the physical extents of the laboratory. We describe two experiments conducted to investigate human sensitivity to walking on a curved path and to validate a new redirected walking technique. In a psychophysical experiment, we found that sensitivity to walking on a curved path was significantly lower for slower walking speeds (radius of 10 m versus 22 m). In an applied study, we investigated the influence of a velocity-dependent dynamic gain controller and an avatar controller on the average distance that participants were able to freely walk before needing to be reoriented. The mean walked distance was significantly greater in the dynamic gain controller condition, as compared to the static controller (22 m versus 15 m). Our results demonstrate that perceptually motivated dynamic redirected walking techniques, in combination with reorientation techniques, allow for unaided exploration of a large virtual city model.',\n",
              "  \"Virtual locomotion system for human-scale virtual environments.[SEP]This paper presents a new virtual locomotion interface based on step-in-place action and a smart-turntable system. The interface provides a turntable as walking platform, on top of which users will stand at its center, and facing a large screen, to perform life-like walking actions that steer their navigation through the virtual environment. Steering actions are tracked seamlessly without attachment to the body through a set of pressure sensors embedded within the turntable and a computer vision system. For instance, in place stepping is treated as a gesture indicating the intention to move forward. Rotation about the body's vertical axis is treated as a gesture changing the walking direction. However, as large screens are usually limited in size and do not allow a surrounding projection, a large turning action may put users in a visual-less situation, which hamper considerably the effectiveness of the walking experience. To avoid such case and keep users always provided with sufficient visual feedback, the turntable will passively and smoothly rotate in opposite direction of users' turning. Rotation speed and acceleration of the turntable are well optimized to keep users well balanced and easily withstand the passive rotation. The interface is shown to be easy and simple to use in virtual environments equipped with large screen.\",\n",
              "  '15 Years of Research on Redirected Walking in Immersive Virtual Environments.[SEP]Virtual reality users wearing head-mounted displays can experience the illusion of walking in any direction for infinite distance while, in reality, they are walking a curvilinear path in physical space. This is accomplished by introducing unnoticeable rotations to the virtual environment-a technique called redirected walking. This paper gives an overview of the research that has been performed since redirected walking was first practically demonstrated 15 years ago.'],\n",
              " '59_reality_augmented_virtual_interaction': ['Development of Adaptive Information Visualization Systems with Augmented Reality.[SEP]Augmented Reality combined with adaptive hypermedia plays an important role on providing effective information visualization systems. In this paper, we propose a comprehensive architecture model in order to provide adaptive information visualization systems with augmented reality. We also provide a novel visual metaphor for real-valued, low-dimensional data with optimal values for each feature inspired on the pseudo-flower metaphor.',\n",
              "  'Situated Visualization in The Decision Process Through Augmented Reality.[SEP]The decision-making process and the development of decision support systems (DSS) have been enhanced by a variety of methods originated from information science, cognitive psychology and artificial intelligence over the past years. Situated visualization (SV) is a method to present data representations in context. Its main characteristic is to display data representations near the data referent. As augmented reality (AR) is becoming more mature, affordable and widespread, using it as a tool for SV becomes feasible in several situations. In addition, it may provide a positive contribution to more effective and efficient decision-making, as the users have contextual, relevant and appropriate information to endorse their choices. As new challenges and opportunities arise, it is important to understand the relevance of intertwining these fields. Based on a literature analysis, this paper addresses and discusses current areas of application, benefits, challenges and opportunities of using SV through AR to visualize data in context and to support a decision-making process and its importance in future DSS.',\n",
              "  'Temporal Coherence Strategies for Augmented Reality Labeling.[SEP]Temporal coherence of annotations is an important factor in augmented reality user interfaces and for information visualization. In this paper, we empirically evaluate four different techniques for annotation. Based on these findings, we follow up with subjective evaluations in a second experiment. Results show that presenting annotations in object space or image space leads to a significant difference in task performance. Furthermore, there is a significant interaction between rendering space and update frequency of annotations. Participants improve significantly in locating annotations, when annotations are presented in object space, and view management update rate is limited. In a follow-up experiment, participants appear to be more satisfied with limited update rate in comparison to a continuous update rate of the view management system.',\n",
              "  'Message from the Paper Chairs and Guest Editors.[SEP]The articles in this special issue contain the full paper proceedings of the IEEE Virtual Reality Conference 2012 (IEEE VR 2012), held March 4-8, 2012 in Orange County, California.',\n",
              "  \"Guest Editors' Introduction: Virtual Reality.[SEP]Presents the guest editorial for this issue of the publication.\",\n",
              "  'Future scenarios of mixed reality: the INTUITION roadmap scenarios.[SEP]INTUITION is a Network of Excellence that aims to integrate the European research efforts on the scientific and technological field of Virtual and Mixed Reality. To perform that, a series of activities have taken place in order to gather knowledge regarding actors and research profiles, projects and research results, products and patents. Having a clear view of research needs and technology trends the Network has envisioned the research goals that need to be pursued within the years to come. The starting point is a set of visionary scenarios which set out the picture for the technological and scientific advances that need to take place. Within this paper a set of indicative scenarios on a higher and descriptive level are provided and the way they contribute to the roadmap definition is explained. With this report we want to share these scenarios and our initial thoughts to stimulate a broader discussion and invite people from all relevant backgrounds to enter the knowledge creation process. The paper is a collective production of the INTUITION Consortium.'],\n",
              " '5_shape_mesh_meshes_subdivision': ['Spectral compression of mesh geometry.[SEP]We show how spectral methods may be applied to 3D mesh data to obtain compact representations. This is achieved by projecting the mesh geometry onto an orthonormal basis derived from the mesh topology. To reduce complexity, the mesh is partitioned into a number of balanced submeshes with minimal interaction, each of which are compressed independently. Our methods may be used for compression and progressive transmission of 3D content, and are shown to be vastly superior to existing methods using spatial techniques, if slight loss can be tolerated.',\n",
              "  'Compressing Polygon Mesh Geometry with Parallelogram Prediction.[SEP]We present a generalization of the geometry coder by Touma and Gotsman (1998) to polygon meshes. We let the polygon information dictate where to apply the parallelogram rule that they use to predict vertex positions. Since polygons tend to be fairly planar and fairly convex, it is beneficial to make predictions within a polygon rather than across polygons. This, for example, avoids poor predictions due to a crease angle between polygons. Up to 90 percent of the vertices can be predicted this way. Our strategy improves geometry compression by 10 to 40 percent depending on (a) how polygonal the mesh is and (b) on the quality (planarity/convexity) of the polygons.',\n",
              "  'Connectivity Compression for Three-Dimensional Planar Triangle Meshes.[SEP]We describe a new algorithm for coding the connectivity information of three-dimensional planar triangle meshes. Vertices of a mesh are placed on a two-dimensional grid. The connectivity pattern of the grid is implicit and hence the only information that needs to be encoded is the diagonal links. We present experimental results that show that the new method has a low connectivity cost of 2.1 bits per vertex on average.',\n",
              "  'A Unified Interpolatory and Approximation sqrt-3 Subdivision Scheme.[SEP]We have found that there is a relationship between the cubic B-spline and four-point curve subdivision method. In the paper it is used to deduce interpolatory subdivision schemes from cubic B-spline based approximation subdivision schemes directly and construct unified schemes for compositing approximation and interpolatory subdivision. A new interpolatory p3 subdivision scheme and a interpolatory and approximation blended p3 subdivision scheme are created by this straightforward method. The former produces C1 limit surface and avoids the problem in the exsiting interpolatory p3 subdivision mask where the weight coefficients on extraordinary vertices can not be described by explicit formulation. The latter can be used to solve the \"popping effect\" problem when switching between meshes at different levels of resolution, provide the possibility to locally choose an interpolating variant of the conventionally approximating subdivision scheme, and give more flexibility for feature modeling. These are realized by only changing the value of a parameter. The method is thoroughly simple without needs of constructing and solving equations.',\n",
              "  'Quad/Triangle Subdivision.[SEP]In this paper we introduce a new subdivision operator that unifies triangular and quadrilateral subdivision schemes. Designers often want the added flexibility of having both quads and triangles in their models. It is also well known that triangle meshes generate poor limit surfaces when using a quad scheme, while quad‐only meshes behave poorly with triangular schemes. Our new scheme is a generalization of the well known Catmull‐Clark and Loop subdivision algorithms. We show that our surfaces are C 1 everywhere and provide a proof that it is impossible to construct such a C 2 scheme at the quad/triangle boundary. However, we provide rules that produce surfaces with bounded curvature at the regular quad/triangle boundary and provide optimal masks that minimize the curvature divergence elsewhere. We demonstrate the visual quality of our surfaces with several examples.',\n",
              "  'A New Interpolatory Subdivision for Quadrilateral Meshes.[SEP]This paper presents a new interpolatory subdivision scheme for quadrilateral meshes based on a 1–4 splitting operator. The scheme generates surfaces coincident with those of the Kobbelt interpolatory subdivision scheme for regular meshes. A new group of rules are designed for computing newly inserted vertices around extraordinary vertices. As an extension of the regular masks,the new rules are derived based on a reinterpretation of the regular masks. Eigen‐structure analysis demonstrates that subdivision surfaces generated using the new scheme are C1 continuous and, in addition, have bounded curvature.',\n",
              "  'Planar Shape Interpolation Based On Teichm[SEP]Shape interpolation is a classical problem in computer graphics and has been widely investigated in the past two decades. Ideal shape interpolation should be natural and smooth which have good properties such as affine and conformal reproduction, bounded distortion, no fold‐overs, etc. In this paper, we present a new approach for planar shape interpolation based on Teichmüller maps ‐ a special type of maps in the class of quasi‐conformal maps. The algorithm consists of two steps. In the first step, a Teichmüller map is computed from the source shape to the target shape, and then the Beltrami coefficient is interpolated such that the conformal distortion is linear with respect to the time variable. In the second step, the intermediate shape is reconstructed by solving the Beltrami equation locally over each triangle and then stitching the mapped triangles by conformal transformations. The new approach preserves all the good properties mentioned above and produces more natural and more uniform intermediate shapes than the start‐of‐the‐art methods. Especially, the conformal distortion changes linearly with respect to the time variable. Experiment results show that our method can produce appealing results regardless of interpolating between the same or different objects.',\n",
              "  'Locally Injective Mappings.[SEP]Mappings and deformations are ubiquitous in geometry processing, shape modeling, and animation. Numerous deformation energies have been proposed to tackle problems like mesh parameterization and volumetric deformations. We present an algorithm that modifies any deformation energy to guarantee a locally injective mapping, i.e., without inverted elements. Our formulation can be used to compute continuous planar or volumetric piecewise‐linear maps and it uses a barrier term to prevent inverted elements. Differently from previous methods, we carefully design both the barrier term and the associated numerical techniques to be able to provide immediate feedback to the user, enabling interactive manipulation of inversion‐free mappings. Stress tests show that our method robustly handles extreme deformations where previous techniques converge very slowly or even fail. We demonstrate that enforcing local injectivity increases fidelity of the results in applications such as shape deformation and parameterization.',\n",
              "  'As-Rigid-As\\ue4f8Possible Distance Field Metamorphosis.[SEP]Widely used for morphing between objects with arbitrary topology, distance field interpolation (DFI) handles topological transition naturally without the need for correspondence or remeshing, unlike surface‐based interpolation approaches. However, lack of correspondence in DFI also leads to ineffective control over the morphing process. In particular, unless the user specifies a dense set of landmarks, it is not even possible to measure the distortion of intermediate shapes during interpolation, let alone control it. To remedy such issues, we introduce an approach for establishing correspondence between the interior of two arbitrary objects, formulated as an optimal mass transport problem with a sparse set of landmarks. This correspondence enables us to compute non‐rigid warping functions that better align the source and target objects as well as to incorporate local rigidity constraints to perform as‐rigid‐as\\ue4f8possible DFI. We demonstrate how our approach helps achieve flexible morphing results with a small number of landmarks.',\n",
              "  'Vega: Non-Linear FEM Deformable Object Simulator.[SEP]This practice and experience paper describes a robust C++ implementation of several non‐linear solid three‐dimensional deformable object strategies commonly employed in computer graphics, named the Vega finite element method (FEM) simulation library. Deformable models supported include co‐rotational linear FEM elasticity, Saint–Venant Kirchhoff FEM model, mass–spring system and invertible FEM models: neo‐Hookean, Saint–Venant Kirchhoff and Mooney–Rivlin. We provide several timestepping schemes, including implicit Newmark and backward Euler integrators, and explicit central differences. The implementation of material models is separated from integration, which makes it possible to employ our code not only for simulation, but also for deformable object control and shape modelling. We extensively compare the different material models and timestepping schemes. We provide practical experience and insight gained while using our code in several computer animation and simulation research projects.',\n",
              "  \"Modal Warping: Real-Time Simulation of Large Rotational Deformation and Manipulation.[SEP]This work proposes a real-time simulation technique for large deformations. Green's nonlinear strain tensor accurately models large deformations; however, time stepping of the resulting nonlinear system can be computationally expensive. Modal analysis based on a linear strain tensor has been shown to be suitable for real-time simulation, but is accurate only for moderately small deformations. In the present work, we identify the rotational component of an infinitesimal deformation and extend traditional linear modal analysis to track that component. We then develop a procedure to integrate the small rotations occurring at the nodal points. An interesting feature of our formulation is that it can implement both position and orientation constraints in a straightforward manner. These constraints can be used to interactively manipulate the shape of a deformable solid by dragging/twisting a set of nodes. Experiments show that the proposed technique runs in real-time, even for a complex model, and that it can simulate large bending and/or twisting deformations with acceptable realism.\",\n",
              "  'Geometric Stiffness for Real-time Constrained Multibody Dynamics.[SEP]This paper focuses on the stable and efficient simulation of articulated rigid body systems for real‐time applications. Specifically, we focus on the use of geometric stiffness which can dramatically increase simulation stability. We examine several numerical problems with the inclusion of geometric stiffness in the equations of motion, as proposed by previous work, and address these issues by introducing a novel method for efficiently building the linear system. This offers improved tractability and numerical efficiency. Furthermore, geometric stiffness tends to significantly dissipate kinetic energy. We propose an adaptive damping scheme, inspired by the geometric stiffness, that uses a stability criterion based on the numerical integrator to determine the amount of non‐constitutive damping required to stabilize the simulation. With this approach, not only is the dynamical behavior better preserved, but the simulation remains stable for mass ratios of 1,000,000‐to‐1 at time steps up to 0.1 s. We present a number of challenging scenarios to demonstrate that our method improves efficiency, and that it increases stability by orders of magnitude compared to previous work.',\n",
              "  'Simplifying surfaces with color and texture using quadric error metrics.[SEP]There are a variety of application areas in which there is a need for simplifying complex polygonal surface models. These models often have material properties such as colors, textures, and surface normals. Our surface simplification algorithm, based on iterative edge contraction and quadric error metrics, can rapidly produce high quality approximations of such models. We present a natural extension of our original error metric that can account for a wide range of vertex attributes.',\n",
              "  'Locally Toleranced Surface Simplification.[SEP]We present a technique for simplifying a triangulated surface. Simplifying consists of approximating the surface with another surface of lower triangle count. Our algorithm can preserve the volume of a solid to within machine accuracy; it favors the creation of near-equilateral triangles. We develop novel methods for reporting and representing a bound to the approximation error between a simplified surface and the original, and respecting a variable tolerance across the surface. A different positive error value is reported at each vertex. By linearly blending the error values in between vertices, we define a volume of space, called the error volume, as the union of balls of linearly varying radii. The error volume is built dynamically as the simplification progresses, on top of preexisting error volumes that it contains. We also build a tolerance volume to forbid simplification errors exceeding a local tolerance. The information necessary to compute error values is local to the star of a vertex; accordingly, the complexity of the algorithm is either linear or in O(n log n) in the original number of surface edges, depending on the variant. We extend the mechanisms of error and tolerance volumes to preserve during simplification scalar and vector attributes associated with surface vertices. Assuming a linear variation across triangles, error and tolerance volumes are defined in the same fashion as for positional error. For normals, a corrective term is applied to the error measured at the vertices to compensate for nonlinearities.',\n",
              "  'Coarse-to-fine surface simplification with geometric guarantees.[SEP]Let PC be a 3D point cloud and ε be a positive value called tolerance. We aim at constructing a triangulated surface S based on a subset PCU of PC such that all the points in PCL=PC∖PCU are at distance at most ε from a facet of S. (PCU and PCL respectively stand for Point Cloud Used and Point Cloud Left.) We call this problem simplification with geometric guarantees.',\n",
              "  'Crest Lines for Surface Segmentation and Flattening.[SEP]We present a method for extracting feature curves called crest lines from a triangulated surface. Then, we calculate the geodesic Voronoi diagram of crest lines to segment the surface into several regions. Afterward, barycentric surface flattening using theory from graph embeddings is implemented and, using the geodesic Voronoi diagram, we develop a faster surface flattening algorithm.',\n",
              "  'On stochastic methods for surface reconstruction.[SEP]In this article, we present and discuss three statistical methods for surface reconstruction. A typical input to a surface reconstruction technique consists of a large set of points that has been sampled from a smooth surface and contains uncertain data in the form of noise and outliers. We first present a method that filters out uncertain and redundant information yielding a more accurate and economical surface representation. Then we present two methods, each of which converts the input point data to a standard shape representation; the first produces an implicit representation while the second yields a triangle mesh.',\n",
              "  'Applied Geometry: Discrete Differential Calculus for Graphics.[SEP]Geometry has been extensively studied for centuries, almost exclusively from a differential point of view. However, with the advent of the digital age, the interest directed to smooth surfaces has now partially shifted due to the growing importance of discrete geometry. From 3D surfaces in graphics to higher dimensional manifolds in mechanics, computational sciences must deal with sampled geometric data on a daily basis‐hence our interest in Applied Geometry.',\n",
              "  'One Point Isometric Matching with the Heat Kernel.[SEP]A common operation in many geometry processing algorithms consists of finding correspondences between pairs of shapes by finding structure‐preserving maps between them. A particularly useful case of such maps is isometries, which preserve geodesic distances between points on each shape. Although several algorithms have been proposed to find approximately isometric maps between a pair of shapes, the structure of the space of isometries is not well understood. In this paper, we show that under mild genericity conditions, a single correspondence can be used to recover an isometry defined on entire shapes, and thus the space of all isometries can be parameterized by one correspondence between a pair of points. Perhaps surprisingly, this result is general, and does not depend on the dimensionality or the genus, and is valid for compact manifolds in any dimension. Moreover, we show that both the initial correspondence and the isometry can be recovered efficiently in practice. This allows us to devise an algorithm to find intrinsic symmetries of shapes, match shapes undergoing isometric deformations, as well as match partial and incomplete models efficiently.',\n",
              "  'Computing Teichm[SEP]Shape indexing, classification, and retrieval are fundamental problems in computer graphics. This work introduces a novel method for surface indexing and classification based on Teichmuller theory. The Teichmuller space for surfaces with the same topology is a finite dimensional manifold, where each point represents a conformal equivalence class, a curve represents a deformation process from one class to the other. We apply Teichmuller space coordinates as shape descriptors, which are succinct, discriminating and intrinsic; invariant under the rigid motions and scalings, insensitive to resolutions. Furthermore, the method has solid theoretic foundation, and the computation of Teichmuller coordinates is practical, stable and efficient. This work focuses on the surfaces with negative Euler numbers, which have a unique conformal Riemannian metric with -1 Gaussian curvature. The coordinates which we will compute are the lengths of a special set of geodesics under this special metric. The metric can be obtained by the curvature flow algorithm, the geodesics can be calculated using algebraic topological method. We tested our method extensively for indexing and comparison of about one hundred of surfaces with various topologies, geometries and resolutions. The experimental results show the efficacy and efficiency of the length coordinate of the Teichmuller space.',\n",
              "  'Bilateral Maps for Partial Matching.[SEP]Feature‐driven analysis forms the basis of many shape processing tasks, where detected feature points are characterized by local shape descriptors. Such descriptors have so far been defined to capture regions of interest centred at individual points. Using such regions to compare feature points can be problematic when performing partial shape matching, because the region of interest is typically defined as an isotropic neighbourhood around a point, which does not adapt to the geometry of the shape parts. We introduce the bilateral map, a local shape descriptor whose region of interest is defined by two feature points. Compared to the classical descriptor definition using a single point, the bilateral approach exploits the use of a second point to place more constraints on the selection of the spatial context for feature analysis. This leads to a descriptor where the shape of the region of interest adapts to the context of the two points, making it more refined for shape matching. In particular, we show that our new descriptor is more effective for partial matching, because potentially extraneous regions of the models are selectively ignored owing to the adaptive nature of the bilateral map. This property also renders the bilateral map partially insensitive to topological changes. We demonstrate the effectiveness of the bilateral map for partial matching via several correspondence and retrieval experiments and evaluate the results both qualitatively and quantitatively.'],\n",
              " '60_molecules_atoms_molecule_halos': [\"Protein Tunnel Reprojection for Physico-Chemical Property Analysis.[SEP]Cavities are crucial for interactions of proteins with other molecules. While a variety of different cavity types exists, tunnels in particular play an important role, as they enable a ligand to deeply enter the active site of a protein where chemical reactions can undergo. Consequently, domain scientists are interested in understanding properties relevant for binding interactions inside molecular tunnels. Unfortunately, when inspecting a 3D representation of the molecule under investigation, tunnels are difficult to analyze due to occlusion issues. Therefore, within this paper we propose a novel reprojection technique that transforms the 3D structure of a molecule to obtain a 2D representation of the tunnel interior. The reprojection has been designed with respect to application-oriented design guidelines, we have identified together with our domain partners. To comply with these guidelines, the transformation preserves individual residues, while the result is capable of showing binding properties inside the tunnel without suffering from occlusions. Thus the reprojected tunnel interior can be used to display physico-chemical properties, e.g., hydrophobicity or amino acid orientation, of residues near a tunnel's surface. As these properties are essential for the interaction between protein and ligand, they can thus hint angles of attack for protein engineers. To demonstrate the benefits of the developed visualization, the obtained results are discussed with respect to domain expert feedback.\",\n",
              "  'Comparative Visualization of Molecular Surfaces Using Deformable Models.[SEP]The comparison of molecular surface attributes is of interest for computer aided drug design and the analysis of biochemical simulations. Due to the non‐rigid nature of molecular surfaces, partial shape matching is feasible for mapping two surfaces onto each other. We present a novel technique to obtain a mapping relation between two surfaces using a deformable model approach. This relation is used for pair‐wise comparison of local surface attributes (e.g. electrostatic potential). We combine the difference value as well as the comparability as derived from the local matching quality in a 3D molecular visualization by mapping them to color. A 2D matrix shows the global dissimilarity in an overview of different data sets in an ensemble. We apply our visualizations to simulation results provided by collaborators from the field of biochemistry to evaluate the effectiveness of our results.',\n",
              "  'CAVER Viewer - the explorer of behaviour of tunnels in proteins.[SEP]Protein exploration in order to discover new medication has been the principal aim of biochemists. In combination with informatics the solution of this task can be faster, more accurate and also more intuitive and straightforward in comparison with traditional methods. Our CAVER Viewer application allows the exploration of protein structures and the visualization of results. It enables to find certain paths from the outer space around the molecule to the specific site inside the protein called the active site. The existence of these important paths (also called tunnels or channels) is crucial in the process of transferring some small molecule of substrate into this active site. Namely, the substrate enters the active site via these precomputed tunnels. There the chemical reaction between the substrate and protein can undergo. The product of this reaction can form the basis of a new medication. This poster describes the key aim of our research in the field of protein visualization, when we have to visualize the protein dynamics - movements of the molecule as well as the behaviour of its tunnels in time space.'],\n",
              " '61_memory_insight_solving_task': ['Constraints on Theories of Serial Order Memory Revisited: The Cases of the Fill-In and Protrusion Effects.[SEP]In his seminal dissertation, Henson (1996) identified a number of constraints on theories of serial order memory. Two constraints, the fill-in constraint, in which an item that is erroneously recalled early is likely to be followed by its predecessor rather than its successor (recall of ACB is more likely than ACD), and the protrusion constraint, in which prior list intrusions are likely to be recalled in the same output position as their previous serial position, were considered evidence against chaining theories. We present results from two experiments which investigate the extent to which these effects are dependent on experimental methodology. When participants are given an open set of items, an equal ratio of fill-in and in-fill errors was observed and a protrusion effect was obtained. However, when a reconstruction of order task was used, a fill-in effect was observed. Implications for theories of serial order memory are discussed.',\n",
              "  \"The Primary and Convergent Retrieval Model of Recall.[SEP]Memory models typically assume that recall is a two-stage process with learning affecting both processes to the same degree. This equal learning assumption is difficult to reconcile with studies of the 'testing effect', which reveal different forgetting rates following learning from test practice versus learning from restudy. Here we present a new memory model, termed Primary and Convergent Retrieval (PCR) that assumes successful recall leads to a selective enhancement for the second stage of recall (Convergent Retrieval). We applied this model to existing testing effect data. In two new experiments, we confirmed novel predictions of the PCR model for transfer between retrieval cues and for recall latencies. This is the first formally specified model of the testing effect and it has broad implications for the nature of learning and retrieval.\",\n",
              "  \"Now I like it, now I don't: Delay effects and retrospective judgment.[SEP]The present paper tests the widely accepted hypothesis that on-line judgment implies functional independence between memory for, and judgment of, verbal stimuli (e.g., Anderson, 1989; Hastie & Park, 1986). In the present study, participants recalled lists of words, after having assessed each for its pleasantness. Presentation position of a negative item within the lists was manipulated. Also, items memorability was manipulated after their presentation – by inserting a filled delay between presentation and the judgment task; in this way, on-line judgment formation was spared. The memory manipulation reduced recall rates for negative items presented in the last position – and their negative influence on pleasantness ratings accordingly. These results contradict the predictions of pure on-line approaches to judgment formation (e.g., Betsch, Plessner, Schwieren, & Gütig, 2001) and suggest that even in on-line judgment tasks, memory plays a role.\",\n",
              "  'Evaluating the Relationship Between Neuropsychological Function and Cognitive Performance.[SEP]The last 2 decades have produced a vast literature describing relationships between cognitive performance and neuropsychological data. This literature has provided the foundation for countless theories about the neural correlates of cognitive processing and specific theories regarding the role of different cortical areas in human cognition. In this paper, we examine a particular theory – the error likelihood model (Brown & Braver, 2005) – that attempts to account for the function of a particular brain area (the anterior cingulate cortex). A careful evaluation of behavioral data from humans raises questions about the error likelihood model and the implications of neuropsychological data for understanding cognitive performance.',\n",
              "  'Using a Cognitive Model for an In-Depth Analysis of the Tower of London.[SEP]The Tower of London (ToL) is a transformation task extensively used and well-established as a neuropsychological diagnostic tool for assessing human planning ability in clinical and research contexts. Behavioral experiments have recently shown that planning in the ToL is substantially influenced by structural task parameters. This work presents an ACT-R model of the ToL that explains structural influences by using different strategies, whereby, strategy selection depends on visually observable characteristics. Model evaluation was based on a problem selection that accounted for systematic variations of task demands. Based on comparisons with empirically observed planning latencies from previously published data, we argue that task-specific structural characteristics are necessary to explain human planning strategies.',\n",
              "  'A Mechanistic Account of Constraints on Control-Dependent Processing: Shared Representation, Conflict and Persistence.[SEP]One of the most fundamental and striking limitations of human cognitive function is the constraint on the number of control-dependent processes that can be executed simultaneously. However, the sources of this capacity constraint remain largely unexplored. Previous work has attributed the constraints on control-dependent processing to the sharing of representations between tasks in neural systems. Here, we examine how shared representations interact with two other factors in producing constraints on control-dependent processing. We first demonstrate that the detrimental effects of shared representations on multitasking performance are contingent on the amount of conflict that is induced by the tasks that share representations. We then examine how the persistence of shared representations between tasks affects processing interference during serial task execution. Finally, we discuss how this set of mechanisms can account for various phenomena in neural architectures, including the psychological refractory period, task switch costs, as well as constraints on cognitive control.'],\n",
              " '62_spline_splines_curves_cubic': ['Surface approximation to scanned data.[SEP]A method to approximate scanned data points with a B-spline surface is presented. The data are assumed to be organized in the form of Q i,j, i=0,…,n; j=0,…,m i, i.e., in a row-wise fashion. The method produces a C (p-1, q-1) continuous surface (p and q are the required degrees) that does not deviate from the data by more than a user-specified tolerance. The parametrization of the surface is not affected negatively by the distribution of the points in each row, and it can be influenced by a user-supplied knot vector.',\n",
              "  \"A recursive evaluation algorithm for a class of Catmull-Rom splines.[SEP]It is known that certain Catmull-Rom splines [7] interpolate their control vertices and share many properties such as affine invariance, global smoothness, and local control with B-spline curves; they are therefore of possible interest to computer aided design. It is shown here that another property a class of Catmull-Rom splines shares with B-spline curves is that both schemes possess a simple recursive evaluation algorithm. The Catmull-Rom evaluation algorithm is constructed by combining the de Boor algorithm for evaluating B-spline curves with Neville's algorithm for evaluating Lagrange polynomials. The recursive evaluation algorithm for Catmull-Rom curves allows rapid evaluation of these curves by pipelining with specially designed hardware. Furthermore it facilitates the development of new, related curve schemes which may have useful shape parameters for altering the shape of the curve without moving the control vertices. It may also be used for constructing transformations to B&eacute;zier and B-spline form.\",\n",
              "  'B-spline surfaces for ship hull design.[SEP]The use of true sculptured surface descriptions for design applications has been proposed by numerous authors. The actual implementation and use of interactive sculptured surface description techniques for design and production has been limited. The use of such techniques for ship hull design has been even more limited. The present paper describes a preliminary implementation of such a system for the design of ship hulls and for the production of towing tank models using numerical control techniques. The present implementation is based on a Cartesian product B-spline surface description. Implementation is on an Evans and Sutherland Picture System supported by a PDP-11/45 minicomputer.'],\n",
              " '63_clustering_clusters_cluster_clusterings': ['A robust and scalable clustering algorithm for mixed type attributes in large database environment.[SEP]Clustering is a widely used technique in data mining applications to discover patterns in the underlying data. Most traditional clustering algorithms are limited to handling datasets that contain either continuous or categorical attributes. However, datasets with mixed types of attributes are common in real life data mining problems. In this paper, we propose a distance measure that enables clustering data with both continuous and categorical attributes. This distance measure is derived from a probabilistic model that the distance between two clusters is equivalent to the decrease in log-likelihood function as a result of merging. Calculation of this measure is memory efficient as it depends only on the merging cluster pair and not on all the other clusters. Zhang et al [8] proposed a clustering method named BIRCH that is especially suitable for very large datasets. We develop a clustering algorithm using our distance measure based on the framework of BIRCH. Similar to BIRCH, our algorithm first performs a pre-clustering step by scanning the entire dataset and storing the dense regions of data records in terms of summary statistics. A hierarchical clustering algorithm is then applied to cluster the dense regions. Apart from the ability of handling mixed type of attributes, our algorithm differs from BIRCH in that we add a procedure that enables the algorithm to automatically determine the appropriate number of clusters and a new strategy of assigning cluster membership to noisy data. For data with mixed type of attributes, our experimental results confirm that the algorithm not only generates better quality clusters than the traditional k-means algorithms, but also exhibits good scalability properties and is able to identify the underlying number of clusters in the data correctly. The algorithm is implemented in the commercial data mining tool Clementine 6.0 which supports the PMML standard of data mining model deployment.',\n",
              "  'Foundations of Perturbation Robust Clustering.[SEP]Clustering is a fundamental data mining tool that aims to divide data into groups of similar items. Intuition about clustering reflects the ideal case - exact data sets endowed with flawless dissimilarity between individual instances. In practice however, these cases are in the minority, and clustering applications are typically characterized by noisy data sets with approximate pairwise dissimilarities. As such, the efficacy of clustering methods necessitates robustness to perturbations. In this paper, we address foundational questions on perturbation robustness, studying to what extent can clustering techniques exhibit this desirable characteristic. Our results also demonstrate the type of cluster structures required for robustness of popular clustering paradigms.',\n",
              "  'Scalable k -Means Clustering via Lightweight Coresets.[SEP]\\\\emphCoresets are compact representations of data sets such that models trained on a coreset are provably competitive with models trained on the full data set. As such, they have been successfully used to scale up clustering models to massive data sets. While existing approaches generally only allow for multiplicative approximation errors, we propose a novel notion of lightweight coresets that allows for both multiplicative and additive errors. We provide a single algorithm to construct lightweight coresets for k -means clustering as well as soft and hard Bregman clustering. The algorithm is substantially faster than existing constructions, embarrassingly parallel, and the resulting coresets are smaller. We further show that the proposed approach naturally generalizes to statistical k -means clustering and that, compared to existing results, it can be used to compute smaller summaries for empirical risk minimization. In extensive experiments, we demonstrate that the proposed algorithm outperforms existing data summarization strategies in practice.'],\n",
              " '64_impaired_visually_tactile_impairments': [\"Design and user evaluation of a joystick-operated full-screen magnifier.[SEP]The paper reports on two development cycles of a joystick-operated full-screen magnifier for visually impaired users. In the first cycle of evaluation, seven visually impaired computer users evaluated the system in comprehension-based sessions using text documents. After considering feedback from these evaluators, a second version of the system was produced and evaluated by a further six visually impaired users. The second evaluation was conducted using information-seeking tasks using Web pages. In both evaluations, the 'thinking aloud protocol' was used. This study makes several contributions to the field. First, it is perhaps the first published study investigating the use of a joystick as an absolute and relative pointing device to control a screen magnifier. Second, the present study revealed that for most of the visually impaired users who participated in the study the joystick had good spatial, cognitive and ergonomic attributes, even for those who had never before used a joystick.\",\n",
              "  'Molder: An Accessible Design Tool for Tactile Maps.[SEP]Tactile materials are powerful teaching aids for students with visual impairments (VIs). To design these materials, designers must use modeling applications, which have high learning curves and rely on visual feedback. Today, Orientation and Mobility (O&M) specialists and teachers are often responsible for designing these materials. However, most of them do not have professional modeling skills, and many are visually impaired themselves. To address this issue, we designed Molder, an accessible design tool for interactive tactile maps, an important type of tactile materials that can help students learn O&M skills. A designer uses Molder to design a map using tangible input techniques, and Molder provides auditory feedback and high-contrast visual feedback. We evaluated Molder with 12 participants (8 with VIs, 4 sighted). After a 30-minute training session, the participants were all able to use Molder to design maps with customized tactile and interactive information.',\n",
              "  'Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: a Participatory Design Approach.[SEP]Current low-tech Orientation & Mobility (O&M) tools for visually impaired people, e.g. tactile maps, possess limitations. Interactive accessible maps have been developed to overcome these. However, most of them are limited to exploration of existing maps, and have remained in laboratories. Using a participatory design approach, we have worked closely with 15 visually impaired students and 3 O&M instructors over 6 months. We iteratively designed and developed an augmented reality map destined at use in O&M classes in special education centers. This prototype combines projection, audio output and use of tactile tokens, and thus allows both map exploration and construction by low vision and blind people. Our user study demonstrated that all students were able to successfully use the prototype, and showed a high user satisfaction. A second phase with 22 international special education teachers allowed us to gain more qualitative insights. This work shows that augmented reality has potential for improving the access to education for visually impaired people.'],\n",
              " '65_distributed_parallel_scientific_convergence': ['Distributed computing: new power for scientific visualization.[SEP]Distributed computing provides unique benefits for scientific visualization in this system (Discover) that supports interactive visualization and cooperative work for nonprogrammers. Discover (Distributed Interactive Scientific Computing and Visualization Environment), is suitable for many areas, but we have concentrated on medical image analysis and generation-one of the the most rapidly growing applications for scientific visualization. In its present form, Discover acts as a framework for clinical applications. True to its name, it allows a variety of users to discover the relevant information in a vast body of scientific data. Nonprogrammers, such as physicians and radiologists, interactively display and manipulate the two and three dimensional medical objects, visualize the results, control system computation, and generally drive the image analysis process. The emphasis is on the distributed nature of the software architecture and its functions. We also describe a unique load balancing algorithm designed to maximize workstation performance.',\n",
              "  \"Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations.[SEP]The performance of massively parallel applications is often heavily impacted by the cost of communication among compute nodes. However, determining how to best use the network is a formidable task, made challenging by the ever increasing size and complexity of modern supercomputers. This paper applies visualization techniques to aid parallel application developers in understanding the network activity by enabling a detailed exploration of the flow of packets through the hardware interconnect. In order to visualize this large and complex data, we employ two linked views of the hardware network. The first is a 2D view, that represents the network structure as one of several simplified planar projections. This view is designed to allow a user to easily identify trends and patterns in the network traffic. The second is a 3D view that augments the 2D view by preserving the physical network topology and providing a context that is familiar to the application developers. Using the massively parallel multi-physics code pF3D as a case study, we demonstrate that our tool provides valuable insight that we use to explain and optimize pF3D's performance on an IBM Blue Gene/P system.\",\n",
              "  'A Concurrent Architecture Proposal for Information Visualization Pipeline.[SEP]This paper identifies an opportunity to reduce the latency in information visualization (InfoVis) systems, exploring the parallelization of the visualization pipeline architecture. We propose a concurrent architecture where the visualization pipeline stages are modified to execute as producers and consumers threads. The threads synchronization is done by memory barriers and the data flow pass the pipeline through a unique data structure, called ring buffer, which reuses a contiguous space preallocated in memory. Two InfoVis prototypes were developed in java, the first one using sequential pipeline and the other using concurrent pipeline. The results obtained with concurrent architecture in comparison with sequential pipeline presented less execution time and memory allocation for data visualization renderization.',\n",
              "  'A Weighted Aggregating SGD for Scalable Parallelization in Deep Learning.[SEP]We investigate the stochastic optimization problem and develop a scalable parallel computing algorithm for deep learning tasks. The key of our study involves a reformation of the objective function for the stochastic optimization in neural network models. We propose a novel update rule, named weighted aggregating stochastic gradient decent, after theoretically analyzing the characteristics of the newly formalized objective function. The new rule introduces a weighted aggregation scheme based on the performance of local workers and does not require a center variable. It assesses the relative importance of local workers and accepts them according to their contributions. Our new rule also allows the implementation of both synchronous and asynchronous parallelization and can result in varying convergence rates. For method evaluation, we benchmark our schemes against the mainstream algorithms, including the elastic averaging SGD in training deep neural networks for classification tasks. We conduct extensive experiments on several classic datasets, and the results confirm the strength of our scheme in accelerating the training of deep architecture and scalable parallelization.',\n",
              "  'Large-scale distributed non-negative sparse coding and sparse dictionary learning.[SEP]We consider the problem of building compact, unsupervised representations of large, high-dimensional, non-negative data using sparse coding and dictionary learning schemes, with an emphasis on executing the algorithm in a Map-Reduce environment. The proposed algorithms may be seen as parallel optimization procedures for constructing sparse non-negative factorizations of large, sparse matrices. Our approach alternates between a parallel sparse coding phase implemented using greedy or convex (l1) regularized risk minimization procedures, and a sequential dictionary learning phase where we solve a set of l0 optimization problems exactly. These two-fold sparsity constraints lead to better statistical performance on text analysis tasks and at the same time make it possible to implement each iteration in a single Map-Reduce job. We detail our implementations and optimizations that lead to the ability to factor matrices with more than 100 million rows and billions of non-zero entries in just a few hours on a small commodity cluster.',\n",
              "  'Parallelization with Multiplicative Algorithms for Big Data Mining.[SEP]We propose a nontrivial strategy to parallelize a series of data mining and machine learning problems, including 1-class and 2-class support vector machines, nonnegative least square problems, and \\\\ell_1 regularized regression (LASSO) problems. Our strategy fortunately leads to extremely simple multiplicative algorithms which can be straightforwardly implemented in parallel computational environments, such as Map Reduce, or CUDA. We provide rigorous analysis of the correctness and convergence of the algorithm. We demonstrate the scalability and accuracy of our algorithms in comparison with other current leading algorithms.'],\n",
              " '66_wikipedia_communities_community_newcomers': [\"Impression formation in online peer production: activity traces and personal profiles in github.[SEP]In this paper we describe a qualitative investigation of impression formation in an online distributed software development community with social media functionality. We find that users in this setting seek out additional information about each other to explore the project space, inform future interactions, and understand the potential future value of a new person. They form impressions around other users' expertise based on history of activity across projects, and successful collaborations with key high status projects in the community. These impressions influence their receptivity to strangers' work contributions.\",\n",
              "  'Community insights: helping community leaders enhance the value of enterprise online communities.[SEP]Online communities are increasingly being deployed in enterprises to increase productivity and share expertise. Community leaders are critical for fostering successful communities, but existing technologies rarely support leaders directly, both because of a lack of clear data about leader needs, and because existing tools are member- rather than leader-centric. We present the evidence-based design and evaluation of a novel tool for community leaders, Community Insights (CI). CI provides actionable analytics that help community leaders foster healthy communities, providing value to both members and the organization. We describe empirical and system contributions derived from a long-term deployment of CI to leaders of 470 communities over 10 months. Empirical contributions include new data showing: (a) which metrics are most useful for leaders to assess community health, (b) the need for and how to design actionable metrics, (c) the need for and how to design contextualized analytics to support sensemaking about community data. These findings motivate a novel community system that provides leaders with useful, actionable and contextualized analytics.',\n",
              "  \"SuggestBot: using intelligent task routing to help people find work in wikipedia.[SEP]Member-maintained communities ask their users to perform tasks the community needs. From Slashdot, to IMDb, to Wikipedia, groups with diverse interests create community-maintained artifacts of lasting value (CALV) that support the group's main purpose and provide value to others. Said communities don't help members find work to do, or do so without regard to individual preferences, such as Slashdot assigning meta-moderation randomly. Yet social science theory suggests that reducing the cost and increasing the personal value of contribution would motivate members to participate more.We present SuggestBot, software that performs intelligent task routing (matching people with tasks) in Wikipedia. SuggestBot uses broadly applicable strategies of text analysis, collaborative filtering, and hyperlink following to recommend tasks. SuggestBot's intelligent task routing increases the number of edits by roughly four times compared to suggesting random articles. Our contributions are: 1) demonstrating the value of intelligent task routing in a real deployment; 2) showing how to do intelligent task routing; and 3) sharing our experience of deploying a tool in Wikipedia, which offered both challenges and opportunities for research.\"],\n",
              " '67_metaphors_metaphor_analogical_analogy': ['Spontaneous Analogy by Piggybacking on a Perceptual System.[SEP]Most computational models of analogy assume they are given a delineated source domain and often a specified target domain. These systems do not address how analogs can be isolated from large domains and spontaneously retrieved from long-term memory, a process we call spontaneous analogy. We present a system that represents relational structures as feature bags. Using this representation, our system leverages perceptual algorithms to automatically create an ontology of relational structures and to efficiently retrieve analogs for new relational structures from long-term memory. We provide a demonstration of our approach that takes a set of unsegmented stories, constructs an ontology of analogical schemas (corresponding to plot devices), and uses this ontology to efficiently find analogs within new stories, yielding significant time-savings over linear analog retrieval at a small accuracy cost.',\n",
              "  'Generalizing relations during analogical problem solving in preschool children: does blocked or interleaved training improve performance?[SEP]Analogical reasoning, the mapping of structured relations across conceptual domains, is commonly recognized as essential to human cognition, but young children often perform poorly in the classical A:B::C:? analogical reasoning task. Particularly, young children have trouble when the objects in the task are not strongly associated with each other, and/or when there are strong associative lures among the potential answers. Here, we examine whether successive trials that repeat the same relation needed to solve the analogy can help overcome some of the challenges with weakly associated items. In the first of two experiments, our results were mixed. In the second, we simplified the design, and were able to more clearly show a benefit of repeating relations across consecutively solved problems.',\n",
              "  'Analogy and Arithmetics: An HDTP-Based Model of the Calculation Circular Staircase.[SEP]Analogical reasoning and its applications are gaining attention not only in cognitive science but also in the context of education and teaching. In this paper we provide a short analysis and a detailed formal model (based on the Heuristic-Driven Theory Projection framework for computational analogy-making) of the Calculation Circular Staircase, a tool for teaching basic arithmetic and insights based on the ordinal number conception of the natural numbers to children in their first years of primary school. We argue that such formal methods and computational accounts of analogy-making can be used to gain additional insights in the inner workings of analogy-based educational methods and tools.',\n",
              "  'An Eye For Figurative Meaning: The Effects of Familiarity on Metaphor Comprehension.[SEP]The career of metaphor hypothesis suggests that processing preference is a result of conventionality whereby conventional metaphors are processed through categorization, and novel ones processed through comparison. Alternatively, the categorization model predicts that apt metaphors are processed as categorizations whether or not they are conventional. However, research has largely ignored another known factor to influence metaphor processing, namely familiarity. The categorization model predicts familiarity to play no role in deciding on processing strategy. On the other hand, the career of metaphor hypothesis predicts that familiarity to play a facilitating role in metaphor comprehension. In this experiment, we used the eye tracking paradigm and controlled for aptness and conventionality, and manipulated familiarity in order to test these predictions. Our initial results support the career of metaphor hypothesis suggesting that familiarity facilitates metaphor processing. We discuss the implications these results have on the psycholinguistic models and briefly speculate on their philosophical consequences.',\n",
              "  \"Formalizing the Pragmatics of Metaphor Understanding.[SEP]While the ubiquity and importance of nonliteral language are clear, people's ability to use and understand it remains a mystery. Metaphor in particular has been studied extensively across many disciplines in cognitive science. One approach focuses on the pragmatic principles that listeners utilize to infer meaning from metaphorical utterances. While this approach has generated a number of insights about how people understand metaphor, to our knowledge there is no formal model showing that effects in metaphor understanding can arise from basic principles of communication. Building upon recent advances in formal models of pragmatics, we describe a computational model that uses pragmatic reasoning to interpret metaphorical utterances. We conduct behavioral experiments to evaluate the model's performance and show that our model produces metaphorical interpretations that closely fit behavioral data. We discuss implications of the model for metaphor understanding, principles of communication, and formal models of language understanding.\",\n",
              "  'Computing Humorous Metaphors.[SEP]It was experimentally showed that humorous texts can be explained using approaches applied to metaphors, such as the salience-imbalance or the domain-interaction approach. It was also demonstrated that humorous metaphors often include a switch between positive and negative emotions. We propose to construct a computer system able to understand and generate such metaphors. Currently we are constructing a metaphor conceptual network, in which links between concepts are calculated accordingly to their roles in metaphor understanding. This will allow the computer to process metaphors. Next, we will adjust the links distance calculation to match the humorous metaphors (to increase the salience-imbalance, as demonstrated in existing research). We will also use an emotiveness-recognition-system to detect emotive associations towards particular phrases, in order to choose pairs with the emotional switch. The system will be evaluated in user-oriented experiments. Acknowledgements: This work was supported by KAKENHI (Project Number: 23-01348)'],\n",
              " '68_crowd_crowds_simulation_pedestrians': ['Improved Obstacle Relevancy, Distance, and Angle for Crowds Constrained to Arbitrary Manifolds in 3D Space.[SEP]Recent work has proposed crowd simulation algorithms on arbitrary manifolds in 3D space. These algorithms simulate crowds on far more realistic surfaces than previously possible, including multi-story structures, science fiction scenarios, and habitats for insects and other animals that can walk on walls. However, current implementations can have distinct artifacts, including collision false positives and false negatives. Also, current implementations fail to account for the cylindrical shape of the characters being simulated. The resulting crowds move unnaturally and have obvious collisions. After identifying the cause of these artifacts, we propose an algorithm that does not struggle from these false positives or false negatives and correctly accounts for the non-spherical shape of agents. The resulting crowds move on large surfaces (over 100k triangles) running with a thousand agents in real-time.',\n",
              "  \"A Graphical Simulator for Modeling Complex Crowd Behaviors.[SEP]Abnormal crowd behaviors of varied real-world settings could represent or pose serious threat to public safety. The video data required for relevant analysis are often difficult to acquire due to security, privacy and data protection issues. Without large amounts of realistic crowd data, it is difficult to develop and verify crowd behavioral models, event detection techniques, and corresponding test and evaluations. This paper presented a synthetic method for generating crowd movements and tendency based on existing social and behavioral studies. Graph and tree searching algorithms as well as game engine-enabled techniques have been adopted in the study. The main outcomes of this research include a categorization model for entity-based behaviors following a linear aggregation approach; and the construction of an innovative agent-based pipeline for the synthesis of A-Star path-finding algorithm and an enhanced Social Force Model. A Spatial-Temporal Texture (STT) technique has been adopted for the evaluation of the model's effectiveness. Tests have highlighted the visual similarities between STTs extracted from the simulations and their counterparts - video recordings - from the real-world.\",\n",
              "  'Perceptual evaluation of maneuvering motion illusion for virtual pedestrians.[SEP]Crowd simulations span a wide spectrum of application domains, most notably video games, evacuation scenarios, and the movie industry. However, it is not obligatory that all virtual populace applications have the primary objective of realistic simulation. In most instances, it is necessary and sufficient that viewers perceive the crowd as plausible. Even for a crowd consisting of agents navigating on linear trajectories without any maneuvers, visual motion illusion elicited by these trajectories might appear to be a natural consequence, causing them to be perceived as wriggling rather than straight. In this respect, we evaluate in this study whether simulated 3D human agents walking with constant, collision-free velocities, induce such a maneuvering motion illusion, aiming toward an efficient real-time crowd simulation. For this purpose, we recorded videos of virtual human crowds with different parameter combinations, such as the agent walking speed, crowd density, camera tilt angle, and camera distance. These videos were watched by human subjects who were instructed to mark the virtual agents who they thought had changed their gait directions. The analyzed results revealed that participants claimed the presence of maneuvering virtual agents in the videos, even though there were none in any of them. Spatial grouping of the markings highlighted that the participants mainly focused on the central area of the simulation environment, and spatiotemporal analysis of the click data also showed stronger evidence to such an illusion (see accompanying video). Furthermore, we found that all of the referred parameters have statistically significant main effects on the number of marked agents per watched video.'],\n",
              " '69_conversational_dialogue_agent_conversation': [\"Whose turn is it anyway? Same- and cross-person compound contributions in dialogue.[SEP]In natural conversation people sometimes build larger grammatical, semantic and pragmatic units out of multiple turns or installments. The incremental and collaborative character of these `compound contributions' presents challenges for theories of natural language processing. Compounds produced over successive turns by one person have often been analysed in essentially the same way as compounds produced by multiple people. In some recent accounts this putative equivalence has been taken as evidence for the claim that within- and cross-person language processing are fundamentally interchangeable. However, in this paper we present an analysis of compound contributions in a corpus of ordinary dialogues which shows that same- and cross-person compound contributions are constructed in different ways and have different semantic and pragmatic effects on the organisation of dialogue. In particular, we show that they differ in the pragmatic environments in which they occur and that they have different consequences for subsequent turn-taking and interpretation. This asymmetry highlights the need for models of dialogue that account for not just the inherent incrementality of dialogue, but the different status of each contributor towards a turn-in-progress.\",\n",
              "  'The Role of Feedback in Aligning Perspectives in Referential Communication.[SEP]Successful dialogue frequently requires that interlocutors construct and align their conceptualizations of referents. This study presents data from a referential communication experiment the manipulates contextual factors such as the availability of feedback and role constancy in order to investigate how conversational partners reconcile their perspectives in the face of mutual uncertainty about what constitutes common ground. The results show that speakers tend to incorporate information about the addressee’s perspective, and that this information tends to come through direct feedback rather than through indirect channels such as turn-taking.',\n",
              "  'Temporal Dynamics of Scan Patterns in Comprehension and Production.[SEP]Speakers and listeners in a dialogue establish mutual understanding by coordinating their linguistic responses. When a visual scene is present, scan patterns on that scene are also coordinated. However, it is an open question which linguistic and scene factors affect coordination. In this paper, we investigate the coordination of scan patterns during the comprehension and generation of scene descriptions. We manipulate the animacy of the subject and the number of visual referents associated with it. By using Cross Recurrence Analysis, we demonstrate that coordination emerges only during linguistic processing, and that it is especially pronounced for inanimate unambiguous subjects. When the subject is referentially ambiguous (more than one visual object associated with it), scan pattern variability increases to the extent that the animacy effect is neutralized.',\n",
              "  \"An Intelligent Assistant for High-Level Task Understanding.[SEP]People are able to interact with domain-specific intelligent assistants (IAs) and get help with tasks. But sometimes user goals are complex and may require interactions with multiple applications. However current IAs are limited to specific applications and users have to directly manage execution spanning multiple applications in order to engage in more complex activities. An ideal personal agent would be able to learn, over time, about tasks that span different resources. This paper addresses the problem of cross-domain task assistance in the context of spoken dialogue systems. We propose approaches to discover users' high-level intentions and using this information to assist users in their task. We collected real-life smartphone usage data from 14 participants and investigated how to extract high-level intents from users' descriptions of their activities. Our experiments show that understanding high-level tasks allows the agent to actively suggest apps relevant to pursuing particular user goals and reduce the cost of users' self-management.\",\n",
              "  '\"Do Animals Have Accents?\": Talking with Agents in Multi-Party Conversation.[SEP]In this paper we unpack the use of conversational agents, or so-called intelligent personal assistants (IPAs), in multi-party conversation amongst a group of friends while they are socialising in a café. IPAs such as Siri or Google Now can be found on a large proportion of personal smartphones and tablets, and are promoted as \\'natural language\\' interfaces. The question we pursue here is how they are actually drawn upon in conversational practice? In our work we examine the use of these IPAs in a mundane and common-place setting and employ an ethnomethodological perspective to draw out the character of the IPA-use in conversation. Additionally, we highlight a number of nuanced practicalities of their use in multi-party settings. By providing a depiction of the nature and methodical practice of their use, we are able to contribute our findings to the design of IPAs.',\n",
              "  'Iris: A Conversational Agent for Complex Tasks.[SEP]Today, most conversational agents are limited to simple tasks supported by standalone commands, such as getting directions or scheduling an appointment. To support more complex tasks, agents must be able to generalize from and combine the commands they already understand. This paper presents a new approach to designing conversational agents inspired by linguistic theory, where agents can execute complex requests interactively by combining commands through nested conversations. We demonstrate this approach in Iris, an agent that can perform open-ended data science tasks such as lexical analysis and predictive modeling. To power Iris, we have created a domain-specific language that transforms Python functions into combinable automata and regulates their combinations through a type system. Running a user study to examine the strengths and limitations of our approach, we find that data scientists completed a modeling task 2.6 times faster with Iris than with Jupyter Notebook.'],\n",
              " '6_game_games_sports_play': [\"Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games.[SEP]Research on sexism in digital games has suggested that women self-select out of playing sexist games; however, assuming a homogenous gender-based response does not account for the diversity of identities within a gender group. Gender-incongruent responses to recent events like #gamergate implies that the gender of the participant is not paramount to experience, but that their beliefs about gender roles are. To explore the role of sexist beliefs on experience in sexist games, we created three versions of a game that were identical except for the presence of sexist imagery and/or dialogue. We show that enjoyment of sexist games is not predicted by player gender, but by the player's pre-existing beliefs about gender. Furthermore, avatar identification is the pathway through which enjoyment is facilitated. Finally, sexist dialogue does not improve the play experience for anyone rather it harms experience for players of all genders who do not hold sexist beliefs.\",\n",
              "  \"Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience.[SEP]Games user research (GUR) measures the performance and preference of digital game players, and interprets these measurements in the context of theories that explain human behavior. There are many validated approaches for measuring player experience that are grounded in psychological theories on motivation and emotion. Attribution theory explains how people assign causes to events and how these attributions affect peoples' emotional reactions and motivations. In this paper we argue that attribution theory can provide additional value to the existing suite of GUR tools; however, there are currently no validated tools to assess player attribution in the context of games. This paper describes the conceptualization of player attribution based on literature, presents the development and validation of a scale to assess player attribution in games, and discusses the implications of adding player attribution to the toolbox of methods for the design and evaluation of digital games.\",\n",
              "  \"Negative Emotion, Positive Experience?: Emotionally Moving Moments in Digital Games.[SEP]Emotions are key to the player experience (PX) and interest in the potential of games to provide unique emotional, sometimes uncomfortable experiences is growing. Yet there has been little empirical investigation of what game experiences players consider emotionally moving, their causes and effects, and whether players find these experiences rewarding at all. We analyzed 121 players' accounts of emotionally moving game experiences in terms of the feelings and thoughts they evoked, different PX constructs, as well as game-related and personal factors contributing to these. We found that most players enjoyed and appreciated experiencing negatively valenced emotions, such as sadness. Emotions were evoked by a variety of interactive and non-interactive game aspects, such as in-game loss, character attachment and (lack of) agency, but also personal memories, and were often accompanied by (self-)reflection. Our findings highlight the potential of games to provide emotionally rewarding and thought-provoking experiences, as well as outline opportunities for future research and design of such experiences. They also showcase that negative affect may contribute to enjoyment, thereby extending our notion of positive player experience.\",\n",
              "  'Exergame Training of Executive Function in Preschool Children: Generalizability and Long-term Effects.[SEP]Studies with older children and adults have found that physically engaging video games (i.e., Exergames) that promote both cognitive control and physical activity improve executive function (EF) skills; yet, children below school age remain understudied with regard to the impact of Exergames on EF. Additionally, research on the extent of the impact of Exergames resulting in prolonged changes, and whether training generalizes to EF-related behaviors in a real-world context remains scarce. This study examined the short- and long-term changes in EF of 4- to 5-year-olds after participation in two 20-minute Exergame sessions. Results indicate that Exergame training improved performance on EF tasks and resulted in higher teacher ratings of EF in the classroom compared to a sex-/classroom-/age-matched control group. The improvements in EF persisted over a one-month period. This study provides novel insights into the short-term and long-term effects of Exergame training on executive function in preschool-aged children.',\n",
              "  'Exploring  designing tools to enhance falls rehabilitation in the home.[SEP]Falls are the leading cause of accidental injury-related deaths in the elderly; a fall can lead to a loss of independence, and a fear of falling. Rehabilitation programmes involving exercise have proved the most successful way to reduce the risk of falls. However, the limitations of standard care (e.g. booklets) could prevent home users from receiving the full therapeutic benefit that rehabilitation offers. Having consulted users and health experts, we developed games, and visualizations for falls rehabilitation that we believe could potentially overcome the main barriers to effective rehabilitation in the home. In this paper, we describe user studies that we carried out with older adults to evaluate the use of these visual tools versus standard care, both in the laboratory and in the home. Our main findings show that our visualizations and games were able to overcome the major limitations of standard care, and that they were usable and acceptable to the end users.',\n",
              "  'Fitmersive Games: Fitness Gamification through Immersive VR.[SEP]The decreasing hardware cost makes it affordable to pair Immersive Virtual Environments (IVR) visors with treadmills and exercise bikes. In this paper, we discuss the application of different gamification techniques in IVR for supporting physical exercise. We describe both the hardware setting and the design of Rift-a-bike, a cycling fitmersive game (immersive games for fitness). We evaluate the effectiveness of such techniques through a user study, which provides different insights on their effectiveness in designing such applications.',\n",
              "  'Chalkboarding: A New Spatiotemporal Query Paradigm for Sports Play Retrieval.[SEP]The recent explosion of sports tracking data has dramatically increased the interest in effective data processing and access of sports plays (i.e., short trajectory sequences of players and the ball). And while there exist systems that offer improved categorizations of sports plays (e.g., into relatively coarse clusters), to the best of our knowledge there does not exist any retrieval system that can effectively search for the most relevant plays given a specific input query. One significant design challenge is how best to phrase queries for multi-agent spatiotemporal trajectories such as sports plays.We have developed a novel query paradigm and retrieval system, which we call Chalkboarding, that allows the user to issue queries by drawing a play of interest (similar to how coaches draw up plays). Our system utilizes effective alignment, templating, and hashing techniques tailored to multi-agent trajectories, and achieves accurate play retrieval at interactive speeds.We showcase the efficacy of our approach in a user study, where we demonstrate orders-of-magnitude improvements in search quality compared to baseline systems.',\n",
              "  'Baseball Timeline: Summarizing Baseball Plays Into a Static Visualization.[SEP]In sports, Play Diagrams are the standard way to represent and convey information. They are widely used by coaches, managers, journalists and fans in general. There are situations where diagrams may be hard to understand, for example, when several actions are packed in a certain region of the field or there are just too many actions to be transformed in a clear depiction of the play. The representation of how actions develop through time, in particular, may be hardly achieved on such diagrams. The time, and the relationship among the actions of the players through time, is critical on the depiction of complex plays. In this context, we present a study on how player actions may be clearly depicted on 2D diagrams. The study is focused on Baseball plays, a sport where diagrams are heavily used to summarize the actions of the players. We propose a new and simple approach to represent spatiotemporal information in the form of a timeline. We designed our visualization with a requirement driven approach, conducting interviews and fulfilling the needs of baseball experts and expert‐fans. We validate our approach by presenting a detailed analysis of baseball plays and conducting interviews with four domain experts.',\n",
              "  'Sports Tournament Predictions Using Direct Manipulation.[SEP]An advanced interface for sports tournament predictions uses direct manipulation to allow users to make nonlinear predictions. Unlike previous interface designs, the interface helps users focus on their prediction tasks by enabling them to first choose a winner and then fill out the rest of the bracket. In real-world tests of the proposed interface (for the 2014 FIFA World Cup tournament and 2015/2016 UEFA Champions League), the authors validated the use of direct manipulation as an alternative to widgets. Using visitor interaction logs, they were able to determine the strategies people use to perform predictions and identify potential areas of improvement for further prediction interfaces.',\n",
              "  'Usability Planner: A Tool to Support the Process of Selecting Usability Methods.[SEP]There is increasing pressure on developers to produce usable systems, which requires the use of appropriate methods to support user centred design during development. There is currently no consistent advice on which methods are appropriate in which circumstances, so the selection of methods relies on individual experience and expertise. Considerable effort is required to collate information from various sources and to understand the applicability of each method in a particular situation. Usability Planner is a tool aimed to support the selection of the most appropriate methods depending on project and organizational constraints. Many of the rules employed are derived from ISO standards, complemented with rules from the authors’ experience.',\n",
              "  'Usability Evaluation in a Digitally Emerging Country: A Survey Study.[SEP]Several emerging countries experience increasing software development activities. With the purpose of provide useful feedback on possible courses of action for increasing application of usability evaluation in such countries, this paper explores the status of usability evaluation in a digitally emerging country. Our aim is to identifying common characteristics or behavioral patterns that could be compared with digitally advanced countries. We used an online survey answered by 26 software development organizations, which gave a snapshot of the application of usability evaluation in these organizations. We found many similarities with advanced countries, several completely new obstacles more connected with software development matters and a relatively positive improvement in the lack of “usability culture”. These findings suggest good conditions to improve conduction of usability evaluations in digitally emerging countries.',\n",
              "  'Usability testing: what have we overlooked?[SEP]For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance. This paper provides evidence suggesting that the focus be shifted to task coverage instead. Our data analysis of nine commercial usability test teams participating in the CUE-4 study revealed no significant correlation between the percentage of problems found or of new problems and number of test users, but correlations of both variables and number of user tasks used by each usability team were significant. The role of participant recruitment on usability test performance and future research directions are discussed.'],\n",
              " '70_tracking_camera_tracker_pose': ['Projection Distortion-based Object Tracking in Shader Lamp Scenarios.[SEP]Shader lamp systems augment the real environment by projecting new textures on known target geometries. In dynamic scenes, object tracking maintains the illusion if the physical and virtual objects are well aligned. However, traditional trackers based on texture or contour information are often distracted by the projected content and tend to fail. In this paper, we present a model-based tracking strategy, which directly takes advantage from the projected content for pose estimation in a projector-camera system. An iterative pose estimation algorithm captures and exploits visible distortions caused by object movements. In a closed-loop, the corrected pose allows the update of the projection for the subsequent frame. Synthetic frames simulating the projection on the model are rendered and an optical flow-based method minimizes the difference between edges of the rendered and the camera image. Since the thresholds automatically adapt to the synthetic image, a complicated radiometric calibration can be avoided. The pixel-wise linear optimization is designed to be easily implemented on the GPU. Our approach can be combined with a regular contour-based tracker and is transferable to other problems, like the estimation of the extrinsic pose between projector and camera. We evaluate our procedure with real and synthetic images and obtain very precise registration results.',\n",
              "  \"Spatio-Temporal Point Path Analysis and Optimization of a Galvanoscopic Scanning Laser Projector.[SEP]Galvanoscopic scanning laser projectors are powerful vector graphic devices offering a tremendous local brightness advantage compared to standard video projection systems. However, such devices have inherent problems, such as temporal flicker and spatially inaccurate rendering. We propose a method to generate an accurate point-based projection with such devices. To overcome the mentioned problems, we present a camera-based method to automatically analyze the laser projector's motion behavior. With this information, a model database is generated that is used to optimize the scanning path of projected point sequences. The optimization considers the overall path length, its angular shape, acceleration behavior, and the spatio-temporal point neighborhood. The method minimizes perceived visual flickering while guaranteeing an accurate spatial point projection at the same time. Comparisons and timing measurements prove the effectiveness of our method. An informal user evaluation shows substantial visual quality improvement as well.\",\n",
              "  'Robust upright adjustment of 360 spherical panoramas.[SEP]With the recent advent of 360 cameras, spherical panorama images are becoming more popular and widely available. In a spherical panorama, alignment of the scene orientation to the image axes is important for providing comfortable and pleasant viewing experiences using VR headsets and traditional displays. This paper presents an automatic method for upright adjustment of 360 spherical panorama images without any prior information, such as depths and gyro sensor data. We take the Atlanta world assumption and use the horizontal and vertical lines in the scene to formulate a cost function for upright adjustment. In addition to fast optimization of the cost function, our method includes outlier handling to improve the robustness and accuracy of upright adjustment. Our method produces visually pleasing results for a variety of real-world spherical panoramas in less than a second, and the accuracy is verified using ground-truth data.',\n",
              "  'Coupled-layer based visual tracking via adaptive kernelized correlation filters.[SEP]Part-based visual model is particularly useful when the target appearance undergoes partial occlusion or deformation. The existing reliable patches tracking (RPT) method has achieved better result by identifying and exploiting the reliable patches that can be tracked correctly, yet it tends to fail in some challenging scenes since it ignores the holistic information of target completely, while, in fact, the target’s holistic appearance provides more discriminative features than local patches with low resolution. Based on the existing RPT and kernelized correlation filters tracking method, in this paper, we propose a coupled-layer visual model based tracker by combining the target’s global and local appearance in a coupled way. The global layer provides the holistic information and is treated as an approximation of the target. The local layer is composed of multiple small patches that are randomly initialized in the first frame. During tracking, the global tracker detects the target itself; its detection result is employed in the local layer to exploit the reliable patches and to estimate the target position corresponding to each patch. The exploited reliable patches are employed to estimate the target scale and to vote the current target location. Finally, both global and local models are updated with carefully designed updating mechanisms. Experiments conducted on 80 challenging benchmark sequences clearly show that our tracker improves the RPT tracker significantly both in overall and individual performance yet without obvious speed cost. Also, our tracker outperforms all the state-of-the-art trackers in overall datasets and eight independent datasets.',\n",
              "  'Object tracking by color distribution fields with adaptive hierarchical structure.[SEP]The essence of visual tracking is to distinguish the target from background, so how to describe the difference between target and background is a key problem. In this paper, tracking algorithm by color distribution fields with adaptive hierarchical structure is presented to solve this problem. First, multichannel color distribution fields are presented for appearance modeling, which represents color distinction between the target and background. Second, in order to adapt to the individuality of each target, the hierarchical structure of its color distribution fields are generated via k-means cluster. Third, weighted multichannel 𝐿1L1 distance is used to measure the similarity between the candidate region and the template; the weight of each channel is adjusted online according to its discrimination. Finally, a search strategy based on simulated annealing is proposed to improve the search efficiency and reduce the probability of falling into the local optimum. Experimental results demonstrate that the proposed algorithm outperforms the state-of-the-art tracking algorithms.',\n",
              "  'An improved correlation filter tracking method with occlusion and drift handling.[SEP]Despite remarkable progress, visual object tracking is still a challenging task as objects usually suffer from significant appearance changes, fast motion, and serious occlusion. In this paper, we propose a correlation filter-based tracking method with reliability evaluation and re-detection mechanism (CF-RERM) to deal with drift and occlusion problems. We first propose a criterion that uses the fluctuation trend of the response values, the displacement difference of the object, and the peak-to-sidelobe ratio to comprehensively evaluate the reliability of the tracking process. Then, a re-detection mechanism with a two-stage screening strategy is proposed for implementing the re-detection task when the criterion is triggered. Experimental results show that our method has achieved considerable performance in terms of accuracy and success rate on widely used OTB-50, OTB-100 and Temple-Color-128 tracking benchmark dataset. In addition, CF-RERM is able to achieve real-time tracking speed.',\n",
              "  'A Backmapping Approach for Graph-Based Object Tracking.[SEP]Model-based methods play a central role to solve different problems in computer vision. A particular important class of such methods rely on graph models where an object is decomposed into a number of parts, each one being represented by a graph vertex. A graph model-based tracking algorithm has been recently introduced in which a model is generated for a given frame (reference frame) and used to track a target object in the subsequent ones. Because the view of an object changes along the video sequence, the solution updated the model using affine transformations. This paper proposes a different approach and improves the previous one in several ways. Firstly, instead of updating the model, each analyzed frame is backmapped to the model space, thus providing more robustness to the method because model parameters do not have to be modified. A different method for model generation based on user traces has also been implemented and used. This model generation approach is much simpler and user-friendly. Finally, a graph-matching algorithm that has been recently proposed is used for object tracking. This new algorithm is more efficient and leads to better matching results. Experimental results using synthetic and real sequences from the CAVIAR project are shown and discussed.',\n",
              "  'Automatic Detection of 2D Human Postures Based on Single Images.[SEP]Estimating human pose in static images is a challenging task due to the high dimensional state space, presence of image clutter and ambiguities of image observations. In this paper we propose a method to automatically detect human poses in a single image, based on a 2D model combined with anthropometric data. Furthermore, we use artificial neural networks to detect high level information about the human posture. Experimental results showed that the proposed technique performs well in non trivial images.',\n",
              "  'Robust motion flow for mesh tracking of freely moving actors.[SEP]4D multi-view reconstruction of moving actors has many applications in the entertainment industry and although studios providing such services become more accessible, efforts have to be done in order to improve the underlying technology to produce high-quality 4D contents. In this paper, we present a method to derive a time-evolving surface representation from a sequence of binary volumetric data representing an arbitrary motion in order to introduce coherence in the data. The context is provided by an indoor multi-camera system which performs synchronized video captures from multiple viewpoints in a chroma-key studio. Our input is given by a volumetric silhouette-based reconstruction algorithm that generates a visual hull at each frame of the video sequence. These 3D volumetric models lack temporal coherence, in terms of structure and topology, as each frame is generated independently. This prevents an easy post-production editing with 3D animation tools. Our goal is to transform this input sequence of independent 3D volumes into a single dynamic structure, directly usable in post-production. Our approach is based on a motion estimation procedure. An unsigned distance function on the volumes is used as the main shape descriptor and a 3D surface matching algorithm minimizes the interference between unrelated surface regions. Experimental results, tested on our multi-view datasets, show that our method outperforms other approaches based on optical flow when considering robustness over several frames.'],\n",
              " '71_shadow_shadows_light_rendering': ['ShadowPix: Multiple Images from Self Shadowing.[SEP]ShadowPixare white surfaces that display several prescribed images formed by the self‐shadowing of the surface when lit from certain directions. The effect is surprising and not commonly seen in the real world. We present algorithms for constructing ShadowPixthat allow up to four images to be embedded in a single surface. ShadowPixcan produce a variety of unusual effects depending on the embedded images: moving the light can animate or relight the object in the image, or three colored lights may be used to produce a single colored image. ShadowPixare easy to manufacture using a 3D printer and we present photographs, videos, and renderings demonstrating these effects.',\n",
              "  'Exponential shadow maps.[SEP]Rendering high-quality shadows in real-time is a challenging problem. Shadow mapping has proved to be an efficient solution, as it scales well for complex scenes. However, it suffers from aliasing problems. Filtering the shadow map alleviates aliasing, but unfortunately, native hardware-accelerated filtering cannot be applied, as the shadow test has to take place beforehand.',\n",
              "  \"Generating soft shadows with a depth buffer algorithm.[SEP]A pragmatic approach is taken to develop an algorithm that combines an existing shadowing method with a popular visible surface rendering technique, called a depth buffer, to generate soft shadows resulting from light sources of finite extent. The method extends F. Crow's shadow volume algorithm (1977) to produce multiple shadows overlapped to yield the characteristic soft edges of a shadow penumbra.\"],\n",
              " '72_narrative_story_stories_storytelling': ['SceneSkim: Searching and Browsing Movies Using Synchronized Captions, Scripts and Plot Summaries.[SEP]Searching for scenes in movies is a time-consuming but crucial task for film studies scholars, film professionals, and new media artists. In pilot interviews we have found that such users search for a wide variety of clips---e.g., actions, props, dialogue phrases, character performances, locations---and they return to particular scenes they have seen in the past. Today, these users find relevant clips by watching the entire movie, scrubbing the video timeline, or navigating via DVD chapter menus. Increasingly, users can also index films through transcripts---however, dialogue often lacks visual context, character names, and high level event descriptions. We introduce SceneSkim, a tool for searching and browsing movies using synchronized captions, scripts and plot summaries. Our interface integrates information from such sources to allow expressive search at several levels of granularity: Captions provide access to accurate dialogue, scripts describe shot-by-shot actions and settings, and plot summaries contain high-level event descriptions. We propose new algorithms for finding word-level caption to script alignments, parsing text scripts, and aligning plot summaries to scripts. Film studies graduate students evaluating SceneSkim expressed enthusiasm about the usability of the proposed system for their research and teaching.',\n",
              "  'CSIUI 2009: story understanding and generation for aware and interactive interface design.[SEP]In order to be helpful to people, the intelligent interfaces of the future will have to acquire, represent, and infer simple knowledge about everyday life and activities. While much work in AI has represented this knowledge at the word, sentence, and logical assertion level, we see a growing need to understand it at a larger granularity, that of stories.',\n",
              "  \"Declarative Optimization-Based Drama Management in Interactive Fiction.[SEP]Our work relates to automatically guiding experiences in large, open-world interactive dramas and story-based experiences where a player interacts with and influences a story. A drama manager (DM) is a system that watches a story as it progresses, reconfiguring the world to fulfill the author's goals. A DM might notice a player doing something that fits poorly with the current story and attempt to dissuade him or her. This is accomplished using soft actions such as having a nonplayer character start a conversation with a player to lure him or her to something else, or by more direct actions such as locking doors. We present work applying search-based drama management (SBDM) to the interactive fiction piece Anchorhead, to further investigate the algorithmic and authorship issues involved. Declarative optimization-based drama management (DODM) guides the player by projecting possible future stories and reconfiguring the story world based on those projections. This approach models stories as a set of possible plot points, and an author-specified evaluation function rates the quality of a particular plot-point sequence\",\n",
              "  'More Than Telling a Story: Transforming Data into Visually Shared Stories.[SEP]The authors take a closer look at how the visualization community has discussed visual storytelling and present a visual data storytelling process, incorporating steps involved in finding insights (explore data), turning these insights into a narrative (make a story), and communicating this narrative to an audience (tell a story). They also discuss opportunities for future research in visualization as a storytelling medium in the light of this broader process.',\n",
              "  'Formalizing Analytical Discourse in Visual Analytics.[SEP]This paper presents a theory of analytical discourse and a formal model of the intentional structure of visual analytic reasoning process. Our model rests on the theory of collaborative discourse, and allows for cooperative human-machine communication in visual interactive dialogues. Using a sample discourse from a crisis management scenario, we demonstrated the utility of our theory in characterizing the discourse context and collaboration. In particular, we view analytical discourse as plans consisting of complex mental attitude towards analytical tasks and issues. Under this view, human reasoning and computational analysis become integral part of the collaborative plan that evolves through discourse.',\n",
              "  \"A Deeper Understanding of Sequence in Narrative Visualization.[SEP]Conveying a narrative with visualizations often requires choosing an order in which to present visualizations. While evidence exists that narrative sequencing in traditional stories can affect comprehension and memory, little is known about how sequencing choices affect narrative visualization. We consider the forms and reactions to sequencing in narrative visualization presentations to provide a deeper understanding with a focus on linear, 'slideshow-style' presentations. We conduct a qualitative analysis of 42 professional narrative visualizations to gain empirical knowledge on the forms that structure and sequence take. Based on the results of this study we propose a graph-driven approach for automatically identifying effective sequences in a set of visualizations to be presented linearly. Our approach identifies possible transitions in a visualization set and prioritizes local (visualization-to-visualization) transitions based on an objective function that minimizes the cost of transitions from the audience perspective. We conduct two studies to validate this function. We also expand the approach with additional knowledge of user preferences for different types of local transitions and the effects of global sequencing strategies on memory, preference, and comprehension. Our results include a relative ranking of types of visualization transitions by the audience perspective and support for memory and subjective rating benefits of visualization sequences that use parallelism as a structural device. We discuss how these insights can guide the design of narrative visualization and systems that support optimization of visualization sequence.\"],\n",
              " '73_authentication_passwords_password_security': [\"Do Users' Perceptions of Password Security Match Reality?[SEP]Although many users create predictable passwords, the extent to which users realize these passwords are predictable is not well understood. We investigate the relationship between users' perceptions of the strength of specific passwords and their actual strength. In this 165-participant online study, we ask participants to rate the comparative security of carefully juxtaposed pairs of passwords, as well as the security and memorability of both existing passwords and common password-creation strategies. Participants had serious misconceptions about the impact of basing passwords on common phrases and including digits and keyboard patterns in passwords. However, in most other cases, participants' perceptions of what characteristics make a password secure were consistent with the performance of current password-cracking tools. We find large variance in participants' understanding of how passwords may be attacked, potentially explaining why users nonetheless make predictable passwords. We conclude with design directions for helping users make better passwords.\",\n",
              "  'Age-related performance issues for PIN and face-based authentication systems.[SEP]Graphical authentication systems typically claim to be more usable than PIN or password-based systems, but these claims often follow limited, single-stage paradigm testing on a young, student population. We present a more demanding test paradigm in which multiple codes are learned and tested over a three-week period. We use this paradigm with two user populations, comparing the performance of younger and older adults. We first establish baseline performance in a study in which populations of younger and older adults learn PIN codes and we follow this with a second study in which younger and older adults use two face-based graphical authentication systems employing young faces vs. old faces as code components. As expected, older adults show relatively poor performance when compared to younger adults, irrespective of the authentication material, but this age-related deficit can be markedly reduced by the introduction of age-appropriate faces. We conclude firstly that this paradigm provides a good basis for the future evaluation of memory-based authentication systems and secondly that age-appropriate face-based authentication is viable in the security marketplace.',\n",
              "  'EpisoDAS: DAS-based password generation using episodic memories.[SEP]We introduce a simple and powerful visual interaction technique for managing strong passwords. Passwords have been used for authentication for decades, but appropriate handling of passwords is difficult because people can easily forget passwords and they can be easily attacked. Better authentication methods have been investigated, and various visual interaction methods have been proposed, including the DAS (draw-a-secret) method. Using DAS, users can log into a service just by drawing a secret pattern on the screen, but remembering complex secret patterns is as difficult as remembering passwords. We developed EpisoDAS, with which users can generate strong passwords based on their secret episodic memories with a simple DAS interface. A user can draw a secret pattern and generate a password, based on their secret episodic memories that they cannot easily forget.'],\n",
              " '74_students_math_solving_achievement': ['Patterns of anxiety in algebraic problem solving in Australian adolescents: A three-step latent variable analysis.[SEP]Adolescents’ math anxiety is commonly assessed using questionnaires that identified the anxiety experienced solving arithmetic problems. A more nuanced understanding of math anxiety would be gained by investigating anxiety associated with math problems encountered in school at the time they are encountered. To this end, we investigated the anxiety associated with algebraic problem solving ability relationships in 129 14-year-olds. We varied problem difficulty and the time allowed to solve problems, and assessed students’ anxiety concurrently as they solved problems. Latent variable mixture modelling revealed meaningfully different patterns of algebra ability and anxiety relationships that changed as a function of problem difficulty and time pressure. A second study, examining 257 13- to 15-year-olds, successfully replicated the Study 1 findings. The results highlight the value of using latent variable analysis to identify subgroup patterns of abilities and caution against making overly general claims about the role of anxiety in math problem solving.',\n",
              "  'Problem-Solving Strategy Selection in Relation to Formal Schooling.[SEP]A study of the literacy-generated cognitive cultural gap was carried out on subjects of different literacy background ranging from illiterate individuals to university students in different majors. The characteristics that aid literate and illiterate people in solving mathematical problems efficiently were identified and analyzed. A field research was carried out in the field of algorithmic problem solving and in the reasoning domain, followed by constructing a software cognitive model to represent the findings. Findings showed that in both domains cognitive ability did not improve with level of literacy, rather the formality of the problem solving strategy selected demonstrating a link between these two domains.',\n",
              "  \"Study on Facilitation of Problem Posing by Learning Examples through Reproduction.[SEP]In general education, learning of production tasks is important but difficult due to it requires heavy cognitive activities such as generation of ideas and synthesis of structures. We proposed a method to facilitate a production task of mathematical problem posing through learning by reproducing examples. In the proposed method, learners learn essential ideas by reproducing examples based on process information indicating how to compose them. We then conducted an experimental investigation where undergraduate students posed their own problems after learning an example by reproducing or solving it. Our previous study had confirmed that undergraduate students without learning of any examples posed many problems that had simple and inappropriate solution structures. In this study, undergraduate students who learned by reproducing the example posed many complex problems, whereas those who learned by solving it didn't do. This proved that learning of ideas for a production task is more effective when it's done through a productive activity.\",\n",
              "  'Improving First-Year Writing Using Argument Diagramming.[SEP]There is substantial evidence from many domains that visual representations aid various forms of cognition. We aimed to determine whether learning to construct visual representations of argument structure enhanced the acquisition and development of argumentative writing skills within the context of first-year college writing course. We found a significant effect of the use of argument diagrams, and this effect was stable even when multiple plausible correlates were controlled for. These results suggest that natural⎯and relatively minor⎯modifications to standard first-year composition courses could provide substantial increases in student writing ability.',\n",
              "  \"Are Teachers Aware of Students' Lack of Spontaneity in Diagram Use? Suggestions from a Mathematical Model-Based Analysis of Teachers' Predictions.[SEP]Although many studies have shown that diagrams are effective tools for problem solving, research evidence shows that students do not always use diagrams effectively. One of the most serious problems is their lack of spontaneity in diagram use. However, no previous studies have examined whether teachers are adequately aware of this problem. In this investigation, data were gathered on students’ mathematics performance (including their spontaneous use of diagrams) and teachers’ predictions of the students’ performance. Using a mathematical model (Uesaka & Nakagawa, 2010) to analyze the data, it was found that the parameter representing the accuracy of teachers’ prediction was lower for their assessment of spontaneous diagram use compared to other mathematical tasks. This suggests that spontaneity in diagram use is an overlooked aspect in teachers’ view of student performance.\",\n",
              "  'The Effect of Graphical Format and Instruction on the Interpretation of Three-Variable Bar and Line Graphs.[SEP]We present a study that investigates how graph format and training can affect undergraduate psychology students’ ability to interpret three-variable bar and line graphs. A pre and post-test design was employed to assess 76 students’ conceptual understanding of three-variable graphs prior to and after a training intervention. The study revealed that significant differences in interpretation are produced by graph format prior to training; bar graph users outperform line graph users. Training also resulted in a statistically significant improvement in interpretation of both graph formats with effect sizes confirming the intervention resulted in substantial learning gains in graph interpretation. This resulted in bar graph users outperforming line graph users pre and post training making it the superior format even when training has occurred. The effect of graph format and training differed depending on task demands. Based on the results of this experiment, it is argued that undergraduate students’ interpretations of such three-variable data are more accurate when using the bar form. Findings also demonstrate how a brief tutorial can result in large gains in graph comprehension scores. We provide a test which can be used to assess students understanding of three-variable graphs and the tutorial developed for the study for educators to use.'],\n",
              " '75_health_patients_self_online': ['Data, Data Everywhere, and Still Too Hard to Link: Insights from User Interactions with Diabetes Apps.[SEP]For those with chronic conditions, such as Type 1 diabetes, smartphone apps offer the promise of an affordable, convenient, and personalized disease management tool. However, despite significant academic research and commercial development in this area, diabetes apps still show low adoption rates and underwhelming clinical outcomes. Through user-interaction sessions with 16 people with Type 1 diabetes, we provide evidence that commonly used interfaces for diabetes self-management apps, while providing certain benefits, can fail to explicitly address the cognitive and emotional requirements of users. From analysis of these sessions with eight such user interface designs, we report on user requirements, as well as interface benefits, limitations, and then discuss the implications of these findings. Finally, with the goal of improving these apps, we identify 3 questions for designers, and review for each in turn: current shortcomings, relevant approaches, exposed challenges, and potential solutions.',\n",
              "  \"Designing Self-tracking Devices for Vulnerable Chronic Ill.[SEP]In my thesis, I take departure in a view on illness perception in design as found in the biopsychosocial (BPS) model. I expect that an equal focus on biological, psychological and social dimensions of illness will successfully assist the design of self-tracking devices. My thesis focusses on vulnerable patients with diabetes or prostate cancer. The objective is to improve patient wellbeing by making self-reflection accessible through the use of personal devices for self-tracking. The self-tracking devices and its surrounding system will be collaboratively developed with the participating patients. This collaboration is done to make sure that the patients lived experiences inform the design of the devices. The system will support communication in treatment between the patient, professional and relatives. Key challenges are in designing for vulnerable. How to create devices that respect patient's everyday life and how to bring the patient in control of self-tracked data, that is shared to others.\",\n",
              "  \"Findings of e-ESAS: a mobile based symptom monitoring system for breast cancer patients in rural Bangladesh.[SEP]Breast cancer (BC) patients need traditional treatment as well as long term monitoring through an adaptive feedback-oriented treatment mechanism. Here, we present the findings of our 31-week long field study and deployment of e-ESAS - the first mobile-based remote symptom monitoring system (RSMS) developed for rural BC patients where patients are the prime users rather than just the source of data collection at some point of time. We have also shown how 'motivation' and 'automation' have been integrated in e-ESAS and creating a unique motivation-persuasion-motivation cycle where the motivated patients become proactive change agents by persuading others. Though in its early deployment stages (2 months), e-ESAS demonstrates the potential to positively impact the cancer care by (1) helping the doctors with graphical charts of long symptom history (automation), (2) facilitating timely interventions through alert generation (automation) and (3) improving three way communications (doctor-patient-attendant) for a better decision making process (motivation) and thereby improving the quality of life of BC patients.\",\n",
              "  'A Sociotechnical Mechanism for Online Support Provision.[SEP]Social support can significantly improve health outcomes for individuals living with disease, and online forums have emerged as an important vehicle for social support. Whereas research has focused on the delivery and use of social support, little is known about how these communities are sustained. We describe one sociotechnical mechanism that enables sustainable communities to provide social support to a large number of people. We focus upon thirteen disease-specific discussion forums hosted by the WebMD online health community. In these forums, small, densely connected cores of members who maintain strong relationships generate the majority of support for others. Through content analysis we find they provide informational support to a large number of more itinerant members, but provide one another with community support. Based on these observations, we describe a sociotechnical mechanism of online support that is distinct from non-support oriented communities, and has implications for the design of self-sustaining online support systems.',\n",
              "  \"Forum77: An Analysis of an Online Health Forum Dedicated to Addiction Recovery.[SEP]Prescription drug abuse is a pressing public health issue, and people who misuse prescription drugs are turning to online forums for help. Are such forums effective? We analyze the process of opioid withdrawal, recovery and relapse on Forum77, MedHelp.org's online health forum for substance abuse recovery. Applying Prochashka's Transtheoretical Model for behavior change, we develop a taxonomy describing phases of addiction expressed by Forum77 members. We examine activity and linguistic features across the phases USING, WITHDRAWING and RECOVERING. We train statistical classifiers to identify addiction phase, relapse and whether a user was RECOVERING at the time of her last post. Applying our classifiers to 2,848 users, we find that while almost 50% relapse, the prognosis for ending in RECOVERING is favorable. Supplementing our results with users' own accounts of their experiences, we discuss Forum77's efficacy and shortcomings, and implications for future technologies.\",\n",
              "  'HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers.[SEP]To address the needs of cancer patients and their caregivers, Microsoft Research and the Fred Hutchinson Cancer Research Center developed HutchWorld, an online community environment, to provide computer-mediated social and informational support. In a controlled clinical study, we deployed HutchWorld to bone marrow transplant patients and their caregivers and assessed the impact of Internet access and HutchWorld on their quality of life. We found that Internet access and the use of HutchWorld helped to buffer study participants against reductions in life satisfaction and social support following the transplant procedure. In particular, participants used the Internet to seek out support from family and friends'],\n",
              " '76_route_map_navigation_wayfinding': ['How Spatial Ability and Stress Impact Escape Path.[SEP]Individual differences and situational factors can both affect how and how well one navigates. This study examined the effects of stress and spatial ability, measured as mental rotation ability, on navigation during an emergency situation. Participants learned a virtual mall environment and were subsequently either told to meet a friend at the far exit (control) or to use the far exit to escape a fire. In an emergency, participants made an initial movement faster, made more errors during navigation, and overestimated the amount of time they took to exit relative to controls. Relative to controls, emergency low spatial participants more often reversed a learned path to exit the mall, whereas high spatial participants more often directly used a previously learned path. The results illustrate that stress from an emergency situation negatively impacts navigation, and that the behavioral consequences of this are in part dependent upon one’s spatial abilities.',\n",
              "  'Constraints, Inferences, and the Shortest Path: Which paths do we prefer?[SEP]How do we reason about incomplete spatio-temporal descriptions? How might a map influence formerly constructed preferred mental models? Little research so far focused on a combination of two central fields important for successful route planning: the way humans deal with constraint based reasoning (especially with some sort of spatio-temporal constraints) and the way in which humans plan with a given map (especially with problems inspired by typical Traveling Salesman Problems). This, however, becomes even more interesting in cases in which the spatio-temporal constraints allow for several solutions. Do the predictions of the preferred mental model theory still hold true in such situations? This article investigates the influence of maps on the generation of preferred models. The goal is to bring together the theory of (preferred) mental models and route planning.',\n",
              "  'The influence of structural salience and verbalisation on finding the return path.[SEP]Are some landmark positions at intersections better for finding a return path than others? This study investigated whether there is a variation in the influence of a landmark on performance and decision times when finding a return path depending on its position at an intersection. A variation of this influence is expected depending on the type of verbalisation of spatial directions used. First, participants learned a path either with direction specific (turn left at or turn right at) or direction unspecific material (turn into direction of or turn in the opposite direction of). In this path the positions of the landmarks were varied systematically. Secondly, participants had to find the return path of the learned route and their third task was to write down verbal route descriptions. An effect of the landmark position on finding the return path can be suggested, although it was barely insignificant, for direction specific and direction unspecific material. A significant influence on the accuracy of the information in the route descriptions depending on the position of a landmark and on the specificity of the spatial directions could be shown. The results are discussed in the context of current wayfinding and landmark research.',\n",
              "  'COPERNICUS: Context-Preserving Engine for Route Navigation with Interactive User-modifiable Scaling.[SEP]In this paper, we present an automated system for generating context‐preserving route maps that depict navigation routes as a path between nodes and edges inside a topographic network. Our application identifies relevant context information to support navigation and orientation, and generates customizable route maps according to design principles that communicate all relevant context information clearly visible on one single page. Interactive scaling allows seamless transition between the original undistorted map and our new map design, and supports user‐specified scaling of regions of interest to create personalized driving directions according to the drivers needs.',\n",
              "  'Drawing Road Networks with Focus Regions.[SEP]Mobile users of maps typically need detailed information about their surroundings plus some context information about remote places. In order to avoid that the map partly gets too dense, cartographers have designed mapping functions that enlarge a user-defined focus region - such functions are sometimes called fish-eye projections. The extra map space occupied by the enlarged focus region is compensated by distorting other parts of the map. We argue that, in a map showing a network of roads relevant to the user, distortion should preferably take place in those areas where the network is sparse. Therefore, we do not apply a predefined mapping function. Instead, we consider the road network as a graph whose edges are the road segments. We compute a new spatial mapping with a graph-based optimization approach, minimizing the square sum of distortions at edges. Our optimization method is based on a convex quadratic program (CQP); CQPs can be solved in polynomial time. Important requirements on the output map are expressed as linear inequalities. In particular, we show how to forbid edge crossings. We have implemented our method in a prototype tool. For instances of different sizes, our method generated output maps that were far less distorted than those generated with a predefined fish-eye projection. Future work is needed to automate the selection of roads relevant to the user. Furthermore, we aim at fast heuristics for application in real-time systems.',\n",
              "  'Designing and Annotating Metro Maps with Loop Lines.[SEP]Schematic metro maps provide an effective means of simplifying the geographical configuration of public rapid transportation systems. Nonetheless, travelers still find it difficult to identify routes of a specific topology on the maps because it is usually hidden behind the conventional octilinear layout of the entire map. In this paper, we present an approach to designing schematic maps with loop lines, which are drawn as circles together with annotation labels for guiding different traveling purposes. Our idea here is to formulate the aesthetic criteria as mathematical constraints in the mixed-integer programming model, which allows us to either align stations on the loop line at a grid if they are interchange stations or noninterchange stations on a circle otherwise. We then distribute the annotation labels associated with stations on the loop line evenly to the four side boundary of the map domain in order to make full use of the annotation space, while maximally avoiding intersections between leader lines and the metro network by employing a flow network algorithm. Finally, we present several experimental results generated by our prototype system to demonstrate the feasibility of the proposed approach.'],\n",
              " '77_gene_genome_genomic_visualization': ['Visualizing virus population variability from next generation sequencing data.[SEP]Advances in genomic sequencing techniques allow for larger scale generation and usage of sequence data. While these techniques afford new types of analysis, they also generate new concerns with regards to data quality and data scale. We present a tool designed to assist in the exploration of the genetic variability of the population of viruses at multiple time points and in multiple individuals, a task that necessitates considering large amounts of sequence data and the quality issues inherent in obtaining such data in a practical manner. Our design affords the examination of the amount of variability and mutation at each position in the genome for many populations of viruses. Our design contains novel visualization techniques that support this specific class of analysis while addressing the issues of data aggregation, confidence visualization, and interaction support that arise when making use of large amounts of sequence data with variable uncertainty. These techniques generalize to a wide class of visualization problems where confidence is not known a priori, and aggregation in multiple directions is necessary.',\n",
              "  'Interactive visual support for metagenomic contig binning.[SEP]Within metagenomics, \"Contig Binning\" is an important step in the process of reconstructing genomes of species in mixed cultures and environmental samples. We present an interactive visual environment which enables a biologist to statistically analyze the multiple dimensions of data that are typically used during binning, and integrate and compare the results of various binning methods. Our system features a web-based parallel coordinate visualization at the front end and a R server back end for analysis and semi-supervised clustering of contig data.',\n",
              "  'Visual analysis of next-generation sequencing data to detect overlapping genes in bacterial genomes.[SEP]Next generation sequencing (NGS) technologies are about to revolutionize biological research. Being able to sequence large amounts of DNA or, indirectly, RNA sequences in a short time period opens numerous new possibilities. However, analyzing the large amounts of data generated in NGS is a serious challenge, which requires novel data analysis and visualization methods to allow the biological experimenter to understand the results. In this paper, we describe a novel system to deal with the flood of data generated by transcriptome sequencing (RNA-seq) using NGS. Our system allows the analyzer to get a quick overview of the data and interactively explore interesting regions based on the three important parameters coverage, transcription, and fit. In particular, our system supports the NGS analysis in the following respects: (1) Representation of the coverage sequence in a way that no artifacts are introduced. (2) Easy determination of a fit of an open reading frame (ORF) to a transcript by mapping the coverage sequence directly into the ORF representation. (3) Providing automatic support for finding interesting regions to address the problems that the overwhelming volume of data comes with. (4) Providing an overview representation that allows parameter tuning and enables quick access to interesting areas of the genome. We show the usefulness of our system by a case study in the area of overlapping gene detection in a bacterial genome.'],\n",
              " '78_image_smoothing_denoising_inpainting': ['Two-level joint local laplacian texture filtering.[SEP]Extracting the structure component from an image with textures is a challenging problem. This paper presents a novel structure-preserving texture-filtering approach based on the two-level local Laplacian filter. The new texture-filtering method is developed by introducing local Laplacian filters into the joint filtering. Our study shows that local Laplacian filters can also be used for texture smoothing by defining a special remapping function, which is closely related to joint bilateral filtering. This finding leads to a variant of the joint bilateral filter, which produces smooth edges while preserving color variations. Our filter shares similar advantages with the joint bilateral filter, such as being simple to implement and easy to understand. Experiments demonstrate that the new filter can produce satisfactory filtering results with the properties of texture smoothing, smooth edges, and edge shape preserving. We compare our method with the state-of-the-art methods to demonstrate its improvements, and apply this filter to a variety of image-editing applications.',\n",
              "  'Non-blind deblurring of structured images with geometric deformation.[SEP]Non-blind deconvolution, which is to restore a sharp version of a given blurred image when the blur kernel is known, is a fundamental step in image deblurring. While the problem has been extensively studied, existing methods have conveniently ignored an important fact that deformation can significantly affect the statistical characteristics of an image and introduce additional blurring effect. In this paper, we show how to enhance non-blind deconvolution by recovering and undoing the deformation while deconvolving a given blurred image. We show that this is the case for almost all popular regularizers that have been proposed for image deblurring such as total variation and its variants. We conduct extensive simulations and experiments on real images and verify that the incorporation of geometric deformation in deconvolution can significantly improve the final deblurring results. Combined with existing blur kernel estimation techniques, our method can also be used to enhance blind image deblurring.',\n",
              "  'Fast high-quality non-blind deconvolution using sparse adaptive priors.[SEP]We present an efficient approach for high-quality non-blind deconvolution based on the use of sparse adaptive priors. Its regularization term enforces preservation of strong edges while removing noise. We model the image-prior deconvolution problem as a linear system, which is solved in the frequency domain. This clean formulation lends to a simple and efficient implementation. We demonstrate its effectiveness by performing an extensive comparison with existing non-blind deconvolution methods, and by using it to deblur photographs degraded by camera shake. Our experiments show that our solution is faster and its results tend to have higher peak signal-to-noise ratio than the state-of-the-art techniques. Thus, it provides an attractive alternative to perform high-quality non-blind deconvolution of large images, as well as to be used as the final step of blind-deconvolution algorithms.'],\n",
              " '79_construction_visualisation_building_heritage': ['Visual analysis method for cultural heritage site risk assessment.[SEP]Many significant cultural heritage sites are at risk caused by natural environment. A unique type of natural risk to heritage sites is deterioration risk. Conservators and managers of heritage sites are attempting to develop a risk management approach to reduce this type of risk. Risk assessment is the essential component part of risk management process. However, it is hindered by several challenges resulting from the complexity of deterioration risk. We propose the use of visual analysis method for deterioration risk assessment focusing on matching the major needs and objectives of deterioration risk analysis. Our purpose is to facilitate risk analysis which consists of perceiving risk as basis, risk level estimate, and risk cause analysis. A spatial view of deterioration risk is designed for the discovery of distribution patterns. Based on clustering technique, we propose a visual analytics method for risk level analysis. Lastly, the proposed multidimensional data analysis technique is used to detect the causes of deterioration risks.',\n",
              "  \"Applying 3D Dynamic Visualisation to (Palaeo) Geomorphic Reconstruction: Modelling a Tenth Century J[SEP]At Sólheimajökull glacier in southern Iceland, field evidence has been collected of a Tenth Century jökulhlaup (or glacial outburst flood). It was an exceptional event in terms of generation, scale, magnitude and geomorphic impact. Although now fragmented and piecemeal, many of its direct (and indirect) geomorphological and sedimentary markers have been identified, mapped and dated to unravel the sequence of events played out during this significant episode in the glacial history. 'VolcVis', an innovative, customised visualisation platform using computer gaming technology is developed and applied for the first time in coalescing and displaying field results from Sólheimajökull, creating an interactive, multi-perspective, three-dimensional (3D) prototype model. A visual simulation of Sólheimajökull's Tenth Century physical environment places the flood into geomorphic and topographic context. This ability to dynamically display and interpret field data presents new possibilities for testing hypotheses, and for data sharing with Icelandic hazard mitigation authorities and the general public.\",\n",
              "  'Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations.[SEP]For preserving the grotto wall paintings and protecting these historic cultural icons from the damage and deterioration in nature environment, a visual analytics framework and a set of tools are proposed for the discovery of degradation patterns. In comparison with the traditional analysis methods that used restricted scales, our method provides users with multi-scale analytic support to study the problems on site, cave, wall and particular degradation area scales, through the application of multidimensional visualization techniques. Several case studies have been carried out using real-world wall painting data collected from a renowned World Heritage site, to verify the usability and effectiveness of the proposed method. User studies and expert reviews were also conducted through by domain experts ranging from scientists such as microenvironment researchers, archivists, geologists, chemists, to practitioners such as conservators, restorers and curators.'],\n",
              " '7_light_illumination_rendering_lighting': ['Unified Mathematical Model for Multilayer-Multiframe Compressive Light Field Displays Using LCDs.[SEP]We propose a unified mathematical model for multilayer-multiframe compressive light field displays that supports both attenuation-based and polarization-based architectures. We show that the light field decomposition of such a display can be cast as a bound constrained nonlinear matrix optimization problem. Efficient light field decomposition algorithms are developed using the limited-memory BFGS (L-BFGS) method for automultiscopic displays with high resolution and high image fidelity. In addition, this framework is the first to support multilayer polarization-based compressive light field displays with time multiplexing. This new architecture significantly reduces artifacts compared with attenuation-based multilayer-multiframe displays; thus, it can allow the requirements regarding the number of layers or the refresh rate to be relaxed. We verify the proposed methods by constructing two 3-layer prototypes using high-speed LCDs, one based on the attenuation architecture and one based on the polarization architecture. Moreover, an efficient CUDA-based program is implemented. Our displays can produce images with higher spatial resolution with thinner form factors compared with traditional automultiscopic displays in both simulations and experiments.',\n",
              "  'Polarization Demosaicking for Monochrome and Color Polarization Focal Plane Arrays.[SEP]Division-of-focal-plane (DoFP) polarization image sensors allow for snapshot imaging of linear polarization effects with inexpensive and straightforward setups. However, conventional interpolation based image reconstruction methods for such sensors produce unreliable and noisy estimates of quantities such as degree of linear polarization (DoLP) or angle of linear polarization (AoLP). In this paper, we propose a polarization demosaicking algorithm by inverting the polarization image formation model for both monochrome and color DoFP cameras. Compared to previous interpolation methods, our approach can significantly reduce noise induced artifacts and drastically increase the accuracy in estimating polarization states. We evaluate and demonstrate the performance of the methods on a new high-resolution color polarization dataset. Simulation and experimental results show that the proposed reconstruction and analysis tools offer an effective solution to polarization imaging.',\n",
              "  'Depth of Field in Plenoptic Cameras.[SEP]Certain new algorithms used by plenoptic cameras require focused microlens images. The range of applicability of these algorithms therefore depends on the depth of field of the relay system comprising the plenoptic camera. We analyze the relationships and tradeoffs between camera parameters and depth of field and characterize conditions for optimal refocusing, stereo, and 3D imaging.',\n",
              "  'A Composite BRDF Model for Hazy Gloss.[SEP]We introduce a bidirectional reflectance distribution function (BRDF) model for the rendering of materials that exhibit hazy reflections, whereby the specular reflections appear to be flanked by a surrounding halo. The focus of this work is on artistic control and ease of implementation for real‐time and off‐line rendering. We propose relying on a composite material based on a pair of arbitrary BRDF models; however, instead of controlling their physical parameters, we expose perceptual parameters inspired by visual experiments [VBF17]. Our main contribution then consists in a mapping from perceptual to physical parameters that ensures the resulting composite BRDF is valid in terms of reciprocity, positivity and energy conservation. The immediate benefit of our approach is to provide direct artistic control over both the intensity and extent of the haze effect, which is not only necessary for editing purposes, but also essential to vary haziness spatially over an object surface. Our solution is also simple to implement as it requires no new importance sampling strategy and relies on existing BRDF models. Such a simplicity is key to approximating the method for the editing of hazy gloss in real‐time and for compositing.',\n",
              "  'Improving the Selection of Bases of BRDFs for Appearance Preservation.[SEP]An important step in the appearance preservation of real materials is the analysis of how they interact with light. Since this phenomena happens at a microscopic level, heuristics with different complexity have been developed to capture and reproduce it. In order to minimize sampling efforts, one of these approaches consists in representing the reflectance of a material as a linear combination of a basis of known reflectance functions. To accomplish realistic and efficient representations, this basis must be expressive and contain a reduced number of elements. This work presents three approaches to select such basis. The first one performs an empirical leave-one-out optimization procedure. The other two are based on classical and evolutionary clustering algorithms. To improve clustering results, a new BRDF-oriented fitness function is designed. These approaches are evaluated using NNLS algorithm to estimate sampled materials and a comparison based on numerical precision is performed.',\n",
              "  'Accurate fitting of measured reflectances using a Shifted Gamma micro-facet distribution.[SEP]Material models are essential to the production of photo‐realistic images. Measured BRDFs provide accurate representation with complex visual appearance, but have larger storage cost. Analytical BRDFs such as Cook‐Torrance provide a compact representation but fail to represent the effects we observe with measured appearance. Accurately fitting an analytical BRDF to measured data remains a challenging problem. In this paper we introduce the SGD micro‐facet distribution for Cook‐Torrance BRDF. This distribution accurately models the behavior of most materials. As a consequence, we accurately represent all measured BRDFs using a single lobe. Our fitting procedure is stable and robust, and does not require manual tweaking of the parameters.'],\n",
              " '80_solid_solids_boundary_polyhedral': ['Set models and Boolean operations for solids and assemblies.[SEP]Applications of solid modeling in computer-aided design, computer-aided manufacturing, and robotics, which often involve aggregates or assemblies of disconnected pieces, are addressed. Models for such assemblies must be subjected to some of the same operations as models for single parts. The mathematical basis of constructive solid geometry (CSG), the usual formalism in solid modelers, leads to difficulties in dealing with assemblies. An alternative CSG-like formalism based on open sets, in which both assemblies and connected pieces are modeled as point sets is presented. Consequently the same Boolean operations apply uniformly to connected pieces and assemblies.< >',\n",
              "  'Volume-Preserving Free-Form Solids.[SEP]Some important trends in geometric modeling are the reliance on solid models rather than surface-based models and the enhancement of the expressive power of models, by using free-form objects in addition to the usual geometric primitives and by incorporating physical principles. An additional trend is the emphasis on interactive performance. In this paper, we integrate all of these requirements into a single geometric primitive by endowing the tri-variate tensor-product free-form solid with several important physical properties, including volume and internal deformation energy. Volume preservation is of benefit in several application areas of geometric modeling, including computer animation, industrial design and mechanical engineering. However, previous physics-based methods, which have usually used some form of \"energy\", have neglected the issue of volume (or area) preservation. We present a novel method for modeling an object composed of several tensor-product solids while preserving the desired volume of each primitive and ensuring high-order continuity constraints between the primitives. The method utilizes the Uzawa algorithm for non-linear optimization, with objective functions based on deformation energy or least squares. We show how the algorithm can be used in an interactive environment by relaxing exactness requirements while the user interactively manipulates free-form solid primitives. On current workstations, the algorithm runs in real-time for tri-quadratic volumes and close to real-time for tri-cubic volumes.',\n",
              "  \"Eliminating redundant primitives from set-theoretic solid models by a consideration of constituents.[SEP]Set-theoretic solid models often contain redundant primitives, which slow down rendering and other processes. They are not simple to remove, especially as there can be alternative eliminations that may not be equally desirable. Existing techniques for eliminating such redundant primitives do not fully consider the possibilities and rely on repeated evaluation of parts of the object's boundary, a process that is likely to be very slow. A technique that allows alternative eliminations to be examined is proposed and a potentially efficient, but geometrically approximate, method of implementation is outlined.< >\"],\n",
              " '81_electricity_households_heating_smart': ['Beyond demand management: the value of sharing electricity information.[SEP]Technologies such as smart meters and electricity feedback are becoming an increasingly compelling focus for HCI researchers in light of rising power prices and peak demand. We argue, however, that a pre-occupation with the goal of demand management has limited the scope of design for these technologies. In this paper we present our work-in-progress investigating the potential value of socially sharing electricity information as a means of broadening the scope of design for these devices. This paper outlines some preliminary findings gathered from a design workshop and a series of qualitative interviews with householders in Brisbane, Australia, regarding their attitudes towards electricity feedback and sharing consumption information. Preliminary findings suggest that; (1) the social sharing of electricity feedback information has the potential to be of value in better informing consumption decisions, however; (2) the potential for sharing may be constrained by attitudes towards privacy, trust and the possibility of misinformation being shared. We conclude by outlining ideas for our future research on this topic and invite comments on these ideas.',\n",
              "  'Comparative Feedback in the Street: Exposing Residential Energy Consumption on House Fa[SEP]This study investigates the impact of revealing the changes in daily residential energy consumption of individual households on their respective house faç ades. While energy feedback devices are now commercially available, still little is known about the potential of making such private information publicly available in order to encourage various forms of social involvement, such as peer pressure or healthy competition. This paper reports on the design rationale of a custom-made chalkboard that conveys different visualizations of household energy consumption, which were updated daily by hand. An in-situ, between-subject study was conducted during which the effects of such a public display were compared with two different control groups over a total period of 7 weeks. The competitive aspects of the public display led to more sustained behavior change and more effective energy conservation, as some graphical depictions such as a historical line graph raised awareness about consumption behavior, and the public character of the display prompted discussions in the wider community. The paper concludes with several considerations for the design of public displays, and of household energy consumption in particular.',\n",
              "  \"Studying always-on electricity feedback in the home.[SEP]The recent emphasis on sustainability has made consumers more aware of their responsibility for saving resources, in particular, electricity. Consumers can better understand how to save electricity by gaining awareness of their consumption beyond the typical monthly bill. We conducted a study to understand consumers' awareness of energy consumption in the home and to determine their requirements for an interactive, always-on interface for exploring data to gain awareness of home energy consumption. In this paper, we describe a three-stage approach to supporting electricity conservation routines: raise awareness, inform complex changes, and maintain sustainable routines. We then present the findings from our study to support design implications for energy consumption feedback interfaces.\"],\n",
              " '82_fractal_fractals_compression_chaos': ['Shape Approximation by a Fractal Model.[SEP]The use of fractals to synthesize complex objects is of current interest in the computer graphics community. A powerful way to compute fractals is the use of IFS (iterated function system) which is a set of contractions with associated probabilities which characterize the fractal. This theory, developed by M. Barnsley and al., can produce very complicated objects. We present a method to solve the inverse problem for these globally constructed fractals : given a set A (attractor), find an IFS that will approximately generate A. We use an optimisation method to minimize a distance between A and the current set L. Several distances have been tested and an algorithm has been implemented which gives good results. A test image is presented.',\n",
              "  'Visualizing Chemical Kinetics in Fractal Domains.[SEP]Chemical reactions occurring within complex domains, such as fractals, can display behavior which differs radically from the expectation of classical chemical kinetics. Rather than relaxing to a uniform distribution at the steady state, these nonclassical systems display large-scale order on many scales. Such self-organization is difficult to measure using the usual statistical techniques, but is visually apparent. The authors discuss some of the problems of visualizing chemical kinetics in fractal domains and describe evolution of the visualization as the chemist and visualization scientist collaborated.< >',\n",
              "  \"Transforming Fractals.[SEP]This issue's article examines the digital artwork of Rod Seeley, who transforms basic fractal images into complex works of art.\"],\n",
              " '83_memories_diary_life_everyday': ['Footprint tracker: supporting diary studies with lifelogging.[SEP]As HCI shifts \"to the wild\", in-situ methods such as Diary Methods and the Experience Sampling Method are gaining momentum. However, researchers have acknowledged the intrusiveness and lack of realism in these methods and have proposed solutions, notably through lightweight and rich media capture. In this paper we explore the concept of lifelogging as an alternative solution to these two challenges. We describe Footprint Tracker, a tool that allows the review of lifelogs with the aim to support recall and reflection over daily activities and experiences. In a field trial, we study how four different types of cues, namely visual, location, temporal and social context, trigger memories of recent events and associated emotions. We conclude with a number of implications for the design of lifelogging systems that support recall and reflection upon recent events as well as ones lying further in our past.',\n",
              "  'Making love in the network closet: the benefits and work of family videochat.[SEP]In this paper, we explore the benefits of videochat for families and the corresponding work that home users engage in to make a video call run smoothly. We explore the varieties of social work required, including coordination work, presentation work, behavioral work, and scaffolding work, as well as the technical work necessary. We outline the benefits families enjoy for doing this work and discuss the ways in which families use videochat to reinforce their identity as a family and reinforce their family values, in effect making - as in creating - love. We conclude with recommendations for improving videochat and for designing with family values in mind more generally.',\n",
              "  \"AutoTypography: what can physical mementos tell us about digital memories?[SEP]Current technology makes it possible to capture huge amounts of information related to everyday experiences. Despite this, we know little about the processes by which people identify and manage mementos - objects which are directly meaningful to their memories. Among the millions of objects people encounter in a lifetime, few become such reminders of people, places or events. We report fieldwork where participants gave us a tour of their homes describing how and why particular objects become mementos. Our findings extend the existing digital memory literature; first our participants didn't view their activities as experiential 'capture', nor were mementos limited to pictorial representations of people and events; instead they included everyday objects. Furthermore, mementos were not only displayed and shared, but also integrated into everyday activities. Finally there were complex relations between house location and memento type. We discuss the theoretical and technical implications of our work.\"],\n",
              " '84_civic_civics_infrastructure_citizens': [\"Shared values/conflicting logics: working around e-government systems.[SEP]In this paper, we describe results from fieldwork conducted at a social services site where the workers evaluate citizens' applications for food and medical assistance submitted via an e-government system. These results suggest value tensions that result - not from different stakeholders with different values - but from differences among how stakeholders enact the same shared value in practice. In the remainder of this paper, we unpack the distinct and conflicting interpretations or logics of three shared values - efficiency, access, and education. In particular, we analyze what happens when social services workers have ideas about what it means to expand access, increase efficiency, and educate the public that conflict with the logics embedded in the e-government system. By distinguishing between overarching values and specific logics, we provide an analytic framework for exploring value tensions as values are enacted in practice.\",\n",
              "  \"Civic Empowerment through Digitalisation: The Case of Greenlandic Women.[SEP]This paper explores the disruptive and transformative effects of digital technology on gendered security asymmetries in Greenland. Through ethnographic fieldwork conducted in Greenland and Denmark, research findings emerged through in-depth interviews, collaborative mappings and field observations with 51 participants. Employing a critical feminist lens, the paper identifies how Greenlandic women develop digital security practices to respond to Greenland's ecologically, politically and socially induced transformation processes. By connecting individual security concerns of Greenlandic women with the broader regional context, the findings highlight how digital technology has created transitory spaces in which collective security is cultivated, shaped and challenged. The contribution to HCI scholarship is therefore threefold: (1) identification and acknowledgement of gendered effects of increased usage of digital technology in remote and hard-to-reach communities, (2) a broader conceptualisation of digital security and (3) a recommendation for more contextualised, pluralistic digitalisation policies and design.\",\n",
              "  \"From Creating Spaces for Civic Discourse to Creating Resources for Action.[SEP]In this paper, we investigate the role of technology to address the concerns of a civil society group carrying out community-level consultation on the allocation of £1 million of community funds. We explore issues of devolved decision-making through the evaluation of a sociodigital system designed to foster deliberative virtues. We describe the ways in which this group used our system in their consultation practices. Our findings highlight how they adopted our technology to privilege specific forms of expression, ascertain issues in their community, make use of and make sense of community data, and create resources for action within their existing practices. Based on related fieldwork we discuss the impacts of structuring and configuring tools for 'talk-based' consultation in order to turn attention to the potential pitfalls and prospects for designing civic technologies that create resources for action for civil society.\"],\n",
              " '85_xml_query_xquery_queries': ['Holistic twig joins: optimal XML pattern matching.[SEP]XML employs a tree-structured data model, and, naturally, XML queries specify patterns of selection predicates on multiple elements related by a tree structure. Finding all occurrences of such a twig pattern in an XML database is a core operation for XML query processing. Prior work has typically decomposed the twig pattern into binary structural (parent-child and ancestor-descendant) relationships, and twig matching is achieved by: (i) using structural join algorithms to match the binary relationships against the XML database, and (ii) stitching together these basic matches. A limitation of this approach for matching twig patterns is that intermediate result sizes can get large, even when the input and output sizes are more manageable.In this paper, we propose a novel holistic twig join algorithm, TwigStack, for matching an XML query twig pattern. Our technique uses a chain of linked stacks to compactly represent partial results to root-to-leaf query paths, which are then composed to obtain matches for the twig pattern. When the twig pattern uses only ancestor-descendant relationships between elements, TwigStack is I/O and CPU optimal among all sequential algorithms that read the entire input: it is linear in the sum of sizes of the input lists and the final result list, but independent of the sizes of intermediate results. We then show how to use (a modification of) B-trees, along with TwigStack, to match query twig patterns in sub-linear time. Finally, we complement our analysis with experimental results on a range of real and synthetic data, and query twig patterns.',\n",
              "  \"Colorful XML: One Hierarchy Isn't Enough.[SEP]XML has a tree-structured data model, which is used to uniformly represent structured as well as semi-structured data, and also enable concise query specification in XQuery, via the use of its XPath (twig) patterns. This in turn can leverage the recently developed technology of structural join algorithms to evaluate the query efficiently. In this paper, we identify a fundamental tension in XML data modeling: (i) data represented as deep trees (which can make effective use of twig patterns) are often un-normalized, leading to update anomalies, while (ii) normalized data tends to be shallow, resulting in heavy use of expensive value-based joins in queries.Our solution to this data modeling problem is a novel multi-colored trees (MCT) logical data model, which is an evolutionary extension of the XML data model, and permits trees with multi-colored nodes to signify their participation in multiple hierarchies. This adds significant semantic structure to individual data nodes. We extend XQuery expressions to navigate between structurally related nodes, taking color into account, and also to create new colored trees as restructurings of an MCT database. While MCT serves as a significant evolutionary extension to XML as a logical data model, one of the key roles of XML is for information exchange. To enable exchange of MCT information, we develop algorithms for optimally serializing an MCT database as XML. We discuss alternative physical representations for MCT databases, using relational and native XML databases, and describe an implementation on top of the Timber native XML database. Experimental evaluation, using our prototype implementation, shows that not only are MCT queries/updates more succinct and easier to express than equivalent shallow tree XML queries, but they can also be significantly more efficient to evaluate than equivalent deep and shallow tree XML queries/updates.\",\n",
              "  'On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques.[SEP]Searching for all occurrences of a twig pattern in an XML document is an important operation in XML query processing. Recently a holistic method TwigStack. [2] has been proposed. The method avoids generating large intermediate results which do not contribute to the final answer and is CPU and I/O optimal when twig patterns only have ancestor-descendant relationships. Another important direction of XML query processing is to build structural indexes [3][8][13][15] over XML documents to avoid unnecessary scanning of source documents. We regard XML structural indexing as a technique to partition XML documents and call it streaming scheme in our paper. In this paper we develop a method to perform holistic twig pattern matching on XML documents partitioned using various streaming schemes. Our method avoids unnecessary scanning of irrelevant portion of XML documents. More importantly, depending on different streaming schemes used, it can process a large class of twig patterns consisting of both ancestor-descendant and parent-child relationships and avoid generating redundant intermediate results. Our experiments demonstrate the applicability and the performance advantages of our approach.'],\n",
              " '86_moral_dilemmas_judgment_harm': [\"Priming Effects of Religious Concepts on Moral Judgment: Between Mean Values and Variation.[SEP]Social psychological researchers have found that most conceptual structures can be primed, i.e. activated unobtrusively and exert an influence on subsequent behavior without the participant’s awareness of this influence. I investigated whether exposing people to words related to a punishing God or a forgiving Christian could influence subsequent moral judgment. Participants completed a 'scrambled sentence' task before rating five vignettes concerning various moral transgressions. Analysis showed that participants in the 'forgiving' condition on average made slightly less severe moral judgments than did participants in both the 'punishing' condition and a control condition. Whereas previous religious priming studies have often treated ‘religious’ concepts as a homogenous category with homogenous priming effects, the current experiment questions that assumption. Also, the study incorporated a measure of participants' associations with the prime words, revealing considerable variation. This suggests that participants’ different interpretations of religious words are an important topic and concern for future studies.\",\n",
              "  \"Apparent Paradoxes in Moral Reasoning; Or how you forced him to do it, even though he wasn't forced to do it.[SEP]The importance of situational constraint for moral evaluations is widely accepted in philosophy, psychology, and the law. However, recent work suggests that this relationship is actually bidirectional: moral evaluations can also influence our judgments of situational constraint. For example, if an agent is thought to have acted immorally rather than morally, that agent is often judged to have acted with greater freedom and under less situational constraint. Moreover, when considering interpersonal situations, we judge that an agent who forces another to act immorally (versus morally) uses more force. These two features can result in contradictory response patterns in which participants judge both that (1) a forcer forced a forcee to act and (2) the forcee was not forced by the forcer to act. Here, we characterize potential psychological mechanisms, in particular, “moral focus” and counterfactual reasoning that account for this paradoxical pattern of judgments.\",\n",
              "  'Mental states are more important in evaluating moral than conventional violations.[SEP]A perpetrator’s mental state – whether she had mens rea or a “guilty mind” – typically plays an important role in evaluating wrongness and assigning punishment. In two experiments, we find that this role for mental states is weaker in evaluating conventional violations relative to moral violations. We also find that this diminished role for mental states may be associated with the fact that conventional violations are wrong by virtue of having violated a rule, whereas moral violations are also wrong inherently.'],\n",
              " '87_volume_volumetric_rendering_opacity': ['Dataset Traversal with Motion-Controlled Transfer Functions.[SEP]In this paper, we describe a methodology and implementation for interactive dataset traversal using motion-controlled transfer functions. Dataset traversal here refers lo the process of translating a transfer function along a specific path. In scientific visualization, it is often necessary to manipulate transfer functions in order to visualize datasets more effectively. This manipulation of transfer functions is usually performed globally, i.e., a new transfer function is applied to the entire dataset. Our approach allows one to locally manipulate transfer functions while controling its movement along a traversal path. The method we propose allows the user to select a traversal path within the dataset, based on the shape of the volumetric model and manipulate a transfer function along this path. Examples of dataset traversal include the animation of transfer functions along a pre-defined path, the simulation of flow in vascular structures, and the visualization of convoluted shapes. For example, this type of traversal is often used in medical illustration to highlight flow in blood vessels. We present an interactive implementation of our method using graphics hardware, based on the decomposition of the volume. We show examples of our approach using a variety of volumetric datasets, and we also demonstrate that with our novel decomposition, the rendering process is faster.',\n",
              "  'ViSizer: A Visualization Resizing Framework.[SEP]Visualization resizing is useful for many applications where users may use different display devices. General resizing techniques (e.g., uniform scaling) and image-resizing techniques suffer from several drawbacks, as they do not consider the content of the visualizations. This work introduces ViSizer, a perception-based framework for automatically resizing a visualization to fit any display. We formulate an energy function based on a perception model (feature congestion), which aims to determine the optimal deformation for every local region. We subsequently transform the problem into an optimization problem by the energy function. An efficient algorithm is introduced to iteratively solve the problem, allowing for automatic visualization resizing.',\n",
              "  'Opacity Optimization for Surfaces.[SEP]In flow visualization, integral surfaces rapidly tend to expand, fold and produce vast amounts of occlusion. While silhouette enhancements and local transparency mappings proved useful for semi‐transparent depictions, they still introduce visual clutter when surfaces grow more complex. An effective visualization of the flow requires a balance between the presentation of interesting surface parts and the avoidance of occlusions that hinder the view. In this paper, we extend the concept of opacity optimization to surfaces to obtain a global approach to the occlusion problem. Starting with a partition of the surfaces into patches, we compute per‐patch opacity as minimizer of a bounded‐variable least‐squares problem. For the final rendering, opacity is interpolated on the surfaces. The resulting visualization technique is interactive, frame‐coherent, view‐dependent and driven by domain knowledge.'],\n",
              " '88_pointing_target_movement_targets': ['Control Theoretic Models of Pointing.[SEP]This article presents an empirical comparison of four models from manual control theory on their ability to model targeting behaviour by human users using a mouse: McRuer’s Crossover, Costello’s Surge, second-order lag (2OL), and the Bang-bang model. Such dynamic models are generative, estimating not only movement time, but also pointer position, velocity, and acceleration on a moment-to-moment basis. We describe an experimental framework for acquiring pointing actions and automatically fitting the parameters of mathematical models to the empirical data. We present the use of time-series, phase space, and Hooke plot visualisations of the experimental data, to gain insight into human pointing dynamics. We find that the identified control models can generate a range of dynamic behaviours that captures aspects of human pointing behaviour to varying degrees. Conditions with a low index of difficulty (ID) showed poorer fit because their unconstrained nature leads naturally to more behavioural variability. We report on characteristics of human surge behaviour (the initial, ballistic sub-movement) in pointing, as well as differences in a number of controller performance measures, including overshoot, settling time, peak time, and rise time. We describe trade-offs among the models. We conclude that control theory offers a promising complement to Fitts’ law based approaches in HCI, with models providing representations and predictions of human pointing dynamics, which can improve our understanding of pointing and inform design.',\n",
              "  'Modeling the Endpoint Uncertainty in Crossing-based Moving Target Selection.[SEP]Modeling the endpoint uncertainty of moving target selection with crossing is essential to understand factors such as speed-accuracy trade-off and interaction efficiency in crossing-based user interfaces with dynamic contents. However, there have been few studies looking into this research topic in the HCI field. This paper presents a Quaternary-Gaussian model to quantitatively measure the endpoint uncertainty in crossing-based moving target selection. To validate this model, we conducted an experiment with discrete crossing tasks on five factors, i.e., initial distance, size, speed, orientation, and moving direction. Results showed that our model fit the data of μ and σ accurately with adjusted R2 of 0.883 and 0.920. We also demonstrated the validity of our model in predicting error rates in crossing-based moving target selection. We concluded with a set of implications for future designs.',\n",
              "  'A probabilistic approach to modeling two-dimensional pointing.[SEP]We investigate and model two-dimensional pointing where the target distance and size vary as does the angle of movement. We first study the spread of hits in a rapid approximate pointing task at varied distances and movement angles. Consistent with the literature, our results show that the spread of hits along the movement direction deviate more than the spread of hits in the direction perpendicular to movement, and both spreads increase with distance. Based on the distribution of this spread of hits, we propose and validate a new probabilistic model that describes two-dimensional pointing. Unlike previous models, our model accounts for more variables of two-dimensional pointing and can be generalized to any target shape, size, orientation, location, and dimension. In contrast to previous work, which suggests that target height has minimal impact on performance when it is larger than the width, our results show that, even when height is greater than width, it can significantly impact movement time.'],\n",
              " '89_indoor_location_positioning_rfid': ['A New Method for Auto-calibrated Object Tracking.[SEP]Ubiquitous computing technologies which are cheap and easy to use are more likely to be adopted by users beyond the ubiquitous computing community. We present an ultrasonic-only tracking system that is cheap to build, self-calibrating and self-orientating, and has a convenient form factor. The system tracks low-power tags in three dimensions. The tags are smaller than AAA batteries and last up to several years on their power source. The system can be configured to track either multiple near-stationary objects or a single fast moving object. Full test results are provided and use of the system within a home application is discussed.',\n",
              "  'Wideband powerline positioning for indoor localization.[SEP]Fingerprinting techniques for indoor localization have been widely explored. A particular approach by Patel et al. suggested leveraging of the residential powerline as the signaling mechanism for a domestic location capability. In this paper, we critically examine that initial work, called powerline positioning (PLP). We find the proposed technique lacking in temporal stability, requiring frequent and undesired recalibration in some environments. We also determine that there is no a priori method to determine a pair of signaling frequencies that will reliably work in any space. We propose a wideband approach to PLP (WPLP) that injects up to 44 different frequencies into the powerline. We show that this WPLP approach improves upon overall positioning accuracy, demonstrates greatly improved temporal stability and has the added advantage of working in commercial indoor spaces.',\n",
              "  'A Probabilistic Room Location Service for Wireless Networked Environments.[SEP]The popularity of wireless networks has increased in recent years and is becoming a common addition to LANs. In this paper we investigate a novel use for a wireless network based on the IEEE 802.11 standard: inferring the location of a wireless client from signal quality measures. Similar work has been limited to prototype systems that rely on nearest-neighbor techniques to infer location. In this paper, we describe Nibble, a Wi-Fi location service that uses Bayesian networks to infer the location of a device. We explain the general theory behind the system and how to use the system, along with describing our experiences at a university campus building and at a research lab. We also discuss how probabilistic modeling can be applied to a diverse range of applications that use sensor data.'],\n",
              " '8_database_query_queries_join': ['Synthesizing Type-Detection Logic for Rich Semantic Data Types using Open-source Code.[SEP]Given a table of data, existing systems can often detect basic atomic types (e.g., strings vs. numbers) for each column. A new generation of data-analytics and data-preparation systems are starting to automatically recognize rich semantic types such as date-time, email address, etc., for such metadata can bring an array of benefits including better table understanding, improved search relevance, precise data validation, and semantic data transformation. However, existing approaches only detect a limited number of types using regular-expression-like patterns, which are often inaccurate, and cannot handle rich semantic types such as credit card and ISBN numbers that encode semantic validations (e.g., checksum).',\n",
              "  'A New Characterization of Independence.[SEP]We introduce a restriction on the structure of a database scheme, called the primary key condition, and show that this condition characterizes independent database schemes when constraints are presented as keys. The primary key condition provides added insight into the structure of independent schemes, and leads to a general design methodology. We describe a linear-time algorithm for recognizing independent schemes.',\n",
              "  'Efficient and Extensible Algorithms for Multi Query Optimization.[SEP]Complex queries are becoming commonplace, with the growing use of decision support systems. These complex queries often have a lot of common sub-expressions, either within a single query, or across multiple such queries run as a batch. Multiquery optimization aims at exploiting common sub-expressions to reduce evaluation cost. Multi-query optimization has hither-to been viewed as impractical, since earlier algorithms were exhaustive, and explore a doubly exponential search space.',\n",
              "  'Leveraging compression in the tableau data engine.[SEP]Data sets are growing rapidly and there is an attendant need for tools that facilitate human analysis of them in a timely manner. To help meet this need, column-oriented databases (or \"column stores\") have come into wide use because of their low latency on analytic workloads. Column stores use a number of techniques to produce these dramatic performance techniques, including the ability to perform operations directly on compressed data. In this paper, we describe how the Tableau Data Engine (an internally developed column store) leverages a number of compression techniques to improve query performance. The approach is simpler than existing systems for operating on compressed data and more unified, removing the necessity for custom data access mechanisms. The approach also uses some novel metadata extraction techniques to improve the choices made by the system\\'s run-time optimizer.',\n",
              "  'ByteSlice: Pushing the Envelop of Main Memory Data Processing with a New Storage Layout.[SEP]Scan and lookup are two core operations in main memory column stores. A scan operation scans a column and returns a result bit vector that indicates which records satisfy a filter. Once a column scan is completed, the result bit vector is converted into a list of record numbers, which is then used to look up values from other columns of interest for a query. Recently there are several in-memory data layout proposals that aim to improve the performance of in-memory data processing. However, these solutions all stand at either end of a trade-off --- each is either good in lookup performance or good in scan performance, but not both. In this paper we present ByteSlice, a new main memory storage layout that supports both highly efficient scans and lookups. ByteSlice is a byte-level columnar layout that fully leverages SIMD data-parallelism. Micro-benchmark experiments show that ByteSlice achieves a data scan speed at less than 0.5 processor cycle per column value --- a new limit of main memory data scan, without sacrificing lookup performance. Our experiments on TPC-H data and real data show that ByteSlice offers significant performance improvement over all state-of-the-art approaches.',\n",
              "  'A Padded Encoding Scheme to Accelerate Scans by Leveraging Skew.[SEP]In-memory data analytic systems that use vertical bit-parallel scan methods generally use encoding techniques. We observe that in such environments, there is an opportunity to turn skew in both the data and predicate distributions (usually a problem for query processing) into a benefit that can be leveraged to encode the column values. This paper proposes a padded encoding scheme to address this opportunity. The proposed scheme creates encodings that map common attribute values to codes that can easily be distinguished from other codes by only examining a few bits in the full code. Consequently, scans on columns stored using the padded encoding scheme can safely prune the computation without examining all the bits in the code, thereby reducing the memory bandwidth and CPU cycles that are consumed when evaluating scan queries. Our padded encoding method results in a fixed-length encoding, as fixed-length encodings are easier to manage. However, the proposed padded encoding may produce longer (fixed-length) codes than those produced by popular order-preserving encoding methods, such as dictionary-based encoding. This additional space overhead has the potential to negate the gains from early pruning of the scan computation. However, as we demonstrate empirically, the additional space overhead is generally small, and the padded encoding scheme provides significant performance improvements.',\n",
              "  'Secondary-storage confidence computation for conjunctive queries with inequalities.[SEP]This paper investigates the problem of efficiently computing the confidences of distinct tuples in the answers to conjunctive queries with inequalities (<) on tuple-independent probabilistic databases. This problem is fundamental to probabilistic databases and was recently stated open.',\n",
              "  'A Query Engine for Probabilistic Preferences.[SEP]Models of uncertain preferences, such as Mallows, have been extensively studied due to their plethora of application domains. In a recent work, a conceptual and theoretical framework has been proposed for supporting uncertain preferences as first-class citizens in a relational database. The resulting database is probabilistic, and, consequently, query evaluation entails inference of marginal probabilities of query answers. In this paper, we embark on the challenge of a practical realization of this framework. We first describe an implementation of a query engine that supports querying probabilistic preferences alongside relational data. Our system accommodates preference distributions in the general form of the Repeated Insertion Model (RIM), which generalizes Mallows and other models. We then devise a novel inference algorithm for conjunctive queries over RIM, and show that it significantly outperforms the state of the art in terms of both asymptotic and empirical execution cost. We also develop performance optimizations that are based on sharing computation among different inference tasks in the workload. Finally, we conduct an extensive experimental evaluation and demonstrate that clear performance benefits can be realized by a query engine with built-in probabilistic inference, as compared to a stand alone implementation with a black-box inference solver.',\n",
              "  'US-SQL: managing uncertain schemata.[SEP]In this paper we describe a demo concerning the management of uncertain schemata. Many works have studied the problem of representing uncertainty on attribute values or tuples, like the fact that a value is 10 with probability .3 or 20 with probability .7, leading to the implementation of probabilistic database management systems. In our demo we deal with the representation of uncertainty about the meta-data, i.e., about the meaning of these values. Using our system it is possible to create alternative probabilistic schemata on a database, execute queries over uncertain schemata and verify how this additional information is stored in an underlying relational database and how queries are executed.',\n",
              "  'High-Performance Geospatial Analytics in HyPerSpace.[SEP]In the past few years, massive amounts of location-based data has been captured. Numerous datasets containing user location information are readily available to the public. Analyzing such datasets can lead to fascinating insights into the mobility patterns and behaviors of users. Moreover, in recent times a number of geospatial data-driven companies like Uber, Lyft, and Foursquare have emerged. Real-time analysis of geospatial data is essential and enables an emerging class of applications. Database support for geospatial operations is turning into a necessity instead of a distinct feature provided by only a few databases. Even though a lot of database systems provide geospatial support nowadays, queries often do not consider the most current database state. Geospatial queries are inherently slow given the fact that some of these queries require a couple of geometric computations. Disk-based database systems that do support geospatial datatypes and queries, provide rich features and functions, but they fall behind when performance is considered: specifically if real-time analysis of the latest transactional state is a requirement. In this demonstration, we present HyPerSpace, an extension to the high-performance main-memory database system HyPer developed at the Technical University of Munich, capable of processing geospatial queries with sub-second latencies.',\n",
              "  'Incremental Distance Join Algorithms for Spatial Databases.[SEP]Two new spatial join operations, distance join and distance semi-join, are introduced where the join output is ordered by the distance between the spatial attribute values of the joined tuples. Incremental algorithms are presented for computing these operations, which can be used in a pipelined fashion, thereby obviating the need to wait for their completion when only a few tuples are needed. The algorithms can be used with a large class of hierarchical spatial data structures and arbitrary spatial data types in any dimensions. In addition, any distance metric may be employed. A performance study using R-trees shows that the incremental algorithms outperform non-incremental approaches by an order of magnitude if only a small part of the result is needed, while the penalty, if any, for the incremental processing is modest if the entire join result is required.',\n",
              "  'STAR: A Distributed Stream Warehouse System for Spatial Data.[SEP]The proliferation of mobile phones and location-based services gives rise to an explosive growth of spatial data. This spatial data contains valuable information, and calls for data stream warehouse systems that can provide real-time analytical results with the latest integrated spatial data. In this demonstration, we present the STAR (Spatial Data Stream Warehouse) system. STAR is a distributed in-memory spatial data stream warehouse system that provides low-latency and up-to-date analytical results over a fast spatial data stream. STAR supports a rich set of aggregate queries for spatial data analytics, e.g., contrasting the frequencies of spatial objects that appear in different spatial regions, or showing the most frequently mentioned topics being tweeted in different cities. STAR processes aggregate queries by maintaining distributed materialized views. Additionally, STAR supports dynamic load adjustment that makes STAR scalable and adaptive. We demonstrate STAR on top of Amazon EC2 clusters using real data sets.'],\n",
              " '90_diffusion_tensor_tracts_brain': ['Case Study: Reconstruction, Visualization, and Quantification of Neuronal Fiber Pathways.[SEP]It is of significant interest for neurological studies to determine and visualize neuronal fiber pathways in the human brain. By exploiting the capability of diffusion tensor magnetic resonance imaging to detect local orientations of neuronal fibers, we have developed a system of algorithms to reconstruct, visualize and quantify neuronal fiber pathways in vivo. Illustrative results show that the system is a promising tool for visual analysis of fiber connectivity and quantitative studies of neuronal fibers.',\n",
              "  'Topological Visualization of Brain Diffusion MRI Data.[SEP]Topological methods give concise and expressive visual representations of flow fields. The present work suggests a comparable method for the visualization of human brain diffusion MRI data. We explore existing techniques for the topological analysis of generic tensor fields, but find them inappropriate for diffusion MRI data. Thus, we propose a novel approach that considers the asymptotic behavior of a probabilistic fiber tracking method and define analogs of the basic concepts of flow topology, like critical points, basins, and faces, with interpretations in terms of brain anatomy. The resulting features are fuzzy, reflecting the uncertainty inherent in any connectivity estimate from diffusion imaging. We describe an algorithm to extract the new type of features, demonstrate its robustness under noise, and present results for two regions in a diffusion MRI dataset to illustrate that the method allows a meaningful visual analysis of probabilistic fiber tracking results.',\n",
              "  'Visualizing crossing probabilistic tracts.[SEP]Diffusion weighted magnetic resonance imaging (dMRI) together with tractography algorithms allow to probe for principal white matter tracts in the living human brain. Specifically, probabilistic tractography quantifies the existence of physical connections to a given seed region as a 3D scalar map of confidence scores. Fiber-Stippling is a visualization for probabilistic tracts that effectively communicates the diffusion pattern, connectivity score, and anatomical context. Unfortunately, it cannot handle multiple diffusion orientations per voxel, which exist in high angular resolution diffusion imaging (HARDI) data. Such data is needed to resolve tracts in complex configurations, such as crossings. In this work, we suggest a visualization based on Fiber-Stippling but sensible to multiple diffusion orientations from HARDI-based diffusion models. With such a technique, it is now possible to visualize probabilistic tracts from HARDI-based tractography algorithms. This implies that tract crossings may now be visualized as crossing stipples, which is an essential step towards an accurate visualization of the neuroanatomy, as crossing tracts are widespread phenomena in the brain.'],\n",
              " '91_ontology_schema_ontologies_schemas': ['Statistical Schema Matching across Web Query Interfaces.[SEP]Schema matching is a critical problem for integrating heterogeneous information sources. Traditionally, the problem of matching multiple schemas has essentially relied on finding pairwise-attribute correspondence. This paper proposes a different approach, motivated by integrating large numbers of data sources on the Internet. On this \"deep Web,\" we observe two distinguishing characteristics that offer a new view for considering schema matching: First, as the Web scales, there are ample sources that provide structured information in the same domains (e.g., books and automobiles). Second, while sources proliferate, their aggregate schema vocabulary tends to converge at a relatively small size. Motivated by these observations, we propose a new paradigm, statistical schema matching: Unlike traditional approaches using pairwise-attribute correspondence, we take a holistic approach to match all input schemas by finding an underlying generative schema model. We propose a general statistical framework MGS for such hidden model discovery, which consists of hypothesis modeling, generation, and selection. Further, we specialize the general framework to develop Algorithm MGSsd, targeting at synonym discovery, a canonical problem of schema matching, by designing and discovering a model that specifically captures synonym attributes. We demonstrate our approach over hundreds of real Web sources in four domains and the results show good accuracy.',\n",
              "  'JSON Schema Matching: Empirical Observations.[SEP]Database schema specifies the desired logical organization of the data it stores. A major challenge in database integration is that of schema matching [10, 12], which seeks to determine schema elements in different databases that correspond to the same real world entity. For example, a simple matcher may determine that the attribute ID in one schema is semantically equivalent to Identification in another.',\n",
              "  'SourceSight: Enabling Effective Source Selection.[SEP]Recently there has been a rapid increase in the number of data sources and data services, such as cloud-based data markets and data portals, that facilitate the collection, publishing and trading of data. Data sources typically exhibit large heterogeneity in the type and quality of data they provide. Unfortunately, when the number of data sources is large, it is difficult for users to reason about the actual usefulness of sources for their applications and the trade-offs between the benefits and costs of acquiring and integrating sources. In this demonstration we present \\\\textsc{SourceSight}, a system that allows users to interactively explore a large number of heterogeneous data sources, and discover valuable sets of sources for diverse integration tasks. \\\\textsc{SourceSight}~uses a novel multi-level source quality index that enables effective source selection at different granularity levels, and introduces a collection of new techniques to discover and evaluate relevant sources for integration.',\n",
              "  'Visualizing Conceptual Relations in Legal Terminology.[SEP]Underlying all specialized terminology is a concept system, which is particularly important in the legal domain. However, this concept system is not explicitly available in terminology management systems. We present a tool that analyzes the relations in a terminological database and presents an interactive visualization of those relations. This tool helps terminologists manage their information, including quality assurance and analysis of the information, as well as aiding in didactic presentations of terminology work.',\n",
              "  'A Visualisation Approach for Collaborative Planning Systems Based on Ontologies.[SEP]In the last decades, many advances have been made in intelligent planning systems. Significant improvements related to core problems, providing faster search algorithms and shortest plans have been proposed. However, there is a lack in researches allowing a better support for a proper use and interaction with planners, where, for instance, visualization can play an important role. This work proposes a way to address the problem of visualization in intelligent planning systems via a more general approach. It consists in an integrated ontology set and reasoning mechanism for multi-modality visualisation destined to collaborative planning environments. This framework will permit organizing and modeling the domain from the visualization perspective, and give a tailored support for presentation of information.',\n",
              "  'User-Friendly Ontology Editing and Visualization Tools: The OWLeasyViz Approach.[SEP]This paper aims to propose solutions to the issue of ontology visualization, by presenting intuitive and user-friendly ontology editing and visualization environments mainly oriented to domain experts. It starts with an overview of existing ontology visualization methods; afterwards it describes the Semantic DB system and the OWLeasyViz ontology editor. Semantic DB is a web application framework to create simple complete semantic web applications, integrating an ontology editor, a resource editor, an inference rule editor, a reasoner, and a search engine. OWLeasyViz is an ontology editor that combines a textual and a graphical representation of OWL ontologies. It meets different user needs by providing a simple and intuitive interface to end-users who are not ontologists, and offering more advanced tools to ontology experts. The OWLeasyViz editor is intended to be a module of a semantic web integrated working environment, developed within the context of a Swiss Government funded CTI applied research project in the domain of waste water management.'],\n",
              " '92_email_emails_mail_inbox': ['Going with the flow: email awareness and task management.[SEP]Email use in the context of everyday work practices, or email flow, has not been heavily studied. We present the results of a pair of studies examining how users interlace email with their day-to-day, ongoing work processes. We demonstrate that our subjects use email as a tool for managing moment-to-moment attention and task focus. We also provide a model of this workflow that builds upon an existing model by Venolia et al. Finally, we provide specific design recommendations to enhance the usability of email clients in support of these modes of interaction.',\n",
              "  \"Overload is overloaded: email in the age of Gmail.[SEP]The term email overload has two definitions: receiving a large volume of incoming email, and having emails of different status types (to do, to read, etc). Whittaker and Sidner proposed the latter definition in 1996, noticing that email inboxes were far more complex than simply containing incoming messages. Sixteen years after Whittaker and Sidner, we replicate and extend their work with a qualitative analysis of Google's Gmail. We find that email overload, both in terms of volume and of status, is still a problem today. Our contributions are 1) updating the state of email overload, 2) extending our understanding of overload in the context of Gmail and 3) comparing personal with work email accounts: while work email tends to be status overloaded, personal email is also type overloaded. These comparisons between work and personal email suggest new avenues for email research.\",\n",
              "  'Revisiting Whittaker  Sidner\\'s \"email overload\" ten years later.[SEP]Ten years ago, Whittaker and Sidner [8] published research on email overload, coining a term that would drive a research area that continues today. We examine a sample of 600 mailboxes collected at a high-tech company to compare how users organize their email now to 1996. While inboxes are roughly the same size as in 1996, our population\\'s email archives have grown tenfold. We see little evidence of distinct strategies for handling email; most of our users fall into a middle ground. There remains a need for future innovations to help people manage growing archives of email and large inboxes.'],\n",
              " '93_security_traffic_cyber_intrusion': ['BubbleNet: A Cyber Security Dashboard for Visualizing Patterns.[SEP]The field of cyber security is faced with ever‐expanding amounts of data and a constant barrage of cyber attacks. Within this space, we have designed BubbleNet as a cyber security dashboard to help network analysts identify and summarize patterns within the data. This design study faced a range of interesting constraints from limited time with various expert users and working with users beyond the network analyst, such as network managers. To overcome these constraints, the design study employed a user‐centered design process and a variety of methods to incorporate user feedback throughout the design of BubbleNet. This approach resulted in a successfully evaluated dashboard with users and further deployments of these ideas in both research and operational environments. By explaining these methods and the process, it can benefit future visualization designers to help overcome similar challenges in cyber security or alternative domains.',\n",
              "  'situ: Situational understanding and discovery for cyber attacks.[SEP]Our entry into the VAST 2012 Mini Challenge 2 is a streaming visual analytic system that scores events based on anomalousness and maliciousness and presents each event to the user in a user-defined groupings in animated small-multiple views. The anomaly detection algorithm identifies low probability events, supporting awareness regarding atypical traffic patterns on the network. The maliciousness classifier incorporates both situated knowledge of an environment (policy and machine roles) and domain knowledge (encoded in the IDS alerts). We discuss the visualization design and classification techniques, as well as provide examples of timely detection from the challenge dataset.',\n",
              "  'Weaving a carpet from log entries: A network security visualization built with co-creation.[SEP]We created a pixel map for multivariate data based on an analysis of the needs of network security engineers. Parameters of a log record are shown as pixels and these pixels are stacked to represent a record. This allows a broad view of a data set on one screen while staying very close to the raw data and to expose common and rare patterns of user behavior through the visualization itself (the \"Carpet\"). Visualizations that immediately point to areas of suspicious activity without requiring extensive filtering, help network engineers investigating unknown computer security incidents. Most of them, however, have limited knowledge of advanced visualization techniques, while many designers and data scientists are unfamiliar with computer security topics. To bridge this gap, we developed visualizations together with engineers, following a co-creative process. We will show how we explored the scope of the engineers\\' tasks and how we jointly developed ideas and designs. Our expert evaluation indicates that this visualization helps to scan large parts of log files quickly and to define areas of interest for closer inspection.'],\n",
              " '94_outlier_outliers_datasets_distance': ['Human-in-the-loop Outlier Detection.[SEP]Outlier detection is critical to a large number of applications from finance fraud detection to health care. Although numerous approaches have been proposed to automatically detect outliers, such outliers detected based on statistical rarity do not necessarily correspond to the true outliers to the interest of applications. In this work, we propose a human-in-the-loop outlier detection approach HOD that effectively leverages human intelligence to discover the true outliers. There are two main challenges in HOD. The first is to design human-friendly questions such that humans can easily understand the questions even if humans know nothing about the outlier detection techniques. The second is to minimize the number of questions. To address the first challenge, we design a clustering-based method to effectively discover a small number of objects that are unlikely to be outliers (aka, inliers) and yet effectively represent the typical characteristics of the given dataset. HOD then leverages this set of inliers (called context inliers) to help humans understand the context in which the outliers occur. This ensures humans are able to easily identify the true outliers from the outlier candidates produced by the machine-based outlier detection techniques. To address the second challenge, we propose a bipartite graph-based question selection strategy that is theoretically proven to be able to minimize the number of questions needed to cover all outlier candidates. Our experimental results on real data sets show that HOD significantly outperforms the state-of-the-art methods on both human efforts and the quality of the discovered outliers.',\n",
              "  'Angle-based outlier detection in high-dimensional data.[SEP]Detecting outliers in a large set of data objects is a major data mining task aiming at finding different mechanisms responsible for different groups of objects in a data set. All existing approaches, however, are based on an assessment of distances (sometimes indirectly by assuming certain distributions) in the full-dimensional Euclidean data space. In high-dimensional data, these approaches are bound to deteriorate due to the notorious \"curse of dimensionality\". In this paper, we propose a novel approach named ABOD (Angle-Based Outlier Detection) and some variants assessing the variance in the angles between the difference vectors of a point to the other points. This way, the effects of the \"curse of dimensionality\" are alleviated compared to purely distance-based approaches. A main advantage of our new approach is that our method does not rely on any parameter selection influencing the quality of the achieved ranking. In a thorough experimental evaluation, we compare ABOD to the well-established distance-based method LOF for various artificial and a real world data set and show ABOD to perform especially well on high-dimensional data.',\n",
              "  'Online Outlier Exploration Over Large Datasets.[SEP]Traditional outlier detection systems process each individual outlier detection request instantiated with a particular parameter setting one at a time. This is not only prohibitively time-consuming for large datasets, but also tedious for analysts as they explore the data to hone in on the appropriate parameter setting and desired results.'],\n",
              " '95_video_videos_frames_temporal': ['CoSummary: adaptive fast-forwarding for surgical videos by detecting collaborative scenes using hand regions and gaze positions.[SEP]This paper presents CoSummary, an adaptive video fast-forwarding technique for browsing surgical videos recorded by wearable cameras. Current wearable technologies allow us to record complex surgical skills, however, an efficient browsing technique for these videos is not well established. In order to assist browsing surgical videos, our study focuses on adaptively changing playback speeds through the learning and detecting collaborative scenes based on surgeon hand placement and gaze information. Our evaluation shows that the proposed method is able to highlight important collaborative scenes and skip less important scenes during surgical procedures. We have also performed a subjective study with surgeons in order to have professional feedback. The results confirmed the effectiveness of the proposed method in comparison to uniform video fast-forwarding.',\n",
              "  'Temporal Magic Lens: Combined Spatial and Temporal Query and Presentation.[SEP]We introduce the concept of a Temporal Magic Lens, a novel interaction technique that supports querying and browsing for video data. Video data is available from an increasing number of sources, and yet analyzing and processing it is still often a manual, tedious task. A Temporal Magic Lens is an interactive tool that combines spatial and temporal components of video, creating a unified mechanism for analyzing video data; it can be used for viewing real-time video data, as well as for browsing and searching archival data. In this paper, we define the Temporal Magic Lens concept and identify its four key components. We present a sample implementation for each component, and then describe two usage scenarios for a prototype surveillance application.',\n",
              "  \"SmartPlayer: user-centric video fast-forwarding.[SEP]In this paper we propose a new video interaction model called adaptive fast-forwarding to help people quickly browse videos with predefined semantic rules. This model is designed around the metaphor of scenic car driving, in which the driver slows down near areas of interest and speeds through unexciting areas. Results from a preliminary user study of our video player suggest the following: (1) the player should adaptively adjust the current playback speed based on the complexity of the present scene and predefined semantic events; (2) the player should learn user preferences about predefined event types as well as a suitable playback speed; (3) the player should fast-forward the video continuously with a playback rate acceptable to the user to avoid missing any undefined events or areas of interest. Furthermore, our user study results suggest that for certain types of video, our SmartPlayer yields better user experiences in browsing and fast-forwarding videos than existing video players' interaction models.\"],\n",
              " '96_tree_trees_plant_plants': ['A Visualization Tool for Studying the Development of the Moss Physcomitrella patens.[SEP]The investigation of mechanisms responsible for the morphogenesis of complex biological organisms is an important area in biology. P. patens is an especially suitable plant for this research because it is a rather simple organism, facilitating its observation, yet it possesses developmental phenomena analogous to those which occur in higher plants, allowing the extrapolation of hypotheses to more complex organisms. The visualization consists of three components: biological data collection, computer-modelling (using L-systems), and model verification. The simulated developmental process is quite realistic and provides an excellent means for verifying the underlying hypotheses of morphogenesis.',\n",
              "  'Data-Driven Synthetic Modeling of Trees.[SEP]In this paper, we develop a data-driven technique to model trees from a single laser scan. A multi-layer representation of the tree structure is proposed to guide the modeling process. In this process, a marching cylinder algorithm is first developed to construct visible branches from the laser scan data. Three levels of crown feature points are then extracted from the scan data to synthesize three layers of non-visible branches. Based on the hierarchical particle flow technique, the branch synthesis method has the advantage of producing visually convincing tree models that are consistent with scan data. User intervention is extremely limited. The robustness of this technique has been validated on both conifer and broadleaf trees.',\n",
              "  'Interactive Design of Bonsai Tree Models.[SEP]Because of their complexity, plant models used in computer graphics are commonly created with proceduralmethods. A difficult problem is the user control of these models: a small number of parameters is insufficient tospecify plant characteristics in detail, while large numbers of parameters are tedious to manipulate and difficultto comprehend. To address this problem, we propose a method for managing parameters involved in plant modelmanipulation. Specifically, we introduce decomposition graphs as multiscale representations of plant structuresand present interactive tools for designing trees that operate on decomposition graphs. The supported operationsinclude browsing of the parameter space, editing of generalized parameters (scalars, functions, and branchingsystem silhouettes), and the definition of dependencies between parameters. We illustrate our method by creatingmodels of bonsai trees.'],\n",
              " '97_entity_entities_name_disambiguation': [\"Automatic Entity Recognition and Typing in Massive Text Data.[SEP]In today's computerized and information-based society, individuals are constantly presented with vast amounts of text data, ranging from news articles, scientific publications, product reviews, to a wide range of textual information from social media. To extract value from these large, multi-domain pools of text, it is of great importance to gain an understanding of entities and their relationships. In this tutorial, we introduce data-driven methods to recognize typed entities of interest in massive, domain-specific text corpora. These methods can automatically identify token spans as entity mentions in documents and label their fine-grained types (e.g., people, product and food) in a scalable way. Since these methods do not rely on annotated data, predefined typing schema or hand-crafted features, they can be quickly adapted to a new domain, genre and language. We demonstrate on real datasets including various genres (e.g., news articles, discussion forum posts, and tweets), domains (general vs. bio-medical domains) and languages (e.g., English, Chinese, Arabic, and even low-resource languages like Hausa and Yoruba) how these typed entities aid in knowledge discovery and management.\",\n",
              "  'Robust Entity Resolution using Random Graphs.[SEP]Entity resolution (ER) seeks to identify which records in a data set refer to the same real-world entity. Given the diversity of ways in which entities can be represented, matched and distinguished, ER is known to be a challenging task for automated strategies, but relatively easier for expert humans. In our work, we abstract the knowledge of experts with the notion of a binary oracle. Our oracle can answer questions of the form \"do records u and v refer to the same entity?\" under a flexible error model, allowing for some questions to be more difficult to answer correctly than others.',\n",
              "  'Entity Resolution with Markov Logic.[SEP]Entity resolution is the problem of determining which records in a database refer to the same entities, and is a crucial and expensive step in the data mining process. Interest in it has grown rapidly, and many approaches have been proposed. However, they tend to address only isolated aspects of the problem, and are often ad hoc. This paper proposes a well-founded, integrated solution to the entity resolution problem based on Markov logic. Markov logic combines first-order logic and probabilistic graphical models by attaching weights to first-order formulas, and viewing them as templates for features of Markov networks. We show how a number of previous approaches can be formulated and seamlessly combined in Markov logic, and how the resulting learning and inference problems can be solved efficiently. Experiments on two citation databases show the utility of this approach, and evaluate the contribution of the different components.'],\n",
              " '98_interruptions_interruption_interruptibility_task': [\"Investigating interruptions in the context of computerised cognitive testing for older adults.[SEP]Interruptions in the home pose a threat to the validity of self-administered computerised cognitive testing. We report the findings of a laboratory experiment investigating the effects of increased interruption workload demand on older adults' computerised cognitive test performance. Related work has reported interruptions having a range of inhibitory and facilitatory effects on primary task performance. Cognitive ageing literature suggests that increased interruption workload demand should have greater detrimental effects on older adults' performance, when compared to younger adults. With 36 participants from 3 age groups (20-54, 55-69, 70+), we found divergent effects of increased interruption demand on two primary tasks. Results suggest that older and younger adults experience interruptions differently, but at no age is test performance compromised by demanding interruptions. This finding is reassuring with respect to the success of a self-administered computerised cognitive assessment test, and is likely to be useful for other applications used by older adults.\",\n",
              "  \"Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors.[SEP]Interruptions of knowledge workers are common and can cause a high cost if they happen at inopportune moments. With recent advances in psycho-physiological sensors and their link to cognitive and emotional states, we are interested whether such sensors might be used to measure interruptibility of a knowledge worker. In a lab and a field study with a total of twenty software developers, we examined the use of psycho-physiological sensors in a real-world context. The results show that a Naive Bayes classifier based on psycho-physiological features can be used to automatically assess states of a knowledge worker's interruptibility with high accuracy in the lab as well as in the field. Our results demonstrate the potential of these sensors to avoid expensive interruptions in a real-world context. Based on brief interviews, we further discuss the usage of such an interruptibility measure and interruption support for software developers.\",\n",
              "  'The effects of time constraints on user behavior for deferrable interruptions.[SEP]Previous studies of multitasking have highlighted the importance of cognitive load in interruptibility by showing that forced interruptions are least disruptive when cognitive load is low, and also that users prefer to address interruptions at low-load points when given a choice. We present an empirical study that uses a ringing-phone scenario to examine how users manage deferrable interruptions in the presence of varying time constraints. We found that while cognitive load did influence multitasking as expected, the time constraints placed on the user also had a significant impact. In particular, we observed three distinct strategies for addressing interruption: the expected strategy of switching at low-load points, but also two other strategies of continuing on after a low-load point or giving up at a high-load point. The presence of the latter two strategies strongly suggests that users can adapt their multitasking behavior with respect to the time constraints of the interrupting task.'],\n",
              " '99_coordination_interpersonal_synchrony_actions': ['Interpersonal Coordination of Perception and Memory in Real-Time Online Social Interaction.[SEP]The quiet hum of interpersonal coordination that runs throughout social communication and interaction shows how individuals can subtly influence one another’s behaviors, thoughts, and emotions over time. While the majority of research on coordination studies face-to-face interaction, recent advances in crowdsourcing afford the opportunity to conduct large-scale, real-time social interaction experiments. We take advantage of these tools to explore interpersonal coordination in a “minimally interactive context,” distilling the richness of natural communication into a tightly controlled setting to explore how people become coupled in their perceptual and memory systems while performing a task together. Consistent with previous work on postural sway and gaze, we found that individuals become coupled to one another’s cognitive processes without needing to be co-located or fully interactive with their partner; interestingly, although participants had no information about their partner and no means of direct communication, we also found hints that social forces can shape minimally interactive contexts, similar to effects observed in face-to-face interaction.',\n",
              "  'Facilitating interpersonal action coordination in a movement control task.[SEP]The present experiment examined how individuals and dyads coordinate action in a movement control task either with or without additional action effects. Participants pressed computer keys to keep a moving dot stimulus within a rectangle by certain key-movement mapping. Pressing a key could also cause visual, auditory, or no effect. Participants completed the task either alone or with a partner they could neither see nor hear. The results showed that individuals had better performance and longer key-press than dyads. The performance of dyads was improved by auditory effects, whereas the performance of individuals was not influenced by any additional action effect. In a subsequent STROOP-like task, participants were asked to press a computer key they used in the movement control task while being primed by either visual or auditory effects. The results revealed an association between auditory effects and correspondent key, whereas no such association was found for visual effects.',\n",
              "  'Synchronizing to Learn and Like.[SEP]Ever seen two people walking down the street in the exact same pace? This kind of interpersonal synchrony has been observed in both humans, as well as in animals (e.g., large groups of fireflies flash at the same time, schools of fish and flocks of birds synchronize their movement). For animals it appears to be beneficial (for survival) to synchronize their behavior, but what are the benefits for humans to do so? There are indications that interpersonal synchrony supports social bonding. Previous studies have shown that interpersonal synchrony can have both an effect on (e.g., increases memory), and can be affected by social factors (e.g., higher likeability ratings, more interpersonal synchrony). The goal of the present study was to examine whether social factors (e.g., popularity, friendship) affect interpersonal synchrony when working together. Furthermore, we looked at the relation between interpersonal synchrony and learning and likeability.'],\n",
              " '9_dimensional_visualization_multidimensional_scatterplots': ['SADIRE: a context-preserving sampling technique for dimensionality reduction visualizations.[SEP]Sampling techniques are widely used in the effort to reduce complexity and improve interpretability of datasets. Given the enormous availability of data, these techniques try to select representative data points that inherently reflect the data structure. In this work, we propose a novel sampling technique that preserves the structures imposed by dimensionality reduction techniques when visualized as scatter plots. In the experiments, we demonstrate how our technique is able to reflect the class boundaries and layout structures, besides decreasing redundancy of the datasets visualized as scatter plots. We also provide an user experiment regarding the perception of sampling from scatter plot visualizations.',\n",
              "  'Role of Human Perception in Cluster-based Visual Analysis of Multidimensional Data Projections.[SEP]Visualization of high-dimensional data requires a mapping to a visual space. Whenever the goal is to preserve similarity relations, multidimensional projections or other dimension reduction techniques are commonly used to project high-dimensional data point to a 2D point using a certain strategy for the 2D layout.Typical analysis tasks for projected multidimensional data do not necessarily match the expectations of human perception. Learning more about the effectiveness of projection layouts from a users perspective is an important step towards consolidating their role in supporting visual analytics tasks. Those tasks often involve detecting and correlating clusters. To understand the role of orientation and cluster properties of size, shape and density, we first conducted a study with synthetic 2D scatter plots, where we can set the respective properties manually. Then we picked five projection methods representative of different approaches to generate layouts of high dimensional dat',\n",
              "  \"Voronoi Diagram Based Dimensional Anchor Assessment for Radial Visualizations.[SEP]Selecting the most expressed dimensions from high dimensional data sets has motivated the design and application of a variety of statistical and machine learning techniques. Here, in our current work, we introduce a metric for assessing the effectiveness of these methods. Our formulation is based on the broad concepts of: (a) devising a formal method of partitioning a visualization's image space; (b) identifying regions that indicate the relative strength of the dimension selection based on how well they are populated by data images; and (c) similarily identifying those regions indicating a poor selection of dimensions. In particular, we explore assessing the quality of radial visualizations. Dimension selection in this class of visualizations strongly effects visualization quality and the sensitivity of cluster formation. We demonstrate the usefulness of Voronoi partitioning the RadViz image space; quantifying radial visualization quality is a direct measure of dimension selection. This work continues to develop and refine the formal theory behind the general class of Normalized Radial Visualizations, including RadViz.\"]}"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        },
        "id": "oVgkLEZeN0Td",
        "outputId": "a9ca9018-6e7c-4315-f544-9cf21ab41d5c"
      },
      "source": [
        "dict_values = repre_docs.values()\n",
        "docs = list(dict_values)[0]\n",
        "docs[0].split('.')[0]"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'list'>\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Target Temperature Driven Dynamic Flame Animation'"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rojHiqM0RYBZ",
        "outputId": "e46dae7a-f186-4aa4-e851-0d65cf8ea0a6"
      },
      "source": [
        "dict_keys = list(repre_docs.keys())\n",
        "dict_keys"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0_flow_fluid_vortex_jet',\n",
              " '1_language_word_linguistic_lexical',\n",
              " '2_visualization_topic_visual_visualizations',\n",
              " '3_recommendation_recommender_recommendations_users',\n",
              " '4_graph_graphs_network_networks',\n",
              " '5_shape_mesh_meshes_subdivision',\n",
              " '6_game_games_sports_play',\n",
              " '7_light_illumination_rendering_lighting',\n",
              " '8_database_query_queries_join',\n",
              " '9_dimensional_visualization_multidimensional_scatterplots',\n",
              " '10_motion_animation_motions_animations',\n",
              " '11_music_musical_voice_sound',\n",
              " '12_education_educational_teaching_classroom',\n",
              " '13_driving_vehicle_vehicles_driver',\n",
              " '14_gesture_gestures_touch_finger',\n",
              " '15_classification_class_feature_kernel',\n",
              " '16_gaze_eye_attention_head',\n",
              " '17_haptic_tactile_force_virtual',\n",
              " '18_rendering_graphics_gpu_splatting',\n",
              " '19_mining_frequent_itemsets_rules',\n",
              " '20_image_images_retrieval_recognition',\n",
              " '21_software_programmers_collaboration_developers',\n",
              " '22_brain_cognitive_attention_visual',\n",
              " '23_trajectory_trajectories_mobility_urban',\n",
              " '24_graphics_graphic_standards_phigs',\n",
              " '25_series_time_patterns_mining',\n",
              " '26_fabrication_printing_print_manufacturing',\n",
              " '27_smart_activities_context_interfaces',\n",
              " '28_vessel_imaging_ultrasound_clinical',\n",
              " '29_texture_textures_synthesis_image',\n",
              " '30_decision_choice_risk_risky',\n",
              " '31_weather_visualization_climate_ocean',\n",
              " '32_ray_rays_traversal_rendering',\n",
              " '33_twitter_tweets_media_sentiment',\n",
              " '34_creativity_painting_art_creative',\n",
              " '35_causal_beliefs_evidence_belief',\n",
              " '36_privacy_security_private_protection',\n",
              " '37_urban_city_building_buildings',\n",
              " '38_transaction_transactions_concurrency_distributed',\n",
              " '39_displays_display_navigation_lenses',\n",
              " '40_search_web_information_pages',\n",
              " '41_category_categories_categorization_similarity',\n",
              " '42_crowdsourcing_workers_crowd_worker',\n",
              " '43_patient_patients_care_clinical',\n",
              " '44_diagrams_diagrammatic_diagram_logic',\n",
              " '45_color_colors_palette_palettes',\n",
              " '46_hci_design_research_practice',\n",
              " '47_robot_robots_robotic_robotics',\n",
              " '48_label_labels_unlabeled_classification',\n",
              " '49_keyboard_keyboards_touch_finger',\n",
              " '50_sketching_sketches_drawing_design',\n",
              " '51_facial_face_animation_faces',\n",
              " '52_machine_fairness_deep_explanations',\n",
              " '53_papers_conference_issue_editorial',\n",
              " '54_heritage_museum_visitors_museums',\n",
              " '55_number_symbolic_magnitude_numbers',\n",
              " '56_facebook_social_privacy_friends',\n",
              " '57_influence_social_networks_network',\n",
              " '58_walking_virtual_locomotion_reality',\n",
              " '59_reality_augmented_virtual_interaction',\n",
              " '60_molecules_atoms_molecule_halos',\n",
              " '61_memory_insight_solving_task',\n",
              " '62_spline_splines_curves_cubic',\n",
              " '63_clustering_clusters_cluster_clusterings',\n",
              " '64_impaired_visually_tactile_impairments',\n",
              " '65_distributed_parallel_scientific_convergence',\n",
              " '66_wikipedia_communities_community_newcomers',\n",
              " '67_metaphors_metaphor_analogical_analogy',\n",
              " '68_crowd_crowds_simulation_pedestrians',\n",
              " '69_conversational_dialogue_agent_conversation',\n",
              " '70_tracking_camera_tracker_pose',\n",
              " '71_shadow_shadows_light_rendering',\n",
              " '72_narrative_story_stories_storytelling',\n",
              " '73_authentication_passwords_password_security',\n",
              " '74_students_math_solving_achievement',\n",
              " '75_health_patients_self_online',\n",
              " '76_route_map_navigation_wayfinding',\n",
              " '77_gene_genome_genomic_visualization',\n",
              " '78_image_smoothing_denoising_inpainting',\n",
              " '79_construction_visualisation_building_heritage',\n",
              " '80_solid_solids_boundary_polyhedral',\n",
              " '81_electricity_households_heating_smart',\n",
              " '82_fractal_fractals_compression_chaos',\n",
              " '83_memories_diary_life_everyday',\n",
              " '84_civic_civics_infrastructure_citizens',\n",
              " '85_xml_query_xquery_queries',\n",
              " '86_moral_dilemmas_judgment_harm',\n",
              " '87_volume_volumetric_rendering_opacity',\n",
              " '88_pointing_target_movement_targets',\n",
              " '89_indoor_location_positioning_rfid',\n",
              " '90_diffusion_tensor_tracts_brain',\n",
              " '91_ontology_schema_ontologies_schemas',\n",
              " '92_email_emails_mail_inbox',\n",
              " '93_security_traffic_cyber_intrusion',\n",
              " '94_outlier_outliers_datasets_distance',\n",
              " '95_video_videos_frames_temporal',\n",
              " '96_tree_trees_plant_plants',\n",
              " '97_entity_entities_name_disambiguation',\n",
              " '98_interruptions_interruption_interruptibility_task',\n",
              " '99_coordination_interpersonal_synchrony_actions',\n",
              " '100_terrain_rendering_terrains_resolution',\n",
              " '101_stream_drift_ensemble_drifting',\n",
              " '102_cartograms_map_maps_cartographic',\n",
              " '103_design_clothing_clothes_designers',\n",
              " '104_skeleton_skeletons_segmentation_mesh',\n",
              " '105_matrix_factorization_nonnegative_matrices',\n",
              " '106_parallel_compiler_cache_parallelism',\n",
              " '107_event_events_sentinel_ranking',\n",
              " '108_wavelet_wavelets_multiresolution_subdivision',\n",
              " '109_children_participatory_child_technologies',\n",
              " '110_tabletop_collaboration_touch_groupware',\n",
              " '111_collision_collisions_deformable_rigid',\n",
              " '112_chatbot_chatbots_chat_conversation',\n",
              " '113_hair_hairs_cloth_hairstyles',\n",
              " '114_watermarking_watermark_watermarks_attacks',\n",
              " '115_surgical_surgery_laparoscopic_minimally',\n",
              " '116_subspace_clustering_clusters_subspaces',\n",
              " '117_location_recommendation_friends_locations',\n",
              " '118_parents_parenting_child_life',\n",
              " '119_location_privacy_crowdsensing_obfuscation',\n",
              " '120_dance_dancers_dancer_choreographers',\n",
              " '121_line_clipping_algorithms_polygon',\n",
              " '122_occlusion_culling_rendering_occluded',\n",
              " '123_multimodal_modality_modalities_speech',\n",
              " '124_religious_dreaming_religion_cultural',\n",
              " '125_spreadsheet_spreadsheets_web_programming',\n",
              " '126_cleaning_repairing_repair_tuples',\n",
              " '127_polygons_polygon_hull_algorithm',\n",
              " '128_spatial_languages_across_meaning',\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner',\n",
              " '130_meetings_communication_informal_messaging',\n",
              " '131_provenance_lakes_workflows_lake']"
            ]
          },
          "metadata": {},
          "execution_count": 94
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-0p0jZ6ASE2O",
        "outputId": "d62696d8-ff54-40c4-8ef4-970e6a35e3c5"
      },
      "source": [
        "docs"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Target Temperature Driven Dynamic Flame Animation.[SEP]Fire/flame plays an important role in virtual environment. Controlling the flame behavior in an intuitive yet precise manner remains a challenging open problem. In this paper, a target temperature driven simulation method is proposed to control flame animation. The diverse descriptions of target flame are unified by temperature field. An adaptive control force is presented to control the degree of target-driven changing over the temperature field. A bidirectional iterative method is proposed to subdivide the final goal into a plurality of intermediate targets. We take geometric model, image, and temperature field as target flames to test our method. Experimental results show that this method allows complex flame animations to be controllably generated with very little additional cost compared to ordinary flow simulations.',\n",
              " 'Simulation and interaction of fluid dynamics.[SEP]In the fluid simulation, the fluids and their surroundings may greatly change properties such as shape and temperature simultaneously, and different surroundings would characterize different interactions, which would change the shape and motion of the fluids in different ways. On the other hand, interactions among fluid mixtures of different kinds would generate more comprehensive behavior. To investigate the interaction behavior in physically based simulation of fluids, it is of importance to build physically correct models to represent the varying interactions between fluids and the environments, as well as interactions among the mixtures. In this paper, we will make a simple review of the interactions, and focus on those most interesting to us, and model them with various physical solutions. In particular, more detail will be given on the simulation of miscible and immiscible binary mixtures. In some of the methods, it is advantageous to be taken with the graphics processing unit (GPU) to achieve real-time computation for middle-scale simulation.',\n",
              " 'Visual simulation of smoke.[SEP]In this paper, we propose a new approach to numerical smoke simulation for computer graphics applications. The method proposed here exploits physics unique to smoke in order to design a numerical method that is both fast and efficient on the relatively coarse grids traditionally used in computer graphics applications (as compared to the much finer grids used in the computational fluid dynamics literature). We use the inviscid Euler equations in our model, since they are usually more appropriate for gas modeling and less computationally intensive than the viscous Navier-Stokes equations used by others. In addition, we introduce a physically consistent vorticity confinement term to model the small scale rolling features characteristic of smoke that are absent on most coarse grid simulations. Our model also correctly handles the inter-action of smoke with moving objects.',\n",
              " 'Construction of Vector Field Hierarchies.[SEP]Presents a method for the hierarchical representation of vector fields. Our approach is based on iterative refinement using clustering and principal component analysis. The input to our algorithm is a discrete set of points with associated vectors. The algorithm generates a top-down segmentation of the discrete field by splitting clusters of points. We measure the error of the various approximation levels by measuring the discrepancy between streamlines generated by the original discrete field and its approximations based on much smaller discrete data sets. Our method assumes no particular structure of the field, nor does it require any topological connectivity information. It is possible to generate multi-resolution representations of vector fields using this approach.',\n",
              " 'Segmentation of Discrete Vector Fields.[SEP]In this paper, we propose an approach for 2D discrete vector field segmentation based on the Green function and normalized cut. The method is inspired by discrete Hodge decomposition such that a discrete vector field can be broken down into three simpler components, namely, curl-free, divergence-free, and harmonic components. We show that the Green function method (GFM) can be used to approximate the curl-free and the divergence-free components to achieve our goal of the vector field segmentation. The final segmentation curves that represent the boundaries of the influence region of singularities are obtained from the optimal vector field segmentations. These curves are composed of piecewise smooth contours or streamlines. Our method is applicable to both linear and nonlinear discrete vector fields. Experiments show that the segmentations obtained using our approach essentially agree with human perceptual judgement',\n",
              " 'PLIC: Briding the Gap Between Streamlines and LIC.[SEP]This paper explores mapping strategies for generating LIC-like images from streamlines and streamline-like images from LIC. The main contribution of this paper is a technique which we call pseudo-LIC or PLIC. By adjusting a small set of key parameters, PLIC can generate flow visualizations that span the spectrum of streamline-like to LIC-like images. Among the advantages of PLIC are: image quality comparable with LIC, performance speedup over LIC, use of a template texture that is independent of the size of the flow field, handles the problem of multiple streamlines occupying the same pixel in image space, reduced aliasing, applicability to time varying data sets, and variable speed animation.',\n",
              " 'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow.[SEP]Numerical simulation of scramjet asymmetric nozzle flow is carried out to visualize and investigate the effects of interaction between engine exhaust and hypersonic external flow. The Single Expansion Ramp Nozzle (SERN) configuration studied here consists of flat ramp and a cowl with different combinations of ramp angle and cowl geometry. UsingPARAS 3D, simulations are performed for a free stream Mach number of 6.5 that constitutes the external flow around the vehicle. Appropriate specific heats ratio has been simulated for the jet and free stream flow. External shock wave due to jet plume interaction with free stream flow, the internal barrel shock wave and the shear layer emanating from the cowl trailing edge and sidewalls are well captured. Wall static pressure distribution on the nozzle ramp for different nozzle expansion angles has been computed for both with and without side fence. Axial thrust and normal force have been evaluated by integrating the wall static pressure. Effect of cowl length variation and side fence on the SERN performance has also been studied and found to be quite significant. Based on this study, an optimum ramp angle at which the SERN generates maximum axial thrust is obtained. SERN angle of 20° was found to be optimum when the flight axis coincides with nozzle axis.',\n",
              " 'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump.[SEP]Comparison between numerical simulation and experimental results for unsteady flow field in a radial diffuser pump is presented for the design operating point. The numerical result is obtained by solving three-dimensional, unsteady Reynolds-averaged Navier-Stokes equations by the commercial CFD code CFX-10 withk-ω based shear stress transport turbulence model. Two-dimensional PIV measurements are conducted to acquire the experiment result. The phase-averaged velocity and turbulent kinetic energy fields are compared in detail between the results by the two methods in the impeller, diffuser and return channel regions. The qualitative comparison between CFD and PIV results is quite good in the phase-averaged velocity field. Although the turbulence level by PIV is higher than that by CFD generally, the main turbulence features are nearly the same. Furthermore, the blade orientation effect and other associated unsteady phenomena are also examined, in order to enhance the understanding on impeller-diffuser interaction in a radial diffuser pump.',\n",
              " 'Characteristic flow phenomena on a tee-branch pipe.[SEP]Osao, A. et al., Advanced Materials Research, 33-37 (2008), 1037–1042.']"
            ]
          },
          "metadata": {},
          "execution_count": 95
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iaHvTz66RCGk",
        "outputId": "cb27747b-f0d4-4607-c177-d2d8e2d62541"
      },
      "source": [
        "topic_docs = []\n",
        "i = 0\n",
        "for doc in docs:\n",
        "  topic_docs.append(doc.split('.')[0])\n",
        "topic_docs"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Target Temperature Driven Dynamic Flame Animation',\n",
              " 'Simulation and interaction of fluid dynamics',\n",
              " 'Visual simulation of smoke',\n",
              " 'Construction of Vector Field Hierarchies',\n",
              " 'Segmentation of Discrete Vector Fields',\n",
              " 'PLIC: Briding the Gap Between Streamlines and LIC',\n",
              " 'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow',\n",
              " 'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump',\n",
              " 'Characteristic flow phenomena on a tee-branch pipe']"
            ]
          },
          "metadata": {},
          "execution_count": 97
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6zGoR5MyRBWI",
        "outputId": "e330b13c-d6ec-4c4c-cae5-d859875e9f08"
      },
      "source": [
        "dict_keys = list(repre_docs.keys())\n",
        "dict_keys"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['0_flow_fluid_vortex_jet',\n",
              " '1_language_word_linguistic_lexical',\n",
              " '2_visualization_topic_visual_visualizations',\n",
              " '3_recommendation_recommender_recommendations_users',\n",
              " '4_graph_graphs_network_networks',\n",
              " '5_shape_mesh_meshes_subdivision',\n",
              " '6_game_games_sports_play',\n",
              " '7_light_illumination_rendering_lighting',\n",
              " '8_database_query_queries_join',\n",
              " '9_dimensional_visualization_multidimensional_scatterplots',\n",
              " '10_motion_animation_motions_animations',\n",
              " '11_music_musical_voice_sound',\n",
              " '12_education_educational_teaching_classroom',\n",
              " '13_driving_vehicle_vehicles_driver',\n",
              " '14_gesture_gestures_touch_finger',\n",
              " '15_classification_class_feature_kernel',\n",
              " '16_gaze_eye_attention_head',\n",
              " '17_haptic_tactile_force_virtual',\n",
              " '18_rendering_graphics_gpu_splatting',\n",
              " '19_mining_frequent_itemsets_rules',\n",
              " '20_image_images_retrieval_recognition',\n",
              " '21_software_programmers_collaboration_developers',\n",
              " '22_brain_cognitive_attention_visual',\n",
              " '23_trajectory_trajectories_mobility_urban',\n",
              " '24_graphics_graphic_standards_phigs',\n",
              " '25_series_time_patterns_mining',\n",
              " '26_fabrication_printing_print_manufacturing',\n",
              " '27_smart_activities_context_interfaces',\n",
              " '28_vessel_imaging_ultrasound_clinical',\n",
              " '29_texture_textures_synthesis_image',\n",
              " '30_decision_choice_risk_risky',\n",
              " '31_weather_visualization_climate_ocean',\n",
              " '32_ray_rays_traversal_rendering',\n",
              " '33_twitter_tweets_media_sentiment',\n",
              " '34_creativity_painting_art_creative',\n",
              " '35_causal_beliefs_evidence_belief',\n",
              " '36_privacy_security_private_protection',\n",
              " '37_urban_city_building_buildings',\n",
              " '38_transaction_transactions_concurrency_distributed',\n",
              " '39_displays_display_navigation_lenses',\n",
              " '40_search_web_information_pages',\n",
              " '41_category_categories_categorization_similarity',\n",
              " '42_crowdsourcing_workers_crowd_worker',\n",
              " '43_patient_patients_care_clinical',\n",
              " '44_diagrams_diagrammatic_diagram_logic',\n",
              " '45_color_colors_palette_palettes',\n",
              " '46_hci_design_research_practice',\n",
              " '47_robot_robots_robotic_robotics',\n",
              " '48_label_labels_unlabeled_classification',\n",
              " '49_keyboard_keyboards_touch_finger',\n",
              " '50_sketching_sketches_drawing_design',\n",
              " '51_facial_face_animation_faces',\n",
              " '52_machine_fairness_deep_explanations',\n",
              " '53_papers_conference_issue_editorial',\n",
              " '54_heritage_museum_visitors_museums',\n",
              " '55_number_symbolic_magnitude_numbers',\n",
              " '56_facebook_social_privacy_friends',\n",
              " '57_influence_social_networks_network',\n",
              " '58_walking_virtual_locomotion_reality',\n",
              " '59_reality_augmented_virtual_interaction',\n",
              " '60_molecules_atoms_molecule_halos',\n",
              " '61_memory_insight_solving_task',\n",
              " '62_spline_splines_curves_cubic',\n",
              " '63_clustering_clusters_cluster_clusterings',\n",
              " '64_impaired_visually_tactile_impairments',\n",
              " '65_distributed_parallel_scientific_convergence',\n",
              " '66_wikipedia_communities_community_newcomers',\n",
              " '67_metaphors_metaphor_analogical_analogy',\n",
              " '68_crowd_crowds_simulation_pedestrians',\n",
              " '69_conversational_dialogue_agent_conversation',\n",
              " '70_tracking_camera_tracker_pose',\n",
              " '71_shadow_shadows_light_rendering',\n",
              " '72_narrative_story_stories_storytelling',\n",
              " '73_authentication_passwords_password_security',\n",
              " '74_students_math_solving_achievement',\n",
              " '75_health_patients_self_online',\n",
              " '76_route_map_navigation_wayfinding',\n",
              " '77_gene_genome_genomic_visualization',\n",
              " '78_image_smoothing_denoising_inpainting',\n",
              " '79_construction_visualisation_building_heritage',\n",
              " '80_solid_solids_boundary_polyhedral',\n",
              " '81_electricity_households_heating_smart',\n",
              " '82_fractal_fractals_compression_chaos',\n",
              " '83_memories_diary_life_everyday',\n",
              " '84_civic_civics_infrastructure_citizens',\n",
              " '85_xml_query_xquery_queries',\n",
              " '86_moral_dilemmas_judgment_harm',\n",
              " '87_volume_volumetric_rendering_opacity',\n",
              " '88_pointing_target_movement_targets',\n",
              " '89_indoor_location_positioning_rfid',\n",
              " '90_diffusion_tensor_tracts_brain',\n",
              " '91_ontology_schema_ontologies_schemas',\n",
              " '92_email_emails_mail_inbox',\n",
              " '93_security_traffic_cyber_intrusion',\n",
              " '94_outlier_outliers_datasets_distance',\n",
              " '95_video_videos_frames_temporal',\n",
              " '96_tree_trees_plant_plants',\n",
              " '97_entity_entities_name_disambiguation',\n",
              " '98_interruptions_interruption_interruptibility_task',\n",
              " '99_coordination_interpersonal_synchrony_actions',\n",
              " '100_terrain_rendering_terrains_resolution',\n",
              " '101_stream_drift_ensemble_drifting',\n",
              " '102_cartograms_map_maps_cartographic',\n",
              " '103_design_clothing_clothes_designers',\n",
              " '104_skeleton_skeletons_segmentation_mesh',\n",
              " '105_matrix_factorization_nonnegative_matrices',\n",
              " '106_parallel_compiler_cache_parallelism',\n",
              " '107_event_events_sentinel_ranking',\n",
              " '108_wavelet_wavelets_multiresolution_subdivision',\n",
              " '109_children_participatory_child_technologies',\n",
              " '110_tabletop_collaboration_touch_groupware',\n",
              " '111_collision_collisions_deformable_rigid',\n",
              " '112_chatbot_chatbots_chat_conversation',\n",
              " '113_hair_hairs_cloth_hairstyles',\n",
              " '114_watermarking_watermark_watermarks_attacks',\n",
              " '115_surgical_surgery_laparoscopic_minimally',\n",
              " '116_subspace_clustering_clusters_subspaces',\n",
              " '117_location_recommendation_friends_locations',\n",
              " '118_parents_parenting_child_life',\n",
              " '119_location_privacy_crowdsensing_obfuscation',\n",
              " '120_dance_dancers_dancer_choreographers',\n",
              " '121_line_clipping_algorithms_polygon',\n",
              " '122_occlusion_culling_rendering_occluded',\n",
              " '123_multimodal_modality_modalities_speech',\n",
              " '124_religious_dreaming_religion_cultural',\n",
              " '125_spreadsheet_spreadsheets_web_programming',\n",
              " '126_cleaning_repairing_repair_tuples',\n",
              " '127_polygons_polygon_hull_algorithm',\n",
              " '128_spatial_languages_across_meaning',\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner',\n",
              " '130_meetings_communication_informal_messaging',\n",
              " '131_provenance_lakes_workflows_lake']"
            ]
          },
          "metadata": {},
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBQ4CJrVZdLQ",
        "outputId": "b35ed062-9b13-4dd5-d6d4-67dc54fbc657"
      },
      "source": [
        "topic_values = list(repre_docs.values())\n",
        "len(topic_values)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "132"
            ]
          },
          "metadata": {},
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GdasDOShQCBq",
        "outputId": "78a2f45c-fcd1-44b9-d5d3-0dc7e02d6ff6"
      },
      "source": [
        "repre_list = {}\n",
        "topic_num = 0\n",
        "for topic in topic_values:\n",
        "  # repre_list[topic_num]:[]\n",
        "  key = dict_keys[topic_num]\n",
        "  repre_list[key] = []\n",
        "  for doc in topic:\n",
        "    repre_list[key].append(doc.split('.')[0])\n",
        "  topic_num += 1\n",
        "\n",
        "repre_list"
      ],
      "execution_count": 117,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'0_flow_fluid_vortex_jet': ['Target Temperature Driven Dynamic Flame Animation',\n",
              "  'Simulation and interaction of fluid dynamics',\n",
              "  'Visual simulation of smoke',\n",
              "  'Construction of Vector Field Hierarchies',\n",
              "  'Segmentation of Discrete Vector Fields',\n",
              "  'PLIC: Briding the Gap Between Streamlines and LIC',\n",
              "  'Numerical flow visualization of a Single Expansion Ramp Nozzle with hypersonic external flow',\n",
              "  'Qualitative comparison between numerical and experimental results of unsteady flow in a radial diffuser pump',\n",
              "  'Characteristic flow phenomena on a tee-branch pipe'],\n",
              " '100_terrain_rendering_terrains_resolution': ['Stereoscopic View-Dependent Visualization of Terrain Height Fields',\n",
              "  'LOD-Sprite Technique for Accelerated Terrain Rendering',\n",
              "  'Interactive Terrain Rendering van Volume Visualization on the Princeton Engine'],\n",
              " '101_stream_drift_ensemble_drifting': ['Dynamic Weighted Majority: A New Ensemble Method for Tracking Concept Drift',\n",
              "  'Polishing the Right Apple: Anytime Classification Also Benefits Data Streams with Constant Arrival Times',\n",
              "  'Detecting Recurring and Novel Classes in Concept-Drifting Data Streams'],\n",
              " '102_cartograms_map_maps_cartographic': ['Generating Tile Maps',\n",
              "  'A prototype Spatial Data Management System',\n",
              "  'A fast and economic scan-to-line-conversion algorithm'],\n",
              " '103_design_clothing_clothes_designers': ['From codes to patterns: designing interactive decoration for tableware',\n",
              "  'Bod-IDE: An Augmented Reality Sandbox for eFashion Garments',\n",
              "  \"What if HCI Becomes a Fashion Driven Discipline?[SEP]Recent research shows that fashion already exists in the HCI domain and influences and affects design and designers' thinking and practices throughout the design process\"],\n",
              " '104_skeleton_skeletons_segmentation_mesh': ['Analytic Curve Skeletons for 3D Surface Modeling and Processing',\n",
              "  'One-step Compact Skeletonization',\n",
              "  'Skeleton computation of orthogonal polyhedra'],\n",
              " '105_matrix_factorization_nonnegative_matrices': ['Unified Solution to Nonnegative Data Factorization Problems',\n",
              "  'Multiplicative Algorithms for Constrained Non-negative Matrix Factorization',\n",
              "  'Recovering Low-Rank and Sparse Matrices via Robust Bilateral Factorization'],\n",
              " '106_parallel_compiler_cache_parallelism': ['Speculative Execution and Branch Prediction on Parallel Machines',\n",
              "  'A Massively Parallel Optimizer for Expression Evaluation',\n",
              "  'Design considerations for parallel performance tools'],\n",
              " '107_event_events_sentinel_ranking': ['Exploring Flow, Factors, and Outcomes of Temporal Event Sequences with the Outflow Visualization',\n",
              "  'Life on the Line: Interacting with Temporal Event Sequence Representations',\n",
              "  'Evaluating Alignment Approaches in Superimposed Time-Series and Temporal Event-Sequence Visualizations'],\n",
              " '108_wavelet_wavelets_multiresolution_subdivision': ['Biorthogonal wavelet construction for hybrid quad/triangle meshes',\n",
              "  'Graph-Based Wavelet Representation of Multi-Variate Terrain Data',\n",
              "  'Multiresolution Analysis on Irregular Surface Meshes'],\n",
              " '109_children_participatory_child_technologies': ['Child-personas: fact or fiction?[SEP]This paper introduces a practice-based, child-centric method of creating child-user archetypes which extends adult-based persona theory to interaction design with children',\n",
              "  \"Children and 'smart' technologies: can children's experiences be interpreted and coded?[SEP]This paper has a focus on young children and their emerging new technologies\",\n",
              "  'Co-Designing with Preschoolers Using Fictional Inquiry and Comicboarding'],\n",
              " '10_motion_animation_motions_animations': ['Real time animation of dynamic processes',\n",
              "  'Real time falling animation with active and protective responses',\n",
              "  'A system for algorithm animation'],\n",
              " '110_tabletop_collaboration_touch_groupware': ['Evaluating the effectiveness of height visualizations for improving gestural communication at distributed tabletops',\n",
              "  'Making big gestures: effects of gesture size on observability and identification for co-located group awareness',\n",
              "  'Exploring the effects of group size and table size on interactions with tabletop shared-display groupware'],\n",
              " '111_collision_collisions_deformable_rigid': ['Interactive continuous collision detection for non-convex polyhedra',\n",
              "  'A Collision Detection and Response Scheme for Simplified Physically Based Animation',\n",
              "  'Continuous collision detection for deformable objects using permissible clusters'],\n",
              " '112_chatbot_chatbots_chat_conversation': ['Adding structured data in unstructured web chat conversation',\n",
              "  \"Transformation through Provocation?[SEP]Can a chatbot enable us to change our conceptions, to be critically reflective? To what extent can interaction with a technologically 'minimal' medium such as a chatbot evoke emotional engagement in ways that can challenge us to act on the world? In this paper, we discuss the design of a provocative bot, a 'bot of conviction', aimed at triggering conversations on complex topics (e\",\n",
              "  'A Conversation Analysis of Non-Progress and Coping Strategies with a Banking Task-Oriented Chatbot'],\n",
              " '113_hair_hairs_cloth_hairstyles': ['3D Hair sketching for real-time dynamic  key frame animations',\n",
              "  'Hybrid fur rendering: combining volumetric fur with explicit hair strands',\n",
              "  'Modeling Dynamic Hair as a Continuum'],\n",
              " '114_watermarking_watermark_watermarks_attacks': ['Secure Authentication Watermarking for Binary Images',\n",
              "  'A new multi-secret image sharing scheme based on DCT',\n",
              "  'Digital Watermarking: From Concepts to Real-Time Video Applications'],\n",
              " '115_surgical_surgery_laparoscopic_minimally': ['Keynote Speaker: Virtual Reality: Current Uses in Medical Simulation and Future',\n",
              "  'Evaluation of a tool-mounted guidance display for computer-assisted surgery',\n",
              "  'Modelling Techniques for Enhanced Realism in an Open Surgery Simulation'],\n",
              " '116_subspace_clustering_clusters_subspaces': ['Subspace Selection for Clustering High-Dimensional Data',\n",
              "  'Mining Quantitative Frequent Itemsets Using Adaptive Density-Based Subspace Clustering',\n",
              "  'Effective and Robust Mining of Temporal Subspace Clusters'],\n",
              " '117_location_recommendation_friends_locations': ['Towards social user profiling: unified and discriminative influence model for inferring home locations',\n",
              "  'Geo-activity recommendations by using improved feature combination',\n",
              "  'Followee recommendation in asymmetrical location-based social networks'],\n",
              " '118_parents_parenting_child_life': ['Dealing with death in design: developing systems for the bereaved',\n",
              "  'Looking for Respite and Support: Technological Opportunities for Spousal Caregivers',\n",
              "  'Understanding technology choices and values through social class'],\n",
              " '119_location_privacy_crowdsensing_obfuscation': ['Differential Location Privacy for Sparse Mobile Crowdsensing',\n",
              "  'Secure and private proofs for location-based activity summaries in urban areas',\n",
              "  'Active Sparse Mobile Crowd Sensing Based on Matrix Completion'],\n",
              " '11_music_musical_voice_sound': ['Dogmas of Understanding in Western Art Music Performance',\n",
              "  'Visualizing the Semantic Structure in Classical Music Works',\n",
              "  'Entrain: Encouraging Social Interaction in Collective Music Making',\n",
              "  'Short-term memory for tonal and verbal information: Comparison with absolute and non-absolute pitch possessors',\n",
              "  'What We Move to Moves Us: Biological Rhythmicity Predicts Musical Preferences',\n",
              "  'Embodying Theoretical Research in Music Cognition: Four Proposals for Theory-Driven Experimentation',\n",
              "  'Using language complexity to measure cognitive load for adaptive interaction design',\n",
              "  'The effect of speech recognition accuracy rates on the usefulness and usability of webcast archives',\n",
              "  'Patterns of Entry and Correction in Large Vocabulary Continuous Speech Recognition System',\n",
              "  'Aural Proxies and Directionally-Varying Reverberation for Interactive Sound Propagation in Virtual Environments',\n",
              "  'Efficient and Accurate Sound Propagation Using Adaptive Rectangular Decomposition',\n",
              "  'Source and Listener Directivity for Interactive Wave-Based Sound Propagation'],\n",
              " '120_dance_dancers_dancer_choreographers': ['Physical Skill and Idea Interaction in the Creation of New Dance Movements',\n",
              "  'Dance Movement: A Focus on the Technology',\n",
              "  'Designing Expressions of Movement Qualities'],\n",
              " '121_line_clipping_algorithms_polygon': ['Anti-Aliased Lines Using Run-Masks',\n",
              "  'A new approach to line and line segment clipping in homogeneous coordinates',\n",
              "  'A New Two Dimensional Line Clipping Algorithm for Small Windows'],\n",
              " '122_occlusion_culling_rendering_occluded': ['Towards Adaptive Occlusion Culling Using Camera Coherence',\n",
              "  'Bent Normals and Cones in Screen-space',\n",
              "  'Integrating Occlusion Culling with Levels of Detail through Hardly-Visible Sets'],\n",
              " '123_multimodal_modality_modalities_speech': ['Usability of user interfaces: from monomodal to multimodal',\n",
              "  'Multimodal Interaction within Ambient Environments: An Exploratory Study',\n",
              "  'Designing socially acceptable multimodal interaction in cooking assistants'],\n",
              " '124_religious_dreaming_religion_cultural': ['Immunity to error through misidentification and non-attributive self-reference',\n",
              "  'Predicting How People Feel: Ownership Matters for Preschoolers',\n",
              "  'New Developments in the Cognitive Science of Religion'],\n",
              " '125_spreadsheet_spreadsheets_web_programming': ['Visualization Exploration and Encapsulation via a Spreadsheet-Like Interface',\n",
              "  'Anti-Freeze for Large and Complex Spreadsheets: Asynchronous Formula Computation',\n",
              "  'Graphical Definitions: Expanding Spreadsheet Languages Through Direct Manipulation and Gestures'],\n",
              " '126_cleaning_repairing_repair_tuples': ['Tracing data errors with view-conditioned causality',\n",
              "  \"Don't be SCAREd: use SCalable Automatic REpairing with maximal likelihood and bounded changes\",\n",
              "  'A Perspective on Databases and Data Mining'],\n",
              " '127_polygons_polygon_hull_algorithm': ['The Implementation of a 2D Convex Hull Algorithm Using Perturbation',\n",
              "  'On Compatible Star Decompositions of Simple Polygons',\n",
              "  'Reducing the Number of Points on the Convex Hull Calculation Using the Polar Space Subdivision in E2'],\n",
              " '128_spatial_languages_across_meaning': ['Both symbolic and embodied representations contribute to spatial language processing; Evidence from younger and older adults',\n",
              "  '\"Natural concepts\" revisited in the spatial-topological domain: Universal tendencies in focal spatial relations',\n",
              "  'Spatial language and visual attention: A new approach to test linguistic relativity'],\n",
              " '129_ubicomp_ubiquitous_design_activitydesigner': ['Addressing Mobile Phone Diversity in Ubicomp Experience Development',\n",
              "  'Towards Deeper Understanding of User Experience with Ubiquitous Computing Systems: Systematic Literature Review and Design Framework',\n",
              "  'Rapidly Exploring Application Design Through Speed Dating'],\n",
              " '12_education_educational_teaching_classroom': ['Distinctive Approaches to Computer Graphics Education',\n",
              "  'Interactive computer graphics applied to chemistry: experiences and new developments',\n",
              "  'Integrating User Studies into Computer Graphics-Related Courses',\n",
              "  'Sara, the Lecturer: Improving Learning in Online Education with a Scaffolding-Based Conversational Agent',\n",
              "  'How Peripheral Data Visualisation Systems Support Secondary School Teachers during VLE-Supported Lessons',\n",
              "  'The Design of an Authoring Interface to Make eLearning Content Accessible'],\n",
              " '130_meetings_communication_informal_messaging': ['The doing of doing stuff: understanding the coordination of social group-activities',\n",
              "  'Accessible Online Meetings and Presentations',\n",
              "  'Automated Assistance for the Telemeeting Lifecycle'],\n",
              " '131_provenance_lakes_workflows_lake': ['C[SEP]Datasets are often derived by manipulating raw data with statistical software packages',\n",
              "  'When the Web is your Data Lake: Creating a Search Engine for Datasets on the Web',\n",
              "  'Debugging Big Data Analytics in Spark with [SEP]To process massive quantities of data, developers leverage Data-Intensive Scalable Computing (DISC) systems such as Apache Spark'],\n",
              " '13_driving_vehicle_vehicles_driver': ['The SKYNIVI Experience: Evoking Startle and Frustration in Dyads and Single Drivers',\n",
              "  'Autonomous Vehicle-Cyclist Interaction: Peril and Promise',\n",
              "  'CarNote: Reducing Misunderstanding between Drivers by Digital Augmentation',\n",
              "  'Learning to Estimate the Travel Time',\n",
              "  'Exploiting Spatio-Temporal Correlations with Multiple 3D Convolutional Neural Networks for Citywide Vehicle Flow Prediction',\n",
              "  'Co-Prediction of Multiple Transportation Demands Based on Deep Spatio-Temporal Neural Network',\n",
              "  'End-to-end Prediction of Driver Intention using 3D Convolutional Neural Networks',\n",
              "  'Learning Interaction-Aware Probabilistic Driver Behavior Models from Urban Scenarios',\n",
              "  'Addressing Inherent Uncertainty: Risk-Sensitive Behavior Generation for Automated Driving using Distributional Reinforcement Learning',\n",
              "  'Deep, spatially coherent Inverse Sensor Models with Uncertainty Incorporation using the evidential Framework',\n",
              "  'Deep Learning based Vehicle Position and Orientation Estimation via Inverse Perspective Mapping Image',\n",
              "  'Camera and LiDAR Fusion for On-road Vehicle Tracking with Reinforcement Learning',\n",
              "  'An Integrated Path-following and Yaw Motion Control Strategy for Autonomous Distributed Drive Electric Vehicles with Differential Steering',\n",
              "  'Predictive Trajectory Planning in Situations with Hidden Road Users Using Partially Observable Markov Decision Processes',\n",
              "  'Semi-Active Suspension Control on Bicycles: Anti-Dive during Road Excitation'],\n",
              " '14_gesture_gestures_touch_finger': ['Preschoolers understand the representational and communicative nature of iconic gestures',\n",
              "  'Gesture structure affects syntactic structure in speech',\n",
              "  'Sign processes in emergence of communication',\n",
              "  \"Understanding users' preferences for surface gestures\",\n",
              "  'Designer Led Computational Approach to Generate Mappings for Devices with Low Gestural Resolution',\n",
              "  'Designing Mid-Air TV Gestures for Blind People Using User- and Choice-Based Elicitation Approaches',\n",
              "  'CyclopsRing: Enabling Whole-Hand and Context-Aware Interactions Through a Fisheye Ring',\n",
              "  \"Small gestures go a long way: how many bits per gesture do recognizers actually need?[SEP]We investigate in this work the effect of bit depth on the performance of today's commonly used nearest-neighbor gesture recognizers\",\n",
              "  'Type-hover-swipe in 96 bytes: a motion sensing mechanical keyboard'],\n",
              " '15_classification_class_feature_kernel': ['Regularized discriminant analysis for high dimensional, low sample size data',\n",
              "  'Binary Classifier Calibration Using an Ensemble of Near Isotonic Regression Models',\n",
              "  'Transductive Component Analysis',\n",
              "  'Extracting key-substring-group features for text classification',\n",
              "  'A parallel learning algorithm for text classification',\n",
              "  'A Bayesian Hierarchical Model for Comparing Average F1 Scores'],\n",
              " '16_gaze_eye_attention_head': ['Detecting eye contact using wearable eye-tracking glasses',\n",
              "  'VRpursuits: interaction in virtual reality using smooth pursuit eye movements',\n",
              "  'Pursuits: spontaneous interaction with displays based on smooth pursuit eye movement and moving targets'],\n",
              " '17_haptic_tactile_force_virtual': ['Haptic Links: Bimanual Haptics for Virtual Reality Using Variable Stiffness Actuation',\n",
              "  'Too Hot to Handle: An Evaluation of the Effect of Thermal Visual Representation on User Grasping Interaction in Virtual Reality',\n",
              "  'Haptic Device Control - Will it Fit Standardized Input Models?[SEP]Over recent years a wide variety of interaction devices involving haptic feedback have been brought to the market, but they vary widely in terms of input measures recorded'],\n",
              " '18_rendering_graphics_gpu_splatting': ['Graphics processing on a graphics supercomputer',\n",
              "  'A display system for the Stellar graphics supercomputer model GS1000',\n",
              "  'The Truga001: A Scalable Rendering Processor',\n",
              "  'An efficient multi-resolution framework for high quality interactive rendering of massive point clouds using multi-way kd-trees',\n",
              "  'Optimized Pattern-Based Adaptive Mesh Refinement Using GPU',\n",
              "  'Optimized View-Dependent Rendering for Large Polygonal Datasets',\n",
              "  'Volume Rendering on a Distributed Memory Parallel Computer',\n",
              "  'Algorithms for rendering realistic terrain image sequences and their parallel implementation',\n",
              "  'A sorting classification of parallel rendering'],\n",
              " '19_mining_frequent_itemsets_rules': ['Bifold Constraint-Based Mining by Simultaneous Monotone and Anti-Monotone Checking',\n",
              "  'Optimizing Constraint-Based Mining by Automatically Relaxing Constraints',\n",
              "  'DualMiner: a dual-pruning algorithm for itemsets with constraints',\n",
              "  'CoLe: A Cooperative Data Mining Approach and Its Application to Early Diabetes Detection',\n",
              "  'MMAC: A New Multi-Class, Multi-Label Associative Classification Approach',\n",
              "  'Brute-Force Mining of High-Confidence Classification Rules'],\n",
              " '1_language_word_linguistic_lexical': ['The role of word-word co-occurrence in word learning',\n",
              "  'Interlocutors preserve complexity in language',\n",
              "  'Linguistic Structure Evolves to Match Meaning Structure',\n",
              "  'Eye-tracking situated language comprehension: Immediate actor gaze versus recent action events',\n",
              "  'Response direction and sentence-tense compatibility effects: An eye tracking study',\n",
              "  \"Visual attention during spatial language comprehension: Reference alone isn't enough\",\n",
              "  'Monsieur, azonnal k[SEP]Automatic localization of cultural resources and UIs is crucial for the survival of minority languages, for which there are insufficient parallel corpora (or no corpus at all) to build machine translation systems',\n",
              "  'Effects of machine translation on collaborative work',\n",
              "  'Machine translation vs'],\n",
              " '20_image_images_retrieval_recognition': ['A Strategy for Boundary Detection Combining Region and Edge Information',\n",
              "  'How to Complete Any Segmentation Process Interactively via Image Foresting Transform',\n",
              "  'Interactive Segmentation by Image Foresting Transform on Superpixel Graphs',\n",
              "  'Spatio-Temporal Frames in a Bag-of-Visual-Features Approach for Human Actions Recognition',\n",
              "  'A survey on activity recognition and behavior understanding in video surveillance',\n",
              "  'Online robust action recognition based on a hierarchical model',\n",
              "  'A co-boost framework for learning object categories from Google Images with 1st and 2nd order features',\n",
              "  'Fast Feature-Oriented Visual Connection for Large Image Collections',\n",
              "  'Delimitation of Regions of Interest in Similarity Queries Visualization',\n",
              "  'Computer-Aided Diagnosis in Brain Computed Tomography Screening',\n",
              "  'Effect of layer-wise fine-tuning in magnification-dependent classification of breast cancer histopathological image',\n",
              "  'Semi-supervised Tissue Segmentation of 3D Brain MR Images',\n",
              "  'Locality-Sensitive Hashing Scheme based on Longest Circular Co-Substring',\n",
              "  'PASE: PostgreSQL Ultra-High-Dimensional Approximate Nearest Neighbor Search Extension',\n",
              "  'A General and Efficient Querying Method for Learning to Hash'],\n",
              " '21_software_programmers_collaboration_developers': ['Variolite: Supporting Exploratory Programming by Data Scientists',\n",
              "  'Consistency maintenance in real-time collaborative graphics editing systems',\n",
              "  'DistEdit: A Distributed Toolkit for Supporting Multiple Group Editors',\n",
              "  'Elucidate: employing information visualisation to aid pedagogy for students',\n",
              "  'Viewing Object-Oriented Software with MetricAttitude: An Empirical Evaluation',\n",
              "  'Enhancing Software Visualization with Information Retrieval'],\n",
              " '22_brain_cognitive_attention_visual': ['Attentive and Pre-Attentive Processes in Multiple Object Tracking: A Computational Investigation',\n",
              "  'A Bayesian Model of the Effect of Object Context on Visual Attention',\n",
              "  'Inattentional Blindness in Visual Search',\n",
              "  'Learning and Variability in Spiking Neural Networks',\n",
              "  'Improving with Practice: A Neural Model of Mathematical Development',\n",
              "  'Thermodynamics and Cognition: Towards a Lawful Explanation of the Mind',\n",
              "  'This is your brain on interfaces: enhancing usability testing with functional near-infrared spectroscopy',\n",
              "  'Visualizing and manipulating brain dynamics',\n",
              "  'Examining the Reliability of Using fNIRS in Realistic HCI Settings for Spatial and Verbal Tasks',\n",
              "  'Eye-Trace: Segmentation of Volumetric Microscopy Images with Eyegaze',\n",
              "  'NeuroLines: A Subway Map Metaphor for Visualizing Nanoscale Neuronal Connectivity',\n",
              "  'The Neuron Navigator: Exploring the information pathway through the neural maze'],\n",
              " '23_trajectory_trajectories_mobility_urban': ['Visual Exploration of Sparse Traffic Trajectory Data',\n",
              "  'Evacuation trace Mini Challenge award: Tool integration analysis of movements with Geospatial Visual Analytics Toolkit',\n",
              "  'Migrant boat mini challenge award: Simple and effective integrated display geo-temporal analysis of migrant boats',\n",
              "  'Mining large-scale, sparse GPS traces for map inference: comparison of approaches',\n",
              "  'Traveling Salesman in Reverse: Conditional Markov Entropy for Trajectory Segmentation',\n",
              "  'CityMomentum: an online approach for crowd behavior prediction at a citywide level'],\n",
              " '24_graphics_graphic_standards_phigs': ['Object-Oriented Data Modelling for Graphics Databases: a Declarative Approach',\n",
              "  'GKS-9x: The Design Output Primitive, an Approach to a Specification',\n",
              "  'The Effectiveness of High-level Graphical Languages in Dealing with Various Graphical Domains',\n",
              "  'Preface',\n",
              "  'A Breezy Summer Read',\n",
              "  'Steps to Effective Business Graphics'],\n",
              " '25_series_time_patterns_mining': ['Dual-Domain Hierarchical Classification of Phonetic Time Series',\n",
              "  'Matrix Profile VIII: Domain Agnostic Online Semantic Segmentation at Superhuman Performance Levels',\n",
              "  'On the Stationarity of Multivariate Time Series for Correlation-Based Data Analysis',\n",
              "  'Sizing the horizon: the effects of chart size and layering on the graphical perception of time series visualizations',\n",
              "  'Visual-Interactive Preprocessing of Multivariate Time Series Data',\n",
              "  'Qualizon graphs: space-efficient time-series visualization with qualitative abstractions'],\n",
              " '26_fabrication_printing_print_manufacturing': ['Stress-Constrained Thickness Optimization for Shell Object Fabrication',\n",
              "  'Computational Design and Fabrication',\n",
              "  'Cost-effective printing of 3D objects with self-supporting property',\n",
              "  'TuVe: A Shape-changeable Display using Fluids in a Tube',\n",
              "  'Happy Moves, Sad Grooves: Using Theories of Biological Motion and Affect to Design Shape-Changing Interfaces',\n",
              "  'Understanding the Benefits and Drawbacks of Shape Change in Contrast or Addition to other Modalities',\n",
              "  'Instrumenting and Analyzing Fabrication Activities, Users, and Expertise',\n",
              "  'Automatics: Dynamically Generating Fabrication Tasks to Adapt to Varying Contexts',\n",
              "  \"Digital Fabrication Tools at Work: Probing Professionals' Current Needs and Desired Futures\"],\n",
              " '27_smart_activities_context_interfaces': ['Mixed-initiative conflict resolution for context-aware applications',\n",
              "  \"A user's perspective of design for context-awareness\",\n",
              "  'A goal-oriented interface to consumer electronics using planning and commonsense reasoning',\n",
              "  'Modelling internet based applications for designing multi-device adaptive interfaces',\n",
              "  'Robust Annotation of Mobile Application Interfaces in Methods for Accessibility Repair and Enhancement',\n",
              "  'Workshop W2: multi-user and ubiquitous user interfaces (MU3I 2006)',\n",
              "  \"The Upcycled Home: Removing Barriers to Lightweight Modification of the Home's Everyday Objects\",\n",
              "  'Alternative Avenues for IoT: Designing with Non-Stereotypical Homes',\n",
              "  'Making place for clutter and other ideas of home',\n",
              "  'Applications of mobile activity recognition',\n",
              "  'Learning from less for better: semi-supervised activity recognition via shared structure discovery',\n",
              "  'Supporting activity recognition by visual analytics'],\n",
              " '28_vessel_imaging_ultrasound_clinical': ['HIFUpm: a Visual Environment to Plan and Monitor High Intensity Focused Ultrasound Treatments',\n",
              "  '3D heart-vessel reconstruction from biplane angiograms',\n",
              "  'Automatic Transfer Function Specification for Visual Emphasis of Coronary Artery Plaque',\n",
              "  'Evolutionary Pathlines for Blood Flow Exploration in Cerebral Aneurysms',\n",
              "  'Illustration-Inspired Visualization of Blood Flow Dynamics',\n",
              "  'Occlusion-free Blood Flow Animation with Wall Thickness Visualization'],\n",
              " '29_texture_textures_synthesis_image': ['Texture Synthesis for Mobile Data Communications',\n",
              "  'Deterministic Texture Analysis and Synthesis Using Tree Structure Vector Quantization',\n",
              "  'Hidden message in a deformation-based texture',\n",
              "  'Application-Specific Tone Mapping Via Genetic Programming',\n",
              "  'A Tone Reproduction Operator for All Luminance Ranges Considering Human Color Perception',\n",
              "  'Style Aware Tone Expansion for HDR Displays'],\n",
              " '2_visualization_topic_visual_visualizations': ['Patterns for visualization evaluation',\n",
              "  'Metrics for measuring human interaction with interactive visualizations for information analysis',\n",
              "  'Learning-based evaluation of visual analytic systems',\n",
              "  'Text visualization techniques: Taxonomy, visual survey, and community insights',\n",
              "  'Visualizing the Performance of Computational Linguistics Algorithms',\n",
              "  'Quantity estimation in visualizations of tagged text',\n",
              "  'MetaLDA: A Topic Model that Efficiently Incorporates Meta Information',\n",
              "  'Discriminatively Enhanced Topic Models',\n",
              "  'Stochastic collapsed variational Bayesian inference for latent Dirichlet allocation'],\n",
              " '30_decision_choice_risk_risky': ['Bar-Gain Boxes: An Informative Illustration of the Pairing Problem',\n",
              "  'Context effects and risk amplification: Why more is risky',\n",
              "  \"How Does Prospect Theory Reflect Heuristics' Probability Sensitivity in Risky Choice?[SEP]Two prominent approaches to describing how people make decisions between risky options are algebraic models and heuristics\"],\n",
              " '31_weather_visualization_climate_ocean': ['User-defined feature comparison for vector field ensembles',\n",
              "  'Analysis of Decadal Climate Predictions with User-guided Hierarchical Ensemble Clustering',\n",
              "  'Extraction and Visual Analysis of Potential Vorticity Banners around the Alps',\n",
              "  'Exploratory Hierarchical Clustering for Management Zone Delineation in Precision Agriculture',\n",
              "  'Gaussian multiple instance learning approach for mapping the slums of the world using very high resolution imagery',\n",
              "  'Regression Models for Spatial Data: An Example from Precision Agriculture'],\n",
              " '32_ray_rays_traversal_rendering': ['Adaptive Ray Tracing of Subdivision Surfaces',\n",
              "  'Octree-R: An Adaptive Octree for Efficient Ray Tracing',\n",
              "  'Improved techniques for ray tracing parametric surfaces'],\n",
              " '33_twitter_tweets_media_sentiment': ['#Indigenous: Tracking the Connective Actions of Native American Advocates on Twitter',\n",
              "  'Thanks and tweets: comparing two public displays',\n",
              "  '(How) will the revolution be retweeted?: information diffusion and the 2011 Egyptian uprising',\n",
              "  'ScatterBlogs: Geo-spatial document analysis',\n",
              "  'TimeSets: Temporal Sensemaking in Intelligence Analysis',\n",
              "  'Can Twitter Save Lives? A Broad-Scale Study on Visual Social Media Analytics for Public Safety'],\n",
              " '34_creativity_painting_art_creative': ['Systematic Integration of Solution Elements: How Does Digital Creativity Support Change Group Dynamics?[SEP]In practice, most creativity techniques are still performed with traditional tools, such as pen and paper, whiteboards, and flipcharts',\n",
              "  'Understanding Creativity Methods in Design',\n",
              "  'What You See Is What You Get: The Impact of Visual Perceived Finishedness (PF) on Collaboration Comments during Electronic Idea Generation',\n",
              "  'The Best of Both Realities',\n",
              "  'Her Work Is All the Buzz',\n",
              "  'A Space to Dream',\n",
              "  'Image-Based Color Ink Diffusion Rendering',\n",
              "  'Pixel Art with Refracted Light by Rearrangeable Sticks',\n",
              "  'Artistic relighting of paintings and drawings'],\n",
              " '35_causal_beliefs_evidence_belief': ['Stable Causal Relationships are Better Causal Relationships',\n",
              "  'Informative Transitions: A Heuristic for Conditionalized Causal Strength Learning',\n",
              "  'Causal Reasoning with Continuous Outcomes'],\n",
              " '36_privacy_security_private_protection': ['Privacy Personas: Clustering Users via Attitudes and Behaviors toward Security Practices',\n",
              "  'Better the Devil You Know: Exposing the Data Sharing Practices of Smartphone Apps',\n",
              "  'Privacy as part of the app decision-making process',\n",
              "  'Maximum Likelihood Postprocessing for Differential Privacy under Consistency Constraints',\n",
              "  'Inference Analysis in Privacy-Preserving Data Re-publishing',\n",
              "  'Concentrated Differentially Private Gradient Descent with Adaptive per-Iteration Privacy Budget'],\n",
              " '37_urban_city_building_buildings': ['Staging Urban Interactions with Media Fa[SEP]Using media façades as a subcategory of urban computing, this paper contributes to the understanding of spatial interaction, sense-making, and social mediation as part of identifying key characteristics of interaction with media façades',\n",
              "  'Immersive Street-level Social Media in the 3D Virtual City: Anticipated User Experience and Conceptual Development',\n",
              "  'Projected Realities: Conceptual Design for Cultural Effect',\n",
              "  'A Survey of Urban Reconstruction',\n",
              "  'Generating 3D Building Models from Architectural Drawings: A Survey',\n",
              "  'Automatic Integration of Facade Textures into 3D Building Models with a Projective Geometry Based Line Clustering'],\n",
              " '38_transaction_transactions_concurrency_distributed': ['Efficient Concurrency Control for Broadcast Environments',\n",
              "  'Concepts for Transaction Recovery in Nested Transactions',\n",
              "  'Implementing Recoverable Requests Using Queues'],\n",
              " '39_displays_display_navigation_lenses': ['360° panoramic overviews for location-based services',\n",
              "  'Effects of display size and navigation type on a classification task',\n",
              "  'Wedge: clutter-free visualization of off-screen locations',\n",
              "  'Elastic windows: improved spatial layout and rapid multiple window operations',\n",
              "  'Copy-and-paste between overlapping windows',\n",
              "  'A window system with leafing through mode: BookWindow',\n",
              "  'ThinVR: Heterogeneous microlens arrays for compact, 180 degree FOV VR near-eye displays',\n",
              "  'Gaussian Light Field: Estimation of Viewpoint-Dependent Blur for Optical See-Through Head-Mounted Displays',\n",
              "  'A Survey of Calibration Methods for Optical See-Through Head-Mounted Displays',\n",
              "  'The Immersive Visualization Probe for Exploring n-Dimensional Spaces',\n",
              "  'Multidimensional virtual reality-MVR method: a new method of visualization of multidimensional worlds',\n",
              "  'ImAxes: Immersive Axes as Embodied Affordances for Interactive Multivariate Data Visualisation'],\n",
              " '3_recommendation_recommender_recommendations_users': ['Smart Pacing for Effective Online Ad Campaign Optimization',\n",
              "  'From 0',\n",
              "  'An Engagement-Based Customer Lifetime Value System for E-commerce'],\n",
              " '40_search_web_information_pages': ['Internet Search Roles of Adults in their Homes',\n",
              "  'Designing the Search Experience',\n",
              "  'Adaptive information search: age-dependent interactions between cognitive profiles and strategies',\n",
              "  'Exploring multi-session web tasks',\n",
              "  'Interest-Determining Web Browser',\n",
              "  'How do people find information on a familiar website?[SEP]Previous research has investigated how people either navigate the web as a whole, or find information on websites of which they have little previous knowledge',\n",
              "  'Freebase: a collaboratively created graph database for structuring human knowledge',\n",
              "  'Hybrid in-database inference for declarative information extraction',\n",
              "  'ONDUX: on-demand unsupervised learning for information extraction'],\n",
              " '41_category_categories_categorization_similarity': ['Similarity-based Ordering of Instances for Efficient Concept Learning',\n",
              "  'Models of Human Category Learning: Do they Generalize?[SEP]Generalization to new examples is an essential aspect of categorization',\n",
              "  'Perceptual Learning in Correlation Estimation: The Role of Learning Category Organization'],\n",
              " '42_crowdsourcing_workers_crowd_worker': ['Demonstration of Qurk: a query processor for humanoperators',\n",
              "  'CrowdFill: collecting structured data from the crowd',\n",
              "  'CrowdDQS: Dynamic Question Selection in Crowdsourcing Systems'],\n",
              " '43_patient_patients_care_clinical': ['Local-universality: designing EMR to support localized informal documentation practices',\n",
              "  'Accountability in an alarming environment',\n",
              "  'Documenting transitional information in EMR',\n",
              "  'Patient Subtyping via Time-Aware LSTM Networks',\n",
              "  'Dynamic Illness Severity Prediction via Multi-task RNNs for Intensive Care Unit',\n",
              "  'Multi-layer Representation Learning for Medical Concepts'],\n",
              " '44_diagrams_diagrammatic_diagram_logic': ['Aristotelian and Duality Relations Beyond the Square of Opposition',\n",
              "  'A Semiotic-Conceptual Analysis of Euler and Hasse Diagrams',\n",
              "  'Euler Diagrams for Defeasible Reasoning',\n",
              "  'The Diagram of Flow: Its Departure from Software Engineering and Its Return',\n",
              "  'Notations for Software Engineering Class Structures',\n",
              "  'Enhancing State-Space Tree Diagrams for Collaborative Problem Solving'],\n",
              " '45_color_colors_palette_palettes': ['Color, Change and Control for Quantitative Data Display',\n",
              "  'Examining Implicit Discretization in Spectral Schemes',\n",
              "  'Modeling Color Difference for Visualization Design'],\n",
              " '46_hci_design_research_practice': ['Metaprobes, Metaphysical Workshops and Sketchy Philosophy',\n",
              "  'From User-Centered to Adoption-Centered Design: A Case Study of an HCI Research Innovation Becoming a Product',\n",
              "  'Design Justice and User Interface Design'],\n",
              " '47_robot_robots_robotic_robotics': ['Museum guide robot based on sociological interaction analysis',\n",
              "  \"A Survey of Users' Expectations Towards On-body Companion Robots\",\n",
              "  'Authoring and Verifying Human-Robot Interactions'],\n",
              " '48_label_labels_unlabeled_classification': ['Active Learning from Multiple Noisy Labelers with Varied Costs',\n",
              "  'Neural Conditional Energy Models for Multi-label Classification',\n",
              "  'Inductive Semi-supervised Multi-Label Learning with Co-Training'],\n",
              " '49_keyboard_keyboards_touch_finger': ['Alphabetically constrained keypad designs for text entry on mobile devices',\n",
              "  'DualKey: Miniature Screen Text Entry via Finger Identification',\n",
              "  'Language modeling for soft keyboards'],\n",
              " '4_graph_graphs_network_networks': ['Discrete Overlapping Community Detection with Pseudo Supervision',\n",
              "  'Communities in Preference Networks: Refined Axioms and Beyond',\n",
              "  'Joint Community and Structural Hole Spanner Detection via Harmonic Modularity',\n",
              "  'Gragnostics: Fast, Interpretable Features for Comparing Graphs',\n",
              "  'Interactively Uncluttering Node Overlaps for Network Visualization',\n",
              "  'Multilayer graph edge bundling',\n",
              "  'Small MultiPiles: Piling Time to Explore Temporal Patterns in Dynamic Networks',\n",
              "  'Edge-stacked Timelines for Visualizing Dynamic Weighted Digraphs',\n",
              "  'Interactive Time-Series of Measures for Exploring Dynamic Networks',\n",
              "  'Denser than the densest subgraph: extracting optimal quasi-cliques with quality guarantees',\n",
              "  'Graph-Structured Sparse Optimization for Connected Subgraph Detection',\n",
              "  'Computing A Near-Maximum Independent Set in Linear Time by Reducing-Peeling',\n",
              "  'Quegel: A General-Purpose System for Querying Big Graphs',\n",
              "  'DUALSIM: Parallel Subgraph Enumeration in a Massive Graph on a Single Machine',\n",
              "  'GTS: A Fast and Scalable Graph Processing Method based on Streaming Topology to GPUs',\n",
              "  'Unsupervised Differentiable Multi-aspect Network Embedding',\n",
              "  'DEMO-Net: Degree-specific Graph Neural Networks for Node and Graph Classification',\n",
              "  'AM-GCN: Adaptive Multi-channel Graph Convolutional Networks',\n",
              "  'Consistency Meets Inconsistency: A Unified Graph Learning Framework for Multi-view Clustering',\n",
              "  'Dual active feature and sample selection for graph classification',\n",
              "  'Shortest-Path Kernels on Graphs'],\n",
              " '50_sketching_sketches_drawing_design': ['nuSketch battlespace: a demonstration',\n",
              "  'Getting Started with Sketch Tools',\n",
              "  'Exploring the Potential of an Intelligent Tutoring System for Sketching Fundamentals'],\n",
              " '51_facial_face_animation_faces': ['Bilinear interpolation for facial expression and metamorphosis in real-time animation',\n",
              "  'Transferring of Speech Movements from Video to 3D Face Space',\n",
              "  'Design, transformation and animation of human faces',\n",
              "  'Spatial pyramid face feature representation and weighted dissimilarity matching for improved face recognition',\n",
              "  'On the Learning of Deep Local Features for Robust Face Spoofing Detection',\n",
              "  'Analysis of the Eyes on Face Images for Compliance with ISO/ICAO Requirements'],\n",
              " '52_machine_fairness_deep_explanations': ['Chainer: A Deep Learning Framework for Accelerating the Research Cycle',\n",
              "  'The business impact of deep learning',\n",
              "  'Principles of Explanatory Debugging to Personalize Interactive Machine Learning'],\n",
              " '53_papers_conference_issue_editorial': ['ScreenCrayons: annotating anything',\n",
              "  'Reflowing digital ink annotations',\n",
              "  'The Breadth and Depth of E-reading and Paper-reading',\n",
              "  'Preface',\n",
              "  'VIS capstone address',\n",
              "  'Preface',\n",
              "  'A Survey of Topology-based Methods in Visualization',\n",
              "  \"Editor's Note [2013 Best Associate Editor Award  2013 Best Reviewer Award]\",\n",
              "  \"Guest Editors' Introduction: Special Section on the IEEE Pacific Visualization Symposium 2012\"],\n",
              " '54_heritage_museum_visitors_museums': ['Web3D representation and cultural heritage: from annotations to narrations',\n",
              "  'Unearthing Virtual History: Using Diverse Interfaces to Reveal Hidden Virtual Worlds',\n",
              "  'Making Place: Designing and Building an Engaging, Interactive and Pedagogical Historical World',\n",
              "  \"Visitors' Evaluations of ICTs Used in Cultural Heritage\",\n",
              "  'Digital Exhibit Labels in Museums: Promoting Visitor Engagement with Cultural Artifacts',\n",
              "  'Articulating Co-Design in Museums: Reflections on Two Participatory Processes',\n",
              "  'Innovative Digital Heuristic Approaches in Architectural Historical Research',\n",
              "  'Managing the real with the virtual: A role for digital media recording in archaeological fieldwork',\n",
              "  'A Repository for Heterogeneous and Complex Digital Cultural Objects'],\n",
              " '55_number_symbolic_magnitude_numbers': ['Magnitude Comparisons of Improper Fractions',\n",
              "  'Mathematical Model of Developmental Changes in Number Cognition',\n",
              "  'Are Fractions Natural Numbers, Too?[SEP]This study presents evidence in favor of a cognitive primitives hypothesis for processing fraction magnitudes'],\n",
              " '56_facebook_social_privacy_friends': ['\"Is it Weird to Still Be a Virgin\": Anonymous, Locally Targeted Questions on Facebook Confession Boards',\n",
              "  \"The post that wasn't: exploring self-censorship on facebook\",\n",
              "  'Techies Against Facebook: Understanding Negative Sentiment Toward Facebook via User Generated Content'],\n",
              " '57_influence_social_networks_network': ['Influence maximization: near-optimal time complexity meets practical efficiency',\n",
              "  'Minimizing seed set selection with probabilistic coverage guarantee in a social network',\n",
              "  'Effective Large-Scale Online Influence Maximization'],\n",
              " '58_walking_virtual_locomotion_reality': ['Velocity-Dependent Dynamic Curvature Gain for Redirected Walking',\n",
              "  'Virtual locomotion system for human-scale virtual environments',\n",
              "  '15 Years of Research on Redirected Walking in Immersive Virtual Environments'],\n",
              " '59_reality_augmented_virtual_interaction': ['Development of Adaptive Information Visualization Systems with Augmented Reality',\n",
              "  'Situated Visualization in The Decision Process Through Augmented Reality',\n",
              "  'Temporal Coherence Strategies for Augmented Reality Labeling',\n",
              "  'Message from the Paper Chairs and Guest Editors',\n",
              "  \"Guest Editors' Introduction: Virtual Reality\",\n",
              "  'Future scenarios of mixed reality: the INTUITION roadmap scenarios'],\n",
              " '5_shape_mesh_meshes_subdivision': ['Spectral compression of mesh geometry',\n",
              "  'Compressing Polygon Mesh Geometry with Parallelogram Prediction',\n",
              "  'Connectivity Compression for Three-Dimensional Planar Triangle Meshes',\n",
              "  'A Unified Interpolatory and Approximation sqrt-3 Subdivision Scheme',\n",
              "  'Quad/Triangle Subdivision',\n",
              "  'A New Interpolatory Subdivision for Quadrilateral Meshes',\n",
              "  'Planar Shape Interpolation Based On Teichm[SEP]Shape interpolation is a classical problem in computer graphics and has been widely investigated in the past two decades',\n",
              "  'Locally Injective Mappings',\n",
              "  'As-Rigid-As\\ue4f8Possible Distance Field Metamorphosis',\n",
              "  'Vega: Non-Linear FEM Deformable Object Simulator',\n",
              "  'Modal Warping: Real-Time Simulation of Large Rotational Deformation and Manipulation',\n",
              "  'Geometric Stiffness for Real-time Constrained Multibody Dynamics',\n",
              "  'Simplifying surfaces with color and texture using quadric error metrics',\n",
              "  'Locally Toleranced Surface Simplification',\n",
              "  'Coarse-to-fine surface simplification with geometric guarantees',\n",
              "  'Crest Lines for Surface Segmentation and Flattening',\n",
              "  'On stochastic methods for surface reconstruction',\n",
              "  'Applied Geometry: Discrete Differential Calculus for Graphics',\n",
              "  'One Point Isometric Matching with the Heat Kernel',\n",
              "  'Computing Teichm[SEP]Shape indexing, classification, and retrieval are fundamental problems in computer graphics',\n",
              "  'Bilateral Maps for Partial Matching'],\n",
              " '60_molecules_atoms_molecule_halos': ['Protein Tunnel Reprojection for Physico-Chemical Property Analysis',\n",
              "  'Comparative Visualization of Molecular Surfaces Using Deformable Models',\n",
              "  'CAVER Viewer - the explorer of behaviour of tunnels in proteins'],\n",
              " '61_memory_insight_solving_task': ['Constraints on Theories of Serial Order Memory Revisited: The Cases of the Fill-In and Protrusion Effects',\n",
              "  'The Primary and Convergent Retrieval Model of Recall',\n",
              "  \"Now I like it, now I don't: Delay effects and retrospective judgment\",\n",
              "  'Evaluating the Relationship Between Neuropsychological Function and Cognitive Performance',\n",
              "  'Using a Cognitive Model for an In-Depth Analysis of the Tower of London',\n",
              "  'A Mechanistic Account of Constraints on Control-Dependent Processing: Shared Representation, Conflict and Persistence'],\n",
              " '62_spline_splines_curves_cubic': ['Surface approximation to scanned data',\n",
              "  'A recursive evaluation algorithm for a class of Catmull-Rom splines',\n",
              "  'B-spline surfaces for ship hull design'],\n",
              " '63_clustering_clusters_cluster_clusterings': ['A robust and scalable clustering algorithm for mixed type attributes in large database environment',\n",
              "  'Foundations of Perturbation Robust Clustering',\n",
              "  'Scalable k -Means Clustering via Lightweight Coresets'],\n",
              " '64_impaired_visually_tactile_impairments': ['Design and user evaluation of a joystick-operated full-screen magnifier',\n",
              "  'Molder: An Accessible Design Tool for Tactile Maps',\n",
              "  'Towards a Multisensory Augmented Reality Map for Blind and Low Vision People: a Participatory Design Approach'],\n",
              " '65_distributed_parallel_scientific_convergence': ['Distributed computing: new power for scientific visualization',\n",
              "  'Visualizing Network Traffic to Understand the Performance of Massively Parallel Simulations',\n",
              "  'A Concurrent Architecture Proposal for Information Visualization Pipeline',\n",
              "  'A Weighted Aggregating SGD for Scalable Parallelization in Deep Learning',\n",
              "  'Large-scale distributed non-negative sparse coding and sparse dictionary learning',\n",
              "  'Parallelization with Multiplicative Algorithms for Big Data Mining'],\n",
              " '66_wikipedia_communities_community_newcomers': ['Impression formation in online peer production: activity traces and personal profiles in github',\n",
              "  'Community insights: helping community leaders enhance the value of enterprise online communities',\n",
              "  'SuggestBot: using intelligent task routing to help people find work in wikipedia'],\n",
              " '67_metaphors_metaphor_analogical_analogy': ['Spontaneous Analogy by Piggybacking on a Perceptual System',\n",
              "  'Generalizing relations during analogical problem solving in preschool children: does blocked or interleaved training improve performance?[SEP]Analogical reasoning, the mapping of structured relations across conceptual domains, is commonly recognized as essential to human cognition, but young children often perform poorly in the classical A:B::C:? analogical reasoning task',\n",
              "  'Analogy and Arithmetics: An HDTP-Based Model of the Calculation Circular Staircase',\n",
              "  'An Eye For Figurative Meaning: The Effects of Familiarity on Metaphor Comprehension',\n",
              "  'Formalizing the Pragmatics of Metaphor Understanding',\n",
              "  'Computing Humorous Metaphors'],\n",
              " '68_crowd_crowds_simulation_pedestrians': ['Improved Obstacle Relevancy, Distance, and Angle for Crowds Constrained to Arbitrary Manifolds in 3D Space',\n",
              "  'A Graphical Simulator for Modeling Complex Crowd Behaviors',\n",
              "  'Perceptual evaluation of maneuvering motion illusion for virtual pedestrians'],\n",
              " '69_conversational_dialogue_agent_conversation': ['Whose turn is it anyway? Same- and cross-person compound contributions in dialogue',\n",
              "  'The Role of Feedback in Aligning Perspectives in Referential Communication',\n",
              "  'Temporal Dynamics of Scan Patterns in Comprehension and Production',\n",
              "  'An Intelligent Assistant for High-Level Task Understanding',\n",
              "  '\"Do Animals Have Accents?\": Talking with Agents in Multi-Party Conversation',\n",
              "  'Iris: A Conversational Agent for Complex Tasks'],\n",
              " '6_game_games_sports_play': [\"Don't Talk Dirty to Me: How Sexist Beliefs Affect Experience in Sexist Games\",\n",
              "  'Why is This Happening to Me?: How Player Attribution can Broaden our Understanding of Player Experience',\n",
              "  'Negative Emotion, Positive Experience?: Emotionally Moving Moments in Digital Games',\n",
              "  'Exergame Training of Executive Function in Preschool Children: Generalizability and Long-term Effects',\n",
              "  'Exploring  designing tools to enhance falls rehabilitation in the home',\n",
              "  'Fitmersive Games: Fitness Gamification through Immersive VR',\n",
              "  'Chalkboarding: A New Spatiotemporal Query Paradigm for Sports Play Retrieval',\n",
              "  'Baseball Timeline: Summarizing Baseball Plays Into a Static Visualization',\n",
              "  'Sports Tournament Predictions Using Direct Manipulation',\n",
              "  'Usability Planner: A Tool to Support the Process of Selecting Usability Methods',\n",
              "  'Usability Evaluation in a Digitally Emerging Country: A Survey Study',\n",
              "  'Usability testing: what have we overlooked?[SEP]For more than a decade, the number of usability test participants has been a major theme of debate among usability practitioners and researchers keen to improve usability test performance'],\n",
              " '70_tracking_camera_tracker_pose': ['Projection Distortion-based Object Tracking in Shader Lamp Scenarios',\n",
              "  'Spatio-Temporal Point Path Analysis and Optimization of a Galvanoscopic Scanning Laser Projector',\n",
              "  'Robust upright adjustment of 360 spherical panoramas',\n",
              "  'Coupled-layer based visual tracking via adaptive kernelized correlation filters',\n",
              "  'Object tracking by color distribution fields with adaptive hierarchical structure',\n",
              "  'An improved correlation filter tracking method with occlusion and drift handling',\n",
              "  'A Backmapping Approach for Graph-Based Object Tracking',\n",
              "  'Automatic Detection of 2D Human Postures Based on Single Images',\n",
              "  'Robust motion flow for mesh tracking of freely moving actors'],\n",
              " '71_shadow_shadows_light_rendering': ['ShadowPix: Multiple Images from Self Shadowing',\n",
              "  'Exponential shadow maps',\n",
              "  'Generating soft shadows with a depth buffer algorithm'],\n",
              " '72_narrative_story_stories_storytelling': ['SceneSkim: Searching and Browsing Movies Using Synchronized Captions, Scripts and Plot Summaries',\n",
              "  'CSIUI 2009: story understanding and generation for aware and interactive interface design',\n",
              "  'Declarative Optimization-Based Drama Management in Interactive Fiction',\n",
              "  'More Than Telling a Story: Transforming Data into Visually Shared Stories',\n",
              "  'Formalizing Analytical Discourse in Visual Analytics',\n",
              "  'A Deeper Understanding of Sequence in Narrative Visualization'],\n",
              " '73_authentication_passwords_password_security': [\"Do Users' Perceptions of Password Security Match Reality?[SEP]Although many users create predictable passwords, the extent to which users realize these passwords are predictable is not well understood\",\n",
              "  'Age-related performance issues for PIN and face-based authentication systems',\n",
              "  'EpisoDAS: DAS-based password generation using episodic memories'],\n",
              " '74_students_math_solving_achievement': ['Patterns of anxiety in algebraic problem solving in Australian adolescents: A three-step latent variable analysis',\n",
              "  'Problem-Solving Strategy Selection in Relation to Formal Schooling',\n",
              "  'Study on Facilitation of Problem Posing by Learning Examples through Reproduction',\n",
              "  'Improving First-Year Writing Using Argument Diagramming',\n",
              "  \"Are Teachers Aware of Students' Lack of Spontaneity in Diagram Use? Suggestions from a Mathematical Model-Based Analysis of Teachers' Predictions\",\n",
              "  'The Effect of Graphical Format and Instruction on the Interpretation of Three-Variable Bar and Line Graphs'],\n",
              " '75_health_patients_self_online': ['Data, Data Everywhere, and Still Too Hard to Link: Insights from User Interactions with Diabetes Apps',\n",
              "  'Designing Self-tracking Devices for Vulnerable Chronic Ill',\n",
              "  'Findings of e-ESAS: a mobile based symptom monitoring system for breast cancer patients in rural Bangladesh',\n",
              "  'A Sociotechnical Mechanism for Online Support Provision',\n",
              "  'Forum77: An Analysis of an Online Health Forum Dedicated to Addiction Recovery',\n",
              "  'HutchWorld: clinical study of computer-mediated social support for cancer patients and their caregivers'],\n",
              " '76_route_map_navigation_wayfinding': ['How Spatial Ability and Stress Impact Escape Path',\n",
              "  'Constraints, Inferences, and the Shortest Path: Which paths do we prefer?[SEP]How do we reason about incomplete spatio-temporal descriptions? How might a map influence formerly constructed preferred mental models? Little research so far focused on a combination of two central fields important for successful route planning: the way humans deal with constraint based reasoning (especially with some sort of spatio-temporal constraints) and the way in which humans plan with a given map (especially with problems inspired by typical Traveling Salesman Problems)',\n",
              "  'The influence of structural salience and verbalisation on finding the return path',\n",
              "  'COPERNICUS: Context-Preserving Engine for Route Navigation with Interactive User-modifiable Scaling',\n",
              "  'Drawing Road Networks with Focus Regions',\n",
              "  'Designing and Annotating Metro Maps with Loop Lines'],\n",
              " '77_gene_genome_genomic_visualization': ['Visualizing virus population variability from next generation sequencing data',\n",
              "  'Interactive visual support for metagenomic contig binning',\n",
              "  'Visual analysis of next-generation sequencing data to detect overlapping genes in bacterial genomes'],\n",
              " '78_image_smoothing_denoising_inpainting': ['Two-level joint local laplacian texture filtering',\n",
              "  'Non-blind deblurring of structured images with geometric deformation',\n",
              "  'Fast high-quality non-blind deconvolution using sparse adaptive priors'],\n",
              " '79_construction_visualisation_building_heritage': ['Visual analysis method for cultural heritage site risk assessment',\n",
              "  'Applying 3D Dynamic Visualisation to (Palaeo) Geomorphic Reconstruction: Modelling a Tenth Century J[SEP]At Sólheimajökull glacier in southern Iceland, field evidence has been collected of a Tenth Century jökulhlaup (or glacial outburst flood)',\n",
              "  'Vis4Heritage: Visual Analytics Approach on Grotto Wall Painting Degradations'],\n",
              " '7_light_illumination_rendering_lighting': ['Unified Mathematical Model for Multilayer-Multiframe Compressive Light Field Displays Using LCDs',\n",
              "  'Polarization Demosaicking for Monochrome and Color Polarization Focal Plane Arrays',\n",
              "  'Depth of Field in Plenoptic Cameras',\n",
              "  'A Composite BRDF Model for Hazy Gloss',\n",
              "  'Improving the Selection of Bases of BRDFs for Appearance Preservation',\n",
              "  'Accurate fitting of measured reflectances using a Shifted Gamma micro-facet distribution'],\n",
              " '80_solid_solids_boundary_polyhedral': ['Set models and Boolean operations for solids and assemblies',\n",
              "  'Volume-Preserving Free-Form Solids',\n",
              "  'Eliminating redundant primitives from set-theoretic solid models by a consideration of constituents'],\n",
              " '81_electricity_households_heating_smart': ['Beyond demand management: the value of sharing electricity information',\n",
              "  'Comparative Feedback in the Street: Exposing Residential Energy Consumption on House Fa[SEP]This study investigates the impact of revealing the changes in daily residential energy consumption of individual households on their respective house faç ades',\n",
              "  'Studying always-on electricity feedback in the home'],\n",
              " '82_fractal_fractals_compression_chaos': ['Shape Approximation by a Fractal Model',\n",
              "  'Visualizing Chemical Kinetics in Fractal Domains',\n",
              "  'Transforming Fractals'],\n",
              " '83_memories_diary_life_everyday': ['Footprint tracker: supporting diary studies with lifelogging',\n",
              "  'Making love in the network closet: the benefits and work of family videochat',\n",
              "  'AutoTypography: what can physical mementos tell us about digital memories?[SEP]Current technology makes it possible to capture huge amounts of information related to everyday experiences'],\n",
              " '84_civic_civics_infrastructure_citizens': ['Shared values/conflicting logics: working around e-government systems',\n",
              "  'Civic Empowerment through Digitalisation: The Case of Greenlandic Women',\n",
              "  'From Creating Spaces for Civic Discourse to Creating Resources for Action'],\n",
              " '85_xml_query_xquery_queries': ['Holistic twig joins: optimal XML pattern matching',\n",
              "  \"Colorful XML: One Hierarchy Isn't Enough\",\n",
              "  'On Boosting Holism in XML Twig Pattern Matching using Structural Indexing Techniques'],\n",
              " '86_moral_dilemmas_judgment_harm': ['Priming Effects of Religious Concepts on Moral Judgment: Between Mean Values and Variation',\n",
              "  \"Apparent Paradoxes in Moral Reasoning; Or how you forced him to do it, even though he wasn't forced to do it\",\n",
              "  'Mental states are more important in evaluating moral than conventional violations'],\n",
              " '87_volume_volumetric_rendering_opacity': ['Dataset Traversal with Motion-Controlled Transfer Functions',\n",
              "  'ViSizer: A Visualization Resizing Framework',\n",
              "  'Opacity Optimization for Surfaces'],\n",
              " '88_pointing_target_movement_targets': ['Control Theoretic Models of Pointing',\n",
              "  'Modeling the Endpoint Uncertainty in Crossing-based Moving Target Selection',\n",
              "  'A probabilistic approach to modeling two-dimensional pointing'],\n",
              " '89_indoor_location_positioning_rfid': ['A New Method for Auto-calibrated Object Tracking',\n",
              "  'Wideband powerline positioning for indoor localization',\n",
              "  'A Probabilistic Room Location Service for Wireless Networked Environments'],\n",
              " '8_database_query_queries_join': ['Synthesizing Type-Detection Logic for Rich Semantic Data Types using Open-source Code',\n",
              "  'A New Characterization of Independence',\n",
              "  'Efficient and Extensible Algorithms for Multi Query Optimization',\n",
              "  'Leveraging compression in the tableau data engine',\n",
              "  'ByteSlice: Pushing the Envelop of Main Memory Data Processing with a New Storage Layout',\n",
              "  'A Padded Encoding Scheme to Accelerate Scans by Leveraging Skew',\n",
              "  'Secondary-storage confidence computation for conjunctive queries with inequalities',\n",
              "  'A Query Engine for Probabilistic Preferences',\n",
              "  'US-SQL: managing uncertain schemata',\n",
              "  'High-Performance Geospatial Analytics in HyPerSpace',\n",
              "  'Incremental Distance Join Algorithms for Spatial Databases',\n",
              "  'STAR: A Distributed Stream Warehouse System for Spatial Data'],\n",
              " '90_diffusion_tensor_tracts_brain': ['Case Study: Reconstruction, Visualization, and Quantification of Neuronal Fiber Pathways',\n",
              "  'Topological Visualization of Brain Diffusion MRI Data',\n",
              "  'Visualizing crossing probabilistic tracts'],\n",
              " '91_ontology_schema_ontologies_schemas': ['Statistical Schema Matching across Web Query Interfaces',\n",
              "  'JSON Schema Matching: Empirical Observations',\n",
              "  'SourceSight: Enabling Effective Source Selection',\n",
              "  'Visualizing Conceptual Relations in Legal Terminology',\n",
              "  'A Visualisation Approach for Collaborative Planning Systems Based on Ontologies',\n",
              "  'User-Friendly Ontology Editing and Visualization Tools: The OWLeasyViz Approach'],\n",
              " '92_email_emails_mail_inbox': ['Going with the flow: email awareness and task management',\n",
              "  'Overload is overloaded: email in the age of Gmail',\n",
              "  'Revisiting Whittaker  Sidner\\'s \"email overload\" ten years later'],\n",
              " '93_security_traffic_cyber_intrusion': ['BubbleNet: A Cyber Security Dashboard for Visualizing Patterns',\n",
              "  'situ: Situational understanding and discovery for cyber attacks',\n",
              "  'Weaving a carpet from log entries: A network security visualization built with co-creation'],\n",
              " '94_outlier_outliers_datasets_distance': ['Human-in-the-loop Outlier Detection',\n",
              "  'Angle-based outlier detection in high-dimensional data',\n",
              "  'Online Outlier Exploration Over Large Datasets'],\n",
              " '95_video_videos_frames_temporal': ['CoSummary: adaptive fast-forwarding for surgical videos by detecting collaborative scenes using hand regions and gaze positions',\n",
              "  'Temporal Magic Lens: Combined Spatial and Temporal Query and Presentation',\n",
              "  'SmartPlayer: user-centric video fast-forwarding'],\n",
              " '96_tree_trees_plant_plants': ['A Visualization Tool for Studying the Development of the Moss Physcomitrella patens',\n",
              "  'Data-Driven Synthetic Modeling of Trees',\n",
              "  'Interactive Design of Bonsai Tree Models'],\n",
              " '97_entity_entities_name_disambiguation': ['Automatic Entity Recognition and Typing in Massive Text Data',\n",
              "  'Robust Entity Resolution using Random Graphs',\n",
              "  'Entity Resolution with Markov Logic'],\n",
              " '98_interruptions_interruption_interruptibility_task': ['Investigating interruptions in the context of computerised cognitive testing for older adults',\n",
              "  'Interruptibility of Software Developers and its Prediction Using Psycho-Physiological Sensors',\n",
              "  'The effects of time constraints on user behavior for deferrable interruptions'],\n",
              " '99_coordination_interpersonal_synchrony_actions': ['Interpersonal Coordination of Perception and Memory in Real-Time Online Social Interaction',\n",
              "  'Facilitating interpersonal action coordination in a movement control task',\n",
              "  'Synchronizing to Learn and Like'],\n",
              " '9_dimensional_visualization_multidimensional_scatterplots': ['SADIRE: a context-preserving sampling technique for dimensionality reduction visualizations',\n",
              "  'Role of Human Perception in Cluster-based Visual Analysis of Multidimensional Data Projections',\n",
              "  'Voronoi Diagram Based Dimensional Anchor Assessment for Radial Visualizations']}"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IitafsV9bU1k",
        "outputId": "2cbdae14-bebe-48fb-ccc7-d8fdfb932370"
      },
      "source": [
        "!pip install json"
      ],
      "execution_count": 118,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement json (from versions: none)\u001b[0m\n",
            "\u001b[31mERROR: No matching distribution found for json\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 198
        },
        "id": "cSSt3tpxbSf0",
        "outputId": "9c63a6f8-b360-4dea-c6b6-d02039bbad94"
      },
      "source": [
        "import json\n",
        "\n",
        "outpath = 'out.json'\n",
        "with open(outpath, \"w\") as f:\n",
        "    f.write(json.dumps(repre_list))\n"
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-123-46252031200a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"w\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepre_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0moutpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'str' object has no attribute 'close'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GEwUaMYlkJ0D",
        "outputId": "afc8022e-9f5d-44f6-88e6-e7cb6d06d399"
      },
      "source": [
        "!ls"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "drive  final_model  out.json  repre_list.json  sample_data  topic_model\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "KTAkJ9BMf904",
        "outputId": "80d5c092-b878-4445-9979-bba3f8edbb96"
      },
      "source": [
        "import shutil\n",
        "shutil.move(\"repre_list.json\", \"/content/drive/My Drive/vitaLITy/\")"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/My Drive/vitaLITy/repre_list.json'"
            ]
          },
          "metadata": {},
          "execution_count": 132
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "id": "PXv7dR9lev9d",
        "outputId": "938bb345-0566-4cc9-b7ad-08b823246c66"
      },
      "source": [
        "json.dump(repre_list, open( \"/content/drive/repre_list.json\", 'w' ) )"
      ],
      "execution_count": 126,
      "outputs": [
        {
          "output_type": "error",
          "ename": "OSError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-126-af5ace3e734e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrepre_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m\"/content/drive/repre_list.json\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'w'\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mOSError\u001b[0m: [Errno 95] Operation not supported: '/content/drive/repre_list.json'"
          ]
        }
      ]
    }
  ]
}